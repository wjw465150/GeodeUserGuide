{"./":{"url":"./","title":"前言","keywords":"","body":"GeodeUserGuideApache Geode的主要特点GeodeUserGuide Geode User Guide 中文翻译版本! 生成的文档在这里:GeodeUserGuide中文版 Apache Geode是一个数据管理平台，可在广泛分布的云架构中提供对数据密集型应用程序的实时，一致的访问。 Geode跨多个进程汇集内存，CPU，网络资源和可选的本地磁盘，以管理应用程序对象和行为。 它使用动态复制和数据分区技术来实现高可用性，改进的性能，可伸缩性和容错性。 除了作为分布式数据容器之外，Geode还是一个内存数据管理系统，可提供可靠的异步事件通知和有保证的消息传递。 Apache Geode的主要特点 本节总结了主要功能和主要功能。 高读写吞吐量 低且可预测的延迟 高可扩展性 持续可用性 可靠的事件通知 数据存储上的并行应用程序行为 无共享磁盘持久性 降低拥有成本 客户/服务器的单跳能力 客户/服务器安全 多站点数据分布 连续查询 异构数据共享 Copyright © WS 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-02-18 14:15:27 "},"Geode_1_Getting_Started_with_Apache_Geode.html":{"url":"Geode_1_Getting_Started_with_Apache_Geode.html","title":"Apache Geode入门","keywords":"","body":"Apache Geode文档Apache Geode入门关于 Apache Apache Geode的主要特点 先决条件和安装说明主机要求如何安装设置CLASSPATH 如何卸载Apache Geode在15分钟或更短时间内完成 Apache Geode文档 本文档介绍了产品概念，并提供了Apache Geode 1.7的完整设置说明。 源文件可从Apache Geode Github存储库获得，有关如何构建此文档的说明如下： 可在[Geode项目自述文件]中找到(../../../../ github.com/apache/geode/blob/develop/geode-book/README.md)。 (../../../../cwiki.apache.org/confluence/display/GEODE/Index).您还可以在Apache Geode Wiki上找到有关Geode的其他文档。 [TOC] Apache Geode入门 教程演示了功能，主要功能部分介绍了主要功能。 关于Apache Apache Geode是一个数据管理平台，可在广泛分布的云架构中提供对数据密集型应用程序的实时，一致的访问。 Apache Geode的主要特点 本节总结了Apache Geode的主要功能和主要功能。 先决条件和安装说明 满足一小部分先决条件的每个Apache Geode主机都可以遵循提供的安装说明。 Apache Geode在15分钟或更短时间内完成 需要快速介绍Apache Geode？ 参加这个简短的游览，尝试基本功能。 关于 Apache Apache Geode是一个数据管理平台，可在广泛分布的云架构中提供对数据密集型应用程序的实时，一致的访问。 Geode跨多个进程汇集内存，CPU，网络资源和可选的本地磁盘，以管理应用程序对象和行为。 它使用动态复制和数据分区技术来实现高可用性，改进的性能，可伸缩性和容错性。 除了作为分布式数据容器之外，Geode还是一个内存数据管理系统，可提供可靠的异步事件通知和有保证的消息传递。 主要概念和组件 Caches是描述Geode集群中节点的抽象。 应用程序架构师可以在peer-to-peer或client/server拓扑中安排这些节点。 在每个缓存中，您可以定义数据regions。 数据区域类似于关系数据库中的表，并以分布式方式管理数据作为name/value对。一个replicated区域在集群的每个缓存成员上存储相同的数据副本。一个partitioned区域在缓存成员之间传播数据。配置系统后，客户端应用程序可以在不了解底层系统体系结构的情况下访问区域中的分布式数据。 您可以定义侦听器以创建有关数据何时更改的通知，并且可以定义到期条件以删除区域中的过时数据。 对于大型生产系统，Geode提供locators。 定位器提供发现和负载平衡服务。 使用定位器服务列表配置客户端，定位器维护成员服务器的动态列表。 默认情况下，Geode客户端和服务器使用端口40404相互发现。 有关产品功能的更多信息，请参阅 Apache Geode的主要特点. Apache Geode的主要特点 本节总结了主要功能和主要功能。 高读写吞吐量 低且可预测的延迟 高可扩展性 持续可用性 可靠的事件通知 数据存储上的并行应用程序行为 无共享磁盘持久性 降低拥有成本 客户/服务器的单跳能力 客户/服务器安全 多站点数据分布 连续查询 异构数据共享 高读写吞吐量 读写吞吐量由并发主存储器数据结构和高度优化的分发基础结构提供。 应用程序可以通过同步或异步复制在内存中动态复制数据，以实现高读取吞吐量，或者跨多个系统成员对数据进行分区，以实现高读写吞吐量。 如果数据访问在整个数据集中相当平衡，则数据分区会使聚合吞吐量翻倍。 吞吐量的线性增加仅受骨干网容量的限制。 低且可预测的延迟 优化的缓存层最大限度地减少了线程和进程之间的上下文切换。 它管理高度并发结构中的数据，以最大限度地减少争用点。 如果接收器可以跟上，则与对等成员的通信是同步的，这使得数据分发的延迟保持最小。 服务器以序列化形式管理对象图，以减少垃圾收集器的压力。 订阅管理（兴趣注册和连续查询）跨服务器数据存储进行分区，确保仅为所有感兴趣的客户端处理订阅一次。 由此带来的CPU使用和带宽利用率的提高可提高吞吐量并减少客户端订阅的延迟。 高可扩展性 通过跨多个成员动态分区数据并在服务器之间统一分布数据来实现可伸缩性。 对于“热”数据，您可以将系统配置为动态扩展以创建更多数据副本。 您还可以将应用程序行为设置为以接近所需数据的分布式方式运行。 如果您需要支持高且不可预测的并发客户端负载突发，您可以增加管理数据的服务器数量，并在其中分配数据和行为，以提供统一且可预测的响应时间。 客户端根据服务器在其负载条件下的持续反馈，不断对服务器场进行负载均衡。 通过跨服务器分区和复制数据，客户端可以动态移动到不同的服务器，以统一加载服务器并提供最佳响应时间。 您还可以通过实现对外部数据存储（如数据库）的数据更改的异步“write behind后写”来提高可伸缩性。 这可以通过按顺序冗余排队所有更新来避免瓶颈。 您还可以混合更新并将它们批量传播到数据库。 持续可用性 除了保证内存中数据的一致性副本之外，应用程序还可以通过使用“无共享磁盘体系结构”将数据同步或异步地保存在一个或多个成员的磁盘上。所有异步事件（存储转发事件）至少是冗余管理的 两个成员，如果一个服务器发生故障，冗余的服务器将接管。 所有客户端都连接到逻辑服务器，并且客户端在故障期间或服务器无响应时自动故障转移到组中的备用服务器。 可靠的事件通知 发布/订阅系统提供数据分发服务，其中新事件被发布到系统中并以可靠的方式路由到所有感兴趣的订户。 传统的消息传递平台专注于消息传递，但接收应用程序通常需要在处理事件之前访问相关数据。 这要求他们在事件传递时访问标准数据库，以数据库的速度限制订阅者。 数据和事件通过单一系统提供。 数据作为一个或多个分布式数据区域中的对象进行管理，类似于数据库中的表。 应用程序只需在数据区域中插入，更新或删除对象，平台就会将对象更改传递给订阅者。 接收事件的订户可以直接访问本地存储器中的相关数据，或者可以通过单跳从其他成员之一获取数据。 数据存储上的并行应用程序行为 您可以在成员上并行执行应用程序业务逻辑。 数据感知功能执行服务允许在成员上执行任意的，依赖于数据的应用程序功能，其中数据被分区以用于参考和缩放的位置。 通过并置相关数据并并行化计算，可以提高整体吞吐量。 计算延迟与可以并行化的成员数成反比。 基本前提是将功能透明地路由到承载功能所需的数据子集的应用程序，并避免在网络上移动数据。 应用程序功能只能在一个成员上执行，在成员子集上并行执行，或在所有成员上并行执行。 此编程模型类似于Google的流行Map-Reduce模型。 数据感知功能路由最适合需要迭代多个数据项的应用程序（例如查询或自定义聚合功能）。 无共享磁盘持久性 每个集群成员独立于其他成员管理磁盘文件上的数据。 一个成员中的磁盘故障或缓存故障不会影响另一个缓存实例在其磁盘文件上安全运行的能力。 这种“无共享”持久性体系结构允许对应用程序进行配置，使得不同类别的数据持久保存在整个系统的不同成员上，即使为应用程序对象配置了磁盘持久性，也会显着提高应用程序的整体吞吐量。 与传统数据库系统不同，单独的文件不用于管理数据和事务日志。 所有数据更新都附加到与传统数据库的事务日志类似的文件中。 如果磁盘未被其他进程同时使用，则可以避免磁盘寻道时间，并且唯一的成本是旋转延迟。 降低拥有成本 您可以在层中配置缓存。 客户端应用程序进程可以在本地（在内存中并溢出到磁盘）托管缓存，并在未命中时委托给缓存服务器场。 即使本地缓存的命中率达到30％，也可以显著节省成本。 与每个事务相关的总成本来自CPU周期花费，网络成本，对数据库的访问以及与数据库维护相关的无形成本。 通过将数据作为应用程序对象进行管理，可以避免与将SQL行映射到对象相关联的额外成本（CPU周期）。 客户/服务器的单跳能力 客户端可以将单个数据请求直接发送到持有数据key的服务器，从而避免多跳以定位已分区的数据。 客户端中的元数据标识正确的服务器。 此功能可提高服务器层中分区区域的性能和客户端访问权限。 客户/服务器安全 客户端应用程序中可能有多个不同的用户。 此功能适用于客户端嵌入应用程序服务器的安装，每个应用程序服务器都支持来自许多用户的数据请求。 每个用户可能被授权访问服务器上的一小部分数据，如在客户应用程序中，其中每个客户只能访问他们自己的订单和货件。 客户端中的每个用户都使用自己的一组凭据连接到服务器，并拥有自己对服务器缓存的访问权限。 多站点数据分布 数据站点在地理上分布在广域网（WAN）上可能导致可伸缩性问题。 模型可以解决这些拓扑问题，从单个对等集群到WAN上数据中心之间的可靠通信。 此模型允许集群以无限且松散耦合的方式扩展，而不会降低性能，可靠性或数据一致性。 该体系结构的核心是用于将区域事件分发到远程站点的网关发送器配置。 您可以并行部署网关发送方实例，从而增加通过WAN分发区域事件的吞吐量。 您还可以配置网关发件人队列以实现持久性和高可用性，以避免在成员发生故障时丢失数据。 连续查询 在Java Message Service等消息传递系统中，客户端订阅主题和队列。 传递给主题的任何消息都将发送给订阅者。 Geode允许通过使用对象查询语言使应用程序表达复杂的兴趣来进行连续查询。 异构数据共享 C＃，C ++和Java应用程序可以共享应用程序业务对象，而无需通过SOAP或XML等转换层。 服务器端行为虽然是用Java实现的，但它为C ++和.NET应用程序提供了唯一的本机缓存。 可以在C ++进程堆中管理应用程序对象，并使用对象的常见“线上”表示将其分发到其他进程。 C ++序列化对象可以直接反序列化为等效的Java或C＃对象。 使用一种语言更改业务对象可以在使用其他支持的语言编写的应用程序中触发可靠的通知。 先决条件和安装说明 满足一小部分先决条件的每个Apache Geode主机都可以遵循提供的安装说明。 主机要求 主机必须满足Apache Geode的一系列要求。 如何安装 从源代码构建或使用ZIP或TAR发行版在将运行Apache Geode的每台物理和虚拟机上安装Apache Geode。 设置CLASSPATH 本主题描述了Geode进程如何设置其CLASSPATH。 如何卸载 本节介绍如何删除Geode。 主机要求 主机必须满足Apache Geode的一系列要求。 每台运行Apache Geode的计算机都必须满足以下要求： Java SE Development Kit 8 with update 121 or a more recent version 8 update. 系统时钟设置为正确的时间和时间同步服务，如网络时间协议（NTP）。 正确的时间戳允许以下活动： 对故障排除有用的日志。 同步时间戳确保可以合并来自不同主机的日志消息，以重现分布式运行的准确时间历史记录。 汇总产品级别和应用程序级别的时间统计信息。 使用脚本和其他工具准确监控Geode系统，这些工具可读取系统统计信息和日志文件。 已为计算机正确配置主机名和主机文件。 主机名和主机文件配置可能会影响gfsh和Pulse功能。 禁用TCP SYN cookie。 大多数默认Linux安装使用SYN cookie来保护系统免受泛滥TCP SYN数据包的恶意攻击，但此功能与稳定和繁忙的Geode集群不兼容。 安全实现应该通过将Geode服务器集群置于高级防火墙保护之下来寻求防止攻击。 要永久禁用SYN cookie： 编辑/etc/sysctl.conf文件以包含以下行： net.ipv4.tcp_syncookies = 0 将此值设置为零将禁用SYN Cookie。 重新加载sysctl.conf： sysctl -p 有关详细信息，请参阅禁用TCP SYN Cookie。 如何安装 从源代码构建或使用ZIP或TAR发行版在将运行Apache Geode的每台物理和虚拟机上安装Apache Geode。 在Unix上从Source构建 设置JAVA_HOME环境变量。 JAVA_HOME=/usr/java/jdk1.8.0_121 export JAVA_HOME 从http://geode.apache.org上的Releases页面下载项目源代码，然后解压缩源代码。 在包含解压缩源代码的目录中，无需测试即可构建： $ ./gradlew build -Dskip.tests=true 或者，使用测试构建： $ ./gradlew build 通过调用gfsh来打印版本信息并退出来验证安装。 在Linux/Unix平台上，版本类似于： $ cd geode-assembly/build/install/apache-geode $ bin/gfsh version v1.1.0 在Windows上从源代码构建 设置JAVA_HOME环境变量。 例如： $ set JAVA_HOME=\"C:\\Program Files\\Java\\jdk1.8.0_121\" 安装Gradle，版本2.3或更新版本。 从http://geode.apache.org上的Releases页面下载项目源代码，然后解压缩源代码。 在包含解压缩源代码的文件夹中，不使用测试进行构建： $ gradle build -Dskip.tests=true 或者，使用测试构建： $ gradle build 通过调用gfsh来打印版本信息并退出来验证安装。 $ cd geode-assembly\\build\\install\\apache-geode\\bin $ gfsh.bat version v1.1.0 从.zip或.tar文件安装二进制文件 从http://geode.apache.org上的Releases页面下载.zip或.tar文件。 解压缩.zip文件或展开.tar文件，其中path_to_product是绝对路径，文件名因版本号而异。 对于.zip格式： $ unzip apache-geode-1.1.0.zip -d path_to_product 对于.tar格式： $ tar -xvf apache-geode-1.1.0.tar -C path_to_product 设置JAVA_HOME环境变量。 在Linux / Unix平台上： JAVA_HOME=/usr/java/jdk1.8.0_121 export JAVA_HOME 在Windows平台上： set JAVA_HOME=\"C:\\Program Files\\Java\\jdk1.8.0_121\" 将Geode脚本添加到PATH环境变量中。 在Linux/Unix平台上： PATH=$PATH:$JAVA_HOME/bin:path_to_product/bin export PATH 在Windows平台上： set PATH=%PATH%;%JAVA_HOME%\\bin;path_to_product\\bin 要验证安装，请在命令行键入gfsh version，并注意输出列出已安装的Geode版本。 例如： $ gfsh version v1.1.0 有关更详细的版本信息，例如构建日期，内部版本号和正在使用的JDK版本，请调用： $ gfsh version --full 设置CLASSPATH 本主题描述了Geode进程如何设置其CLASSPATH。 为了简化CLASSPATH环境设置，Geode将Geode进程所需的所有应用程序库组织成* -dependencies.jar文件。 所有依赖项JAR文件都位于path_to_product/lib目录中。 使用gfsh启动服务器或定位器进程时，应用程序JAR文件会自动从两个目录加载到进程的CLASSPATH中： path_to_product/lib/ path_to_product/extensions/ 注意： 要在应用程序中嵌入Geode，请将path_to_product/lib/geode-dependencies.jar添加到CLASSPATH中。 下表列出了与各种Geode进程关联的依赖项JAR文件： Geode Process Associated JAR Files gfsh gfsh-dependencies.jar server and locator geode-dependencies.jarNote:Use this library for all standalone or embedded Geode processes (including Java clients) that host cache data. 在gfsh管理的进程中修改CLASSPATH 有两个选项可用于更新geode服务器的CLASSPATH和在gfsh命令行上启动的定位器进程。 选项1： 在进程启动时指定--classpath参数。 例如，要修改定位器的CLASSPATH： gfsh> start locator --name=locator1 --classpath=/path/to/applications/classes.jar 并修改服务器的CLASSPATH： gfsh> start server --name=server1 --classpath=/path/to/applications/classes.jar 作为--classpath选项的参数提供的应用程序类是prepended到服务器或定位器的CLASSPATH，从第二个位置开始。 出于安全原因，CLASSPATH中的第一个条目保留用于核心Geode jar文件。 选项 2: 在OS环境中定义CLASSPATH环境变量。 然后，在进程启动时指定--include-system-classpath参数。 例如： gfsh> start locator --name=locator1 --include-system-classpath=true 服务器进程也可以这样做： gfsh> start server --name=server1 --include-system-classpath=true 此选项在启动时将系统CLASSPATH环境变量的内容附加到定位器或服务器的CLASSPATH。 在没有值的情况下指定此选项会将其设置为true。 为应用程序和独立Java进程设置CLASSPATH 如果以编程方式（独立或嵌入式）启动Geode进程，我们建议您在程序执行时使用java -classpath或java -cpcommand-line选项指定CLASSPATH。 此方法首选将CLASSPATH设置为环境变量，因为它允许您为每个应用程序单独设置值，而不会影响其他应用程序，也不会修改其值的其他应用程序。 例如，要使用LocatorLauncher API启动Geode定位器进程，可以在命令行上执行以下命令： prompt# java -cp \"path_to_product/lib/geode-dependencies.jar\" org.apache.geode.distributed.LocatorLauncher start locator1 要使用ServerLauncher API启动Geode服务器进程，请执行以下操作： prompt# java -cp \"path_to_product/lib/geode-dependencies.jar:/path/to/your/applications/classes.jar\" org.apache.geode.distributed.ServerLauncher start server1 请注意，除了与进程关联的* -dependencies.jar文件之外，还必须指定要在Geode进程中访问的任何自定义应用程序JAR。 例如，如果您计划在区域上使用自定义压缩器，则应指定包含要使用的压缩器应用程序的应用程序JAR。 要使用嵌入式缓存启动应用程序： java -cp \"path_to_product/lib/geode-dependencies.jar:/path/to/your/applications/classes.jar\" com.mycompany.package.ApplicationWithEmbeddedCache 注意: 使用您自己的应用程序更新服务器进程的CLASSPATH的另一种方法是使用gfsh deploy命令。 部署应用程序JAR文件将自动更新所有部署目标成员的CLASSPATH。有关详细信息，请参阅将应用程序JAR部署到Apache Geode成员。 如何卸载 本节介绍如何删除Geode。 关闭所有正在运行的Geode进程，然后删除整个目录树。 不需要对Windows注册表项进行其他系统修改或修改。 Apache Geode在15分钟或更短时间内完成 需要快速介绍Apache Geode？ 参加这个简短的游览，尝试基本功能。 步骤 1: 安装Apache Geode 有关说明，请参见如何安装. 步骤 2: 使用gfsh启动定位器 在终端窗口中，使用gfsh命令行界面启动定位器。 Apache Geode gfsh(发音为“jee-fish”)提供了一个直观的命令行界面，您可以从中启动，管理和监控Apache Geode流程，数据和应用程序。 见gfsh。 locator是一个Geode进程，它告诉运行成员所在的新连接成员，并为服务器使用提供负载均衡。 默认情况下，定位器启动JMX Manager，该管理器用于监视和管理Geode集群。 集群配置服务使用定位器将集群配置保留并分发到集群成员。参见 运行Geode定位器进程 和 集群配置服务概述. 创建一个临时工作目录（例如my_geode）和将目录切换到它。 gfsh在此位置保存定位器和服务器工作目录和日志文件。 通过在命令行键入gfsh来启动gfsh(如果使用的是Windows，则输入gfsh.bat)。 _________________________ __ / _____/ ______/ ______/ /____/ / / / __/ /___ /_____ / _____ / / /__/ / ____/ _____/ / / / / /______/_/ /______/_/ /_/ 1.7 Monitor and Manage Geode gfsh> 在gfsh提示符下，键入start locator命令并指定定位符的名称： gfsh>start locator --name=locator1 Starting a Geode Locator in /home/username/my_geode/locator1... ................................. Locator in /home/username/my_geode/locator1 on ubuntu.local[10334] as locator1 is currently online. Process ID: 3529 Uptime: 18 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /home/username/my_geode/locator1/locator1.log JVM Arguments: -Dgemfire.enable-cluster-configuration=true -Dgemfire.load-cluster-configuration-from-dir=false -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /home/username/Apache_Geode_Linux/lib/geode-core-1.0.0.jar: /home/username/Apache_Geode_Linux/lib/geode-dependencies.jar Successfully connected to: JMX Manager [host=10.118.33.169, port=1099] Cluster configuration service is up and running. 如果从gfsh运行start locator而不指定成员名称，gfsh将自动选择一个随机成员名称。 这对自动化很有用。 步骤 3: 启动`Pulse` 启动基于浏览器的Pulse监控工具。 Pulse是一个Web应用程序，它提供了一个图形仪表板，用于监视Geode集群，成员和区域的重要实时运行状况和性能。 请参阅Geode Pulse。 gfsh>start pulse 此命令启动Pulse并自动将您连接到定位器中运行的JMX Manager。 在Pulse登录界面，输入默认用户名admin和密码admin。 Pulse应用程序现在显示刚刚启动的定位器(locator1)： 步骤 4: 启动一个`server` Geode服务器是一个作为集群的长期可配置成员运行的进程。 Geode服务器主要用于托管长期数据区域以及运行标准Geode进程，例如客户端/服务器配置中的服务器。 请参阅运行Geode服务器进程。 启动缓存服务器： gfsh>start server --name=server1 --server-port=40411 此命令在指定的40411端口上启动名为“server1”的缓存服务器。 如果从gfsh运行start server而不指定成员名称，gfsh将自动选择一个随机成员名称。 这对自动化很有用。 观察Pulse中的更改（新成员和服务器）。 尝试扩展分布式系统图标以图形方式查看定位器和缓存服务器。 步骤 5: Create a replicated, persistent region(创建一个复制的持久区域) 在此步骤中，您将使用gfsh命令行实用程序创建一个区域。 区域是Geode集群的核心构建块，并提供组织数据的方法。 您为此练习创建的区域使用复制来跨集群成员复制数据，并利用持久性将数据保存到磁盘。 请参阅数据区域。 Create a replicated, persistent region(创建一个复制的持久区域): gfsh>create region --name=regionA --type=REPLICATE_PERSISTENT Member | Status ------- | -------------------------------------- server1 | Region \"/regionA\" created on \"server1\" 请注意，该区域托管在server1上。 使用gfsh命令行查看集群中的区域列表。 gfsh>list regions List of regions --------------- regionA 列出集群的成员。 您启动的定位器和缓存服务器显示在列表中： gfsh>list members Name | Id ------------ | --------------------------------------- Coordinator: | 192.0.2.0(locator1:3529:locator):59926 locator1 | 192.0.2.0(locator1:3529:locator):59926 server1 | 192.0.2.0(server1:3883):65390 要查看有关区域的详细信息，请键入以下内容： gfsh>describe region --name=regionA .......................................................... Name : regionA Data Policy : persistent replicate Hosting Members : server1 Non-Default Attributes Shared By Hosting Members Type | Name | Value ------ | ---- | ----- Region | size | 0 在Pulse中，单击绿色集群图标以查看刚刚添加到集群中的所有新成员和新区域。 注意: 保持这个gfsh提示符打开以进行后续步骤。 步骤 6: 处理区域中的数据并演示持久性 Apache Geode将数据作为键/值对进行管理。 在大多数应用程序中，Java程序会添加，删除和修改存储的数据。 您还可以使用gfsh命令添加和检索数据。 请参阅数据命令。 运行以下put命令将一些数据添加到该区域： gfsh>put --region=regionA --key=\"1\" --value=\"one\" Result : true Key Class : java.lang.String Key : 1 Value Class : java.lang.String Old Value : gfsh>put --region=regionA --key=\"2\" --value=\"two\" Result : true Key Class : java.lang.String Key : 2 Value Class : java.lang.String Old Value : 运行以下命令以从该区域检索数据： gfsh>query --query=\"select * from /regionA\" Result : true startCount : 0 endCount : 20 Rows : 2 Result ------ two one 请注意，结果显示使用put命令创建的两个数据条目的值。 请参阅数据条目。 使用以下命令停止缓存服务器： gfsh>stop server --name=server1 Stopping Cache Server running in /home/username/my_geode/server1 on ubuntu.local[40411] as server1... Process ID: 3883 Log File: /home/username/my_geode/server1/server1.log .... 使用以下命令重新启动缓存服务器： gfsh>start server --name=server1 --server-port=40411 运行以下命令再次从该区域检索数据 - 请注意数据仍然可用： gfsh>query --query=\"select * from /regionA\" Result : true startCount : 0 endCount : 20 Rows : 2 Result ------ two one 由于regionA使用持久性，因此它会将数据副本写入磁盘。 当托管regionA的服务器启动时，数据将填充到缓存中。 请注意，结果显示在停止服务器之前使用put命令创建的两个数据条目的值。 请参阅数据条目。 请参阅数据区域。 步骤 7: 检查复制的影响 在此步骤中，您将启动第二个缓存服务器。 由于regionA被复制，因此数据将在托管该区域的任何服务器上可用。 请参阅数据区域。 启动第二个缓存服务器： gfsh>start server --name=server2 --server-port=40412 运行describe region命令查看有关regionA的信息： gfsh>describe region --name=regionA .......................................................... Name : regionA Data Policy : persistent replicate Hosting Members : server1 server2 Non-Default Attributes Shared By Hosting Members Type | Name | Value ------ | ---- | ----- Region | size | 2 请注意，您无需再次为server2创建regionA。 该命令的输出显示regionA托管在server1和server2上。 当gfsh启动服务器时，它会从集群配置服务请求配置，然后将共享配置分发到任何加入集群的新服务器。 添加第三个数据条目： gfsh>put --region=regionA --key=\"3\" --value=\"three\" Result : true Key Class : java.lang.String Key : 3 Value Class : java.lang.String Old Value : 打开Pulse应用程序（在Web浏览器中）并观察集群拓扑。 您应该看到一个带有两个连接服务器的定位器。 单击“数据”选项卡以查看有关regionA的信息。 使用以下命令停止第一个缓存服务器： gfsh>stop server --name=server1 Stopping Cache Server running in /home/username/my_geode/server1 on ubuntu.local[40411] as server1... Process ID: 4064 Log File: /home/username/my_geode/server1/server1.log .... 从剩余的缓存服务器中检索数据。 gfsh>query --query=\"select * from /regionA\" Result : true startCount : 0 endCount : 20 Rows : 3 Result ------ two one three 请注意，数据包含3个条目，包括您刚添加的条目。 添加第四个数据条目： gfsh>put --region=regionA --key=\"4\" --value=\"four\" Result : true Key Class : java.lang.String Key : 3 Value Class : java.lang.String Old Value : 请注意，只有server2正在运行。 由于数据被复制并保留，因此所有数据仍然可用。 但新数据条目目前仅在服务器2上可用。 gfsh>describe region --name=regionA .......................................................... Name : regionA Data Policy : persistent replicate Hosting Members : server2 Non-Default Attributes Shared By Hosting Members Type | Name | Value ------ | ---- | ----- Region | size | 4 停止剩余的缓存服务器： gfsh>stop server --name=server2 Stopping Cache Server running in /home/username/my_geode/server2 on ubuntu.local[40412] as server2... Process ID: 4185 Log File: /home/username/my_geode/server2/server2.log ..... 步骤 8: 并行重新启动缓存服务器 在此步骤中，您将并行重新启动缓存服务器。 由于数据是持久的，因此服务器重新启动时数据可用。 由于数据是复制的，因此必须并行启动服务器，以便在启动之前同步数据。 启动server1。 因为regionA是复制和持久的，所以它需要来自其他服务器的数据才能启动并等待服务器启动： gfsh>start server --name=server1 --server-port=40411 Starting a Geode Server in /home/username/my_geode/server1... ............................................................................ ............................................................................ 请注意，如果查看重新启动的服务器的server1.log文件，您将看到类似于以下内容的日志消息： [info 2015/01/14 09:08:13.610 PST server1 tid=0x1] Region /regionA has pot entially stale data. It is waiting for another member to recover the latest data. My persistent id: DiskStore ID: 8e2d99a9-4725-47e6-800d-28a26e1d59b1 Name: server1 Location: /192.0.2.0:/home/username/my_geode/server1/. Members with potentially new data: [ DiskStore ID: 2e91b003-8954-43f9-8ba9-3c5b0cdd4dfa Name: server2 Location: /192.0.2.0:/home/username/my_geode/server2/. ] Use the \"gfsh show missing-disk-stores\" command to see all disk stores that are being waited on by other members. 在第二个终端窗口中，将目录更改为临时工作目录（例如，my_geode）并启动gfsh： [username@localhost ~/my_geode]$ gfsh _________________________ __ / _____/ ______/ ______/ /____/ / / / __/ /___ /_____ / _____ / / /__/ / ____/ _____/ / / / / /______/_/ /______/_/ /_/ 1.7 Monitor and Manage Geode 运行以下命令以连接到集群： gfsh>connect --locator=localhost[10334] Connecting to Locator at [host=localhost, port=10334] .. Connecting to Manager at [host=ubuntu.local, port=1099] .. Successfully connected to: [host=ubuntu.local, port=1099] 启动 server2: gfsh>start server --name=server2 --server-port=40412 当server2启动时，请注意 server1在第一个gfsh窗口中完成其启动： Server in /home/username/my_geode/server1 on ubuntu.local[40411] as server1 is currently online. Process ID: 3402 Uptime: 1 minute 46 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /home/username/my_geode/server1/server1.log JVM Arguments: -Dgemfire.default.locators=192.0.2.0[10334] -Dgemfire.use-cluster-configuration=true -XX:OnOutOfMemoryError=kill -KILL %p -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /home/username/Apache_Geode_Linux/lib/geode-core-1.0.0.jar: /home/username/Apache_Geode_Linux/lib/geode-dependencies.jar 验证定位器和两个服务器是否正在运行： gfsh>list members Name | Id ------------ | --------------------------------------- Coordinator: | ubuntu(locator1:2813:locator):46644 locator1 | ubuntu(locator1:2813:locator):46644 server2 | ubuntu(server2:3992):21507 server1 | ubuntu(server1:3402):36532 运行查询以验证您使用put命令输入的所有数据是否可用： gfsh>query --query=\"select * from /regionA\" Result : true startCount : 0 endCount : 20 Rows : 5 Result ------ one two four Three NEXT_STEP_NAME : END 使用以下命令停止server2： gfsh>stop server --dir=server2 Stopping Cache Server running in /home/username/my_geode/server2 on 192.0.2.0[40412] as server2... Process ID: 3992 Log File: /home/username/my_geode/server2/server2.log .... 运行查询以验证您使用put命令输入的所有数据是否仍然可用： gfsh>query --query=\"select * from /regionA\" Result : true startCount : 0 endCount : 20 Rows : 5 Result ------ one two four Three NEXT_STEP_NAME : END 步骤 9: 关闭系统，包括定位器 要关闭集群，请执行以下操作： 在当前的gfsh会话中，停止集群： gfsh>shutdown --include-locators=true 请参阅shutdown。 出现提示时，键入'Y'以确认集群已关闭。 As a lot of data in memory will be lost, including possibly events in queues, do you really want to shutdown the entire distributed system? (Y/n): Y Shutdown is triggered gfsh> No longer connected to ubuntu.local[1099]. gfsh> 输入exit退出gfsh shell。 步骤 10: 接下来做什么… 以下是Apache Geode下一步要探索的一些建议： 继续阅读下一部分，以了解有关刚刚介绍的组件和概念的更多信息。 要使用gfsh进行更多练习，请参阅教程 - 使用gfsh执行常见任务。 要了解集群配置服务，请参阅教程 - 创建和使用集群配置。 Copyright © WS 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-12-06 10:25:44 "},"Geode_2_Configuring_and_Running_a_Cluster.html":{"url":"Geode_2_Configuring_and_Running_a_Cluster.html","title":"配置和运行集群","keywords":"","body":"配置和运行集群集群配置服务概述教程 - 创建和使用集群配置 将应用程序JAR部署到Apache Geode成员 使用成员组导出和导入集群配置集群配置文件和故障排除使用gfsh通过HTTP或HTTPS管理远程集群 在没有集群配置服务的情况下部署配置文件部署配置文件的主要步骤默认文件规范和搜索位置更改文件规范部署配置JAR的示例 启动和关闭系统运行Geode定位器进程 运行Geode服务器进程 管理系统输出文件防火墙注意事项防火墙和连接防火墙和端口配置和运行集群 使用gfsh命令行实用程序配置Apache Geode集群。 集群配置服务会保留集群配置并将配置分发给集群成员。 还有其他几种配置集群的方法。 使用gfsh配置区域，磁盘存储，成员和其他Geode对象。 您还可以使用gfsh来启动和停止定位器，服务器和Geode监视工具。 执行这些命令时，集群配置服务会保留配置。 当新成员加入集群时，该服务会将配置分发给新成员。 gfsh是配置和管理Apache Geode集群的推荐方法,但您仍然可以使用cache.xml和gemfire.properties文件的旧方法配置集群的许多方面. 请参阅cache.xml和参考了解配置参数. 您还可以使用Java API配置集群的某些方面. 请参阅管理Apache Geode. 集群配置服务概述 Apache Geode集群配置服务将由gfshcommands创建的集群配置持久保存到集群中的定位器，并将配置分发给集群成员。 教程 - 创建和使用集群配置 A short walk-through that uses a single computer to demonstrate how to use gfsh to create a cluster configuration for a Geode cluster. 将应用程序JAR部署到Apache Geode成员 您可以将应用程序JAR文件动态部署到特定成员或集群中的所有成员。 Geode自动跟踪JAR文件版本; 将已部署的JAR文件自动加载到CLASSPATH; 并自动注册JAR包含的任何函数。 使用成员组 Apache Geode允许您将集群成员组织到逻辑成员组中。 导出和导入集群配置 集群配置服务导出和导入使用gfsh为整个Apache Geode集群创建的配置。 集群配置文件和故障排除 在Geode中使用集群配置服务时，可以检查定位器上cluster_config目录中生成的配置文件。 gfsh在集群级别和单个组级别保存配置文件。 使用gfsh通过HTTP或HTTPS管理远程集群 您可以通过HTTP或HTTPS将gfsh连接到远程集群，并使用gfsh命令管理集群。 在没有集群配置服务的情况下部署配置文件 您可以在系统目录结构或jar文件中部署Apache Geode配置文件。 您可以确定部署配置文件的方式并相应地进行设置。 启动和关闭系统 确定正确的启动和关闭过程，并编写启动和关闭脚本。 运行Geode定位器进程 定位器是一个Geode进程，它告诉运行成员所在的新连接成员，并为服务器使用提供负载均衡。 运行Geode服务器进程 Geode服务器是一个作为客户端/服务器系统的长期可配置成员运行的进程。 管理系统输出文件 Geode输出文件是可选的，可以变得非常大。 与系统管理员一起确定放置它们的位置，以避免干扰其他系统活动。 防火墙注意事项 您可以为涉及防火墙的情况配置和限制端口使用，例如，在客户端 - 服务器或服务器 - 服务器连接之间。 集群配置服务概述 Apache Geode集群配置服务将由gfshcommands创建的集群配置持久保存到集群中的定位器，并将配置分发给集群成员。 为什么使用集群配置服务 我们强烈建议您使用gfsh命令行和集群配置服务作为管理集群配置的主要机制。 在cache.xml文件中指定配置，仅用于那些使用gfsh无法指定或更改的项。使用通用集群配置可减少在配置集群中的新成员时配置单个成员所花费的时间并实施一致的配置。 您不再需要重新配置添加到集群的每个新成员。 您不再需要担心验证cache.xml文件。 在整个集群中传播配置更改并将配置更改部署到不同的环境也变得更加容易。 您可以使用集群配置服务： 保存整个Apache Geode集群的配置。 使用以前保存的配置重新启动成员。 从开发环境导出配置并迁移该配置以创建测试或生产系统。 无需单独配置每个服务器即可启动其他服务器。 配置一些服务器以托管某些区域和其他服务器以托管不同的区域，并将所有服务器配置为托管一组公共区域。 使用集群配置服务 要在Geode中使用集群配置服务，必须在部署中使用专用的独立定位器。 您不能将集群配置服务与位于同一位置的定位器（在另一个进程（如服务器）中运行的定位器）或多播环境中一起使用。 独立定位器将配置分发到集群中的所有定位器。 将--enable-cluster-configuration设置为true的集群中的每个定位器都会记录所有集群级别和组级别配置设置。 注意: gfsh的默认行为是创建和保存集群配置。 启动定位器时，可以使用--enable-cluster-configuration = false选项禁用集群配置服务。 您可以使用gfsh import cluster-configuration命令在启动定位器后将现有配置加载到集群中。 随后，任何以-use-cluster-configuration设置为true的gfsh开头的服务器将从定位器以及任何适当的组级配置中获取集群配置(对于成员组，它们 属于)。 要在服务器上禁用集群配置服务，必须使用--use-cluster-configuration参数设置为false来启动服务器。 默认情况下，该参数设置为true。 集群配置服务的工作原理 使用gfsh命令创建Apache Geode区域，磁盘存储和其他对象时，集群配置服务会保存集群中每个定位器的配置。 如果在发出这些命令时指定组，则会保存单独的配置，其中仅包含适用于该组的配置。 当您使用gfsh启动新的Apache Geode服务器时，定位器会将持久配置分发到新服务器。 如果在启动服务器时指定组，则除了集群级配置外，服务器还会接收组级配置。 集群级配置在集群范围配置后应用; 因此，您可以使用组级别来覆盖集群级别设置。 gfsh创建集群配置的命令 以下gfsh命令会将配置写入集群中的所有定位器（定位器将配置写入磁盘）： configure pdx* create region alter region alter runtime destroy region create index destroy index create disk-store destroy disk-store create async-event-queue deploy jar undeploy jar create gateway-sender create gateway-receiver * 请注意，必须在启动数据成员之前执行configure pdx命令。 此命令不会影响系统中当前正在运行的任何成员。 运行此命令后启动的数据成员（已启用集群配置）将获取新的PDX配置。 gfsh限制 这些是您无法使用gfsh创建或更改的配置。 这些配置必须位于cache.xml文件中，或者使用API： 客户端缓存配置 您无法直接修改以下对象的属性： function custom-load-probe compressor serializer instantiator pdx-serializer 注意: configure pdx命令总是指定org.apache.geode.pdx.ReflectionBasedAutoSerializer类。 您无法在gfsh中指定自定义PDX序列化程序。 initializer lru-heap-percentage lru-memory-size partition-resolver partition-listener transaction-listener transaction-writer Adding or removing a TransactionListener Deleting an AsyncEventQueue Configuring a GatewayConflictResolver 您无法为以下内容指定Java类的参数和值： gateway-listener gateway-conflict-resolver gateway-event-filter gateway-transport-filter gateway-event-substitution-filter 禁用集群配置服务 如果您不想使用集群配置服务，请启动定位器，并将--enable-cluster-configuration参数设置为false，或者不要使用独立定位器。 然后，您需要在所有集群成员上单独配置缓存（通过cache.xml或API）。 教程 - 创建和使用集群配置 一个简短的演练，使用一台计算机演示如何使用gfsh为Geode集群创建集群配置。 gfsh命令行工具允许您配置和启动Geode集群。 集群配置服务使用Apache Geode定位器在组和集群级别存储配置，并在新成员启动时将这些配置提供给新成员。 定位器将配置存储在可供所有定位器使用的隐藏区域中，并将配置数据作为XML文件写入磁盘。 配置数据在执行gfsh命令时更新。 本节提供了配置简单Apache Geode集群，然后在新上下文中重用该配置的演练示例。 创建一个工作目录(例如：/home/username/my_geode)并切换到新目录。 该目录将包含集群的配置。 启动gfsh命令行工具。 例如： $ gfsh 显示gfsh命令提示符。 _________________________ __ / _____/ ______/ ______/ /____/ / / / __/ /___ /_____ / _____ / / /__/ / ____/ _____/ / / / / /______/_/ /______/_/ /_/ 1.7 Monitor and Manage Apache Geode gfsh> 使用以下示例中的命令启动定位器： gfsh>start locator --name=locator1 Starting a Geode Locator in /Users/username/my_geode/locator1... ............................. Locator in /Users/username/my_geode/locator1 on 192.0.2.0[10334] as locator1 is currently online. Process ID: 5203 Uptime: 15 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /Users/username/my_geode/locator1/locator1.log JVM Arguments: -Dgemfire.enable-cluster-configuration=true -Dgemfire.load-cluster-configuration-from-dir=false -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /Users/username/Apache_Geode_1.0.0_Linux/lib/geode-dependencies.jar Successfully connected to: [host=192.0.2.0, port=1099] Cluster configuration service is up and running. 请注意，gfsh会响应一条消息，指示集群配置服务已启动并正在运行。 如果看到指示问题的消息，请查看定位器日志文件以查找可能的错误。 日志文件的路径显示在gfsh的输出中。 使用以下示例中的命令启动Apache Geode服务器： gfsh>start server --name=server1 --groups=group1 Starting a Geode Server in /Users/username/my_geode/server1... ..... Server in /Users/username/my_geode/server1 on 192.0.2.0[40404] as server1 is currently online. Process ID: 5627 Uptime: 2 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /Users/username/my_geode/server1/server1.log JVM Arguments: -Dgemfire.default.locators=192.0.2.0[10334] -Dgemfire.groups=group1 -Dgemfire.use-cluster-configuration=true -XX:OnOutOfMemoryError=kill -KILL %p -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /Users/username/Apache_Geode_1.0.0_Linux/lib/geode-dependencies.jar gfsh>start server --name=server2 --groups=group1 --server-port=40405 Starting a Geode Server in /Users/username/my_geode/server2... ..... Server in /Users/username/my_geode/server2 on 192.0.2.0[40405] as server2 is currently online. Process ID: 5634 Uptime: 2 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /Users/username/my_geode/server2/server2.log JVM Arguments: -Dgemfire.default.locators=192.0.2.0[10334] -Dgemfire.groups=group1 -Dgemfire.use-cluster-configuration=true -XX:OnOutOfMemoryError=kill -KILL %p -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /Users/username/Apache_Geode_1.0.0_Linux/lib/geode-dependencies.jar gfsh>start server --name=server3 --server-port=40406 Starting a Geode Server in /Users/username/my_geode/server3... ..... Server in /Users/username/my_geode/server3 on 192.0.2.0[40406] as server3 is currently online. Process ID: 5637 Uptime: 2 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /Users/username/my_geode/server3/server3.log JVM Arguments: -Dgemfire.default.locators=192.0.2.0[10334] -Dgemfire.use-cluster-configuration=true -XX:OnOutOfMemoryError=kill -KILL %p -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /Users/username/Apache_Geode_1.0.0_Linux/lib/geode-dependencies.jar 请注意，用于启动server1和server2的gfsh命令指定了一个名为group1的组，而server3的命令没有指定组名。 使用以下示例中的命令创建一些区域： gfsh>create region --name=region1 --groups=group1 --type=REPLICATE Member | Status ------- | -------------------------------------- server2 | Region \"/region1\" created on \"server2\" server1 | Region \"/region1\" created on \"server1\" gfsh>create region --name=region2 --type=REPLICATE Member | Status ------- | -------------------------------------- server1 | Region \"/region2\" created on \"server1\" server2 | Region \"/region2\" created on \"server2\" server3 | Region \"/region2\" created on \"server3\" 请注意，在启动缓存服务器(在此示例中为server1和server2)时，在指定名为group1的组的所有缓存服务器上创建region1。 因为没有指定组，所以在所有成员上创建region2。 部署jar文件。 使用gfsh deploy命令将应用程序jar文件部署到所有成员或指定的成员组。 以下示例从分发中部署mx4j-3.0.1.jar和ra.jar文件。 (注意：这只是一个示例，您不需要部署这些文件来使用集群配置服务。或者，您可以使用任何两个jar文件进行此演示。) gfsh>deploy --groups=group1 --jars=/lib/mx4j-3.0.1.jar Post substitution: deploy --groups=group1 --jars=/Users/username/Apache_Geode_1.0.0_Linux/lib/mx4j-3.0.1.jar Member | Deployed JAR | Deployed JAR Location ------- | ------------------ | ------------------------------------------------------- server1 | mx4j-3.0.1.jar | /Users/username/my_geode/server1/vf.gf#mx4j-3.0.1.jar#1 server2 | mx4j-3.0.1.jar | /Users/username/my_geode/server2/vf.gf#mx4j-3.0.1.jar#1 gfsh>deploy --jars=/lib/ra.jar Post substitution: deploy --jar=/Users/username/Apache_Geode_1.0.0_Linux/lib/ra.jar Member | Deployed JAR | Deployed JAR Location ------- | ------------ | ----------------------------------------------- server1 | ra.jar | /Users/username/my_geode/server1/vf.gf#ra.jar#1 server2 | ra.jar | /Users/username/my_geode/server1/vf.gf#ra.jar#1 server3 | ra.jar | /Users/username/my_geode/server1/vf.gf#ra.jar#1 请注意，mx4j-3.0.1.jar文件仅部署到group1的成员，而ra.jar部署到所有成员。 导出集群配置。 您可以使用gfsh export cluster-configuration命令创建一个包含集群持久配置的zip文件。 zip文件包含cluster_config目录内容的副本。 例如： gfsh>export cluster-configuration --zip-file-name=/Users/username/myClConfig.zip Apache Geode将集群配置写入指定的zip文件。 Downloading cluster configuration : /Users/username/myClConfig.zip 其余步骤演示了如何使用刚刚创建的集群配置。 使用以下命令关闭集群： gfsh>shutdown --include-locators=true As a lot of data in memory will be lost, including possibly events in queues, do you really want to shutdown the entire distributed system? (Y/n): Y Shutdown is triggered gfsh> No longer connected to 192.0.2.0[1099]. gfsh> 退出gfsh命令shell： gfsh>quit Exiting... 创建一个新的工作目录(例如：new_geode)并切换到新目录。 启动gfsh命令shell： $ gfsh 启动一个新的定位器。 例如： gfsh>start locator --name=locator2 --port=10335 Starting a Geode Locator in /Users/username/new_geode/locator2... ............................. Locator in /Users/username/new_geode/locator2 on 192.0.2.0[10335] as locator2 is currently online. Process ID: 5749 Uptime: 15 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /Users/username/new_geode/locator2/locator2.log JVM Arguments: -Dgemfire.enable-cluster-configuration=true -Dgemfire.load-cluster-configuration-from-dir=false -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /Users/username/Apache_Geode_1.0.0_Linux/lib/geode-dependencies.jar Successfully connected to: [host=192.0.2.0, port=1099] Cluster configuration service is up and running. 使用import cluster-configuration命令导入集群配置。 例如： gfsh>import cluster-configuration --zip-file-name=/Users/username/myClConfig.zip Cluster configuration successfully imported 请注意，locator2目录现在包含cluster_config子目录。 启动不引用组的服务器： gfsh>start server --name=server4 --server-port=40414 Starting a Geode Server in /Users/username/new_geode/server4... ........ Server in /Users/username/new_geode/server4 on 192.0.2.0[40414] as server4 is currently online. Process ID: 5813 Uptime: 4 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /Users/username/new_geode/server4/server4.log JVM Arguments: -Dgemfire.default.locators=192.0.2.0[10335] -Dgemfire.use-cluster-configuration=true -XX:OnOutOfMemoryError=kill -KILL %p -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /Users/username/Apache_Geode_1.0.0_Linux/lib/geode-dependencies.jar 启动另一个引用group1的服务器： gfsh>start server --name=server5 --groups=group1 --server-port=40415 Starting a Geode Server in /Users/username/new_geode/server5... ..... Server in /Users/username/new_geode/server2 on 192.0.2.0[40415] as server5 is currently online. Process ID: 5954 Uptime: 2 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /Users/username/new_geode/server5/server5.log JVM Arguments: -Dgemfire.default.locators=192.0.2.0[10335] -Dgemfire.groups=group1 -Dgemfire.use-cluster-configuration=true -XX:OnOutOfMemoryError=kill -KILL %p -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /Users/username/Apache_Geode_1.0.0_Linux/lib/geode-dependencies.jar 使用list regions命令显示已配置的区域。 请注意，在以前集群级别中配置的region1和region2可用。 gfsh>list regions List of regions --------------- region1 region2 使用describe region命令查看哪些成员托管每个区域。 请注意，region1仅由server5托管，因为server5是使用group1配置启动的。 region2托管在server4和server5上，因为在没有指定组的情况下创建了region2。 gfsh>describe region --name=region1 .......................................................... Name : region1 Data Policy : replicate Hosting Members : server5 Non-Default Attributes Shared By Hosting Members Type | Name | Value ------ | ----------- | --------------- Region | data-policy | REPLICATE | size | 0 | scope | distributed-ack gfsh>describe region --name=region2 .......................................................... Name : region2 Data Policy : replicate Hosting Members : server5 server4 Non-Default Attributes Shared By Hosting Members Type | Name | Value ------ | ----------- | --------------- Region | data-policy | REPLICATE | size | 0 | scope | distributed-ack 此新集群使用与原始系统相同的配置。 您可以使用此集群配置启动任意数量的服务器。 所有服务器都将收到集群级配置。 指定group1的服务器也接收group1配置。 使用以下命令关闭集群： gfsh>shutdown --include-locators=true As a lot of data in memory will be lost, including possibly events in queues, do you really want to shutdown the entire distributed system? (Y/n): Y Shutdown is triggered gfsh> No longer connected to 192.0.2.0[1099]. 将应用程序JAR部署到Apache Geode成员 您可以将应用程序JAR文件动态部署到特定成员或集群中的所有成员。 Geode自动跟踪JAR文件版本; 将已部署的JAR文件自动加载到CLASSPATH; 并自动注册JAR包含的任何函数。 要在Apache Geode中部署和取消部署应用程序JAR文件，请使用gfsh deploy或undeploy命令。 您可以部署单个JAR或多个JAR（通过指定JAR文件名或指定包含JAR文件的目录），也可以将部署目标指向成员组或多个成员组。 例如，在连接到要部署JAR文件的集群后，可以在gfsh提示符下键入： gfsh> deploy --jars=group1_functions.jar 此命令将group1_functions.jar文件部署到集群中的所有成员。 要将JAR文件部署到成员的子集，请使用--groups参数。 例如： gfsh> deploy --jars=group1_functions.jar --groups=MemberGroup1 在示例中，假设您已经定义了在启动成员时要使用的成员组。有关如何定义成员组以及如何将成员添加到组的详细信息，请参阅配置和运行集群。 要将位于特定目录中的所有JAR文件部署到所有成员： gfsh> deploy --dir=libs/group1-libs 您可以提供JAR文件名或JAR目录以进行部署，但不能同时指定两者。 要在整个集群中取消部署所有以前部署的JAR文件： gfsh> undeploy 要取消部署特定的JAR文件： gfsh> undeploy --jars=group1_functions.jar 在取消部署所有JAR文件时定位特定成员组： gfsh> undeploy --groups=MemberGroup1 只有先前部署在MemberGroup1组中的成员上的JAR文件才会被取消部署。 要查看集群中所有已部署的JAR文件的列表： gfsh> list deployed 要查看特定成员组中所有已部署JAR的列表，请执行以下操作： gfsh> list deployed --groups=MemberGroup1 样本输出： Member | Deployed JAR | JAR Location --------- | -------------------- | --------------------------------------------------- datanode1 | group1_functions.jar | /usr/local/gemfire/deploy/vf.gf#group1_functions.jar#1 datanode2 | group1_functions.jar | /usr/local/gemfire/deploy/vf.gf#group1_functions.jar#1 有关gfsh用法的更多信息，请参阅gfsh. JAR文件的部署位置 在每个成员上写入JAR文件的系统位置由为该成员配置的deploy-working-dir Geode属性确定。 例如，您可以在您的成员的gemfire.properties文件中配置以下内容： #gemfire.properties deploy-working-dir=/usr/local/gemfire/deploy 此部署位置可以是本地或多个成员使用的共享网络资源（例如装载位置），以减少磁盘空间使用。 如果使用共享目录，则仍需要在要访问应用程序的每个成员上部署JAR文件，因为部署会更新CLASSPATH和自动注册功能。 关于部署JAR文件和集群配置服务 默认情况下，集群配置服务将已部署的JAR文件分发到集群中的所有定位器。 当您使用gfsh启动新服务器时，定位器将配置文件和已部署的jar文件提供给成员，并将它们写入服务器的目录。 请参见集群配置服务概述. JAR文件的版本控制 将JAR文件部署到集群或成员组时，将修改JAR文件以在其名称中指示版本信息。 每个JAR文件名都以vf.gf #为前缀，并在文件名末尾包含一个版本号。 例如，如果您将MyClasses.jar部署五次，则在列出所有已部署的jar时，文件名将显示为vf.gf＃MyClasses.jar＃5。 部署新的JAR文件时，接收部署的成员会检查JAR文件是否重复，因为JAR文件已部署在该成员上，或者因为JAR文件已部署到共享部署工作目录， 其他成员也在使用。如果另一个成员已将此JAR文件部署到共享目录（通过与其目录中的最新版本进行逐字节比较来确定），则接收最新部署的成员不会将该文件写入磁盘。相反，该成员更新ClassPathLoader以使用已部署的JAR文件。 如果在磁盘上检测到较新版本的JAR文件并且已在使用中，则会取消部署。 当成员开始使用JAR文件时，该成员将获取该文件的共享锁。 如果成员通过部署接收到较新版本，则该成员将释放共享锁并尝试删除现有JAR文件以支持较新版本。 如果没有其他成员在现有JAR上具有共享锁，则会删除现有的旧版本JAR。 自动类路径加载 启动缓存时，新缓存会请求将当前工作目录中每个JAR文件的最新版本添加到ClassPathLoader。 如果已将JAR文件部署到ClassPathLoader，则ClassPathLoader会在找到更新版本时更新其加载的版本; 否则，没有变化。 如果检测到，则如果没有其他成员对其具有共享锁，则会删除旧版本的JAR文件。 取消部署JAR文件不会自动卸载部署期间加载的类。 您需要重新启动成员才能卸载这些类。 当缓存关闭时，它会请求从ClassPathLoader中删除所有当前部署的JAR文件。 如果使用共享部署工作目录，则共享该目录的所有成员应属于同一成员组。 重新启动后，共享同一部署工作目录的所有成员将使用当前工作目录中找到的任何JAR部署和自动加载其CLASSPATH。 这意味着某些成员可能会加载JAR，即使它们不是接收原始部署的成员组的一部分。 自动函数注册 部署包含函数的JAR文件（换句话说，包含实现Function接口的类）时，该函数将通过FunctionService.registerFunction方法自动注册。如果使用相同的函数部署了另一个JAR文件（具有相同的JAR文件名或另一个文件名），则会注册该函数的新实现，覆盖旧的实现。如果取消部署JAR文件，则在部署时自动注册的任何功能都将取消注册。 由于多次部署具有相同名称的JAR文件会导致JAR未部署和重新部署，因此JAR中的函数将在每次发生时取消注册并重新注册。如果从多个不同名称的JAR文件中注册了具有相同ID的函数，则在重新部署或取消部署任何这些JAR文件时，将取消注册该函数。 在cache.xml加载期间，保存任何声明的参数。 如果在JAR文件中找到的函数也是可声明的，并且与加载cache.xml后保存参数的声明符具有相同的类名，则使用这些参数创建函数实例并进行注册。 因此，如果在具有不同参数集的cache.xml中多次声明相同的函数，则在部署JAR时，将为每组参数实例化一个函数。 如果使用来自cache.xml加载的参数注册任何函数，则不会注册默认的无参数函数。 使用成员组 Apache Geode允许您将集群成员组织到逻辑成员组中。 在Apache Geode中使用成员组是可选的。 使用成员组的好处是能够根据逻辑组成员身份协调成员上的某些操作。 例如，通过定义和使用成员组，您可以： 更改特定成员的配置属性的子集。 请参阅gfsh中的alter runtime。 执行某些磁盘操作，例如跨成员组进行磁盘存储压缩。 有关命令列表，请参阅磁盘存储命令。 管理组中所有成员的特定索引或区域。 在成员组中启动和停止多站点（WAN）服务，例如网关发件人和网关接收器。 在组中的所有成员上部署或取消部署JAR应用程序。 在特定组的所有成员上执行功能。 您可以在成员的gemfire.properties文件的groups属性中或在gfsh中的成员启动时定义组名。 注意: 现在的roles属性中定义的任何角色现在都将被视为一个组。 如果您希望向集群添加成员资格角色，则应将它们作为成员组添加到groups属性中。 'roles属性已被弃用，建议使用groups`属性。 要将成员添加到组，请在启动之前将成员组的名称添加到成员的gemfire.properties文件中，或者可以在gfsh中在启动成员时传入--groups参数 。 单个成员可以属于多个组。 成员组还可以用于从客户的角度或从同行成员的角度组织成员。 请参阅将对等方组织到逻辑成员组 和 将服务器组织到逻辑成员组以获取更多信息。在客户端，您可以在配置客户端的连接池时提供成员组名称。 使用客户端的cache.xml中的元素。 导出和导入集群配置 集群配置服务导出和导入使用gfsh为整个Apache Geode集群创建的配置。 使用gfsh命令创建区域，磁盘存储和其他对象时，集群配置服务会保存集群配置。 您可以将此配置以及包含应用程序文件的任何jar文件导出到zip文件，然后导入此配置以创建新集群。 导出集群配置 发出gfsh``export cluster-configuration命令，以便在zip文件中保存集群的配置数据。 此zip文件包含集群级配置的子目录和集群中指定的每个组的目录。 集群配置文件和故障排除中介绍了这些目录的内容。 要导出集群配置，请在连接到Geode集群时运行gfsh``export cluster-configuration命令。 例如： export cluster-configuration --zip-file-name=/home/username/configs/myClusterConfig.zip 参见 导出集群配置. 注意: gfsh仅保存使用gfsh指定的配置的集群配置值。 管理API创建的配置不随集群配置一起保存。 导入集群配置 使用gfsh``import cluster-configuration命令根据从其他系统导出的配置信息来配置新的集群。 您只能将集群配置导入新集群，即： 没有正在运行的缓存服务器 或者 唯一运行的缓存服务器满足以下所有条件： 是刚刚启动的 没有定义区域 自从它们启动以来，没有给出任何其他配置更改 导入配置后，您启动的任何服务器都将收到此集群配置。 要导入集群配置，请启动一个或多个定位器，然后运行gfsh``import cluster-configuration命令。 例如： import cluster-configuration --zip-file-name=/home/username/configs/myClusterConfig.zip 请参阅导入集群配置。 集群配置文件和故障排除 在Geode中使用集群配置服务时，可以检查定位器上cluster_config目录中生成的配置文件。 gfsh在集群级别和单个组级别保存配置文件。 运行集群配置服务的定位器上提供了以下目录和配置文件： Cluster-level configuration 对于适用于集群的所有成员的配置，定位器在cluster_config目录中创建一个clustersubdirectory（或在使用--cluster-config-dir=value启动定位器时在集群配置目录中参数）指定。 所有服务器在使用gfsh`启动时都会收到此配置。 该目录包含： cluster.xml – Geodecache.xml文件，包含所有成员共有的配置 cluster.properties – Geodegemfire.properties文件，包含所有成员共有的属性 用于部署到所有成员的Jar文件 Group-level configuration 当您在gfsh命令中指定--groups参数时（例如，start server或create region），定位器会将每个组的配置写入与该组同名的子目录中。 启动指定一个或多个组名的服务器时，服务器将同时接收集群级配置和指定的所有组的配置。 该子目录包含： .xml – Geodecache.xml文件，包含该组所有成员共有的配置 .properties – Geodegemfire.properties文件，包含该组所有成员共有的属性 用于部署到组的所有成员的Jar文件 您可以导出包含集群配置的所有工件的zip文件。 zip文件包含定位器的cluster_config（或其他指定的）子目录中的所有文件。 您可以将此配置导入新集群。 请参见导出和导入集群配置。 故障排除提示 当您使用gfsh启动定位器时，您应该看到以下消息： Cluster configuration service is up and running. 如果您没有看到此消息，则集群配置服务可能存在问题。 使用status cluster-config-service命令检查集群配置的状态。 如果该命令返回RUNNING，则集群配置正常运行。 如果命令返回WAITING，则运行status locator命令。 此命令的输出返回WAITING状态的原因。 使用cache.xml文件进行配置时，这些文件中的配置应用程序有一个特定的顺序。 Geode首先应用集群范围的配置文件, 接着是组级配置。 最后一个是成员自己的配置文件（cache.xml和gemfire.properties文件）中的配置。 如果服务器启动失败并出现以下异常：ClusterConfigurationNotAvailableException，则集群配置服务可能不处于RUNNING状态。 因为服务器从定位器请求集群配置不可用，所以start server命令失败。 您可以通过检查服务器的日志文件来确定服务器从定位器接收的配置。 请参阅Logging。 如果start server命令指定与现有集群配置冲突的cache.xml文件，则服务器启动可能会失败。 如果由于无法保存集群配置而导致gfsh命令失败，则会显示以下消息： Failed to persist the configuration changes due to this command, Revert the command to maintain consistency. Please use \"status cluster-config-service\" to determine whether Cluster configuration service is RUNNING.\" 有些类型的配置无法使用gfsh进行。 请参阅gfsh限制。 使用gfsh通过HTTP或HTTPS管理远程集群 您可以通过HTTP或HTTPS将gfsh连接到远程集群，并使用gfshcommands管理集群。 要使用HTTP协议将gfsh连接到远程集群： 启动gfsh。 请参阅启动gfsh。 在远程主机上启动远程集群时，可以选择在启动JMX管理器（服务器或定位器）时将--http-bind-address和--http-service-port指定为Geode属性。 然后，可以在从本地系统连接到远程集群中的HTTP服务时使用的URL中使用这些属性。 例如： gfsh>start server --name=server1 --J=-Dgemfire.jmx-manager=true \\ --J=-Dgemfire.jmx-manager-start=true --http-service-port=8080 \\ --http-service-bind-address=myremotecluster.example.com 此命令必须直接在主机上执行，该主机最终将充当承载HTTP服务以进行远程管理的远程服务器。 （您无法远程启动服务器。） 在本地系统上，运行gfsh connect命令连接到远程系统。 包括--use-http和--url参数。 例如： gfsh>connect --use-http=true --url=\"http://myremotecluster.example.com:8080/geode/v1\" Successfully connected to: Geode Manager's HTTP service @ http://myremotecluster.example.com:8080/geode/v1 See connect. gfsh现在连接到远程系统。 大多数gfsh命令现在将在远程系统上执行; 但是，也有例外。 在本地集群上执行以下命令： alter disk-store compact offline-disk-store describe offline-disk-store help hint sh (for executing OS commands) sleep start jconsole (however, you can connect JConsole to a remote cluster when gfsh is connected to the cluster via JMX) start jvisualvm start locator start server start vsd status locator``* status server``* stop locator``* stop server``* run (for executing gfsh scripts) validate disk-store version *当gfsh通过JMX或HTTP / S连接到集群时，可以通过对这些stop /status命令使用--name选项来停止并获取远程定位器和服务器的状态。 如果对这些命令使用--pid或--dir选项，则stop /status命令仅在本地执行。 要为远程连接（HTTPS）配置SSL，请在gemfire.properties或gfsecurity-properties或服务器启动时为http组件启用SSL。 有关配置SSL参数的详细信息，请参阅SSL。 这些SSL参数也适用于配置的JMX Manager上托管的所有HTTP服务，其中包括以下内容： Developer REST API service Pulse monitoring tool 在没有集群配置服务的情况下部署配置文件 您可以在系统目录结构或jar文件中部署Apache Geode配置文件。 您可以确定部署配置文件的方式并相应地进行设置。 注意: 如果使用集群配置服务来创建和管理Apache Geode集群配置，则不需要本节中描述的过程，因为Geode会自动管理配置文件和jar文件到集群成员的分发。 请参见集群配置服务概述。 您可以使用本节中描述的过程来分发特定于成员的配置，或者您不希望使用集群配置服务的情况。 部署配置文件的主要步骤 这些是部署配置文件的基本步骤，以及后续章节中的相关详细信息。 默认文件规范和搜索位置 每个文件都有一个默认名称，一组文件搜索位置以及可用于覆盖默认值的系统属性。 更改文件规范 您可以在gemfire.properties文件和命令行中更改所有文件规范。 在JAR文件中部署配置文件 本节提供了在JAR文件中部署配置文件的过程和示例。 部署配置文件的主要步骤 这些是部署配置文件的基本步骤，以及后续章节中的相关详细信息。 确定安装所需的配置文件。 将文件放在目录或jar文件中。 对于具有非默认名称或位置的任何文件，请在系统属性文件 和/或 成员`CLASSPATH中提供文件规范。 Geode配置文件 gemfire.properties. 包含集群成员所需的设置。 这些设置包括许可，系统成员发现，通信参数，日志记录和统计信息。 请参阅Geode属性参考。 gfsecurity.properties. 一个可选的单独文件，包含与gemfire.properties中另外定义的安全相关（security- *）设置。 将这些成员属性放入单独的文件允许您限制用户对这些特定设置的访问。 请参阅Geode属性参考。 cache.xml. 声明性缓存配置文件。 此文件包含缓存，区域和区域条目配置的XML声明。 您还可以使用它来配置磁盘存储，数据库登录凭据，服务器和远程站点位置信息以及套接字信息。 请参阅cache.xml。 默认文件规范和搜索位置 每个文件都有一个默认名称，一组文件搜索位置以及可用于覆盖默认值的系统属性。 要使用默认规范，请将文件放在其目录或jar文件的顶层。 系统属性是标准文件规范，可以具有绝对或相对路径名和文件名。 注意: 如果未指定绝对文件路径和名称，搜索将检查文件的所有搜索位置。 Default File Specification Search Locations for Relative File Specifications Available Property for File Specification gemfire.properties current directoryhome directoryCLASSPATH As a Java system property, use gemfirePropertyFile cache.xml current directoryCLASSPATH In gemfire.properties, use the cache-xml-file property 有效gemfirePropertyFile规范的示例： /zippy/users/jpearson/gemfiretest/gemfire.properties c:\\gemfiretest\\gemfire.prp myGF.properties test1/gfprops 对于test1 / gfprops规范，如果你在Unix文件系统中从/ testDir启动Geode系统成员，Geode会按此顺序查找文件，直到它找到文件或耗尽所有位置： /testDir/test1/gfprops /test1/gfprops under every location in your CLASSPATH for test1/gfprops 更改文件规范 您可以在gemfire.properties文件和命令行中更改所有文件规范。 注意: Geode应用程序可以使用API将java.lang.System属性传递给集群连接。 这会更改在命令行和gemfire.properties文件中生成的文件规范。 您可以在应用程序启动时记录的配置信息中验证应用程序的属性设置。 当gemfire.properties``log-level设置为config或更低时，会列出配置。 这个对应用程序testApplication.TestApp1的调用为cache.xml和gemfire.properties文件提供了非默认规范： java -Dgemfire.cache-xml-file=\\ /gemfireSamples/examples/dist/cacheRunner/queryPortfolios.xml \\ -DgemfirePropertyFile=defaultConfigs/gemfire.properties \\ testApplication.TestApp1 gfsh start server命令可以使用相同的规范： gfsh>start server \\ --J=-Dgemfire.cache-xml-file=/gemfireSamples/examples/dist/cacheRunner/queryPortfolios.xml \\ --J=-DgemfirePropertyFile=defaultConfigs/gemfire.properties 您还可以在gemfire.properties文件中更改cache.xml文件的规范。 注意: gemfire.properties文件中的规范不能使用环境变量。 示例gemfire.properties文件，带有非默认的cache.xml规范： #Tue May 09 17:53:54 PDT 2006 mcast-address=192.0.2.0 mcast-port=10333 locators=cache-xml-file=/gemfireSamples/examples/dist/cacheRunner/queryPortfolios.xml 在JAR文件中部署配置文件 本节提供了在JAR文件中部署配置文件的过程和示例。 程序 Jar文件。 将Apache Geode系统属性设置为指向存放在jar文件中的文件。 在你的CLASSPATH中包含jar文件 验证jar文件副本是运行时应用程序唯一可见的副本。 Geode在搜索其他位置后搜索CLASSPATH，因此这些文件在其他搜索区域中无法使用。 启动应用程序。 配置文件从jar文件加载。 部署配置JAR的示例 以下示例在my.jar中部署缓存配置文件myCache.xml。 以下显示了'my.jar`的内容： % jar -tf my.jar META-INF META-INF/MANIFEST.MF myConfig/ myConfig/myCache.xml 在此示例中，您将执行以下步骤来部署配置jar文件： 将系统属性gemfire.cache-xml-file设置为myConfig/myCache.xml。 将CLASSPATH设置为包含my.jar。 验证名为./myConfig/myCache.xml的文件系统中是否已有文件，因此Geode将被强制搜索jar文件以查找它。 启动应用程序时，将从jar文件加载配置文件。 启动和关闭系统 确定正确的启动和关闭过程，并编写启动和关闭脚本。 精心设计的启动和停止系统的程序可以加快启动速度并保护您的数据。 启动和停止所需的过程包括服务器和定位器进程以及您的其他Geode应用程序，包括客户端。 您使用的过程部分取决于系统的配置以及系统进程之间的依赖关系。 使用以下准则创建启动和关闭过程和脚本。 其中一些说明使用gfsh。 启动你的系统 您应该在启动Geode系统时,遵循一定的顺序准则。 在启动客户端应用程序之前启动服务器。 在每个集群中，请遵循以下成员启动准则： 首先启动定位器。 有关定位器启动命令的示例，请参阅运行Geode定位器进程。 在其余进程之前启动缓存服务器，除非实现要求在其之前启动其他进程。 有关服务器启动命令的示例，请参阅运行Geode服务器进程。 如果您的集群同时使用持久性复制和非持久性复制区域，则应在启动非持久性区域之前并行启动所有持久性复制成员。 这样，持久成员不会延迟其他持久成员使用以后的数据启动。 对于包含持久区域的系统，请参阅使用磁盘存储启动和关闭。 如果您正在运行生产者进程和消费者或事件侦听器进程，请首先启动消费者。 这可确保消费者和侦听器不会错过任何通知或更新。 如果您同时启动定位器和对等成员，则可以在进程启动时使用locator-wait-time属性（以秒为单位）。 此超时允许对等方在尝试加入集群之前等待定位器完成启动。 如果已将进程配置为等待定位器启动，则会记录信息级消息 GemFire初创公司无法联系定位器。 等待一个开始。 配置的定位器是frodo [12345]，pippin [12345] . 然后，该进程将休眠一秒钟并重试，直到它连接或者locator-wait-time中指定的秒数已经过去。 默认情况下，locator-wait-time设置为零，这意味着在启动时无法连接到定位器的进程将引发异常。 注意: 您可以选择覆盖关闭单个进程的默认超时期限。 必须在成员启动期间指定此覆盖设置。 有关详细信息，请参阅关闭系统。 在磁盘上丢失数据后启动 此信息与Geode磁盘存储文件的灾难性丢失有关。 如果丢失磁盘存储文件，则下一次启动可能会挂起，等待丢失的磁盘存储重新联机。 如果您的系统在启动时挂起，请使用gfsh命令show missing-disk-store列出缺少的磁盘存储，如果需要，还可以撤消丢失的磁盘存储，以便完成系统启动。 您必须使用磁盘存储ID来撤消磁盘存储。 这些是两个命令： gfsh>show missing-disk-stores Disk Store ID | Host | Directory ------------------------------------ | --------- | ------------------------------------- 60399215-532b-406f-b81f-9b5bd8d1b55a | excalibur | /usr/local/gemfire/deploy/disk_store1 gfsh>revoke missing-disk-store --id=60399215-532b-406f-b81f-9b5bd8d1b55a 注意: 此gfsh命令要求您通过JMX Manager节点连接到集群。 关闭系统 使用gfsh``shutdown命令关闭Geode系统，或者一次关闭一个成员。 使用shutdown命令 如果您正在使用持久性区域（成员将数据持久保存到磁盘），则应使用gfsh``shutdown命令以有序的方式停止正在运行的系统。 此命令在关闭之前同步持久分区区域，这使得集群的下一次启动尽可能高效。 如果可能，所有成员应在关闭之前运行，以便进行同步。 使用以下gfsh命令关闭系统： gfsh>shutdown 默认情况下，shutdown命令仅关闭数据节点。 如果要关闭包括定位器在内的所有节点，请指定--include-locators = true参数。 例如： gfsh>shutdown --include-locators=true 这将逐个关闭所有定位器，最后关闭管理器。 要在宽限期后关闭所有数据成员，请指定超时选项（以秒为单位）。 gfsh>shutdown --time-out=60 要在宽限期后关闭包括定位器在内的所有成员，请指定超时选项（以秒为单位）。 gfsh>shutdown --include-locators=true --time-out=60 单独关闭系统成员 如果您不使用持久性区域，则可以按照与启动相反的顺序关闭每个成员来关闭集群。 （有关成员启动的建议顺序，请参阅启动系统。） 根据成员的类型关闭集群成员。 例如，使用以下机制关闭成员： 使用适当的机制关闭集群中运行的任何与Geode连接的客户端应用程序。 关闭所有缓存服务器。 要关闭服务器，请发出以下gfsh命令： gfsh>stop server --name= 或者 gfsh>stop server --dir= 关闭任何定位器。 要关闭定位器，请发出以下gfsh命令： gfsh>stop locator --name= 或者 gfsh>stop locator --dir= 在正常情况下，不要使用命令行kill -9来关闭服务器。特别是在具有少量成员的系统上，使用kill而不是gfsh stop会导致分区检测机制将系统置于最终状态，该状态将永远等待重新连接到被杀死的服务器，并且 无法重启那个被杀死的服务器。 如果出现kill命令是摆脱服务器系统的唯一方法，那么kill all 集群的进程或使用kill -INT，这将允许有序关闭进程。 系统成员关闭行为的选项 DISCONNECT_WAIT命令行参数设置关闭过程中每个步骤的最长时间。 如果任何步骤花费的时间超过指定的数量，则强制结束。 每个操作都给出此宽限期，因此缓存成员关闭所需的总时间长度取决于操作数和“DISCONNECT_WAIT”设置。 在关机过程中，Geode会生成以下消息： Disconnect listener still running DISCONNECT_WAIT默认值是10000毫秒。 要更改它，请在用于成员启动的Java命令行上设置此系统属性。 例如： gfsh>start server --J=-DDistributionManager.DISCONNECT_WAIT= 每个进程可以有不同的DISCONNECT_WAIT设置。 运行Geode定位器进程 定位器是一个Geode进程，它告诉运行成员所在的新连接成员，并为服务器使用提供负载均衡。 您可以将定位器作为对等定位器，服务器定位器或两者运行： 对等定位器将连接成员的连接信息提供给已在定位器集群中运行的成员。 服务器定位器为客户端的集群中运行的服务器提供连接信息。 服务器定位器还监视服务器负载并将客户端发送到负载最少的服务器。 默认情况下，定位器作为对等和服务器定位器运行。 您可以独立运行定位器或嵌入另一个Geode过程。 独立运行定位器可提供定位器服务的最高可靠性和可用性。 定位器配置和日志文件 定位器配置和日志文件具有以下属性： 使用gfsh启动独立定位器时，gfsh会自动将所需的JAR文件lib/geode-dependencies.jar加载到JVM进程的CLASSPATH中。 如果使用LocatorLauncher API启动独立定位器，则必须在用于启动定位器进程的命令中指定此JAR文件。 有关Geode中CLASSPATH设置的更多信息，请参阅设置CLASSPATH。 您可以通过指定--classpath参数来修改CLASSPATH。 定位器是集群的成员，就像任何其他成员一样。 在“mcast-port”和“locators”配置方面，应该以与服务器相同的方式配置定位器。 因此，如果集群中还有另外两个定位器，则每个定位器应引用其他定位器（就像服务器成员一样）。 例如： gfsh> start locator --name=locator1 --port=9009 --mcast-port=0 \\ --locators='host1[9001],host2[9003]' 您可以在gemfire.properties文件中配置定位器，也可以在命令行上指定启动参数。 如果要在属性文件中指定定位器的配置，则定位器需要与集群的其他成员相同的gemfire.properties设置，并且如果使用单独的受限访问安全设置文件，则需要相同的gfsecurity.properties设置。 例如，在gemfire.properties：中配置定位器和多播端口 locators=host1[9001],host2[9003] mcast-port=0 没有特定于定位器的缓存配置。 对于日志记录输出，定位器在其当前工作目录中创建日志文件。 日志文件输出默认为定位器工作目录中的locator_name.log。 如果使用以前使用的定位器名称重新启动定位器，则会自动为您重命名现有的locator_name .log文件（例如，locator1-01-01.log或locator1-02-01.log）。 您可以通过在启动定位器时在--log-level参数中指定级别来修改此文件中的日志记录详细信息的级别。 默认情况下，定位器将从执行gfsh的目录下的子目录（以定位器命名）开始。 该子目录被视为当前工作目录。 在gfsh中启动定位器时，您还可以指定其他工作目录。 默认情况下，由于网络分区事件或成员无响应而已关闭和断开连接的定位器将自行重新启动并自动尝试重新连接到现有集群。 当定位器处于重新连接状态时，它不为集群提供任何发现服务。 有关详细信息，请参阅使用自动重新连接处理强制高速缓存断开连接。 定位器和集群配置服务 定位器使用集群配置服务来保存适用于所有集群成员或指定组成员的配置。 配置保存在Locator的目录中，并传播到集群中的所有定位器。 使用gfsh启动服务器时，服务器从定位器接收组级别和集群级别配置。 请参见集群配置服务概述。 启动定位器 使用以下准则启动定位器： 独立定位器. 以下列方式之一启动独立定位器： 使用gfsh命令行实用程序。 有关使用gfsh的更多信息，请参阅gfsh。 例如： gfsh>start locator --name=locator1 gfsh> start locator --name=locator2 --bind-address=192.0.2.0 --port=13489 使用org.apache.geode.distributed.LocatorLauncher类中的main方法和Java可执行文件启动定位器。 具体来说，您使用LocatorLauncher类API在您创建的Java应用程序进程中运行嵌入式Locator服务。 执行java命令的目录成为定位器进程的工作目录。 启动多个定位器时，不要并行启动它们（换句话说，同时启动它们）。 作为最佳实践，您应该等待大约30秒，以便第一个定位器在启动任何其他定位器之前完成启动。 要检查定位器的成功启动，请检查定位器日志文件。 要查看正在运行的定位器的正常运行时间，可以使用gfsh status locator命令。 嵌入式（共置）定位器. 在成员启动时或通过API管理共置定位器： 使用gemfire.properties``start-locator设置在Geode成员中自动启动定位器。 请参阅参考。 成员退出时定位器自动停止。 该属性具有以下语法： #gemfire.properties start-locator=[address]port[,server={true|false},peer={true|false}] Example: #gemfire.properties start-locator=13489 使用org.apache.geode.distributed.LocatorLauncher API启动代码中的定位器。 使用LocatorLauncher.Builder类构造LocatorLauncher的实例，然后使用start()方法启动嵌入在Java应用程序进程中的Locator服务。 LocatorLauncher类中的其他方法提供有关定位器的状态信息，并允许您停止定位器。 import org.apache.geode.distributed.LocatorLauncher; public class MyEmbeddedLocator { public static void main(String[] args){ LocatorLauncher locatorLauncher = new LocatorLauncher.Builder() .setMemberName(\"locator1\") .setPort(13489) .build(); locatorLauncher.start(); System.out.println(\"Locator successfully started\"); } } 这是另一个将定位器嵌入应用程序，启动它然后在允许其他成员访问它之前检查定位器状态的示例： package example; import ... class MyApplication implements Runnable { private final LocatorLauncher locatorLauncher; public MyApplication(final String... args) { validateArgs(args); locatorLauncher = new LocatorLauncher.Builder() .setMemberName(args[0]) .setPort(Integer.parseInt(args[1]) .setRedirectOutput(true) .build(); } protected void args(final String[] args) { ... } public void run() { ... // start the Locator in-process locatorLauncher.start(); // wait for Locator to start and be ready to accept member (client) connections locatorLauncher.waitOnStatusResponse(30, 5, TimeUnit.SECONDS); ... } public static void main(final String... args) { new MyApplication(args).run(); } } 然后执行应用程序，您将运行： /working/directory/of/MyApplication$ java \\ -server -classpath \"path/to/installation/lib/geode-dependencies.jar:/path/to/application/classes.jar\" \\ example.MyApplication Locator1 11235 执行java命令的目录成为定位器进程的工作目录。 检查定位器状态 如果使用gfsh连接到集群，则可以通过提供定位器名称来检查正在运行的定位器的状态。 例如： gfsh>status locator --name=locator1 如果未连接到集群，则可以通过提供进程ID，定位器的主机名和端口或定位器的当前工作目录来检查本地定位器的状态。 例如： gfsh>status locator --pid=2986 或者 gfsh>status locator --host=host1 --port=1035 或者 $ gfsh status locator --dir= 其中 locator_working_directory >对应于运行定位器的本地工作目录。 如果成功，该命令将返回以下信息（使用启动时提供的JVM参数）： $ gfsh status locator --dir=locator1 Locator in /home/user/locator1 on ubuntu.local[10334] as locator1 is currently online. Process ID: 2359 Uptime: 17 minutes 3 seconds GemFire Version: 8.0.0 Java Version: 1.8.0_121 Log File: /home/user/locator1/locator1.log JVM Arguments: -Dgemfire.enable-cluster-configuration=true -Dgemfire.load-cluster-configuration-from-dir=false -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /Users/username/apache_geode/lib/geode-dependencies.jar Cluster configuration service is up and running. 停止定位器 如果使用gfsh连接到集群，则可以通过提供定位器名称来停止正在运行的定位器。 例如： gfsh>stop locator --name=locator1 如果未连接到集群，则可以通过指定定位器的进程ID或定位器的当前工作目录来停止本地定位器。 例如： gfsh>stop locator --pid=2986 或者 gfsh>stop locator --dir= 其中 locator_working_directory >对应于运行定位器的本地工作目录。 定位器和多站点（WAN）部署 如果使用多站点（WAN）配置，则可以在启动定位器时将定位器连接到远程站点。 要将新定位器进程连接到WAN配置中的远程定位器，请在启动时指定以下内容： gfsh> start locator --name=locator1 --port=9009 --mcast-port=0 \\ --J='-Dgemfire.remote-locators=192.0.2.0[9009],198.51.100.0[9009]' 运行Geode服务器进程 Geode服务器是一个作为客户端/服务器系统的长期可配置成员运行的进程。 Geode服务器主要用于托管长期数据区域以及运行标准Geode进程，例如客户端/服务器配置中的服务器。 您可以使用以下方法启动和停止服务器： gfsh命令行工具。 以编程方式，通过org.apache.geode.distributed.ServerLauncher API。 ServerLauncher API只能用于以gfsh或ServerLauncher类本身启动的Geode服务器。 默认服务器配置和日志文件 gfsh实用程序为其配置文件和日志文件使用工作目录。 这些是默认值和配置选项： 使用gfsh启动独立服务器时，gfsh会自动将所需的JAR文件lib/geode-dependencies.jar加载到JVM进程的CLASSPATH中。 如果使用ServerLauncher API启动独立服务器，则必须在命令中指定此JAR文件以启动该过程。 有关Geode中CLASSPATH设置的更多信息，请参阅设置CLASSPATH。 服务器的配置与任何其他Geode进程一样，使用gemfire.properties和共享集群配置文件。 除了应用程序插件外，它不可编程。 通常，您提供gemfire.properties文件和gfsecurity.properties文件。 您还可以在缓存服务器的工作目录中指定cache.xml文件。 默认情况下，以“gfsh”启动的新服务器从集群配置服务接收其初始缓存配置，假设定位器正在运行集群配置服务。 如果在启动服务器时指定组，则服务器还会接收适用于组的配置。 共享配置包括cache.xml文件，gemfire.properties文件和部署的jar文件。 使用gfsh启动服务器时，可以通过指定--use-cluster-configuration = false来禁用集群配置服务。 请参见集群配置服务概述。 如果您使用的是Spring Framework，则可以使用--spring-xml-location命令行选项在gfsh中启动服务器时指定Spring ApplicationContext XML文件。 此选项允许您使用Spring应用程序的配置引导Geode服务器进程。 有关此文件的更多信息，请参阅Spring文档。 对于日志记录输出，日志文件输出默认为缓存服务器工作目录中的 .log。 如果重新启动具有相同服务器名称的服务器，则会自动重命名现有日志文件，例如server1-01-01.log和server1-02-01.log。 您可以通过在启动服务器时在--log-level参数中指定级别来修改此文件中的日志记录详细信息的级别。 默认情况下，服务器将在一个子目录中启动，该子目录以服务器指定的名称命名，位于执行gfsh的目录下。 该子目录被视为当前工作目录。 在gfsh中启动缓存服务器时，您还可以指定其他工作目录。 默认情况下，由于网络分区事件或成员无响应而已关闭和断开连接的服务器进程将自行重新启动并自动尝试重新连接到现有集群。 有关详细信息，请参阅使用自动重新连接处理强制高速缓存断开连接。 您可以在服务器启动时使用-J = -Dproperty.name = value将JVM参数传递到服务器的JVM。 这些参数可以是Java属性或Geode属性，例如gemfire.jmx-manager。 例如： gfsh>start server --name=server1 --J=-Dgemfire.jmx-manager=true \\ --J=-Dgemfire.jmx-manager-start=true --J=-Dgemfire.http-port=8080 我们建议您在启动服务器时不要使用-XX：+ UseCompressedStrings和-XX：+ UseStringCacheJVM配置属性。 这些JVM选项可能会导致数据损坏和兼容性问题。 使用gfsh启动服务器 有关语法信息，请参阅gfsh start server命令参考页。 这些示例gfsh start server start命令为缓存配置指定cache.xml文件，并使用不同的传入客户端连接端口： gfsh>start server --name=server1 \\ --cache-xml-file=../ServerConfigs/cache.xml --server-port=40404 gfsh>start server --name=server2 \\ --cache-xml-file=../ServerConfigs/cache.xml --server-port=40405 可以在gemfire.properties文件中定义cache.xml文件的位置和客户端连接端口的设置。 然后，启动指定gemfire.properties文件的服务器，如示例命令中所示： gfsh>start server --name=server1 \\ --properties-file=/home/username/cluster/gemfire.properties 要使用嵌入式JMX Manager启动服务器： gfsh>start server --name=server2 \\ --J=-Dgemfire.jmx-manager=true --J=-Dgemfire.jmx-manager-start=true 当在服务器启动期间指定--max-heap和--initial-heap时，代表您指定其他GC参数。 如果您不想设置其他默认GC属性，请使用-Xms和-Xmx JVM选项来设置这些参数。 有关详细信息，请参阅使用资源管理器控制堆使用。 要启动服务器，请提供JVM配置设置： gfsh>start server --name=server3 \\ --J=-Xms80m,-Xmx80m --J=-XX:+UseConcMarkSweepGC,-XX:CMSInitiatingOccupancyFraction=65 以编程方式启动服务器 使用org.apache.geode.distributed.ServerLauncher API在代码中启动缓存服务器进程。 使用ServerLauncher.Builder类构造ServerLauncher的实例，然后使用start（）方法启动服务器服务。 ServerLauncher类中的其他方法提供有关服务器的状态信息，并允许您停止服务器。 import org.apache.geode.distributed.ServerLauncher; public class MyEmbeddedServer { public static void main(String[] args){ ServerLauncher serverLauncher = new ServerLauncher.Builder() .setMemberName(\"server1\") .setServerPort(40405) .set(\"jmx-manager\", \"true\") .set(\"jmx-manager-start\", \"true\") .build(); serverLauncher.start(); System.out.println(\"Cache server successfully started\"); } } 检查服务器状态 在gfsh中连接到集群后，通过提供服务器名称来检查正在运行的缓存服务器的状态： gfsh>status server --name=server1 如果未连接到集群，则可以通过提供进程ID或服务器的当前工作目录来检查本地缓存服务器的状态。 例如： gfsh>status server --pid=2484 或者 % gfsh status server --dir=server1 如果成功，输出将提供此示例中的信息： % gfsh status server --dir=server4 Server in /home/username/server4 on 192.0.2.0[40404] as server4 is currently online. Process ID: 49008 Uptime: 2 minutes 4 seconds Geode Version: 1.7 Java Version: 1.8.0_144 Log File: /home/username/server4/server4.log JVM Arguments: ... 停止服务器 当连接到gfsh中的集群时，通过提供服务器名称来停止正在运行的缓存服务器： gfsh>stop server --name=server1 如果未连接，则可以通过指定服务器的当前工作目录或进程ID来停止本地缓存服务器。 例如： gfsh>stop server --pid=2484 或者 gfsh>stop server --dir=server1 您还可以使用gfsh shutdown命令以有序的方式关闭所有缓存服务器。 对于具有持久区域的系统，执行shutdown是正确的方法。 有关详细信息，请参阅启动和关闭系统。 管理系统输出文件 Geode输出文件是可选的，可以变得非常大。 与系统管理员一起确定放置它们的位置，以避免干扰其他系统活动。 Geode包括几种类型的可选输出文件，如下所述。 Log Files. 全面的日志消息，可帮助您确认系统配置并调试配置和代码中的问题。 在gemfire.properties文件中配置日志文件行为。 请参阅Logging。 Statistics Archive Files. 缓存和分发活动的标准统计信息，可以在磁盘上存档。 在gemfire.properties，archive-disk-space-limit和archive-file-size-limit中配置统计信息收集和归档。 请参阅参考。 Disk Store Files. 保持缓存中的持久性和溢出数据。 您可以配置区域以将数据持久保存到磁盘以进行备份或溢出到磁盘以控制内存使用。 服务器用于向客户端发送事件的订阅队列可以溢出到磁盘。 网关发件人自动将磁盘溢出到磁盘，并且可以持久保存以实现高可用性。 通过cache.xml配置它们。 请参阅磁盘存储。 防火墙注意事项 您可以为涉及防火墙的情况配置和限制端口使用，例如，在客户端 - 服务器或服务器 - 服务器连接之间。 Firewalls and Connections 请注意在计算机上运行防火墙可能导致的连接问题。 Firewalls and Ports 确保为防火墙正确配置了端口设置。 防火墙和连接 请注意在计算机上运行防火墙可能导致的连接问题。 Apache Geode是一个以网络为中心的分布式系统，因此如果您的计算机上运行了防火墙，则可能会导致连接问题。 例如，如果防火墙对基于Java的套接字的入站或出站权限设置了限制，则连接可能会失败。 您可能需要修改防火墙配置以允许流量到您计算机上运行的Java应用程序。 具体配置取决于您使用的防火墙。 例如，由于超时设置，防火墙可能会关闭与Geode的连接。 如果防火墙在某个时间段内未检测到任何活动，则可能会在活动恢复时关闭连接并打开新连接，这可能会导致您对哪些连接产生混淆。 有关Geode客户端和服务器如何连接的更多信息，请参阅以下主题： 客户端/服务器连接如何工作 套接字通信 控制套接字使用 设置套接字缓冲区大小 防火墙和端口 确保为防火墙正确配置了端口设置。 使用防火墙时需要考虑几种不同的端口设置： 缓存服务器侦听的端口。 这可以使用cache.xml中的cache-server元素，Java API中的CacheServer类，以及gfsh start server命令的命令行选项进行配置。 默认情况下，如果没有另外指定，Geode客户端和服务器会在localhost上的预定义端口( 40404 )上相互发现。 定位器端口。 Geode客户端可以使用定位器自动发现缓存服务器。 定位器端口可配置为gfsh start locator命令的命令行选项。 定位器用于对等缓存部署以发现其他进程。 客户端可以使用它们来定位服务器，作为使用一组服务器地址和端口配置客户端的替代方法。 默认情况下，如果没有另外指定，Geode定位器使用默认端口 10334 。 由于定位器启动集群，定位器还必须通过防火墙使其临时端口范围和TCP端口可供其他成员访问。 对于客户端，您将客户端配置为使用客户端池配置连接到服务器。 客户端的池配置有两个选项：您可以使用服务器元素列表或定位器元素列表创建池。 对于每个元素，指定主机和端口。 必须通过防火墙访问指定的端口。 限制短暂的端口以实现点对点成员资格 默认情况下，Geode分配 ephemeral 端口，即从指定范围分配的临时端口，可以包含大量可能的端口。 当存在防火墙时，短暂的端口范围通常必须限制为更小的数量，例如六个。 如果要通过防火墙配置P2P通信，则还必须为每个进程设置TCP端口，并确保允许UDP流量通过防火墙。 防火墙和端口配置的属性 此表包含可能涉及防火墙行为的属性，并提供每个属性的简要说明。 Configuration area Property or Setting Definition peer-to-peer config conserve-sockets 指定套接字是否由系统成员的线程共享。 peer-to-peer config locators 系统成员使用的定位器列表。 必须为集群的每个成员一致地配置列表。 peer-to-peer config mcast-address 用于发现集群的其他成员的地址。 仅在mcast-port为非零时使用。 此属性必须在整个集群中保持一致。 peer-to-peer config mcast-port 与mcast-address一起使用的端口，用于与集群的其他成员进行多播通信。 如果为零，则禁用多播以进行数据分发。 peer-to-peer config membership-port-range 可用于单播UDP消息传递和对等集群中的TCP故障检测的临时端口范围。 peer-to-peer config tcp-port 侦听缓存通信的TCP端口。 Configuration Area Property or Setting Definition cache server config hostname-for-clients 作为服务器正在侦听的位置传递给客户端的主机名或IP地址。 cache server config max-connections 服务器的最大客户端连接数。 达到最大值时，服务器拒绝其他客户端连接。 cache server config port (cache.xml) or --portparameter to the gfsh start server command 服务器侦听以进行客户端通信的端口。 默认端口配置 Port Name Related Configuration Setting Default Port Cache Server port (cache.xml) 40404 HTTP http-service-port 7070 Locator start-locator (for embedded locators) or --port parameter to the gfsh start locatorcommand. if not specified upon startup or in the start-locator property, uses default port 10334 Membership Port Range membership-port-range 1024 to 65535 Memcached Port memcached-port not set Multicast mcast-port 10334 RMI jmx-manager-port 1099 TCP tcp-port ephemeral port 多站点（WAN）配置中的防火墙和端口配置的属性 每个网关接收器使用单个端口接受来自其他系统中的网关发送器的连接。 网关接收器的配置指定要使用的一系列可能的端口值。 当网关接收器启动时，Geode从指定范围中选择一个可用端口。 配置防火墙，以便WAN上的网关发件人可以访问所有可能的端口值。 Configuration Area Property or Setting Definition multi-site (WAN) config for gateway sender hostname-for-senders 网关发件人用于连接的网关接收器的主机名或IP地址。 multi-site (WAN) config for locator remote-locators 远程WAN站点上可用的定位器（及其端口）列表。 multi-site (WAN) config for gateway receiver start-port and end-port (cache.xml) or --start-port and --end-port parameters to the gfsh start gateway receivercommand 网关接收器可用于侦听网关发送方通信的端口范围。 Copyright © WS 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-02-22 11:33:00 "},"Geode_3_Basic_Configuration_and_Programming.html":{"url":"Geode_3_Basic_Configuration_and_Programming.html","title":"基本配置和编程","keywords":"","body":"基本配置和编程集群和缓存配置集群成员设置属性配置缓存和数据区域的选项本地和远程成员身份和缓存缓存管理缓存管理简介管理对等或服务器缓存管理客户端缓存管理安全系统中的缓存管理多个安全用户的RegionServices 初始化缓存后启动应用程序数据区域区域管理区域命名区域快捷方式和自定义命名区域属性存储和检索区域快捷方式和自定义命名区域属性管理区域属性为区域和条目创建自定义属性用现有内容构建新区域数据条目管理数据条目在数据缓存中使用自定义类的要求基本配置和编程 基本配置和编程 介绍如何为Apache Geode安装配置集群和缓存属性。 对于您的应用程序，它提供了编写代码以管理缓存和集群连接，数据区域和数据条目（包括自定义类）的指导。 集群和缓存配置 要使用Apache Geode应用程序，可以使用配置文件和应用程序代码的组合。 缓存管理 Geode缓存是Geode缓存管理的入口点。 Geode提供不同的API和XML配置模型来支持不同成员的行为。 数据区域 该区域是Apache Geode集群的核心构建块。 所有缓存的数据都组织到数据区域中，您可以针对它们执行所有数据的放置，获取和查询活动。 数据条目 数据条目是存储数据的键/值对。 您可以单独和批量管理您的条目。 要将域对象用于条目值和键，您需要遵循Apache Geode要求进行数据存储和分发。 集群和缓存配置 要使用Apache Geode应用程序，可以使用配置文件和应用程序代码的组合。 集群成员 集群成员是连接到Geode集群的程序。 您将成员配置为属于单个集群，并且可以选择将它们配置为客户端或服务器以配置到其他集群中的成员，以及与其他集群通信。 设置属性 Geode为开箱即用的系统提供默认的集群配置。 要使用非默认配置并微调成员通信，可以使用各种选项的混合来自定义集群配置。 配置缓存和数据区域的选项 要填充Apache Geode缓存并微调其存储和分发行为，您需要定义缓存数据区域并为缓存和区域提供自定义配置。 本地和远程成员身份和缓存 对于许多Apache Geode讨论，您需要了解本地和远程成员资格和缓存之间的区别。 集群成员 集群成员是连接到Geode集群的程序。 您将成员配置为属于单个集群，并且可以选择将它们配置为客户端或服务器以配置到其他集群中的成员，以及与其他集群通信。 成员概述 集群成员（或简称“成员”）在创建Geode数据缓存时连接到Geode集群。 成员的集群通过Geode属性配置。 请参阅gemfire.properties和gfsecurity.properties(Geode Properties)。 Geode属性指定成员启动，初始化和通信的所有必要信息。 注意: 当成员连接到集群时，您无法更改成员的属性。 使用属性来定义： 如何查找和与其他成员沟通 如何执行日志记录和统计活动 哪个持久性配置或cache.xml文件用于缓存和数据区域初始化 其他选项，包括事件合并，如何处理网络丢失和安全设置 成员资格和系统拓扑 每个Geode进程都是集群的成员，即使集群被定义为独立的，只有一个成员。 您可以单独运行单个集群，也可以组合集群进行垂直和水平缩放。 请参阅拓扑和通信一般概念。 Peer-to-Peer Clusters. 定义相同成员发现属性的成员属于同一集群，并且彼此对等。 Client/Server Installations. 客户端/服务器拓扑使用您在多个集群的成员之间配置的关系。 您可以将一个集群中的部分或全部对等配置为从集群外部连接的客户端的缓存服务器。 每个服务器都可以托管许多客户端进程，在高效的垂直分层缓存配置中管理所有客户端的缓存访问。 您使用客户端缓存配置将客户端应用程序配置为连接到服务器。 客户端作为独立Geode集群的成员运行，没有对等体，因此所有数据更新和请求都将发送到服务器。 多站点安装 多站点拓扑使用您在多个集群的成员之间配置的关系。 通过此配置，您可以松散地耦合两个或更多集群以进行自动数据分发。 这通常针对地理位置不同的站点进行。 您可以使用网关发件人和/或网关接收器配置每个集群站点中的对等项子集，以管理在站点之间分发的事件。 在单个集群的上下文中，除非另有说明，否则“远程成员”指的是同一集群的另一个成员。 在客户端/服务器和多站点安装中，“远程”通常是指其他集群中的成员。 例如，所有服务器都是“远程”连接到它们的客户端。 每个客户端独立运行，仅连接到服务器层，因此所有服务器及其他客户端都是“远程”到单个客户端。 所有网关接收器都“远程”到网关发送器，这些发送器从其他集群连接到它们，并连接到那些网关发送器的对等体。 设置属性 Geode为开箱即用的系统提供默认配置。 要使用非默认配置并微调成员通信，可以使用各种选项的混合来自定义配置。 Geode属性用于连接集群并配置系统成员行为。 通过gemfire.properties文件，Java API或命令行输入配置Geode属性。 通常，您将所有属性存储在gemfire.properties文件中，但您可能需要通过其他方式提供属性，例如，为您从键盘输入接收的用户名和密码传入安全属性。 注意: 在通过API更改属性之前，请咨询Geode系统管理员，包括gemfire.properties和gfsecurity.properties设置。 系统管理员可能需要在命令行或配置文件中设置属性。 通过API进行的任何更改都将覆盖其他设置。 注意: 产品defaultConfigs目录有一个带有所有默认设置的示例gemfire.properties文件。 通过以下任意组合设置属性。 系统按列出的顺序查找设置： java.lang.System属性设置。 通常在命令行设置。 对于应用程序，请在代码或命令行中设置它们。 命名：以gemfire.property-name格式指定这些属性，其中property-name匹配gemfire.properties文件中的名称。 要设置gemfire属性文件名，请单独使用gemfirePropertyFile 在API中，在缓存创建调用之前设置System属性。 例： System.setProperty(\"gemfirePropertyFile\", \"gfTest\"); System.setProperty(\"gemfire.mcast-port\", \"10999\"); Cache cache = new CacheFactory().create(); 在java命令行中，使用-D开关传入System属性。 例： java -DgemfirePropertyFile=gfTest -Dgemfire.mcast-port=10999 test.Program 在“属性”对象中输入。 命名：使用gemfire.properties文件中的名称指定这些属性。 要设置gemfire属性文件名，请使用gemfirePropertyFile。 在API中，创建一个Properties对象并将其传递给缓存create方法。 例： Properties properties= new Properties(); properties.setProperty(\"log-level\", \"warning\"); properties.setProperty(\"name\", \"testMember2\"); ClientCache userCache = new ClientCacheFactory(properties).create(); 对于缓存服务器，将gfsh命令行上的属性文件作为命令行选项传递。 例： gfsh>start server --name=server_name --mcast-port=10338 --properties-file=serverConfig/gemfire.properties --security-properties-file=gfsecurity.properties 有关运行缓存服务器的详细信息，请参阅运行Geode服务器进程。 在gemfire.properties文件中输入。 请参见不使用集群配置服务部署配置文件。 例： cache-xml-file=cache.xml conserve-sockets=true disable-tcp=false 默认值。 默认值在org.apache.geode.distributed.ConfigurationProperties的API中定义。 配置缓存和数据区域的选项 要填充Apache Geode缓存并微调其存储和分发行为，您需要定义缓存数据区域并为缓存和区域提供自定义配置。 缓存配置属性定义： 缓存范围的设置，例如磁盘存储，通信超时以及将成员指定为服务器的设置 缓存数据区域 通过以下一种或多种方法配置缓存及其数据区域： 通过在发出使用gfsh命令行实用程序的命令时定义的持久性配置。 gfsh实用程序支持Apache Geode进程和应用程序的管理，调试和部署。 您可以使用gfsh配置区域，定位器，服务器，磁盘存储，事件队列和其他对象。 在发出命令时，gfsh会保存一组适用于整个集群的配置，并保存仅适用于集群中已定义成员组的配置。 您可以重复使用这些配置来创建集群。 请参见集群配置服务概述。 通过在cache-xml-file``gemfire.properties设置中命名的XML文件中的声明。 此文件通常称为cache.xml文件，但它可以具有任何名称。 请参阅cache.xml。 通过应用程序调用org.apache.geode.cache.CacheFactory，org.apache.geode.cache.Cache和org.apache.geode.cache.Region API。 本地和远程成员身份和缓存 对于许多Apache Geode讨论，您需要了解本地和远程成员资格和缓存之间的区别。 有关Geode成员资格和缓存活动的讨论通常会区分本地和远程。 本地缓存总是指向在讨论的中心成员，如果有一个这样明显的成员，而远程指的是其他成员。 如果没有明确的单一本地成员，则讨论会为成员分配名称以进行区分。 “成员Q本地”的操作，数据，配置等正在成员Q进程内运行或驻留。 “远离成员Q”的操作，数据，配置等正在运行或驻留在其他成员中。 本地缓存是属于本地成员的缓存。 所有其他缓存都是远程的，无论是在同一集群的其他成员中还是在不同的集群中。 缓存管理 Geode缓存是Geode缓存管理的入口点。 Geode提供不同的API和XML配置模型来支持不同成员的行为。 缓存管理简介 缓存为您的数据提供内存存储和管理。 管理对等或服务器缓存 您可以使用XML声明和API调用的组合来启动对等或服务器缓存。 完成后关闭缓存。 管理客户端缓存 您有多个客户端缓存配置选项。 使用XML声明和API调用的组合启动客户端缓存。 完成后关闭客户端缓存。 管理安全系统中的缓存 在安全系统中创建缓存时，您需要为连接过程提供凭据，以便已经运行的安全成员进行身份验证。 客户端连接到安全服务器。 对等方由安全定位器或对等成员进行身份验证。 管理多个安全用户的RegionServices 在安全系统中，您可以通过与每个客户端的服务器建立多个安全连接来创建客户端。 最常见的用例是嵌入在应用服务器中的Geode客户端，该服务器支持来自许多用户的数据请求。 可以授权每个用户访问服务器上的数据子集。 例如，可以允许客户用户仅查看和更新他们自己的订单和货件。 初始化缓存后启动应用程序 您可以指定在缓存初始化后启动的回调应用程序。 缓存管理简介 缓存为您的数据提供内存存储和管理。 您将缓存中的数据组织到数据区域中，每个数据区域都有自己的可配置行为。 您将数据存储在名为 data entries 的键/值对中的区域中。 缓存还提供事务，数据查询，磁盘存储管理和日志记录等功能。 有关org.apache.geode.cache.Cache的信息，请参阅Javadocs。 您通常使用gfsh命令行实用程序或XML声明和API调用的组合来配置缓存。 首次创建缓存时，Geode会加载并处理您的XML声明。 Geode有一种用于管理服务器和对等缓存的缓存类型，另一种用于管理客户端缓存。 缓存服务器进程在启动时自动创建其服务器缓存。 在应用程序进程中，缓存创建将返回服务器/对等或客户端缓存的实例。 从那时起，您可以通过应用程序中的API调用来管理缓存。 缓存API Geode的缓存API为不同的系统成员类型和安全设置提供专门的行为。 org.apache.geode.cache.RegionService. 通常，您通过Cache和ClientCache的实例使用RegionService功能。 您只在为许多用户提供服务的安全客户端应用程序中为受限访问用户专门使用RegionService实例。 RegionService API提供对现有缓存数据区域和缓存的标准查询服务的访问。 对于客户端缓存，查询将发送到服务器层。 对于服务器和对等缓存，查询在当前缓存和任何可用对等体中运行。 RegionService由GemFireCache实现。 org.apache.geode.cache.GemFireCache. 你没有专门使用GemFireCache的实例，但你在Cache和ClientCache的实例中使用GemFireCache功能。 GemFireCache扩展了RegionService并添加了一般缓存功能，如区域属性，区域持久性和溢出的磁盘存储以及对底层集群的访问。 GemFireCache由Cache和ClientCache实现。 org.apache.geode.cache.Cache. 使用Cache接口来管理服务器和对等缓存。 每个服务器或对等进程都有一个Cache。 Cache扩展了GemFireCache并添加了服务器/对等缓存功能，如集群内的通信，区域创建，事务和查询以及缓存服务器功能。 org.apache.geode≈setting_cache_initializer.cache.ClientCache. 使用ClientCache接口管理客户端中的缓存。 每个客户端进程有一个ClientCache。 “ClientCache”扩展了“GemFireCache”并添加了客户端特定的缓存功能，如客户端区域创建，持久客户端的订阅保持活动管理，查询服务器和客户端层，以及RegionService创建，以便客户端内的多个用户进行安全访问。 缓存XML 您的cache.xml必须根据产品XML模式定义cache-1.0.xsd进行格式化。 架构定义文件位于http://geode.apache.org/schema/cache/cache-1.0.xsd。 您可以将一种格式用于对等和服务器缓存，将另一种格式用于客户端缓存。 对等/服务器的cache.xml： ... 客户端的cache.xml： ... 有关cache.xml文件的更多信息，请参阅cache.xml。 创建并关闭缓存 启动成员进程并创建每个成员的Geode缓存时，将初始化您的系统配置和缓存配置。 如果您使用的是集群配置服务，则成员进程可以从集群或组的当前配置中获取其缓存配置。 请参见集群配置服务概述。 本节中的步骤使用gemfire.properties和cache.xml文件示例，除非需要API。 您也可以通过API配置集群属性和缓存，并且可以使用文件配置和API配置的组合。 XML示例可能不包含完整的cache.xml文件列表。 所有声明性缓存配置必须符合http://geode.apache.org/schema/cache/cache-1.0.xsd上的缓存XSD。 对于您的所有Geode应用程序： 为客户端应用程序创建用于对等/服务器应用程序的Cache或ClientCache。 这将连接到您已配置的Geode系统，并初始化任何已配置的数据区域。 使用缓存实例访问您的区域并执行应用程序工作。 完成后关闭缓存。 这将释放资源并以有序的方式断开应用程序与集群的连接。 按照缓存管理下的子主题中的说明自定义缓存创建和关闭以满足您的应用程序需求。 您可能需要组合多个指令集。 例如，要在具有安全性的系统中创建客户端缓存，您可以按照创建和关闭客户端缓存以及在安全系统中创建和关闭缓存的说明进行操作。 导出和导入缓存快照 为了帮助管理缓存数据并加快新环境的设置，您可以导出整个缓存（所有区域）的快照，然后将快照导入新缓存。 例如，您可以获取生产环境缓存的快照，以便将缓存的数据导入测试环境。 有关导出和导入缓存快照的更多详细信息，请参阅缓存和区域快照。 使用gfsh和集群配置服务进行缓存管理 您可以使用gfsh命令管理服务器缓存。 有gfsh命令可用于创建区域，启动服务器以及创建队列和其他对象。 在发出这些命令时，Cluster Configuration Service会在定位器上保存cache.xml和gemfire.properties文件，并将这些配置分发给任何加入集群的新成员。 请参见集群配置服务概述。 管理对等或服务器缓存 您可以使用XML声明和API调用的组合来启动对等或服务器缓存。 完成后关闭缓存。 Geode对等体是Geode集群的成员，它不充当另一个Geode集群的客户端。 Geode服务器是同时监听和处理客户端请求的对等服务器。 创建缓存： 启动集群和集群配置服务： 启动“--enable-cluster-configuration”设置为true的定位器。 （默认设置为true。） gfsh>start locator --name=locator1 启动使用集群配置服务的成员进程（默认情况下启用）： gfsh>start server --name=server1 --server-port=40404 创建区域： gfsh>create region --name=customerRegion --type=REPLICATE gfsh>create region --name=ordersRegion --type=PARTITION 或者，如果您未使用集群配置服务，请直接在集群的每个成员中配置cache.xml。 在cache.xml中，使用cache DOCTYPE并在元素中配置缓存。 例： // NOTE: Use this element only for server processes 以编程方式创建Cache实例： 在Java应用程序中，使用CacheFactory创建方法： Cache cache = new CacheFactory().create(); 如果您使用Geodecacheserver进程运行服务器，它会在启动时自动创建缓存和连接，并在退出时关闭它们。 系统根据您的gemfire.properties和cache.xml规范创建连接并初始化缓存。 使用Cache实例的继承close方法完成后关闭缓存： cache.close(); 管理客户端缓存 您有多个客户端缓存配置选项。 使用XML声明和API调用的组合启动客户端缓存。 完成后关闭客户端缓存。 Geode客户端是将大部分或全部数据请求和更新发送到Geode服务器系统的进程。 客户端作为独立进程运行，没有自己的同级进程。 注意: Geode自动为您的ClientCache配置集群，这意味着客户端没有对等体。 不要尝试为客户端应用程序设置gemfire.properties``mcast-port或locators，否则系统将抛出异常。 创建客户端缓存： 在cache.xml中，使用client-cache DOCTYPE并在元素中配置缓存。 根据需要配置服务器连接池和区域。 例： 注意: 使用client-cache的应用程序可能希望为区域设置concurrency-checks-enabled为false，以便查看该区域的所有事件。 Geode服务器成员可以继续使用并发检查，但是它们会将所有事件传递到客户端缓存。 此配置可确保客户端查看所有区域事件，但不会阻止客户端缓存区域与服务器缓存不同步。 请参阅区域更新的一致性。 如果使用多个服务器池，请为每个客户端区域显式配置池名称。 例： 在Java客户端应用程序中，使用ClientCacheFactory``createmethod创建缓存。 例： ClientCache clientCache = new ClientCacheFactory().create(); 这将创建服务器连接并根据您的gemfire.properties和cache.xml规范初始化客户端的缓存。 使用Cache实例的close方法完成后关闭缓存： cache.close(); 如果您的客户端是持久的，并且您希望在关闭客户端缓存时维护持久队列，请使用： clientCache.close(true); 管理安全系统中的缓存 要在安全系统中创建缓存，连接时的身份验证将需要凭据。 授权允许按配置操作。 这些步骤演示了程序化缓存创建。 要创建缓存： 向gemfire.properties或gfsecurity.properties文件添加必要的安全属性，以配置您的特定安全实现。 例子： security-client-auth-init=mySecurity.UserPasswordAuthInit.create security-peer-auth-init=myAuthPkg.myAuthInitImpl.create 创建缓存时，请使用以下方法之一将安全实现所需的任何属性传递给缓存工厂创建调用： ClientCacheFactory or CacheFactory set methods. Example: ClientCache clientCache = new ClientCacheFactory() .set(\"security-username\", username) .set(\"security-password\", password) .create(); 传递给ClientCacheFactory或CacheFactory``create方法的Properties对象。 这些通常是敏感性质的属性，您不希望将它们放在gfsecurity.properties文件中。 例： Properties properties = new Properties(); properties.setProperty(\"security-username\", username); properties.setProperty(\"security-password\", password); Cache cache = new CacheFactory(properties).create(); 注意: 传递给缓存创建方法的属性会覆盖gemfire.properties文件或gfsecurity.properties中的任何设置。 完成后关闭缓存，使用ClientCache实例的close方法或Cache实例的继承close方法。 例： cache.close(); 管理多个安全用户的RegionServices 在安全系统中，您可以通过与每个客户端的服务器建立多个安全连接来创建客户端。 最常见的用例是嵌入在应用服务器中的Geode客户端，该服务器支持来自许多用户的数据请求。 可以授权每个用户访问服务器上的数据子集。 例如，可以允许客户用户仅查看和更新他们自己的订单和货件。 在单个客户端中，多个经过身份验证的用户都可以通过RegionService接口的实例访问相同的ClientCache。 由于有多个用户具有不同的授权级别，因此对缓存数据的访问完全通过服务器完成，其中可以管理每个用户的授权。附加得步骤请参照 管理安全系统中的缓存. 创建缓存和RegionService实例： 配置客户端的服务器池以进行多个安全用户身份验证。 例： 这样就可以通过池访问RegionService实例，并为ClientCache实例禁用它。 在您的ClientCache实例创建ClientCache之后，为每个用户调用createAuthenticatedView方法，提供用户的特定凭据。 这些是两个用户的create方法调用： Properties properties = new Properties(); properties.setProperty(\"security-username\", cust1Name); properties.setProperty(\"security-password\", cust1Pwd); RegionService regionService1 = clientCache.createAuthenticatedView(properties); properties = new Properties(); properties.setProperty(\"security-username\", cust2Name); properties.setProperty(\"security-password\", cust2Pwd); RegionService regionService2 = clientCache.createAuthenticatedView(properties); 对于每个用户，通过指定的RegionServiceinstance完成所有缓存和区域的工作。 对服务器缓存的访问将受服务器为每个用户配置的授权规则的约束。 通过仅关闭“ClientCache”实例来关闭缓存。 不要先关闭RegionService实例。 这是持久的客户来说尤其重要。 RegionService的要求和注意事项 创建每个区域后，您可以通过ClientCache实例或RegionService实例对其执行操作，但不能同时对它们执行操作。 注意: 您可以使用ClientCache创建一个区域，该区域使用为多用户身份验证配置的池，然后使用您的RegionService实例访问并对该区域进行操作。 要使用RegionService，必须将区域配置为EMPTY。 根据您的数据访问要求，此配置可能会影响性能，因为客户端会在每次获取时转到服务器。 初始化缓存后启动应用程序 您可以指定在缓存初始化后启动的回调应用程序。 通过在cache.xml文件中指定元素，可以触发回调应用程序，该应用程序在初始化缓存后运行。 使用cacheserver脚本启动服务器的应用程序也可以使用此功能挂钩到回调应用程序。 要使用此功能，需要在元素中指定回调类。 应该将此元素添加到cache.xml文件的末尾。 您可以为服务器缓存或客户端缓存指定元素。 回调类必须实现Declarable接口。 加载回调类时，调用其init方法，并将元素中定义的任何参数作为属性传递。 以下是示例规范。 在cache.xml中： MyInitializer 2 这是相应的类定义： import org.apache.geode.cache.Declarable; public class MyInitializer implements Declarable { public void init(Properties properties) { System.out.println(properties.getProperty(\"members\")); } } 以下是一些其他实际使用场景： 启动SystemMembershipListener TestSystemMembershipListener 编写一个监视缓存资源的自定义工具 ResourceMonitorCacheXmlLoader 可以使用initializer元素实例化和启动任何单例或计时器任务或线程。 数据区域 该区域是Apache Geode集群的核心构建块。 所有缓存的数据都组织到数据区域中，您可以针对它们执行所有数据的放置，获取和查询活动。 区域管理 Apache Geode提供gfsh命令，API和XML配置模型，以支持数据区域的配置和管理。 区域命名 为了能够对您的数据区域执行所有可用操作，请遵循这些区域命名准则。 区域快捷方式和自定义命名区域属性 Geode提供区域快捷方式设置，其中包含最常见区域类型的预设区域配置。 对于最简单的配置，请从快捷方式设置开始，并根据需要进行自定义。 您还可以将自己的自定义配置存储在缓存中以供多个区域使用。 存储和检索区域快捷方式和自定义命名区域属性 使用这些示例开始使用Geode区域快捷方式。 管理区域属性 使用区域属性可以微调区域快捷方式设置提供的区域配置。 为区域和条目创建自定义属性 使用自定义属性可以在缓存中存储与您的区域或其条目相关的信息。 这些属性仅对本地应用程序可见，并且不会分发。 用现有内容构建新区域 可能需要使用现有系统的数据加载新的区域或集群。 有两种方法可以完成此任务。 使用的方法取决于新集群和现有集群的组织。 区域管理 创建，销毁，无效，清除和更改区域配置的操作可以使用gfsh命令，XML描述和API调用。 将数据存储在区域条目键/值对中，键和值是应用程序所需的任何对象类型。 org.apache.geode.cache.Region接口实现了java.util.Map。 每个区域的属性定义如何存储，分发和管理区域中的数据。 数据区域可以在系统成员之间分配，分区，也可以在成员本地分配。 区域快捷方式 识别常用的区域类型。 有关详细信息，请参阅区域快捷方式。 注意: 如果更改定义区域的属性，则必须重新启动成员才能使更改生效。 创建区域 使用gfsh创建区域 在Apache Geode缓存中创建数据区域的一种简单快捷的方法是使用gfshcommand-line工具。 区域创建受属性一致性检查的约束，这两者都在缓存内部，如果区域不是本地，则在定义区域的所有缓存之间。 gfsh create region 命令参考页详细说明了使用创建区域的命令行选项gfsh。 将gfsh连接到JMX服务器时，创建复制区域的示例命令是 gfsh>create region --name=region1 --type=REPLICATE 导出服务器的配置文件，以便在下次启动缓存服务器时保存区域的配置并重新创建具有相同属性的区域。 有关详细信息，请参阅export config。 注意: 默认情况下启用的集群配置服务会自动将配置保存在集群中的定位器上。 使用gfsh create region命令后，您启动的任何连接到同一定位器的新服务器都会收到相同的配置。 您还可以通过在创建区域和启动服务器时指定组来在集群中创建备用配置。 请参见集群配置服务概述。 通过cache.xml文件创建区域 在Apache Geode缓存中创建数据区域的常用方法是通过cache.xml声明。 使用cache.xml文件启动成员时，将创建该区域。 区域创建受属性一致性检查的约束，这两者都在缓存内部，如果区域不是本地，则在定义区域的所有缓存之间。 在cache.xml文件中，为新区域创建一个元素作为元素或元素的子元素。 定义区域名称并使用区域快捷方式（如果适用）。 根据需要添加其他属性以自定义区域的行为。 cache.xml文件示例 名为Portfolios的复制区域的region声明： 名为myRegion的分区区域的region声明： 将内容备份到磁盘的分区区域的region声明： 在区域中配置了高可用性和修改后的存储容量的分区区域的region声明： 复制区域的region声明，配置了一个事件监听器，其中条目到期： myPackage.MyCacheListener 通过API创建区域 Geode的区域API为不同的系统成员类型提供专门的行为。 对等/服务器 区域API 使用这些方法，接口和类来创建对等/服务器区域。 这些都在org.apache.geode.cache package. 它们对应于cache.xml 内部的声明用于创建和配置区域的元素。 org.apache.geode.cache.Cache.createRegionFactory . 这个方法采用RegionShortcut enum来启动区域配置，并返回一个RegionFactory。 使用createRegionFactory()而不是new RegionFactory来创建RegionFactory。 org.apache.geode.cache.RegionFactory. 提供设置单个区域属性和创建区域的方法。 create调用返回一个Region。 org.apache.geode.cache.RegionShortcut. 定义公共区域配置。 Client Region APIs. 使用这些方法，接口和类来创建客户端区域。 它们位于org.apache.geode.cache.client包中。 它们对应于元素中的cache.xml声明，用于创建和配置区域。 这些是对等/服务器区域API的客户端版本。 这些客户端API提供类似的功能，但是根据客户区域的需求和行为进行定制。 org.apache.geode.cache.clientCache.createRegionFactory . 这个方法使用ClientRegionShortcut enum来启动区域配置，并返回一个ClientRegionFactory。 org.apache.geode.cache.client.ClientRegionFactory. 提供设置单个区域属性和创建区域的方法。 create调用返回Region。 org.apache.geode.cache.client.ClientRegionShortcut . 定义公共区域配置。 Region APIs Used For All Member Types. 这些接口和类通常用于区域管理。 它们位于org.apache.geode.cache包中。 它们对应于和元素中的cache.xml声明，用于创建和配置区域。 org.apache.geode.cache.Region . 用于管理区域及其条目的接口。 org.apache.geode.cache.RegionAttributes . 对象保持区域配置设置。 使用API在启动后在缓存中创建区域。 对于运行时区域创建，您需要使用API。 区域创建受属性一致性检查的约束，这两者都在缓存内部，如果区域不是本地，则在定义区域的所有缓存之间。 使用区域快捷方式创建区域工厂。 在对等体和服务器中，使用org.apache.geode.cache.RegionFactory。 在客户端中，使用org.apache.geode.cache.client.ClientRegionFactory。 (可选的) 使用区域工厂进一步配置您的区域。 从配置的区域工厂创建您的区域。 API 例子 创建名为Portfolios的复制区域： Cache cache = CacheFactory.create(); RegionFactory rf = cache.createRegionFactory(REPLICATE); Region pfloRegion = rf.create(\"Portfolios\"); 使用侦听器创建分区区域： RegionFactory rf = cache.createRegionFactory(RegionShortcut.PARTITION); rf.addCacheListener(new LoggingCacheListener()); custRegion = rf.create(\"customer\"); 创建一个分区区域，其中包含用于共处区域的分区解析程序： PartitionAttributesFactory paf = new PartitionAttributesFactory(); paf.setPartitionResolver(new CustomerOrderResolver()); RegionFactory rf = cache.createRegionFactory(RegionShortcut.PARTITION); rf.setPartitionAttributes(paf.create()); rf.addCacheListener(new LoggingCacheListener()); custRegion = rf.create(\"customer\"); 使用池规范创建客户区域： ClientRegionFactory cRegionFactory = cache.createClientRegionFactory(PROXY); Region region = cRegionFactory.setPoolName(\"Pool3\").create(\"DATA\"); 创建和访问数据子区域 单个区域可以包含多个子区域。 子区域是一项较旧的功能，在新设计和应用程序中无用。 它们用于在缓存中创建分层命名空间，提供与文件系统中的路径类似的命名。 以下是对次区域使用的限制： 具有LOCAL范围的区域只能具有LOCAL范围的子区域。 分区区域类型不能与子区域一起使用。 子区域可能没有作为分区区域的父级，子区域可能不是PARTITION类型。 子区域必须具有与其父区域相同的范围（GLOBAL，DISTRIBUTED_ACK，DISTRIBUTED_NO_ACK）。 子区域名称在缓存中必须是唯一的。 您可以使用以下方法之一创建子区域： cache.xml中的声明： ... 在创建缓存时加载cache.xml时，系统会自动创建任何声明的区域和子区域。 RegionFactory API调用： Cache cache = CacheFactory.create(); RegionFactory rf = cache.createRegionFactory(REPLICATE); Region pfloRegion = rf.create(\"Portfolios\"); Region pvtSubregion = rf.createSubregion(pfloRegion, \"Private\"); 带有recursive参数的Region方法调用对给定的区域进行操作，然后对所有包含的子区域进行递归操作。 更新数据区域的配置 通过alter region命令，API或cache.xml文件声明更新您的区域属性和内容。 使用gfsh alter region命令。 在API中，使用Cache和Region方法来更改配置参数并修改区域结构和数据。 使用Cache.loadCacheXml方法加载新的XML声明。 在可能的情况下，新的cache.xml文件中的声明将取代现有的定义。 例如，如果在cache.xml文件中声明的区域已经存在于缓存中，则根据文件声明修改其可变属性。 不可变属性不受影响。 如果某个区域尚不存在，则会创建该区域。 根据缓存状态和文件声明创建或更新条目和索引。 使区域无效 无效(Invalidate )区域操作将删除区域的所有条目值，同时保持条目的键不变。 只能通过Region实例上的API调用此操作。 发生事件通知。 // Invalidate the entire distributed region Region.invalidateRegion(); API还提供了一种方法，仅使本地缓存中的条目无效。 此方法可能不会在复制区域上使用，因为这样做会使复制协定无效。 // Invalidate the region within this member Region.localInvalidateRegion(); 清除区域 清除(clear )区域操作将删除区域中的所有条目。 此操作不适用于分区区域。 可以通过Region实例上的API调用此操作： // Remove all entries for the region Region.clear(); 它可以使用gfsh命令调用： gfsh>remove --region=Region1 --all 清除区域操作发生事件通知。 销毁区域 销毁(destroy )区域操作移除整个区域。 可以通过Region实例上的API调用此操作： // Remove the entire region Region.destroyRegion(); 可以使用gfsh命令调用destroy区域操作： gfsh>destroy region --name=Region1 销毁区域操作发生事件通知。 可以通过从cache.xml文件中删除区域的规范来销毁区域。 在所有成员联机时通过API调用或使用gfsh destroy命令销毁区域是删除区域的最佳方式，因为Geode处理删除的所有方面，包括删除区域的在线成员的持久磁盘存储 主办该地区。 通过从cache.xml文件中删除其规范来销毁该区域不会删除该区域的现有永久磁盘存储。 销毁操作只能传播给在线成员。 如果某个区域在线并且其他成员处于脱机状态时，系统将遇到重启问题。 作为脱机重启的成员，它们将无限期地阻塞，等待不再存在的持久区域数据。 要解决此问题，请关闭所有被阻止等待删除区域的成员。 一旦这些成员处于脱机状态，使用gfsh alter disk-store命令和每个脱机成员上的--remove选项来删除该区域。 然后，重新启动每个成员。 边缘情况在通过从cache.xml文件中删除其规范来销毁持久区域（R-removed）时导致问题，并且区域R-removed与另一个持久区域（R-remain）共存。 出现此问题是因为R-remaining中包含的持久性信息与R-removed的（缺乏）规范不一致。 重新启动R-remain后，其持久化元数据将R-remove视为共置区域，R-remaining的启动依赖于已删除的区域。 因此，R-started的启动仍然无法完成。 该问题可能表现为R-still区域上的操作，例如查询，放置或获取，从未完成。 要解决此问题，请使用引用已删除区域的持久元数据关闭所有成员。 一旦这些成员处于脱机状态，使用gfsh alter disk-store命令和每个脱机成员上的--remove选项删除该区域。 然后，重新启动每个成员。 关闭区域 使用此选项可以在不关闭整个缓存的情况下停止持久和分区区域的本地缓存： Region.close(); Region.close操作就像Region.localDestroyRegion操作一样，具有以下显着差异： 为区域上安装的每个回调调用close方法。 没有调用任何事件。 特别值得注意的是，不调用入口事件beforeDestroy和afterDestroy，以及区域事件beforeRegionDestroy和afterRegionDestroy。 请参阅事件和事件处理。 如果持久，则从内存中删除该区域，但保留其磁盘文件。 如果已分区，则从本地缓存中删除该区域。 如果分区区域是冗余的，则本地数据缓存会故障转移到另一个缓存。 否则，本地数据将丢失。 区域命名 为了能够对您的数据区域执行所有可用操作，请遵循这些区域命名准则。 区域名称中允许的字符是字母数字字符（ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789），下划线字符（_）和连字符（-）。 不要使用斜杠字符（/）。 不要使用两个下划线字符（__）开始区域名称，因为这是为内部使用而保留的。 区域快捷方式和自定义命名区域属性 Geode提供区域快捷方式设置，其中包含最常见区域类型的预设区域配置。 对于最简单的配置，请从快捷方式设置开始，并根据需要进行自定义。 您还可以将自己的自定义配置存储在缓存中以供多个区域使用。 您可以通过区域快捷方式和区域属性配置数据区域及其条目的自动管理。 这些区域配置设置确定数据所在的位置，内存中如何管理区域，可靠性行为以及数据条目的自动加载，分发和到期等内容。 注意: 尽可能使用区域快捷方式配置您的区域，并使用区域属性进一步自定义行为。 快捷方式设置使用最常见的区域配置进行预设。 Geode提供了许多预定义的快捷方式区域属性设置供您使用。 您还可以定义自己的自定义区域属性，并使用标识符存储它们以供以后检索。 两种类型的存储属性都称为命名区域属性。 您可以在cache.xml文件中通过API创建和存储属性设置。 通过在refid属性设置中为区域创建提供ID来检索区域快捷方式和自定义命名属性。 此示例使用快捷方式REPLICATE属性创建区域： 您可以根据需要通过在区域属性声明中提供id来创建自己的命名属性。 以下区域声明： 检索持久分区区域快捷方式提供的所有属性设置 通过指定用于持久性的磁盘存储名称来修改快捷方式属性设置 将新属性设置分配给名为testPR的新区域 将属性设置存储在名为testPRPersist的新自定义属性中： PRPersist1 PRPersist2 快捷方式属性选项 您可以从Geode在这些类中预定义的命名区域属性中选择最常用的区域属性设置： org.apache.geode.cache.RegionShortcut. 对于对等和服务器。 org.apache.geode.cache.client.ClientRegionShortcut. 对于客户端。 快捷方式属性仅为方便起见。 它们只是Geode已经为您存储的命名属性。 您可以通过存储与预定义属性具有相同ID的新属性来覆盖其设置。 有关所有可用区域快捷方式的完整列表，请参阅区域快捷方式快速参考。 org.apache.geode.cache.RegionShortcut Javadocs提供了完整的选项列表。 对等和服务器的RegionShortcuts 这些是区域快捷方式设置中可用的主要选项。 列出的名称单独或组合显示在快捷方式标识符中，如“PARTITION”，“PARTITION_PROXY”和“PARTITION_REDUNDANT”中的“PARTITION”。 缓存数据存储模式 PARTITION 创建分区区域。 这是该地区的数据存储。 您也可以使用指定这些选项PARTITION: PROXY. 数据不存储在本地缓存中，成员是该区域的数据访问者。 这需要其他成员创建该区域的非代理副本，因此数据存储在某处。 REDUNDANT. 该区域存储所有数据的辅助副本，以实现高可用性。 REPLICATE 创建复制区域。 这是该地区的数据存储。 您也可以使用指定这些选项REPLICATE: PROXY. 数据不存储在本地缓存中，成员是该区域的数据访问者。 这需要其他成员创建该区域的非代理副本，因此数据存储在某处。 LOCAL. 创建一个专用于定义成员的区域。 Data Eviction HEAP_LRU.当Geode资源管理器确定缓存已达到配置的存储限制时，导致最近最少使用的数据从内存中逐出。 Disk Storage 您可以单独或组合指定这些： PERSISTENT. 除了将所有数据存储在内存中之外，还将所有数据备份到磁盘。 OVERFLOW. 当内存使用率过高时，将数据从内存中移出并移至磁盘上。 客户端的ClientRegionShortcuts  这些是客户端区域快捷方式设置中可用的主要选项。 列出的名称单独或组合出现在快捷方式标识符中，如“PROXY”和“CACHING_PROXY”中的“PROXY”。 与服务器和数据存储的通信 PROXY. 不将数据存储在客户端缓存中，而是将区域连接到服务器以进行数据请求和更新，兴趣注册等。 客户端是该地区的数据访问者。 CACHING_PROXY. 将数据存储在客户端缓存中，并将该区域连接到服务器以进行数据请求和更新，兴趣注册等。 LOCAL. 将数据存储在客户端缓存中，并且不将该区域连接到服务器。 这是一个仅限客户端的区域。 请注意，这与将区域的scope属性设置为LOCAL不同。 Data Eviction HEAP_LRU. 当Geode资源管理器确定缓存已达到配置的存储限制时，导致最近最少使用的数据从内存中逐出。 Disk Storage 使用LOCAL和CACHING数据存储快捷方式选项，您还可以单独或组合指定这些磁盘存储选项： PERSISTENT. 除了将所有数据存储在内存中之外，还将所有数据备份到磁盘。 OVERFLOW. 当内存使用率过高时，将数据从内存中移出并移至磁盘上。 存储和检索区域快捷方式和自定义命名区域属性 使用这些示例开始使用Geode区域快捷方式。 对于对等方和服务器的org.apache.geode.cache.RegionShortcut和用于客户端的org.apache.geode.cache.client.ClientRegionShortcut的Geode区域快捷方式，无论您在cache.xml中创建区域，都可以使用或通过API。 您存储的自定义命名属性从您存储它们的那一刻起就可用。 区域快捷方式是特殊的Geode命名区域属性，具有标识名称。 通过设置属性并使用区域属性id中的唯一标识符存储属性来创建自定义命名区域属性。 通过提供快捷枚举值或您在id中为区域创建指定的名称来检索命名属性： 在API中，使用区域工厂创建中的标识符 在cache.xml中，使用或``refid设置中的标识符。 为方便起见，refid在两个元素中都可用 例子 Example #1 此示例显示cache.xml中的分区区域创建： 第一个region-attributes声明以预定义的PARTITION_REDUNDANT属性开头，修改local-max-memory设置，并将结果属性存储在自定义命名的myPartition属性中。 区域声明使用新存储的属性，但每个属性都有自己的兴趣策略，该策略在单个区域创建中指定。 Example #2 这个例子使用RegionFactory API根据预定义的PARTITION区域快捷方式创建一个区域： final Region diskPortfolios = new RegionFactory(\"PARTITION\").create(\"Portfolios\"); 此示例检索属性模板，并使用修改的池规范将其传递给区域创建： ClientRegionFactory regionFactory = cache.createClientRegionFactory(PROXY); Region region = regionFactory .setPoolName(\"publisher\") .create(\"DATA\"); 管理区域属性 使用区域属性可以微调区域快捷方式设置提供的区域配置。 所有区域属性都具有默认设置，因此您只需使用区域属性来设置要覆盖的属性。 见。 定义区域属性 使用以下任一方法创建区域属性： cache.xml`` 元素中的声明： quickstart.SimpleCacheListener 在启动时加载cache.xml时，会自动创建声明的区域属性并将其应用于该区域。 RegionFactory APIset *方法调用： // Creating a partitioned region using the RegionFactory RegionFactory rf = cache.createRegionFactory(RegionShortcut.PARTITION); rf.addCacheListener(new LoggingCacheListener()); custRegion = rf.create(\"customer\"); // Creating a partitioned region using the RegionFactory, with attribute modifications RegionFactory rf = cache.createRegionFactory(RegionShortcut.PARTITION); rf.setPartitionResolver(new CustomerOrderResolver()); rf.addCacheListener(new LoggingCacheListener()); custRegion = rf.create(\"customer\"); // Creating a client with a Pool Specification Using ClientRegionFactory ClientRegionFactory cRegionFactory = cache.createClientRegionFactory(PROXY); Region region = cRegionFactory.setPoolName(\"Pool3\").create(\"DATA\"); 通过发出gfshcreate region命令。 修改区域属性 您可以在创建区域后修改区域的事件处理程序以及到期和逐出属性。 注意: 除非绝对必要，否则不要修改现有区域的属性。 在区域创建时创建所需的属性更有效。 以下列方式之一修改属性： 通过加载带有修改的区域属性规范的cache.xml： quickstart.ComplicatedCacheListener ... 使用AttributesMutator API： 从区域中检索AttributesMutator 调用mutator set方法来修改属性： currRegion = cache.getRegion(\"root\"); AttributesMutator mutator = this.currRegion.getAttributesMutator(); mutator.addCacheListener(new LoggingCacheListener()); 通过发出gfshalter region命令。 参见alter region。 为区域和条目创建自定义属性 使用自定义属性可以在缓存中存储与您的区域或其条目相关的信息。 这些属性仅对本地应用程序可见，并且不会分发。 您可以定义自定义用户属性，以便可以将数据与区域或条目相关联，并在以后检索它。 与其他配置设置不同，这些属性仅供您的应用程序使用。 注意: 用户属性不是分布式的。 使用属性定义创建JavaObject。 将对象附加到区域或条目： Region.setUserAttribute(userAttributeObject) Region.getEntry(key).setUserAttribute(userAttributeObject) 获取属性值： Region.getUserAttribute() Region.getEntry(key).getUserAttribute() 此示例存储属性以供稍后由缓存编写器检索。 // Attach a user attribute to a Region with database info for table portfolio Object myAttribute = \"portfolio\"; final Region portfolios = new RegionFactory().setCacheWriter(new PortfolioDBWriter()).create(\"Portfolios\"); Portfolios.setUserAttribute(myAttribute); //Implement a cache writer that reads the user attribute setting public class PortfolioDBWriter extends CacheWriterAdapter { public void beforeCreate(RegionEvent event) { table = (String)event.getRegion().getUserAttribute(); // update database table using name from attribute . . . } } 限制和替代方案 用户属性不会分发给其他进程，因此如果需要在使用该区域或条目的每个进程中定义每个属性。 您需要单独更新该区域的每个实例。 用户属性不会存储到磁盘以进行区域持久性或溢出，因此无法恢复它们以重新初始化该区域。 如果您的应用程序需要用户属性不支持的功能，则可以选择创建一个单独的区域来保存此数据。 例如，您定义的区域AttributesRegion可以使用区域名称作为键，使用用户属性作为值。 对AttributesRegion的更改将分发给其他进程，您可以根据需要配置该区域的持久性或溢出。 用现有内容构建新区域 可能需要使用现有系统的数据加载新的区域或集群。 有两种方法可以完成此任务。 使用的方法取决于新集群和现有集群的组织。 如果新集群和现有集群中成员的数量和类型相同，则最简单的选项是对永久磁盘存储内容使用备份和还原。 在现有集群的磁盘存储中对持久数据进行完全联机备份。 将组成备份的文件复制到新的集群位置。 还原将数据注入新集群。有关如何进行备份以及使用备份还原磁盘存储的详细信息，请参见创建系统恢复和操作管理备份。 当新成员和现有集群中成员的数量或类型不相同时，采用不同的方法。 此方法使用区域数据的导出和导入。 导出现有集群的区域数据以创建快照。 将快照复制到新的集群位置。 将快照导入新集群。有关制作和使用快照的详细信息，请参阅缓存和区域快照中的相应部分。 数据条目 数据条目是存储数据的键/值对。 您可以单独和批量管理您的条目。 要将域对象用于条目值和键，您需要遵循Apache Geode要求进行数据存储和分发。 管理数据条目 编写应用程序以创建，修改和管理缓存的数据条目。 在数据缓存中使用自定义类的要求 请遵循以下准则，为缓存的条目键和值使用自定义域类。 管理数据条目 编写应用程序以创建，修改和管理缓存的数据条目。 注意: 如果没有将缓存的copy-on-read属性设置为true，请不要更改从Java条目访问方法返回的对象。 而是创建对象的副本，然后修改副本并将其传递给Javaput方法。 修改适当的值会绕过Geode提供的整个分发框架，包括缓存侦听器和到期活动，并可能产生不希望的结果。 基本创建和更新 要在缓存中创建或更新条目，请使用“Region.put”。 例如： String name = ... String value = ... this.currRegion.put(name,value); 注意: 您还可以使用gfsh put命令向区域添加条目，使用get命令从区域中检索条目。 见get和put了解更多信息。 如果只想创建条目（如果条目已存在，则为空值且方法失败），请改用Region.create。 批处理操作(getAll，putAll，removeAll) Geode提供了三个API来对多个区域条目执行批处理操作： Region.getAll Region.putAll Region.removeAll getAll方法获取一组键并返回所提供键的值的“Map”。 如果区域中不存在给定键，则返回映射中该键的值将为null。 putAll方法接受键值对的Map并将它们放入缓存中并在单个操作中分发它们。 例子: void putAll(String command) throws CacheException { // Get Entry keys and values into Strings key1, ... keyN and value1, ... valueN Map map = new LinkedHashMap(); map.put(key1, value1)); ... map.put(keyN, valueN)); this.currRegion.putAll(map); } 缓存的更新按照它们放置在“Map”中的顺序单独完成。 对于分区区域，多个事件作为单个消息发送到主存储桶，然后分发到辅助存储桶。 注意: 处理具有很多条目和/或非常大的数据的映射可能会影响系统性能并导致缓存更新超时，尤其是在该区域对磁盘使用溢出或持久性的情况下。 removeAll方法获取一组键，并从该区域中删除指定键的所有条目。 对于指定集合中的每个键，此调用对此区域执行一次调用destroy（Object）。 如果条目不存在，则跳过该键。 不抛出EntryNotFoundException。 如果区域的范围未设置为Scope.LOCAL，则此操作将分发给其他缓存。 安全条目修改 从缓存中获取条目值时，默认情况下，检索方法会返回对缓存对象的直接引用。 这样可以尽快提供值，但也会打开缓存以进行直接的就地更改。 注意: 不要直接修改缓存的值。 修改适当的值会绕过Geode分发框架，包括缓存编写器和侦听器，到期活动和事务管理，并可能产生不希望的结果。 始终使用检索到的对象的副本更改条目 - 永远不要直接修改返回的对象。 您可以通过以下两种方式之一完成此操作： 通过将缓存属性copy-on-read设置为true(默认值为false)来更改缓存的条目检索行为。 ... 当copy-on-read为真时，条目访问方法返回条目的副本。 这可以防止您无意中就地修改，但在不需要复制时会对性能和内存消耗产生负面影响。 如果copy-on-read为false，则这些条目访问方法返回条目引用;如果copy-on-read为true，则返回条目的副本： Region.get result of Region.put EntryEvent.getNewValue Region.values Region.Entry.getValue EntryEvent.getOldValue Query.select 创建返回对象的副本并使用它。 对于可克隆或可序列化的对象，可以使用org.apache.geode.CopyHelper.copy将条目值复制到新对象。 例： Object o = (StringBuffer)region.get(\"stringBuf\"); StringBuffer s = (StringBuffer) CopyHelper.copy(o); s.append(\"Changes to value, added using put.\"); region.put(\"stringBuf\", s); 从代理成员中检索区域条目 Region.values方法调用仅适用于本地区域实例。 如果使用PROXY快捷方式从客户区域调用values方法，则方法调用将不会重定向到服务器区域。 要从客户端获取Region中所有值的集合，您应该在ALL_KEYS上使用兴趣注册，或使用查询。 如果从代理成员使用Region.get方法，则方法调用将重定向到服务器上的区域，如果它无法在本地找到密钥。 使用gfsh来get和put 您可以使用gfshget和put命令来管理数据。 见get和put。 例如： get --key=('id':'133abg124') --region=region1 // Retrieving when key type is a wrapper(primitive)/String get --key=('133abg124') --region=/region1/region12 --value-class=data.ProfileDetails get --key=('100L') --region=/region1/region12 --value-class=data.ProfileDetails --key-class=java.lang.Long put --key=('id':'133abg125') --value=('firstname':'James','lastname':'Gosling') --region=/region1 --key-class=data.ProfileKey --value-class=data.ProfileDetails put --key=('133abg124') --value=('Hello World!!') --region=/region2 put --key=('100F') --value=('2146547689879658564') --region=/region1/region12 --key-class=java.lang.Float --value-class=java.lang.Long 在数据缓存中使用自定义类的要求 请遵循以下准则，为缓存的条目键和值使用自定义域类。 CLASSPATH 每个成员的CLASSPATH必须包含成员访问的所有对象的类。 对于Java应用程序，请使用标准JavaCLASSPATH。 对于缓存服务器进程，使用CLASSPATH环境变量或gfsh start server的--classpath参数。 请参阅运行Geode服务器进程。 数据以序列化形式在客户端和服务器之间发送，服务器以序列化形式存储客户端数据。 服务器不需要反序列化数据以将其发送到另一个客户端或通过PDXInstance访问它，但它需要反序列化它以通过其他方式访问它。 服务器CLASSPATH必须包含以下类： 所有条目键 服务器持久保存到磁盘的区域中的条目值 服务器访问的条目值，除了使用PdxInstance或将完整条目值传输到客户端之外的任何其他原因 有关PdxInstances的信息，请参阅数据序列化。 数据序列化 Geode序列化数据输入键和值以进行分发，因此Geode因任何原因移出本地缓存的所有数据都必须是可序列化的。 另外，分区区域以序列化形式存储数据。 几乎每个配置都需要序列化。 有关数据序列化的要求和选项的信息，请参阅数据序列化。 用作键的类 该区域使用键上的散列。 如果您定义要用作键的自定义类，则对于该类，重写： equals hashCode. 从Object继承的默认hashCode使用identity，在每个系统成员中都是不同的。 在分区区域中，基于标识的散列将数据放在错误的位置。 有关详细信息，请参阅“java.lang.Object”的Java API文档。 Copyright © WS 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-12-10 10:47:47 "},"Geode_4_Topologies_and_Communication.html":{"url":"Geode_4_Topologies_and_Communication.html","title":"拓扑和通信","keywords":"","body":"拓扑和通信拓扑和通信一般概念拓扑类型规划拓扑和通信成员发现如何运作通信如何工作使用绑定地址在IPv4和IPv6之间进行选择 点对点配置配置Peer-to-Peer(点对点)发现 配置对等通信将Peer(同行)组织成逻辑成员组 客户端/服务器配置 标准客户端/服务器部署 服务器发现如何工作客户端/服务器连接如何工作 配置客户端/服务器系统 将服务器组织到逻辑成员组中客户端/服务器示例配置 微调您的客户端/服务器配置 多站点(WAN)配置 多站点(WAN)系统的工作原理 多站点(WAN)拓扑 配置多站点(WAN)系统 过滤多站点(WAN)分发的事件 解决冲突事件拓扑和通信 拓扑和通信 解释了如何规划和配置Apache Geode成员发现，对等和客户端/服务器通信拓扑。 拓扑和通信一般概念 在配置Apache Geode成员之前，请确保了解拓扑和通信的选项。 点对点配置 使用对等配置在单个集群中设置成员发现和通信。 客户端/服务器配置 在客户端/服务器体系结构中，相对较小的服务器场管理许多客户端应用程序的缓存数据和访问相同数据。 客户端可以有效地更新和访问数据，使服务器管理向其他客户端的数据分发以及与外部数据存储的任何同步。 多站点(WAN)配置配置) 使用多站点配置在不同的，松散耦合的集群之间水平扩展。 广域网(WAN)是多站点拓扑的主要用例。 拓扑和通信一般概念 在配置Apache Geode成员之前，请确保了解拓扑和通信的选项。 拓扑类型 Apache Geode拓扑选项允许您水平和垂直缩放。 规划拓扑和通信 创建拓扑计划以及成员将使用的计算机和通信端口的详细列表。 配置Apache Geode系统以及系统之间的通信。 成员发现如何运作 Apache Geode为集群内以及客户端和服务器之间的成员发现提供了各种选项。 沟通如何运作 Geode使用TCP和UDP单播和多播的组合来进行成员之间的通信。 您可以更改默认行为以优化系统通信。 使用绑定地址 您使用绑定地址配置通过非默认网卡发送网络流量，并在多个卡上分配Geode的网络流量负载。 如果未找到绑定地址设置，Geode将使用主机的默认地址。 在IPv4和IPv6之间进行选择 默认情况下，Apache Geode将Internet协议版本4用于Geode地址规范。 如果所有计算机都支持Internet协议，则可以切换到Internet协议版本6。 您可能会失去性能，因此您需要了解进行切换的成本。 拓扑类型 Apache Geode拓扑选项允许您水平和垂直缩放。 Apache Geode提供各种缓存拓扑： 所有系统的核心是单个对等集群。 对于水平和垂直扩展，您可以将各个系统组合到客户端/服务器和多站点(WAN)拓扑中： 在客户端/服务器系统中，少数服务器进程管理更大的客户端组的数据和事件处理。 在多站点系统中，几个地理上不同的系统松散地耦合到单个，内聚的处理单元中。 点对点配置 对等集群是所有Geode安装的构建块。 单独对等是最简单的拓扑。 每个缓存实例或成员直接与集群中的每个其他成员通信。 此缓存配置主要是为需要在应用程序进程空间中嵌入缓存并参与集群的应用程序而设计的。 典型示例是应用程序服务器集群，其中应用程序和缓存位于同一位并共享同一堆。 客户端/服务器配置 客户端/服务器拓扑是垂直扩展的模型，其中客户端通常在应用程序进程空间中托管一小部分数据，并为其余部分委托给服务器系统。 与点对点本身相比，客户端/服务器架构提供了更好的数据隔离，高获取性能和更高的可扩展性。 如果数据分发会给网络带来非常沉重的负担，那么客户端/服务器架构通常会提供更好的性能。 在任何客户端/服务器安装中，服务器系统本身是对等系统，数据在服务器之间分配。 客户端系统具有连接池，用于与服务器和其他Geode成员通信。 客户端还可以包含本地缓存。 多站点配置 对于水平扩展，您可以使用松散耦合的多站点拓扑。 对于多站点，多个Geode系统松散耦合，通常跨越地理距离，连接速度较慢，例如WAN。 此拓扑提供了比单个系统的紧密耦合更好的性能，以及位置之间更大的独立性，因此如果连接或远程站点不可用，每个站点都可以自行运行。 在多站点安装中，每个站点都是对等或客户端/服务器系统。 规划拓扑和通信 创建拓扑计划以及成员将使用的计算机和通信端口的详细列表。 配置Apache Geode系统以及系统之间的通信。 确定协议和地址 您的配置管理应用程序如何相互查找以及相互之间分发事件和数据。 与系统管理员一起确定将用于成员身份和通信的协议和地址。 对于具有多个网络适配卡的每台主机，请确定是使用默认地址还是使用一个或多个非默认绑定地址。 您可以为对等和服务器使用不同的卡。 确定您想要作为独立，孤立的成员运行而没有成员发现的任何成员。 对于客户来说，这可能是一个不错的选择，因为它具有更快的启动速度，但没有任何类型的点对点分发。 对于所有非独立成员： 确定要使用的定位器数量以及运行位置。 要确保最稳定的启动和可用性，请在多台计算机上使用多个定位器。 创建定位器的地址和端口对列表。 您将使用该列表配置系统成员，任何客户端和定位器本身。 如果要使用多播进行通信，请记下地址和端口。 为集群选择唯一的多播端口和唯一地址。 注意:即使您使用不同的多播地址，也请为不同的系统使用不同的端口号。 某些操作系统不会在具有唯一地址但具有相同端口号的系统之间保持通信分离。 设置好成员和通讯 使用上面确定的协议和地址，执行以下操作： 在您的系统中设置成员身份。 建立系统成员之间的通信。 请参阅配置对等通信。 根据需要，在系统之间建立通信。 请参阅配置客户端/服务器系统。 成员发现如何运作 Apache Geode为集群内以及客户端和服务器之间的成员发现提供了各种选项。 对等成员发现 独立成员 客户端发现服务器 对等成员发现 对等成员发现是定义集群的原因。 使用相同设置进行对等发现的所有应用程序和缓存服务器都是同一集群的成员。 每个系统成员都具有唯一的身份，并且知道其他成员的身份。 成员一次只能属于一个集群。 一旦他们找到对方，成员就会直接进行通信，而不依赖于发现机制。 在对等点发现中，Geode使用成员协调器来管理成员加入和离开。 成员使用一个或多个定位器发现彼此。 定位器提供发现和负载平衡服务。 对等定位器管理集群成员的动态列表。 新成员连接到其中一个定位器以检索用于加入系统的成员列表。 注意: 多个定位器可确保集群的最稳定启动和可用性。 独立成员 独立成员没有对等体，没有对等体发现，因此不使用定位器。 它仅创建集群连接以访问Geode缓存功能。 独立运行具有更快的启动速度，适用于与其他应用程序隔离的任何成员。 主要用例是客户端应用程序。 如果您允许该成员成为JMX Manager，则可以访问和监视独立成员。 客户端发现服务器 定位器为客户端提供动态服务器发现和服务器负载平衡。 客户端配置有服务器系统的定位器信息，并转向定位器以获取要使用的服务器的指示。 服务器可以来去，它们为新客户端连接提供服务的能力可能会有所不同。 定位器持续监控服务器可用性和服务器负载信息，随时为客户端提供负载最小的服务器的连接信息。 注意: 对于性能和高速缓存一致性，客户端必须作为独立成员运行，或者在与其服务器不同的集群中运行。 您无需运行任何特殊进程即可使用定位器进行服务器发现。 在服务器系统中提供对等点发现的定位器还为客户端向服务器系统提供服务器发现。 这是标准配置。 多站点发现 在多站点(WAN)配置中，Geode集群使用定位器来发现远程Geode集群以及发现本地Geode成员。 WAN配置中的每个定位器唯一标识它所属的本地集群，还可以识别它将连接到WAN分发的远程Geode集群中的定位器。 当定位器启动时，它会联系每个远程定位器，以交换有关远程集群中可用定位器和网关接收器配置的信息。 除了共享有关其自己的集群的信息之外，定位器还共享从所有其他连接集群获取的信息。 每次新定位器启动或现有定位器关闭时，更改的信息都会通过WAN广播到其他连接的Geode集群。 有关详细信息，请参阅多站点系统发现。 通信如何工作 Geode使用TCP和UDP单播和多播的组合来进行成员之间的通信。 您可以更改默认行为以优化系统通信。 客户端/服务器通信和网关发送器与网关接收器通信使用TCP/IP套接字。 服务器侦听已发布地址的客户端通信，客户端建立连接，发送其位置。 类似地，网关接收器侦听网关发送器通信，并在站点之间建立连接。 在对等系统中，对于一般消息传递和区域操作分发，Geode使用TCP或UDP单播。 默认值为TCP。 您可以对所有通信使用TCP或UDP单播，也可以将其用作默认通信，但可以将特定区域作为目标，以使用UDP多播进行操作分发。 安装的最佳组合在很大程度上取决于您的数据使用和事件消息传递。 TCP TCP（传输控制协议）提供系统消息的可靠有序传送。 如果数据是分区的，如果集群很小，或者网络负载是不可预测的，则TCP比UDP更合适。 TCP优于较小集群中的UDP单播，因为它在操作系统级别实现比UDP更可靠的通信，并且其性能可以比UDP快得多。 然而，随着集群规模的增加，UDP的相对较小的开销使其成为更好的选择。 TCP为每个成员添加了新的线程和套接字，随着系统的增长导致更多的开销。 注意: 即使Geode配置为使用UDP进行消息传递，Geode在尝试检测失败的成员时也会使用TCP连接。 有关详细信息，请参阅故障检测和成员资格视图。 此外，TCP连接的ping不用于保持活动目的; 它仅用于检测失败的成员。 有关TCP保持活动配置，请参阅TCP/IP KeepAlive配置。 UDP单播和多播 UDP（用户数据报协议）是一种无连接协议，它使用的资源远少于TCP。 向集群添加另一个进程会导致UDP消息传递的开销很小。 然而，UDP本身并不可靠，并且消息的大小限制为64k字节或更少，包括消息头的开销。 大型消息必须分段并作为多个数据报消息传输。 因此，在许多情况下UDP比TCP慢，而在其他情况下如果网络流量不可预测或严重拥塞则不可用。 UDP在Geode中用于单播和多播消息传递。 Geode实现重传协议以确保通过UDP正确传递消息。 UDP单播 UDP单播是用于一般消息传递的TCP的替代方案。 当集群中有大量进程，网络不拥塞，缓存对象很小，并且应用程序可以为缓存提供足够的处理时间来从网络读取时，UDP比TCP更适合单播消息传递。 如果禁用TCP，Geode将使用UDP进行单播消息传递。 对于每个成员，Geode为UDP单播通信选择一个唯一的端口。 您可以通过在gemfire.properties文件中设置membership -port-range来限制用于选择的范围。 例： membership-port-range=1024-60000 注意:除UDP端口配置外，membership-port-range属性还定义了用于故障检测的TCP端口。 有关Geode属性的说明，请参阅参考。 UDP多播 常规消息传递和默认区域操作消息传递的选项是TCP和UDP单播之间。 您可以选择使用UDP多播替换默认值，以用于部分或全部区域的操作分发。 对于要使用多播的每个区域，您可以在区域本身上设置其他属性。 为区域启用多播时，集群中的所有进程都将接收该区域的所有事件。 每个成员都会收到该区域的每条消息，并且必须将其解压缩，安排进行处理，然后进行处理，所有这些都在发现它是否对消息感兴趣之前。 因此，多播适用于集群中普遍感兴趣的区域，其中大多数或所有成员具有定义的区域并且有兴趣接收该区域的大多数或所有消息。 多播不应该用于集群中一般不太感兴趣的区域。 当集群中的大多数进程使用相同的缓存区域并且需要为它们获取更新时，例如当进程定义复制区域或将其区域配置为接收所有事件时，多播是最合适的。 即使您对区域使用多播，Geode也会在适当时发送单播消息。 如果数据被分区，则多播不是一个有用的选项。 即使启用了多播，分区区域仍然几乎用于所有目的的单播。 使用绑定地址 您可以使用绑定地址配置通过非默认网卡发送网络流量，并在多个卡上分配Geode的网络流量负载。 如果未找到绑定地址设置，Geode将使用主机的默认地址。 主机将数据传输到网络并通过一个或多个网卡（也称为网络接口卡（NIC）或LAN卡）从网络接收数据。 具有多个卡的主机称为多宿主主机。 在多宿主主机上，默认使用一个网卡。 您可以使用绑定地址将Geode成员配置为在多宿主主机上使用非默认网卡。 注意: 为进程指定非默认卡地址时，连接到该进程的所有进程都需要在其连接设置中使用相同的地址。 例如，如果对服务器定位器使用绑定地址，则必须使用相同的地址来配置客户端中的服务器池。 使用IPv4或IPv6数字地址规范进行绑定地址设置。 有关这些规范的信息，请参阅在IPv4和IPv6之间选择。 不要使用主机名作为地址规范。 主机名解析为默认计算机地址。 对等和服务器通信 您可以配置对等和服务器通信，以便每种通信类型使用自己的地址或类型使用相同的地址。 如果未找到特定通信类型的设置，Geode将使用主机的默认地址。 注意: 通过API设置的绑定地址（如“CacheServer”和“DistributedSystem”）优先于此处讨论的设置。 如果您的设置不起作用，请检查以确保没有通过API调用完成绑定地址设置。 此表列出了用于对等和服务器通信的设置，按优先级排序。 例如，对于服务器通信，Geode首先搜索缓存服务器绑定地址，然后搜索gfsh start server``server-bind-address设置，依此类推，直到找到设置或所有可能性都用完为止。 Property Setting Ordered by Precedence Peer Server Gateway Receiver Syntax cache.xml bind-address X bind-address=address gfsh start server command-line –server-bind-address X X gfsh start server –server-bind-address=address gemfire.properties server-bind-address X X server-bind-address=address gemfire.properties bind-address X X X bind-address=address 例如，在gemfire.properties和cache.xml文件中使用这些配置启动的成员将使用两个单独的地址进行对等和服务器通信： // gemfire.properties setting for peer communication bind-address=192.0.2.0 //cache.xml settings // Server communication 网关接收器通信 如果使用多站点（WAN）拓扑，还可以配置网关接收器通信（除了对等和服务器通信），以便每种通信类型使用自己的地址。 此表列出了用于对等，服务器和网关接收器通信的设置，按优先级排序。 例如，对于网关接收器通信，Geode首先搜索cache.xml bind-address设置。 如果没有设置，Geode将搜索gfsh start server server-bind-address设置，依此类推，直到找到设置或所有可能性都用完为止。 Property Setting Ordered by Precedence Peer Server Gateway Receiver Syntax cache.xml bind-address X bind-address=address cache.xml bind-address X bind-address=address gfsh start server command-line –server-bind-address X X gfsh start server –server-bind-address=address gemfire.properties server-bind-address X X server-bind-address=address gemfire.properties bind-address X X X bind-address=address 例如，在gemfire.properties和cache.xml文件中以这些配置开头的成员将使用三个单独的地址进行对等，服务器和网关接收器通信： // gemfire.properties setting for peer communication bind-address=192.0.2.0 //cache.xml settings // Gateway receiver configuration // Server communication 定位器通信 使用以下方法之一设置定位器绑定地址： 在gfsh命令行上，在启动定位器时指定绑定地址，与指定任何其他地址相同： gfsh>start locator --name=my_locator --bind-address=ip-address-to-bind --port=portNumber 在Geode应用程序中，执行以下操作之一： 使用gemfire属性start-locator自动启动共址定位器，并在该属性设置中为其指定绑定地址。 使用org.apache.geode.distributed.LocatorLauncher API启动代码中的定位器。 使用LocatorLauncher.Builder类构造LocatorLauncher的实例，使用setBindAddress方法指定要使用的IP地址，然后使用start()方法启动嵌入在Java应用程序进程中的Locator服务。 如果您的定位器使用绑定地址，请确保访问定位器的每个进程都具有该地址。 对于定位器的对等访问，请使用定位器的绑定地址和gemfire.properties locators列表中的定位器端口。 对于客户端/服务器安装中的服务器发现，请在客户端的服务器池配置中使用定位器的绑定地址和您提供的定位器列表中的定位器端口。 在IPv4和IPv6之间进行选择 默认情况下，Apache Geode将Internet协议版本4用于Geode地址规范。 如果所有计算机都支持Internet协议，则可以切换到Internet协议版本6。 您可能会失去性能，因此您需要了解进行切换的成本。 IPv4使用32位地址。 IPv4是第一个协议，仍然是主要使用的协议，但其地址空间预计将在几年内耗尽。 IPv6使用128位地址。 IPv6接替IPv4，并将提供更多的地址。 根据当前使用Geode的测试，通常建议使用IPv4。 IPv6连接往往需要更长的时间才能形成，并且通信往往更慢。 并非所有机器都支持IPv6寻址。 要使用IPv6，分布式系统中的所有计算机都必须支持它，否则您将遇到连接问题。 注意: 不要混用IPv4和IPv6地址。 全面使用其中一个。 IPv4是默认版本。 要使用IPv6，请将Java属性java.net.preferIPv6Addresses设置为true。 这些示例显示了用于在Geode中指定地址的格式。 IPv4: 192.0.2.0 IPv6: 2001:db8:85a3:0:0:8a2e:370:7334 点对点配置 使用对等配置在单个集群中设置成员发现和通信。 配置Peer-to-Peer(点对点)发现 同行成员使用一个或多个定位器发现彼此。 配置对等通信 默认情况下，Apache Geode使用TCP在单个集群的成员之间进行通信。 您可以在成员和区域级别修改它。 将Peers(同行)组织成逻辑成员组 在对等配置中，您可以将成员组织为逻辑成员组，并使用这些组关联特定数据或将任务分配给预定义的成员集。 配置Peer-to-Peer(点对点)发现 同行成员使用一个或多个定位器发现彼此。 gemfire.properties文件可以列出定位器： locators=[],[] 要运行独立成员，gemfire.properties文件禁用使用定位器： locators= mcast-address= mcast-port=0 注意: 定位器设置必须在整个集群中保持一致。 配置对等通信 默认情况下，Apache Geode使用TCP在单个分布式系统的成员之间进行通信。 您可以在成员和区域级别修改它。 在开始之前，您应该已经确定了多播的地址和端口设置，包括任何绑定地址。 请参阅拓扑和通信一般概念。 请参阅参考。 配置常规消息传递以使用TCP或UDP单播. TCP是通信的默认协议。 要使用它，只需确保在gemfire.properties中没有禁用它。 要么没有'disable-tcp`条目，要么有这个条目： disable-tcp=false 要将UDP单播用于常规消息传递，请将此条目添加到gemfire.properties： disable-tcp=true disable-tcp设置对TCP定位器的使用或用于检测失败成员的TCP连接没有影响。 使用UDP多播配置要分发的任何区域. 为区域消息传递配置UDP多播，在gemfire.properties中设置非默认多播地址和端口选择： mcast-address= mcast-port= 在cache.xml中，为需要多播消息传递的每个区域启用多播： 注意: 配置不当可能会影响生产系统。 如果您打算在共享网络上使用多播，请在项目的规划阶段与网络管理员和系统管理员一起使用。 此外，您可能需要解决Geode，操作系统和网络级别的相关设置和调优问题。 一旦您的成员建立了彼此的连接，他们将根据您的配置发送分布式数据和消息。 将Peer(同行)组织成逻辑成员组 在对等配置中，您可以将成员组织为逻辑成员组，并使用这些组关联特定数据或将任务分配给预定义的成员集。 您可以使用逻辑成员组跨多个成员部署JAR应用程序，或跨成员组执行功能。 要将对等体添加到成员组，您可以配置以下内容： 将成员组名称添加到成员的gemfire.properties文件中。 例如： #gemfire.properties groups=Portfolios,ManagementGroup1 成员可以属于多个成员组。 如果为成员指定多个成员组，请使用逗号分隔列表。 或者，如果您使用gfsh命令接口来启动成员，请提供组名称或组名称作为参数。 例如，要启动服务器并将其与成员组关联，可以键入： gfsh>start server --name=server1 \\ --group=Portfolios,ManagementGroup1 例如，要启动定位器并将其与成员组关联，可以键入： gfsh>start locator --name=locator1 \\ --group=ManagementGroup1 然后，您可以使用成员组名称来执行部署应用程序或执行功能等任务。 例如，要跨成员组部署应用程序，可以在gfsh中键入以下内容： gfsh>deploy --jar=group1_functions.jar --group=ManagementGroup1 客户端/服务器配置 在客户端/服务器体系结构中，相对较小的服务器场管理许多客户端应用程序的缓存数据和访问相同数据。 客户端可以有效地更新和访问数据，使服务器管理向其他客户端的数据分发以及与外部数据存储的任何同步。 标准客户端/服务器部署 在最常见的客户端/服务器拓扑中，缓存服务器场为许多客户端提供缓存服务。 缓存服务器在数据区域中具有同类数据存储，这些数据区域在服务器场中进行复制或分区。 服务器发现如何工作 Apache Geode定位器为您的客户提供可靠，灵活的服务器发现服务。 您可以根据功能将所有服务器用于所有客户端请求或组服务器，定位器将每个客户端请求定向到正确的服务器组。 客户端/服务器连接如何工作 Apache Geode客户端进程中的服务器池管理对服务器层的所有客户端连接请求。 要充分利用池功能，您应该了解池如何管理服务器连接。 配置客户端/服务器系统 配置服务器和客户端进程以及数据区域以运行客户端/服务器系统。 将服务器组织到逻辑成员组中 在客户端/服务器配置中，通过将服务器放入逻辑成员组，您可以控制客户端使用哪些服务器，并针对特定数据或任务定位特定服务器。 您可以配置服务器以管理不同的数据集或将特定的客户端流量定向到服务器的子集，例如直接连接到后端数据库的服务器。 客户端/服务器示例配置 为了便于配置，您可以从这些示例客户端/服务器配置开始，并为您的系统进行修改。 微调您的客户端/服务器配置 您可以使用服务器负载平衡和池连接的客户端线程使用来微调客户端/服务器系统。 例如，您可以配置服务器使用缓存服务器load-poll-interval属性检查其加载的频率，或者通过实现org.apache.geode.cache.server包来配置您自己的服务器负载指标。 标准客户端/服务器部署 在最常见的客户端/服务器拓扑中，缓存服务器场为许多客户端提供缓存服务。 缓存服务器在数据区域中具有同类数据存储，这些数据区域在服务器场中进行复制或分区。 客户端/服务器数据流程如下： 如果使用定位器，则缓存服务器将其地址和加载信息发送到服务器定位器。 如果使用定位器，则客户端从定位器请求服务器连接信息。 定位器以最小负载服务器的地址响应。 客户端池定期检查其连接以获得正确的服务器负载平衡。 池根据需要重新平衡。 客户端可以在启动时订阅事件。 事件从服务器自动流式传输到客户端侦听器并进入客户端缓存。 客户端缓存未满足的客户端数据更新和数据请求会自动转发到服务器。 服务器发现如何工作 Apache Geode定位器为您的客户提供可靠，灵活的服务器发现服务。 您可以根据功能将所有服务器用于所有客户端请求或组服务器，定位器将每个客户端请求定向到正确的服务器组。 默认情况下，Geode客户端和服务器在localhost上的预定义端口（40404）上相互发现。 这可行，但通常不是部署客户端/服务器配置的方式。 建议的解决方案是使用一个或多个专用定位器。 定位器提供发现和负载均衡服务。 使用服务器定位器，客户端配置了定位器列表，定位器维护动态服务器列表。 定位器侦听用于连接客户端的地址和端口，并为客户端提供服务器信息。 客户端配置了定位器信息，并且没有特定于服务器的配置。 基本配置 在此图中，仅显示了一个定位器，但建议的配置使用多个定位器以实现高可用性。 定位器和服务器在其gemfire.properties中配置了相同的对等发现： locators=lucy[41111] 服务器在各自的主机上运行，在cache.xml中有这个cache-server配置： 客户端的cache.xml, pool配置和region-attributes： 使用成员组 您可以控制与命名成员组一起使用的服务器。 如果您希望服务器管理不同的数据集或将特定客户端流量定向到服务器的子集（例如直接连接到后端数据库的服务器），请执行此操作。 要在服务器之间拆分数据管理，请将一些服务器配置为承载一组数据区域，将一些服务器配置为托管另一组数 将服务器分配给两个单独的成员组。 然后，在客户端定义两个单独的服务器池，并将池分配给适当的相应客户端区域。 在此图中，区域的客户端使用也是分开的，但您可以在所有客户端中定义两个池和两个区域。 这是服务器1的gemfire.properties定义： #gemfire.properties groups=Portfolios 客户端1的pool声明： 客户端/服务器连接如何工作 Apache Geode客户端进程中的服务器池管理对服务器层的所有客户端连接请求。 要充分利用池功能，您应该了解池如何管理服务器连接。 客户端/服务器通信以两种不同的方式完成。 每种通信都使用不同类型的连接，以获得最佳性能和可用性。 Pool 连接. 池连接用于将单独的操作发送到服务器以更新缓存的数据，以满足本地缓存未命中或运行即席查询。 每个池连接都转到服务器正在侦听的主机/端口位置。 服务器响应同一连接上的请求。 通常，客户端线程对单个操作使用池连接，然后将连接返回到池以供重用，但您可以配置为具有线程拥有的连接。 此图显示了一个客户端和一个服务器的池连接。 在任何时候，池可能具有从零到多个池连接到任何服务器。 Subscription connections(订阅连接). 订阅连接用于将缓存事件从服务器传输到客户端。 要使用它，请将客户端属性subscription-enabled设置为true。 服务器建立队列以异步发送订阅事件，池建立订阅连接以处理传入消息。 发送的事件取决于客户端的订阅方式。 池如何选择服务器连接 池从服务器定位器获取服务器连接信息，或者从静态服务器列表获取服务器连接信息。 服务器定位器. 服务器定位器维护有关哪些服务器可用以及哪些服务器负载最小的信息。 新连接将发送到负载最小的服务器。 池在需要新连接时从定位器请求服务器信息。 池随机选择要使用的定位器，池用定位器粘住，直到连接失败。 静态服务器列表. 如果使用静态服务器列表，则池在启动时将其洗牌一次，以在具有相同列表配置的客户端之间提供随机性，然后运行列表循环连接，根据需要连接到列表中的下一个服务器。 静态服务器列表没有负载平衡或动态服务器发现。 池如何连接到服务器 当池需要新连接时，它会执行这些步骤，直到它成功建立连接，已耗尽所有可用服务器，或达到“free-connection-timeout”。 从定位器请求服务器连接信息或从静态服务器列表中检索下一个服务器。 向服务器发送连接请求。 如果池在创建订阅连接或配置池以达到“min-connections”设置时无法连接，则会记录一个精细级别的消息，并在“ping-interval”指示的时间后重试。 如果应用程序线程调用需要连接的操作并且池无法创建它，则该操作将返回“NoAvailableServersException”。 池如何管理池连接 客户端中的每个Pool实例都维护自己的连接池。 池尽可能有效地响应连接丢失和新连接请求，根据需要打开新连接。 当您将池与服务器定位器一起使用时，池可以快速响应服务器可用性的更改，添加新服务器并断开与不健康或死机服务器的连接，而对客户端线程几乎没有影响。 静态服务器列表需要更加密切关注，因为客户端池只能连接到列表中指定位置的服务器。 当发生以下某种情况时，池会添加新的池连接： 打开连接的数量少于Pool的'min-connections`设置。 线程需要连接，所有打开的连接都在使用中，添加另一个连接不会在池的“max-connections”设置上采用开放连接计数。 如果已达到最大连接数设置，则线程将阻塞，直到连接可用。 发生以下任一情况时，池将关闭池连接： 客户端从服务器接收连接异常。 服务器不响应客户端配置的“读取超时”期间的直接请求或ping。 在这种情况下，池将删除与该服务器的所有连接。 池连接数超过池的“min-connections”设置，客户端不会通过连接发送任何“idle-timeout”期间的请求。 当它关闭线程正在使用的连接时，池会将线程切换到另一个服务器连接，并在需要时打开一个新连接。 池如何管理订阅连接 池的订阅连接的建立方式与池连接的方式相同，方法是从定位器请求服务器信息，然后向服务器发送请求，或者，如果您使用的是静态服务器列表，则连接到下一个服务器。名单。 服务器每秒通过计时器中安排的任务发送一次ping消息。 您可以使用系统属性gemfire.serverToClientPingPeriod调整间隔，以毫秒为单位指定。 服务器将其ping间隔设置发送到客户端。 然后，客户端使用此和乘数在缓存中建立读取超时。 您可以将客户端属性`subscription-timeout-multiplier'设置为启用订阅源的超时，并将故障转移到另一台服务器。 值选项包括： 值为零（默认值）会禁用超时。 在指定的ping间隔数过去之后，服务器连接的值超过一次或多次。 不建议值为1。 池条件服务器如何加载 使用定位器时，池会定期调整其池连接。 每个连接都有一个内部寿命计数器。 当计数器达到配置的“load-conditioning-interval”时，池会检查定位器以查看连接是否正在使用负载最小的服务器。 如果没有，则池建立与最少加载的服务器的新连接，静默地将其置于旧连接的位置，并关闭旧连接。 在任何一种情况下，当操作完成时，计数器从零开始。 调节发生在幕后，不会影响应用程序的连接使用。 这种自动调节功能可以非常有效地升级服务器池。 在计划内和计划外服务器中断之后，它也很有用，在此期间，整个客户端负载将被放置在正常服务器集的子集上。 配置客户端/服务器系统 配置服务器和客户端进程以及数据区域以运行客户端/服务器系统。 先决条件 使用定位器配置服务器系统以进行成员发现。 请参阅配置点对点发现和管理对等或服务器缓存。 将客户端配置为独立应用程序。 请参阅管理客户端缓存。 熟悉缓存区域配置。 请参阅数据区域。 熟悉服务器和客户端配置属性。 请参阅cache.xml。 程序 通过完成以下一项或两项任务来配置服务器以侦听客户端。 通过在应用程序的cache.xml中指定元素并可选地指定要监听客户端连接的非默认端口，将每个应用程序服务器配置为服务器。 例如： 可选的。 使用非默认端口配置每个cacheserver进程以侦听客户端连接。 例如： prompt> cacheserver start -port=\"44454\" 配置客户端以连接到服务器。 在客户端cache.xml中，使用服务器系统的定位器列表配置客户端服务器池并配置客户端区域以使用池。 例如： ... 您无需在启动时向客户端提供完整的定位器列表，但您应尽可能提供完整的列表。 定位器维护定位器和服务器的动态列表，并根据需要向客户端提供信息。 按照这些准则配置服务器数据区域以进行客户端/服务器工作。 这些不需要按此顺序执行。 将服务器区域配置为已分区或已复制，以便为所有客户端提供服务器数据的一致缓存视图。 注意：如果未将服务器区域配置为已分区或已复制，则可以通过检查服务器区域内容的调用获得意外结果，例如keySetOnServer和containsKeyOnServer。 您可能只获得部分结果，并且您可能也会从两个连续调用中获得不一致的响应。 出现这些结果是因为服务器仅报告其本地缓存内容，并且如果没有分区或复制区域，它们可能无法完整查看其本地缓存中的数据。 定义复制的服务器区域时，请使用除REPLICATE_PROXY之外的任何REPLICATE,RegionShortcut设置。 复制的服务器区域必须具有distributed-ack或global``范围，并且定义该区域的每个服务器都必须存储数据。 区域快捷方式使用distributed-ack范围，所有非代理设置都存储数据。 定义分区服务器区域时，请使用PARTITION，RegionShortcut选项。你可以在一些服务器本地数据存储，而在其他没有本地存储。 当你启动服务器和客户端系统，客户区域将使用服务器区域的高速缓存未命中，事件订阅，查询和其它高速缓存活动。 接下来做什么 配置客户端以使用缓存并根据应用程序的需要订阅服务器中的事件。 请参阅配置客户端/服务器事件消息传递。 将服务器组织到逻辑成员组中 在客户端/服务器配置中，通过将服务器放入逻辑成员组，您可以控制客户端使用哪些服务器，并针对特定数据或任务定位特定服务器。 您可以配置服务器以管理不同的数据集或将特定的客户端流量定向到服务器的子集，例如直接连接到后端数据库的服务器。 您还可以定义成员组以并行部署JAR或跨成员组执行管理命令。 要将服务器添加到成员组，您可以配置以下内容： 将成员组名称添加到服务器的gemfire.properties文件中。 例如： groups=Portfolios,ManagementGroup1 服务器可以属于多个成员组。 如果为服务器指定多个组成员身份，请使用逗号分隔列表。 或者，如果您使用gfsh命令接口来启动服务器，请提供组名作为参数： gfsh>start server --name=server1 \\ --group=Portfolios,ManagementGroup1 要配置客户端连接到特定成员组，请修改客户端的cache.xml文件，为每个server-group定义一个不同的池，并将池分配给相应的客户区： ... ... 客户端/服务器示例配置 为了便于配置，您可以从这些示例客户端/服务器配置开始，并为您的系统进行修改。 标准客户端/服务器配置的示例 通常，定位器和服务器使用相同的属性文件，该文件将定位器列为对等成员和连接客户端的发现机制。 例如： mcast-port=0 locators=localhost[41111] 在您希望运行定位器的计算机上（在此示例中为“localhost”），您可以从gfsh提示符启动定位器： gfsh>start locator --name=locator_name --port=41111 或直接从命令行： prompt# gfsh start locator --name=locator_name --port=41111 指定要在localhost上启动的定位器的名称。 如果您未指定成员名称，gfsh将自动选择一个随机名称。 这对自动化很有用。 服务器的cache.xml声明了一个cache-server元素，它将JVM标识为集群中的服务器。 启动定位器和服务器后，定位器将服务器作为其集群中的对等方跟踪，并作为服务器在端口40404处侦听客户端连接。 您还可以使用gfsh命令行实用程序配置缓存服务器。 例如： gfsh>start server --name=server1 --server-port=40404 参见 start server. 客户端的cache.xml 声明自动将其配置为独立的Geode应用程序。 客户端的cache.xml： 使用定位器声明单个连接池作为获取服务器连接信息的参考。 使用客户端区域快捷方式配置CACHING_PROXY创建cs_region。 这会将其配置为在客户端缓存中存储数据的客户端区域。 只为客户端定义了一个池，因此池会自动分配给所有客户端区域。 这样，客户端被配置为转到服务器连接位置的定位器。 然后，任何缓存未命中或放入客户端区域都会自动转发到服务器。 示例 - 独立发布服务器客户端，客户端池和区域 以下API示例介绍了独立发布者客户端以及客户端池和区域的创建过程。 public static ClientCacheFactory connectStandalone(String name) { return new ClientCacheFactory() .set(\"log-file\", name + \".log\") .set(\"statistic-archive-file\", name + \".gfs\") .set(\"statistic-sampling-enabled\", \"true\") .set(\"cache-xml-file\", \"\") .addPoolLocator(\"localhost\", LOCATOR_PORT); } private static void runPublisher() { ClientCacheFactory ccf = connectStandalone(\"publisher\"); ClientCache cache = ccf.create(); ClientRegionFactory regionFactory = cache.createClientRegionFactory(PROXY); Region region = regionFactory.create(\"DATA\"); //... do work ... cache.close(); } 示例 - 独立订阅客户端 此API示例使用与上一示例相同的connectStandalone方法创建独立订阅客户端。 private static void runSubscriber() throws InterruptedException { ClientCacheFactory ccf = connectStandalone(\"subscriber\"); ccf.setPoolSubscriptionEnabled(true); ClientCache cache = ccf.create(); ClientRegionFactory regionFactory = cache.createClientRegionFactory(PROXY); Region region = regionFactory .addCacheListener(new SubscriberListener()) .create(\"DATA\"); region.registerInterestRegex(\".*\", // everything InterestResultPolicy.NONE, false/*isDurable*/); SubscriberListener myListener = (SubscriberListener)region.getAttributes().getCacheListeners()[0]; System.out.println(\"waiting for publisher to do \" + NUM_PUTS + \" puts...\"); myListener.waitForPuts(NUM_PUTS); System.out.println(\"done waiting for publisher.\"); cache.close(); } 客户端/服务器配置中的静态服务器列表示例 您可以在客户端配置中指定静态服务器列表而不是定位器列表。 使用此配置，客户端的服务器信息在客户端成员的生命周期内不会更改。 您没有获得动态服务器发现，服务器负载调节或逻辑服务器分组选项。 此模型对于您的服务器池稳定的非常小的部署（例如测试系统）非常有用。 它避免了运行定位器的管理开销。 如果必须使用硬件负载平衡器，此模型也适用。 您可以将负载均衡器的地址放在服务器列表中，并允许平衡器重定向客户端连接。 客户端的服务器规范必须与服务器正在侦听的地址匹配。 在服务器缓存配置文件中，以下是相关设置。 客户端的cache.xml文件声明了一个显式列出服务器的连接池，并在客户端区域的属性中命名池。 此XML文件使用区域属性模板初始化区域属性配置。 微调您的客户端/服务器配置 您可以使用服务器负载均衡和池连接的客户端线程使用来微调客户端/服务器系统。 例如，您可以配置服务器使用缓存服务器load-poll-interval属性检查其加载的频率，或者通过实现org.apache.geode.cache.server包来配置您自己的服务器负载指标。 服务器负载调节如何工作 当客户端池从服务器定位器请求连接信息时，定位器返回连接类型最少的服务器。 池使用此“最佳服务器”响应来打开新连接并调整（重新平衡）其现有池连接。 定位器根据服务器提供的信息跟踪服务器可用性和负载。 每个服务器定期探测其负载指标，并在检测到更改时将新信息发送到定位器。 此信息包括当前负载级别以及每个附加连接将添加多少负载的估计值。 定位器比较来自其服务器的负载信息，以确定哪些服务器可以最好地处理更多连接。 您可以配置服务器使用缓存服务器的“load-poll-interval”检查其负载的频率。 如果在正常操作期间发现服务器负载波动太大，您可能希望将其设置得更低。 但是，设置得越低，负载均衡将使用的开销就越大。 在来自服务器的更新之间，定位器通过使用服务器估计额外连接的成本来估计哪个服务器的负载最小。 例如，如果服务器连接的当前池连接负载为0.4，并且每个附加连接将0.1加载到其负载，则定位器可以估计添加两个新池连接将使服务器的池连接负载为0.6。 定位器之间不共享连接信息。 这些估计值为服务器更新之间的各个定位器提供了粗略的指导。 Geode提供了一个默认实用程序，用于探测服务器及其资源使用情况，以便为定位器提供加载信息。 默认探测器返回以下负载指标： - 池连接负载是服务器的连接数除以服务器的max-connections设置。 这意味着具有较低max-connections设置的服务器比具有较高设置的服务器接收的连接更少。 加载是0到1之间的数字，其中0表示没有连接，1表示服务器位于max-connections。 每个附加池连接的负载估计值为1/max-connections。 - 订阅连接负载是此服务器托管的订阅队列的数量。 每个附加订阅连接的负载估计值为1。 要使用您自己的服务器负载指标而不是默认值，请在org.apache.geode.cache.serverpackage中实现ServerLoadProbe或ServerLoadProbeAdapter以及相关的接口和类。 每台服务器的负载相对于系统中其他服务器报告的负载进行加权。 客户端线程使用池连接 客户端线程使用默认情况下，客户端线程从每个转发操作的开放连接池中检索连接，并在请求完成后立即将连接返回到池。 例如，如果客户端线程在客户端区域上运行put，那么该操作会抓取服务器连接，将put发送到服务器，然后将连接返回到池。 此操作使连接可用于池连接的大多数线程 设置线程本地(专用)连接 通过将thread-local-connections设置为true，可以将线程配置为使用专用连接。 在这种情况下，线程保持其连接，直到线程显式释放连接，或者连接基于idle-timeout或load-conditioning-interval到期。 释放线程本地连接 如果使用线程本地连接，则应在线程完成其服务器活动后立即释放连接。 在您用于该区域的Pool实例上调用releaseThreadLocalConnection： Region myRegion ... PoolManager.find(myRegion).releaseThreadLocalConnection(); 多站点(WAN)配置 使用多站点配置在不同的，松散耦合的集群之间水平扩展。 广域网(WAN)是多站点拓扑的主要用例。 多站点(WAN)系统的工作原理 Apache Geode多站点实现连接不同的集群。 系统在耦合时充当一个系统，当站点之间的通信失败时，它们充当独立系统。 耦合可以容忍集群站点之间的弱或慢链接。 广域网(WAN)是多站点拓扑的主要用例。 多站点(WAN)拓扑 要配置多站点拓扑，您应该了解建议的拓扑和要避免的拓扑。 配置多站点(WAN)系统 规划和配置多站点拓扑，并配置将在系统之间共享的区域。 过滤多站点(WAN)分发的事件 您可以选择创建网关发送方和/或网关接收方筛选器，以控制将哪些事件排队并分发到远程站点，或修改在Geode站点之间传输的数据流。 解决冲突事件 您可以选择创建GatewayConflictResolver缓存插件，以确定是否应将从其他站点传递的潜在冲突事件应用于本地缓存。 多站点(WAN)系统的工作原理 Apache Geode多站点实现连接不同的集群。 集群在耦合时充当一个分布式系统，当站点之间的通信失败时，它们充当独立系统。 耦合可以容忍集群站点之间的弱或慢链接。 广域网(WAN)是多站点拓扑的主要用例。 多站点缓存概述 多站点安装由两个或多个松散耦合的集群组成。 每个站点都管理自己的集群，但区域数据使用一个或多个逻辑连接分发到远程站点。 WAN更新的一致性 Geode确保区域的所有副本最终在托管该区域的所有成员和客户端上达到一致状态，包括通过WAN分发区域事件的Geode成员。 多站点系统的发现 WAN配置中的每个Geode集群都使用定位器来发现远程集群以及本地成员。 网关发件人 Geode集群使用gateway sender将区域事件分发到另一个远程Geode集群。 您可以创建多个网关发件人配置，以将区域事件分发到多个远程集群，和/或将区域事件同时分发到另一个远程集群。 网关接收器 网关接收器配置物理连接，用于从一个或多个远程Geode集群中的网关发送器接收区域事件。 多站点缓存概述 多站点安装由两个或多个松散耦合的集群组成。 每个站点都管理自己的集群，但区域数据使用一个或多个逻辑连接分发到远程站点。 逻辑连接包括发送站点中的网关发送方和接收站点中的网关接收方。 在客户端/服务器安装中，在服务器层中配置网关发件人和网关接收器。 网关发件人和接收者在成员缓存中启动时定义。 站点可以使用serial和/或parallel gateway sender配置，如[Gateway Senders]中所述(http://geode.apache.org/docs/guide/17/topologies_and_comm/topology_concepts/multisite_overview.html#topic_9AA37B43642D4DE19072CA3367C849BA)。 WAN更新的一致性 Geode确保区域的所有副本最终在托管该区域的所有成员和客户端上达到一致状态，包括通过WAN分发区域事件的Geode成员。 默认情况下，使用时间戳机制解决潜在的WAN冲突。 在确定是否应用通过WAN接收的可能存在冲突的更新时，您可以选择安装自定义冲突解决程序以应用自定义逻辑。 区域更新的一致性描述了Geode如何确保集群内，客户端缓存中以及应用更新时的一致性 通过广域网。 解决冲突事件提供了有关为WAN更新实施自定义冲突解决程序的更多详细信息。 多站点系统的发现 WAN配置中的每个Geode集群都使用定位器来发现远程集群以及本地成员。 WAN配置中的每个定位器都定义了一个唯一的distributed-system-id属性，用于标识它所属的本地集群。 定位器使用remote-locators属性来定义远程集群中一个或多个定位器的地址，以用于WAN分发。 当定位器启动时，它会联系remote-locators属性中配置的每个定位器，以交换有关集群中可用定位器和网关接收器的信息。 定位器还在已连接到集群的任何其他Geode集群中共享有关定位器和网关接收器的信息。 然后，连接的集群可以使用共享网关接收器信息来根据其配置的网关发送器来分发区域事件。 每次新定位器启动或现有定位器关闭时，更改的信息都会广播到其他连接的Geode集群。 网关发件人 Geode集群使用gateway sender将区域事件分发到另一个远程Geode集群。 您可以创建多个网关发件人配置，以将区域事件分发到多个远程集群，和/或将区域事件同时分发到另一个远程集群。 网关发送方始终与远程集群中的网关接收方通信。 网关发件人不直接与其他缓存服务器实例通信。 请参阅Gateway Receivers。 Geode提供两种类型的网关发件人配置：serial gateway发件人和parallel gateway发件人。 串行网关发件人 A 串行网关发送方通过本地集群中的单个Geode服务器将区域事件汇集到远程Geode集群中的网关接收器。 虽然多个区域可以使用相同的串行网关进行分发，但串行网关使用单个逻辑事件队列为所有使用网关发送方的区域分派事件。 由于串行网关发送方具有单个分发点，因此它可以在订购区域事件分布在WAN上时提供最大程度的控制。 但是，串行网关发送器仅提供有限的吞吐量，因此可能是性能瓶颈。 在向本地集群添加更多区域和服务器时，可能需要手动配置其他串行网关发件人，并隔离特定串行网关发件人的各个区域，以处理增加的分发流量。 并行网关发件人 A 并行网关发送方从托管分区区域的每个Geode服务器分发区域事件。 对于分区区域，承载该区域主存储桶的每个服务器都使用其自己的逻辑队列来分配这些存储区的事件。 在添加新服务器以扩展分区区域时，WAN分发吞吐量会自动与并行网关发送方的每个新实例一起扩展。 复制区域不能使用并行网关发件人。 虽然并行网关发送器为WAN分发提供了最佳吞吐量，但它们对事件排序的控制较少。 不保留整个区域的事件排序，因为多个Geode服务器同时分发区域事件。 但是，可以保留给定分区的事件顺序。 请参阅配置多站点(WAN)事件队列。 网关发件人队列 网关发件人用于将事件分发到远程站点的队列会根据需要溢出到磁盘，以防止Geode成员内存不足。 您可以配置每个队列使用的最大内存量，以及处理队列中批次的批量大小和频率。 您还可以将这些队列配置为持久保存到磁盘，以便网关发送方可以在其成员关闭并稍后重新启动时从中断处继续。 默认情况下，网关发件人队列使用5个线程来分派排队的事件。 使用串行网关发送器，成员上托管的单个逻辑队列将分为多个物理队列(默认情况下为5个)，每个物理队列都有一个专用的调度程序线程。 您可以配置线程是按键，按线程还是按照将事件添加到队列的相同顺序来调度排队事件。 对于并行网关发送方，成员上托管的每个逻辑队列由多个线程同时处理。 请参阅配置多站点(WAN)事件队列。 网关发件人的高可用性 将串行网关发件人配置部署到多个Geode成员时，在给定时间只有一个“主”发件人处于活动状态。 所有其他串行网关发送方实例都是非活动的“辅助节点”，如果主发送方关闭，它们可用作备份。 Geode指定第一个网关发件人作为主发件人启动，所有其他发件人成为辅助发件人。 当网关发件人启动和关闭时，Geode会确保最早运行的网关发件人作为主要发件人运行。 默认情况下，并行网关发送方部署到多个Geode成员，并且为分区区域托管主存储区的每个成员都会主动将数据分发到远程Geode站点。 使用并行网关发件人时，如果将分区区域配置为冗余，则会提供WAN分发的高可用性。 对于冗余分区区域，如果承载主存储桶的成员发生故障或关闭，则承载这些存储区冗余副本的Geode成员将接管这些存储区的WAN分发。 停止网关发件人 网关发送方停止操作的范围是调用它的VM。 当您使用GatewaySender.stop()或gfsh stop gateway-sender停止并行网关发送方时，网关发送方将在调用此API的单个节点上停止。 如果网关发送方不是并行(串行)，则网关发送方将在本地VM上停止，并且辅助网关发送方将成为主要发送方并开始分派事件。 网关发送方将在停止之前等待GatewaySender.MAXIMUM_SHUTDOWN_WAIT_TIME秒(默认情况下，此值设置为0)。 在gfsh中启动服务器成员时，可以设置此Java系统属性。 如果Java系统属性设置为-1，则网关发送方进程将等待，直到在停止之前从队列调度所有事件。 注意: 使用GatewaySender.stop()API或gfsh stop gateway-sender命令停止并行网关发件人时要格外小心。 API和gfsh命令会在一个成员中停止并行网关发件人，这会导致数据丢失，因为停止的发件人将丢弃该成员中的存储桶事件。 由于成员仍在运行，因此分区区域在此方案中不会进行故障转移。 相反，为了确保发送剩余事件，请关闭整个成员以确保分区区域事件的正确故障转移。 当关闭已停止并行发送方的成员时，托管分区区域的其他并行网关发送方成员将成为主要成员并传递其余事件。 此外，如果在停止单个并行网关发送方后关闭整个集群，则可能会丢失在该网关发送方上排队的事件。 暂停网关发件人 与停止网关发件人类似，暂停网关发件人的范围是调用它的VM。 暂停网关发件人会暂时停止从基础队列调度事件。 请注意，事件仍排队到队列中。 在网关发送方是并行的情况下，网关发送方暂停在调用GatewaySender.pause()API或调用gfsh pause gateway-sender命令的单个节点上。 其他成员上的并行网关发件人仍然可以调度事件。 如果暂停的网关发送方不是并行(串行)且不是主要网关，则主网关发送方仍将继续调度事件。 无论暂停操作的状态如何，都将调度正在调度的一批事件。 即使在网关发件人暂停后，我们也可以预期在网关接收器上最多接收一批事件。 网关接收器 网关接收器配置物理连接，用于从一个或多个远程Geode集群中的网关发送器接收区域事件。 网关接收器将每个区域事件应用于本地Geode成员中托管的相同区域或分区。 (如果接收者收到未定义的区域的事件，则抛出异常。) 网关发件人使用目标集群中的任何可用网关接收器来发送区域事件。 您可以根据需要将网关接收器配置部署到多个Geode成员，以实现高可用性和负载均衡，但是每个成员只能托管一个网关接收器。 创建网关接收器后，您可以将网关接收器配置为自动启动或需要手动启动。 默认情况下，网关接收器自动启动(manual-start设置为false)。 在一个WAN站点上创建并启动新的网关接收器后，您可以执行load-balance gateway-sender在gfsh现有远程网关发件人，使得新的接收器可以拿起连接在不同的位点到网关发件人命令。您可以在网关发件人上调用此命令，以便在所有网关接收器之间更均匀地重新分配连接。 另一种选择是使用GatewaySender.rebalance Java API。 请参阅配置网关接收器。 多站点(WAN)拓扑 要配置多站点拓扑，您应该了解建议的拓扑和要避免的拓扑。 本节介绍Geode对各种拓扑的支持。 根据您的应用程序需求，可能有多种拓扑可行。 这些是要记住的注意事项： 当Geode站点收到来自网关发件人的消息时，它会将其转发到它知道的其他站点，排除那些它知道已经看过该消息的站点。 每条消息都包含初始发件人的ID和初始发件人发送到的每个站点的ID，因此没有站点转发到这些站点。 但是，消息不会获取它们通过的站点的ID，因此在某些拓扑中可以将多个消息副本发送到一个站点。 在某些配置中，一个站点的丢失会影响其他站点之间的通信方式。 完全连接的网状拓扑 完全连接的网状网络拓扑是所有站点彼此了解的拓扑。 这是一个强大的配置，因为任何一个站点都可以在不中断其他站点之间的通信的情况下停机。 完全连接的网状拓扑还可确保没有站点接收同一消息的多个副本。 图中显示了具有三个位置的完全连接的网格。 在这种情况下，如果站点1向站点2发送更新，站点2将转发到站点3.如果站点1向站点2和3发送更新，则不会转发到站点2。 对于任何其他发起站点也是如此。 如果删除了任何站点，则其余站点仍然完全连接。 环形拓扑 环形拓扑是每个站点将信息转发到另一个站点，并且站点以循环方式连接的拓扑。 该图显示了具有三个站点的环。 在此拓扑中，如果站点1向站点2发送更新，站点2会将更新转发到站点3.不会将更新转发到原始发件人，因此站点3不会将更新发送回站点1。 环形拓扑保证每个站点都收到任何站点发送的每条消息的一个副本。 在一个环中，每个站点都必须保持连接以保持连接。 任何网站的失败都会破坏更新到达所有网站的能力。 例如，如果站点2发生故障，站点3可能会发送到站点1，但站点1无法发送到站点3。 混合多站点拓扑 有许多混合网络拓扑。 一些站点完全连接，而其他站点形成一个环。 下图显示了形成环的混合拓扑，具有完全连接站点1和3的额外连接。 使用此混合拓扑，如果站点2发生故障，则不会影响站点1和站点3之间的通信。但是，如果站点3发生故障，站点2将无法发送到站点1。 第二个示例混合拓扑结构如下图所示。 在此树形拓扑中，站点1作为树的根，站点2和3不会相互通信。 此拓扑适用于其中站点1是生产者且消费者(站点2和3)彼此连接无法获得的应用程序。 此拓扑还可确保没有站点两次收到相同的更新。 不支持的拓扑 可以向特定站点提供两次相同更新的拓扑不起作用且不受支持。 此图中显示的DAG拓扑是不受支持的技术的示例。 当站点1向站点2和3发送消息时，站点4将收到同一消息的多个副本，站点2和3各自将消息转发到站点4。 配置多站点(WAN)系统 规划和配置多站点拓扑，并配置将在系统之间共享的区域。 先决条件 在开始之前，您应该了解如何使用定位器在对等系统中配置成员资格和通信。 请参阅配置点对点发现和[配置对等通信](http://geode.apache.org/docs/guide/17/topologies_and_comm/p2p_configuration/setting_up_peer_communication.html）。 WAN部署增加了Geode系统的消息传递需求。 为避免与WAN消息传递相关的挂起，请始终为参与WAN部署的Geode成员设置conserve-sockets = false。 请参阅在多站点(WAN)部署中配置套接字和确保您有足够的套接字。 主要步骤 使用以下步骤配置多站点系统： 规划多站点系统的拓扑。 有关不同多站点拓扑的说明，请参见多站点(WAN)拓扑。 为多站点系统中的每个集群配置成员身份和通信。 您必须在WAN配置中使用定位器进行对等发现。 请参阅配置点对点发现。 使用唯一的distributed-system-id启动每个集群，并使用remote-locators识别远程集群。 例如： mcast-port=0 locators=[],[] distributed-system-id=1 remote-locators=[],[] 配置将用于将区域事件分发到远程系统的网关发件人。 请参阅配置网关发件人。 创建要参与多站点系统的数据区域，指定每个区域应用于WAN分发的网关发件人。 在目标集群中配置相同的区域以应用分布式事件。 请参阅为多站点通信创建数据区域。 在每个Geode集群中配置网关接收器，以接收来自另一个集群的区域事件。 请参阅配置网关接收器。 以正确的顺序启动集群成员进程(首先是定位器，然后是数据节点)，以确保有效发现WAN资源。 请参阅启动和关闭系统。 (可选)部署自定义冲突解决程序以处理在通过WAN应用事件时检测到的潜在冲突。 请参阅解决冲突事件。 (可选)部署WAN过滤器以确定哪些事件通过WAN分发，或修改通过WAN分发的事件。 请参阅过滤多站点(WAN)分发的事件。 (可选)使用配置多站点（WAN）事件队列中的说明为网关发件人队列配置持久性，混合和/或调度程序线程. 配置网关发件人 每个网关发件人配置包括： 网关发件人配置的唯一ID。 发件人传播区域事件的远程站点的分布式系统ID。 一种属性，指定网关发件人是串行网关发件人还是并行网关发件人。 配置网关发件人队列的可选属性。 这些队列属性确定诸如队列使用的内存量，队列是否持久保存到磁盘以及一个或多个网关发送方线程如何从队列中分派事件等功能。 注意: 要配置使用gfsh创建下面描述的cache.xml配置的网关发件人，以及其他选项，请参阅create gateway-sender。 有关各个配置属性的详细信息，请参阅WAN配置。 对于每个Geode系统，选择将承载网关发件人配置并将区域事件分发到远程站点的成员： 您必须在承载使用发件人的区域的每个Geode成员上部署并行网关发件人配置。 必须共同使用相同并行网关发送方ID的区域。 您可以选择在一个或多个Geode成员上部署串行网关发件人配置，以提供高可用性。 但是，给定的串行网关发送方配置中只有一个实例在任何给定时间分配区域事件。 使用gfsh，cache.xml或Java API在Geode成员上配置每个网关发件人： gfsh配置命令 gfsh>create gateway-sender --id=\"sender2\" --parallel=true --remote-distributed-system-id=\"2\" gfsh>create gateway-sender --id=\"sender3\" --parallel=true --remote-distributed-system-id=\"3\" cache.xml配置 这些示例cache.xml条目配置两个并行网关发送器，以将区域事件分发到两个远程Geode集群（集群“2”和“3”）： ... Java配置 此示例代码显示如何使用API配置并行网关发件人： // Create or obtain the cache Cache cache = new CacheFactory().create(); // Configure and create the gateway sender GatewaySenderFactory gateway = cache.createGatewaySenderFactory(); gateway.setParallel(true); GatewaySender sender = gateway.create(\"sender2\", \"2\"); sender.start(); 您可能需要在每个网关发件人中配置其他功能，具体取决于您的应用程序。 你需要考虑的事情是： 每个网关发件人队列可以使用的最大内存量。 当队列超过配置的内存量时，队列的内容将溢出到磁盘。 例如： gfsh>create gateway-sender --id=sender2 --parallel=true --remote-distributed-system-id=2 --maximum-queue-memory=150 在cache.xml中： 是否启用磁盘持久性，以及是否使用命名磁盘存储来实现持久性或溢出队列事件。 请参阅持久化事件队列。 例如： gfsh>create gateway-sender --id=sender2 --parallel=true --remote-distributed-system-id=2 \\ --maximum-queue-memory=150 --enable-persistence=true --disk-store-name=cluster2Store 在cache.xml中： 用于处理来自每个网关队列的事件的调度程序线程数。 网关发送方的dispatcher-threads属性指定处理队列的线程数(默认值为5)。 例如： gfsh>create gateway-sender --id=sender2 --parallel=true --remote-distributed-system-id=2 \\ --dispatcher-threads=2 --order-policy=partition 在cache.xml中： 注意: 为串行队列配置多个调度程序线程时，每个线程都在其自己的网关发送方队列副本上运行。 对于您配置的每个调度程序线程，将重复队列配置属性，例如maximum-queue-memory。 请参阅为事件分发配置调度程序线程和顺序策略。 对于使用多个dispatcher-threads的串行网关发件人(parallel=false)，还要配置用于调度事件的排序策略。 请参阅为事件分发配置调度程序线程和顺序策略。 确定是否应该将事件混淆在队列中。 请参阅配置队列中的事件。 注意: 在承载网关发件人的每个Geode成员上，特定发件人id的网关发件人配置必须相同。 为多站点通信创建数据区域 使用多站点配置时，您可以选择在站点之间共享的数据区域。 由于在不同地理位置之间分发数据的成本很高，因此并非所有更改都在站点之间传递。 请注意这些区域的重要限制： 复制区域不能使用并行网关发件人。 请改用串行网关发件人。 除了使用网关发件人配置区域以分发事件之外，还必须在目标集群中配置相同的区域以应用分布式事件。 接收集群中的区域名称必须与发送集群中的区域名称完全匹配。 必须共同使用相同并行网关发送方ID的区域。 定义网关发件人后，配置区域以使用网关发件人分发区域事件。 gfsh配置 gfsh>create region --name=customer --gateway-sender-id=sender2,sender3 或修改现有区域： gfsh>alter region --name=customer --gateway-sender-id=sender2,sender3 cache.xml配置 使用gateway-sender-ids region属性将网关发件人添加到区域。 要分配多个网关发件人，请使用逗号分隔列表。 例如： Java API配置 此示例显示将两个网关发件人（在前面的示例中配置）添加到分区区域： RegionFactory rf = cache.createRegionFactory(RegionShortcut.PARTITION); rf.addCacheListener(new LoggingCacheListener()); rf.addGatewaySenderId(\"sender2\"); rf.addGatewaySenderId(\"sender3\"); custRegion = rf.create(\"customer\"); 注意: 使用Java API时，必须先配置并行网关发送方，然后才能将其ID添加到区域。 这可确保发件人分发在新缓存操作发生之前保留的区域事件。 如果在将区域添加到区域时网关发件人ID不存在，则会收到IllegalStateException。 配置网关接收器 始终在每个Geode集群中配置一个网关接收器，该接收器将从另一个集群接收和应用区域事件。 网关接收器配置可应用于多个Geode服务器，以实现负载平衡和高可用性。 但是，承载网关接收器的每个Geode成员还必须定义接收器可以接收事件的所有区域。 如果网关接收器收到本地成员未定义的区域的事件，则Geode会抛出异常。 请参阅为多站点通信创建数据区域。 注意: 每个成员只能托管一个网关接收器。 网关接收器配置指定要监听的可能端口号的范围。 Geode服务器从指定范围中选取一个未使用的端口号，以用于接收器进程。 您可以使用此功能轻松地将相同的网关接收器配置部署到多个成员。 您可以选择配置网关接收器，以便为网关发送方连接提供特定的IP地址或主机名。 如果配置hostname-for-senders，则在指示网关发件人如何连接到网关接收器时，定位器将使用提供的主机名或IP地址。 如果您提供“”或null作为值，则默认情况下，网关接收方的绑定地址将发送给客户端。 此外，您可以将网关接收器配置为自动启动，或者通过将manual-start设置为true来要求手动启动。 默认情况下，网关接收器自动启动。 注意: 要配置网关接收器，您可以使用gfsh，cache.xml或Java API配置，如下所述。 有关在gfsh中配置网关接收器的更多信息，请参阅create gateway-receiver。 gfsh配置命令 gfsh>create gateway-receiver --start-port=1530 --end-port=1551 \\ --hostname-for-senders=gateway1.mycompany.com cache.xml配置 以下配置定义了一个网关接收器，用于侦听1530到1550范围内未使用的端口： ... Java API配置 // Create or obtain the cache Cache cache = new CacheFactory().create(); // Configure and create the gateway receiver GatewayReceiverFactory gateway = cache.createGatewayReceiverFactory(); gateway.setStartPort(1530); gateway.setEndPort(1551); gateway.setHostnameForSenders(\"gateway1.mycompany.com\"); GatewayReceiver receiver = gateway.create(); 注意: 使用Java API时，必须创建可能在创建网关接收器之前从远程站点接收事件的任何区域。 否则，在创建这些事件的区域之前，可以从远程站点到达批量事件。 如果发生这种情况，本地站点将抛出异常，因为接收区域尚不存在。 如果在cache.xml中定义区域，则会自动处理正确的启动顺序。 启动新的网关接收器后，您可以执行load-balance gateway-sender命令 在gfsh中，以便特定的网关发送方能够重新平衡其连接并连接新的远程网关接收器。 调用此命令可在所有网关接收器之间更均匀地重新分配网关发送方连接。 另一种选择是使用GatewaySender.rebalance Java API。 例如，假设以下情形： 在NY站点创建1个接收器。 在LN站点创建4个发件人。 在NY创建另外3个接收器。 然后，您可以在gfsh中执行以下操作以查看重新平衡的效果： gfsh -e \"connect --locator=localhost[10331]\" -e \"list gateways\" ... (2) Executing - list gateways Gateways GatewaySender GatewaySender Id | Member | Remote Cluster Id | Type | Status | Queued Events | Receiver Location ---------------- | --------------------------------- | ----------------- | -------- | ------- | ------------- | ----------------- ln | boglesbymac(ny-1:88641):33491 | 2 | Parallel | Running | 0 | boglesbymac:5037 ln | boglesbymac(ny-2:88705):29329 | 2 | Parallel | Running | 0 | boglesbymac:5064 ln | boglesbymac(ny-3:88715):36808 | 2 | Parallel | Running | 0 | boglesbymac:5132 ln | boglesbymac(ny-4:88724):52993 | 2 | Parallel | Running | 0 | boglesbymac:5324 GatewayReceiver Member | Port | Sender Count | Sender's Connected --------------------------------- | ---- | ------------ | -------------------------------------------------------------------------- boglesbymac(ny-1:88641):33491 | 5057 | 24 | [\"boglesbymac(ln-1:88651):48277\",\"boglesbymac(ln-4:88681):42784\",\"boglesbymac(ln-2:88662):12796\",\"boglesbymac(ln-3:88672):43675\"] boglesbymac(ny-2:88705):29329 | 5082 | 0 | [] boglesbymac(ny-3:88715):36808 | 5371 | 0 | [] boglesbymac(ny-4:88724):52993 | 5247 | 0 | [] 执行load-balance命令： gfsh -e \"connect --locator=localhost[10441]\" -e \"load-balance gateway-sender --id=ny\"... (2) Executing - load-balance gateway-sender --id=ny Member | Result | Message --------------------------------- | ------ |-------------------------------------------------------------------------- boglesbymac(ln-1:88651):48277 | OK | GatewaySender ny is rebalanced on member boglesbymac(ln-1:88651):48277 boglesbymac(ln-4:88681):42784 | OK | GatewaySender ny is rebalanced on member boglesbymac(ln-4:88681):42784 boglesbymac(ln-3:88672):43675 | OK | GatewaySender ny is rebalanced on member boglesbymac(ln-3:88672):43675 boglesbymac(ln-2:88662):12796 | OK | GatewaySender ny is rebalanced on member boglesbymac(ln-2:88662):12796 在ny中列出网关再次表明连接在接收器之间传播得更好。 gfsh -e \"connect --locator=localhost[10331]\" -e \"list gateways\"... (2) Executing - list gateways Gateways GatewaySender GatewaySender Id | Member | Remote Cluster Id | Type | Status | Queued Events | Receiver Location ---------------- | --------------------------------- | ---------------- | -------- | ------- | ------------- | ----------------- ln | boglesbymac(ny-1:88641):33491 | 2 | Parallel | Running | 0 | boglesbymac:5037 ln | boglesbymac(ny-2:88705):29329 | 2 | Parallel | Running | 0 | boglesbymac:5064 ln | boglesbymac(ny-3:88715):36808 | 2 | Parallel | Running | 0 | boglesbymac:5132 ln | boglesbymac(ny-4:88724):52993 | 2 | Parallel | Running | 0 | boglesbymac:5324 GatewayReceiver Member | Port | Sender Count | Sender's Connected --------------------------------- | ---- | ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------- boglesbymac(ny-1:88641):33491 | 5057 | 9 |[\"boglesbymac(ln-1:88651):48277\",\"boglesbymac(ln-4:88681):42784\",\"boglesbymac(ln-3:88672):43675\",\"boglesbymac(ln-2:88662):12796\"] boglesbymac(ny-2:88705):29329 | 5082 | 4 |[\"boglesbymac(ln-1:88651):48277\",\"boglesbymac(ln-4:88681):42784\",\"boglesbymac(ln-3:88672):43675\"] boglesbymac(ny-3:88715):36808 | 5371 | 4 |[\"boglesbymac(ln-1:88651):48277\",\"boglesbymac(ln-4:88681):42784\",\"boglesbymac(ln-3:88672):43675\"] boglesbymac(ny-4:88724):52993 | 5247 | 3 |[\"boglesbymac(ln-1:88651):48277\",\"boglesbymac(ln-4:88681):42784\",\"boglesbymac(ln-3:88672):43675\"] 在站点ln中运行负载平衡命令再次产生更好的平衡。 Member | Port | Sender Count | Sender's Connected --------------------------------- | ---- | ------------ |------------------------------------------------------------------------------------------------------------------------------------------------- boglesbymac(ny-1:88641):33491 | 5057 | 7 |[\"boglesbymac(ln-1:88651):48277\",\"boglesbymac(ln-4:88681):42784\",\"boglesbymac(ln-2:88662):12796\",\"boglesbymac(ln-3:88672):43675\"] boglesbymac(ny-2:88705):29329 | 5082 | 3 |[\"boglesbymac(ln-1:88651):48277\",\"boglesbymac(ln-3:88672):43675\",\"boglesbymac(ln-2:88662):12796\"] boglesbymac(ny-3:88715):36808 | 5371 | 5 |[\"boglesbymac(ln-1:88651):48277\",\"boglesbymac(ln-4:88681):42784\",\"boglesbymac(ln-2:88662):12796\",\"boglesbymac(ln-3:88672):43675\"] boglesbymac(ny-4:88724):52993 | 5247 | 6 |[\"boglesbymac(ln-1:88651):48277\",\"boglesbymac(ln-4:88681):42784\",\"boglesbymac(ln-2:88662):12796\",\"boglesbymac(ln-3:88672):43675\"] 过滤多站点(WAN)分发的事件 您可以选择创建网关发送方和/或网关接收方筛选器，以控制将哪些事件排队并分发到远程站点，或修改在Geode站点之间传输的数据流。 您可以为多站点事件实现和部署两种不同类型的过滤器： GatewayEventFilter. GatewayEventFilter实现确定区域事件是否放置在网关发送方队列中和/或网关队列中的事件是否分发到远程站点。 您可以选择将一个或多个GatewayEventFilter实现添加到网关发送方，在cache.xml配置文件中或使用Java API。 Geode在网关发送方队列中放置区域事件之前，会对过滤器的beforeEnqueue方法进行同步调用。 过滤器返回一个布尔值，指定是否应将事件添加到队列中。 Geode异步调用过滤器的beforeTransmit方法，以确定网关发送方调度程序线程是否应将事件分发给远程网关接收方。 对于分发到另一个站点的事件，Geode调用侦听器的afterAcknowledgement方法，以指示在收到事件后已从远程站点收到ack。 GatewayTransportFilter. 使用GatewayTransportFilter实现来处理TCP流，该TCP流发送一批通过WAN从一个Geode集群分发到另一个Geode集群的事件。 GatewayTransportFilter通常用于对分发的数据执行加密或压缩。 您在网关发送器和网关接收器上安装相同的GatewayTransportFilter实现。 当网关发件人处理一批事件以进行分发时，Geode将流传递到已配置的GatewayTransportFilter实现的getInputStream方法。 过滤器处理并返回流，然后将其传输到网关接收器。 当网关接收器收到批处理时，Geode调用已配置过滤器的getOutputStream方法，该方法再次处理并返回流，以便可以在本地集群中应用事件。 配置多站点事件筛选器 您将GatewayEventFilter实现安装到已配置的网关发送方，以便确定排队和分发哪些事件。 您将GatewayTransportFilter实现安装到网关发送方和网关接收方，以处理在两个站点之间分发的批处理事件流： XML示例 org.apache.geode.util.SampleEventFilter \"value1\" org.apache.geode.util.SampleTransportFilter \"value1\" xml ... org.apache.geode.util.SampleTransportFilter \"value1\" gfsh的例子 gfsh>create gateway-sender --id=remoteA --parallel=true --remote-distributed-id=\"1\" --gateway-event-filter=org.apache.geode.util.SampleEventFilter --gateway-transport-filter=org.apache.geode.util.SampleTransportFilter 请参阅create gateway-sender。 gfsh>create gateway-receiver --start-port=1530 --end-port=1551 \\ --gateway-transport-filter=org.apache.geode.util.SampleTransportFilter 注意: 您不能使用--gateway-transport-filter选项指定您指定的Java类的参数和值。 请参阅create gateway-receiver。 API示例 Cache cache = new CacheFactory().create(); GatewayEventFilter efilter = new SampleEventFilter(); GatewayTransportFilter tfilter = new SampleTransportFilter(); GatewaySenderFactory gateway = cache.createGatewaySenderFactory(); gateway.setParallel(true); gateway.addGatewayEventFilter(efilter); gateway.addTransportFilter(tfilter); GatewaySender sender = gateway.create(\"remoteA\", \"1\"); sender.start(); Cache cache = new CacheFactory().create(); GatewayTransportFilter tfilter = new SampleTransportFilter(); GatewayReceiverFactory gateway = cache.createGatewayReceiverFactory(); gateway.setStartPort(1530); gateway.setEndPort(1551); gateway.addTransportFilter(tfilter); GatewayReceiver receiver = gateway.create(); receiver.start(); 解决冲突事件 您可以选择创建GatewayConflictResolver缓存插件，以确定是否应将从其他站点传递的潜在冲突事件应用于本地缓存。 默认情况下，当成员应用从另一个集群成员或通过WAN从远程集群接收的更新时，所有区域都会执行一致性检查。 在如何在WAN部署中实现一致性中描述了WAN事件的默认一致性检查。 您可以通过编写和配置自定义GatewayConflictResolver来覆盖默认的一致性检查行为。 GatewayConflictResolver实现可以使用WAN更新事件中包含的时间戳和分布式系统ID来确定是否应用更新。 例如，当更新之间的时间戳差异小于某个固定的时间段时，您可以决定来自特定集群的更新应始终“赢得”冲突。 实现GatewayConflictResolver 注意: 仅对可能导致区域冲突的更新事件调用GatewayConflictResolver实现。 这对应于具有与上次更新区域条目的分布式系统不同的分布式系统ID的更新事件。 如果相同的分布式系统ID对区域条目进行连续更新，则不会发生冲突，并且不会调用GatewayConflictResolver。 程序 编程事件处理程序： 创建一个实现GatewayConflictResolver接口的类。 如果要在cache.xml中声明处理程序，也要实现org.apache.geode.cache.Declarable接口。 实现处理程序的onEvent()方法以确定是否应该允许WAN事件。 onEvent()接收TimestampedEntryEvent和GatewayConflictHelperinstance。 TimestampedEntryEvent具有获取更新事件和当前区域条目的时间戳和分布式系统ID的方法。 使用GatewayConflictHelper中的方法来禁止更新事件(保留现有的区域条目值)或提供备用值。 例子: public void onEvent(TimestampedEntryEvent event, GatewayConflictHelper helper) { if (event.getOperation().isUpdate()) { ShoppingCart oldCart = (ShoppingCart)event.getOldValue(); ShoppingCart newCart = (ShoppingCart)event.getNewValue(); oldCart.updateFromConflictingState(newCart); helper.changeEventValue(oldCart); } } 注意: 为了保持区域的一致性，您的冲突解决程序必须始终以相同的方式解析两个事件，无论它首先接收哪个事件。 使用cache.xml文件或Java API为缓存安装冲突解决程序。 cache.xml ... myPackage.MyConflictResolver ... Java API // Create or obtain the cache Cache cache = new CacheFactory().create(); // Create and add a conflict resolver cache.setGatewayConflictResolver(new MyConflictResolver); Copyright © WS 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-12-06 10:45:22 "},"Geode_5_Managing_Apache_Geode.html":{"url":"Geode_5_Managing_Apache_Geode.html","title":"管理 Apache Geode","keywords":"","body":"管理 Apache GeodeApache Geode管理和监控 管理和监控功能Geode管理和监控工具概述 架构和组件JMX管理器操作 联邦MBean架构 配置RMI注册表端口和RMI连接器 通过Management API执行gfsh命令 管理堆和堆外内存调整JVM垃圾收集参数 使用Geode资源管理器 使用资源管理器控制堆使用配置堆用于LRU管理的Geode 设置JVM GC调整参数 监视和调整堆LRU配置 资源管理器示例配置管理 Off-Heap 内存 锁定内存(仅限Linux系统) 磁盘存储磁盘存储的工作原理磁盘存储文件名和扩展名磁盘存储操作日志配置磁盘存储使用磁盘存储优化系统启动并关闭磁盘存储磁盘存储管理为系统恢复和运营管理创建备份缓存和区域快照用法和性能说明导出缓存和区域快照导入缓存和区域快照导入或导出期间过滤条目以编程方式读取快照区域压缩怎样得到压缩如何在区域中启用压缩使用压缩器压缩和非压缩区域的性能比较网络分区网络分区管理的工作原理故障检测和成员资格视图成员协调员，主要成员和成员加权网络分区方案配置Apache Geode处理网络分区 防止网络分区安全安全实施简介和概述安全细节考虑因素使用属性定义启用安全性认证授权区域数据的后处理SSL性能调整和配置禁用TCP SYN Cookies 提高vSphere的性能 性能控制系统成员性能带有TCP/IP的慢速接收器 慢分布式确认消息套接字通信UDP 通信 组播通信维护缓存一致性日志Geode日志如何工作 了解日志消息及其类别命名，搜索和创建日志文件 设置日志记录高级用户 - 为Geode配置Log4j 2 统计统计如何运作瞬态区域和条目统计应用程序定义和自定义统计配置和使用统计信息查看存档统计信息故障排除和系统恢复生成用于故障排除的工件诊断系统问题系统故障和恢复使用自动重新连接处理强制缓存断开连接从应用程序和缓存服务器崩溃中恢复从机器崩溃中恢复从ConfictingPersistentDataExceptions中恢复 防止和恢复磁盘完全错误理解和恢复网络中断管理 Apache Geode 管理 Apache Geode 描述如何规划和实现与Apache Geode的管理，监视和故障排除相关的任务。 Apache Geode管理和监控 Apache Geode提供用于管理集群和监视集群成员运行状况的API和工具。 管理堆和堆外内存 默认情况下，Apache Geode使用JVM堆。 Apache Geode还提供了一种从堆中存储数据的选项。 本节介绍如何管理堆和堆外内存以最好地支持您的应用程序。 磁盘存储 使用Apache Geode磁盘存储，您可以将数据保存到磁盘，作为内存中副本的备份，并在内存使用过高时将数据溢出到磁盘。 缓存和区域快照 快照允许您保存区域数据并在以后重新加载。 典型的用例是将数据从一个环境加载到另一个环境，例如从生产系统捕获数据并将其移动到较小的QA或开发系统中。 区域压缩 本节介绍区域压缩，其优点和用法。 网络分区 Apache Geode体系结构和管理功能有助于检测和解决网络分区问题。 安全 安全框架通过在连接时验证组件和成员来建立信任。 它有助于操作的授权。 性能调整和配置 一组工具和控件允许您监视和调整Apache Geode性能。 日志 全面的日志消息可帮助您确认配置和代码中的系统配置和调试问题。 统计 集群中的每个应用程序和服务器都可以访问有关Apache Geode操作的统计数据。 您可以使用gfsh的alter runtime命令或gemfire.properties文件来配置统计信息的收集，以便于系统分析和故障排除。 故障排除和系统恢复 本节提供了处理常见错误和故障情况的策略。 Apache Geode管理和监控 Apache Geode提供用于管理集群和监控成员运行状况的API和工具。 管理和监控功能 Apache Geode使用联合Open Open MBean策略来管理和监视集群的所有成员。 此策略为您提供集群的统一单代理视图。 Geode管理和监控工具概述 Geode提供了各种管理工具，可用于管理Geode集群。 架构和组件 Geode的管理和监视系统由一个JMX Manager节点(应该只有一个)和一个集群中的一个或多个受管节点组成。 集群中的所有成员都可通过MBean和Geode Management Service API进行管理。 JMX管理器操作 任何成员都可以托管嵌入式JMX Manager，它提供集群的所有MBean的联合视图。 通过在ManagementService上调用相应的API调用，可以将成员配置为在启动时或在其生命中的任何时间成为管理器。 联合MBean架构 Geode使用MBean来管理和监控Geode的不同部分。 Geode的联合MBean架构是可扩展的，允许您拥有Geode集群的单代理视图。 配置RMI注册表端口和RMI连接器 Geode以编程方式模拟Java提供的开箱即用的JMX，并在所有可管理成员上创建带有RMI Registry和RMI Connector端口的JMXServiceURL。 通过Management API执行gfsh命令 您还可以使用管理API以编程方式执行gfsh命令。 管理和监控功能 Apache Geode使用联合Open Open MBean策略来管理和监视集群的所有成员。 此策略为您提供集群的统一单代理视图。 应用程序和管理器开发更容易，因为您不必在MBean上找到正确的MBeanServer来发出请求。 相反，您与单个MBeanServer交互，该MBeanServer从所有其他本地和远程MBeanServers聚合MBean。 Geode管理架构的其他一些关键优势和特性： Geode监控紧密集成到Geode的流程中，而不是在单独安装和配置的监控代理中运行。 您可以使用相同的框架来实际管理Geode并执行管理操作，而不仅仅是监控它。 所有Geode MBean都是MXBeans。 它们代表有关集群状态及其所有成员的有用且相关的信息。 由于MXBeans将Open MBean模型与预定义的一组类型一起使用，因此客户端和远程管理程序不再需要访问表示MBean类型的特定于模型的类。 使用MXBeans可以为您选择的客户端增加灵活性，并使Geode管理和监控更容易使用。 集群中的每个成员都可以通过MXBeans进行管理，每个成员在Platform MBeanServer中托管自己的MXBean。 可以将任何Geode成员配置为为Geode集群中的所有成员提供所有MXBean的联合视图。 Geode还将JMX的使用修改为行业标准，并且对通用JMX客户端友好。 您现在可以使用任何符合JMX的第三方工具轻松监控或管理集群。 例如，JConsole。 参考 有关MXBeans和Open MBean的更多信息，请参阅： http://docs.oracle.com/javase/8/docs/api/javax/management/MXBean.html http://docs.oracle.com/javase/8/docs/api/javax/management/openmbean/package-summary.html Geode管理和监控工具概述 Geode提供了各种管理工具，可用于管理Geode集群。 Geode管理和监视工具允许您配置集群的所有成员和进程，监视系统中的操作以及启动和停止成员。 在内部，Geode使用Java MBean（特别是MXBeans）来公开管理控件和监视功能。 您可以通过编写使用这些MXBeans的Java程序来监视和控制Geode，也可以使用Geode提供的几种工具之一来监视和管理您的集群。 这些任务的主要工具是gfsh命令行工具，如本节所述。 Geode提供以下工具来管理Geode安装： gfsh命令行工具 gfsh命令行工具提供了一组用于配置，管理和监视集群的命令。 gfsh是管理集群的推荐工具。 使用gfsh： 启动和停止Geode进程，例如定位器和缓存服务器 部署应用程序 创建和销毁区域 执行函数 管理磁盘存储 导入和导出数据 监控Geode流程 启动Geode监控工具 关闭集群 编写涉及Geode成员的各种操作 保存集群的所有成员的配置 gfsh在它自己的shell中运行，或者你可以直接从OS命令行执行gfsh命令。 gfsh可以与远程系统交互使用http协议。 您还可以编写在gfsh shell中运行的脚本以自动启动系统。 您可以使用gfsh为集群创建共享集群配置。 您可以定义适用于整个集群的配置，或仅适用于类似组的配置 架构和组件 Geode的管理和监视系统由一个JMX Manager节点(应该只有一个)和一个集群中的一个或多个受管节点组成。 集群中的所有成员都可通过MBean和Geode Management Service API进行管理。 架构 下图描绘了管理和监视系统组件的体系结构。 在这个架构中，每个Geode成员都是可管理的。 本地Geode进程的所有Geode MBean都自动注册在Platform MBeanServer（托管平台MXBeans的每个JVM的默认MBeanServer）中。 受管节点 群集的每个成员都是一个受管节点。 当前未同时充当JMX Manager节点的任何节点都简称为受管节点。 受管节点具有以下资源，因此它可以在本地和远程回答JMX查询： 代表节点上本地监视的组件的本地MXBean。 请参阅Geode JMX MBean列表，以获取受管节点现有的可能MXBean列表。 内置平台MBeans。 JMX Manager Node JMX Manager节点是可以管理其他Geode成员（即其他受管节点）以及自身的成员。 JMX Manager节点可以管理集群中的所有其他成员。 要将受管节点转换为JMX Manager节点，请在gemfire.properties文件中配置Geode属性jmx-manager = true，并将该成员作为JMX Manager节点启动。 当您将-J=-Dgemfire.jmx-manager=true作为start server或start locator命令的参数提供时，可以将该成员作为JMX Manager节点启动。 有关详细信息，请参阅启动JMX Manager。 JMX Manager节点分配了以下额外资源，以便它可以回答JMX查询： RMI连接器，允许JMX客户端连接并访问集群中的所有MXBean。 Local MXBean，表示此节点上本地监视的组件，与任何其他受管节点相同。 Aggregate MXBeans: DistributedSystemMXBean DistributedRegionMXBean DistributedLockServiceMXBean 具有Scope=ALL的ManagerMXBean，它允许各种集群范围的操作。 受管节点上的MXBeans代理。 内置平台MXBeans。 JMX集成 管理和监视工具(如gfsh命令行界面和Pulse)使用JMX/RMI作为连接到Geode节点的通信层。 默认情况下，所有Geode进程都允许从localhost到Platform MBeanServer的JMX连接。 默认情况下，受管节点和JMX管理器节点都启用了RMI连接器以允许JMX客户端连接。 JConsole（以及支持Sun的Attach API的其他类似JMX客户端）可以通过使用Attach API连接到任何本地JVM，而无需RMI连接器。 这允许来自同一台机器的连接。 如果JVM配置为启动RMI连接器，则JConsole（和其他JMX客户端）可以连接到任何JVM。 这允许来自其他机器的远程连接。 JConsole可以连接到任何Geode成员，但如果它连接到非JMX-Manager成员，则JConsole仅检测节点的本地MBean，而不检测集群的MBean。 当Geode定位器或服务器成为集群的JMX Manager时，它将启用RMI连接器。 然后，JConsole只能连接到那个JVM，以查看整个集群的MBean。 它不需要连接到所有其他JVM。 Geode管理提供集群中所有MBean的联合视图所需的JVM间通信。 gfsh只能连接到JMX Manager或定位器。 如果连接到定位器，定位器将为现有JMX Manager提供必要的连接信息。 如果定位器检测到JMX Manager尚未在集群中运行，则定位器使自己成为JMX Manager。 gfsh无法连接到其他非Manager或非定位器成员。 有关如何配置RMI注册表和RMI连接器的信息，请参阅配置RMI注册表端口和RMI连接器。 管理API Geode管理API代表JMX用户的Geode集群。 但是，它们不提供JMX中存在的功能。 它们仅为Geode监控和管理提供的各种服务提供网关。 Geode管理的入口点是通过ManagementService接口。 例如，要创建Management Service的实例： ManagementService service = ManagementService.getManagementService(cache); 生成的ManagementService实例特定于提供的缓存及其集群。 getManagementService的实现现在是一个单例，但最终可能支持多个缓存实例。 您可以使用Geode管理API来完成以下任务： 监控客户端的健康状态。 获取单个磁盘备份的状态和结果。 查看与特定成员的磁盘使用情况和性能相关的指标。 浏览为特定成员设置的Geode属性。 查看JVM指标，例如内存，堆和线程使用情况。 查看网络指标，例如接收和发送的字节数。 查看分区区域属性，例如存储区总数，冗余副本和最大内存信息。 查看持久成员信息，例如磁盘存储区ID。 浏览区域属性。 请参阅org.apache.geode.managementJavaDocs获得更多细节。 您还可以使用ManagementService API执行gfsh命令。 请参阅通过Management API执行gfsh命令和org.apache.geode.management.cli的JavaDocs。 Geode管理和监控工具 本节列出了当前可用于管理和监控Geode的工具： gfsh. Apache Geode命令行界面，提供简单而强大的命令shell，支持Geode应用程序的管理，调试和部署。 它具有上下文相关帮助，脚本以及使用简单API从应用程序内调用任何命令的功能。 见gfsh。 Geode Pulse. 易于使用的基于浏览器的仪表板，用于监控Geode部署。 Geode Pulse提供集群中所有Geode成员的集成视图。 请参阅Geode Pulse。 Pulse Data Browser. 此Geode Pulse实用程序提供了一个图形界面，用于在Geode集群中执行OQL即席查询。 请参阅数据浏览器。 Other Java Monitoring Tools such as JConsole and jvisualvm.JConsole是Java 2平台中提供的基于JMX的管理和监视工具，它提供有关Java应用程序的性能和资源消耗的信息。 请参阅http://docs.oracle.com/javase/6/docs/technotes/guides/management/jconsole.html。 Java VisualVM (jvisualvm) 是一个用于分析Java虚拟机的分析工具。 Java VisualVM对Java应用程序开发人员有用，可以对应用程序进行故障排除，并监视和改进应用程序的性能。 Java VisualVM可以允许开发人员生成和分析堆转储，跟踪内存泄漏，执行和监视垃圾收集，以及执行轻量级内存和CPU分析。 有关使用jvisualvm的更多详细信息，请参阅http://docs.oracle.com/javase/6/docs/technotes/tools/share/jvisualvm.html。 JMX管理器操作 任何成员都可以托管嵌入式JMX Manager，它提供集群的所有MBean的联合视图。 通过在ManagementService上调用相应的API调用，可以将成员配置为在启动时或在其生命中的任何时间成为管理器。 您需要在集群中启动JMX Manager才能使用Geode管理和监视工具，例如gfsh 和Geode Pulse。 注意: 充当JMX Manager的每个节点都有额外的内存要求，具体取决于它管理和监视的资源数量。 作为JMX Manager可以增加任何进程的内存占用，包括定位器进程。 有关计算Geode进程内存开销的更多信息，请参阅缓存数据的内存要求。 启动一个 JMX Manager 配置一个 JMX Manager 停止一个 JMX Manager 启动一个 JMX Manager JMX Manager节点是管理其他Geode成员（以及他们自己）的成员。 JMX Manager节点可以管理集群中的所有其他成员。 通常，定位器将用作JMX Manager，但您也可以将任何其他成员（如服务器）转换为JMX Manager节点。 要允许服务器成为JMX Manager，请在服务器的gemfire.properties文件中配置Geode属性jmx-manager=true。 此属性将节点配置为被动地成为JMX Manager节点; 如果gfsh在连接到集群时找不到JMX Manager，则服务器节点将作为JMX Manager节点启动。 注意: 所有定位器的默认属性设置是gemfire.jmx-manager=true。 对于其他成员，默认属性设置为gemfire.jmx-manager=false。 要在服务器启动时强制服务器成为JMX Manager节点，请在服务器的gemfire.properties文件中设置Geode属性jmx-manager-start=true和jmx-manager=true。 请注意，对于节点，必须将这两个属性都设置为true。 要在命令行上将成员作为JMX Manager节点启动，请提供-J=-Dgemfire.jmx-manager-start =true和-J=-Dgemfire.jmx-manager=true作为参数。 start server或`start locator'命令。 例如，要在gfsh命令行上将服务器作为JMX Manager启动： gfsh>start server --name= --J=-Dgemfire.jmx-manager=true \\ --J=-Dgemfire.jmx-manager-start=true 默认情况下，任何定位器在启动时都可以成为JMX Manager。 启动定位器时，如果集群中未检测到其他JMX Manager，则定位器会自动启动定位器。 如果启动第二个定位器，它将检测当前的JMX Manager，并且不会启动另一个JMX Manager，除非第二个定位器的gemfire.jmx-manager-start属性设置为true。 对于大多数部署，每个集群只需要一个JMX Manager。 但是，如有必要，您可以运行多个JMX Manager。 如果要为Pulse监视工具提供高可用性和冗余，或者运行除gfsh之外的其他JMX客户端，则使用jmx-manager-start = true属性强制单个节点(定位器或服务器)成为JMX管理器在启动时。 由于作为JMX Manager存在一些性能开销，我们建议使用定位器作为JMX Manager。 如果您不希望定位器成为JMX管理器，则在启动定位器时必须使用jmx-manager = false属性。 节点成为JMX Manager后，将应用配置JMX Manager中列出的所有其他jmx-manager- *配置属性。 以下是启动新定位器也启动嵌入式JMX Manager的示例（在检测到另一个JMX Manager不存在之后）。 此外，gfsh还会自动将您连接到新的JMX Manager。 例如： gfsh>start locator --name=locator1 Starting a Geode Locator in /Users/username/apache-geode/locator1... .... Locator in /Users/username/apache-geode/locator1 on 192.0.2.0[10334] as locator1 is currently online. Process ID: 27144 Uptime: 5 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /Users/username/apache-geode/locator1/locator1.log JVM Arguments: -Dgemfire.enable-cluster-configuration=true -Dgemfire.load-cluster-configuration-from-dir=false -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /Users/username/apache-geode/lib/geode-core-1.2.0.jar :/Users/username/apache-geode/lib/geode-dependencies.jar Successfully connected to: JMX Manager [host=192.0.2.0, port=1099] Cluster configuration service is up and running. 定位器还跟踪可以成为JMX Manager的所有节点。 创建缓存后，JMX Manager节点立即开始从其他成员联合MBean。 JMX Manager节点准备就绪后，JMX Manager节点会向所有其他成员发送通知，通知他们它是新的JMX Manager。 然后其他成员将完整的MBean状态放入每个隐藏的管理区域。 在任何时候，您都可以使用MemberMXBean.isManager()方法确定节点是否为JMX Manager。 使用Java API，任何使用jmx-manager=true配置的受管节点也可以通过调用ManagementService.startManager()方法转换为JMX Manager节点。 注意: 如果以编程方式启动JMX Manager并希望启用命令处理，则还必须将gfsh-dependencies.jar的绝对路径(位于安装的lib目录中)添加到应用程序的CLASSPATH。 不要将此库复制到CLASSPATH，因为此库通过相对路径引用lib中的其他依赖项。 配置一个 JMX Manager 在gemfire.properties文件中，您可以按如下方式配置JMX管理器。 属性 描述 缺省值 http-service-port 如果非零，则Geode启动一个侦听此端口的嵌入式HTTP服务。 HTTP服务用于托管Geode Pulse Web应用程序。 如果您在自己的Web服务器上托管Pulse Web应用程序，则通过将此属性设置为零来禁用此嵌入式HTTP服务。 如果jmx-manager为false，则忽略。 7070 http-service-bind-address 如果设置，则Geode成员将嵌入式HTTP服务绑定到指定的地址。 如果未设置此属性但使用http-service-port启用HTTP服务，则Geode会将HTTP服务绑定到成员的本地地址。 not set jmx-manager 如果是true则该成员可以成为JMX Manager。 所有其他jmx-manager- *属性在成为JMX Manager时使用。 如果此属性为false，则忽略所有其他jmx-manager- *属性。定位器上的默认值为true。 false (with Locator exception) jmx-manager-access-file 默认情况下，JMX Manager允许任何客户端完全访问所有MBean。 如果将此属性设置为文件名，则可以将客户端限制为仅读取MBean; 他们无法修改MBean。 对于密码文件中定义的每个用户名，可以在此文件中以不同方式配置访问级别。 有关此文件格式的更多信息，请参阅Oracle的com.sun.management.jmxremote.access.file系统属性文档。 如果jmx-manager为false或者jmx-manager-port为零，则忽略。 not set jmx-manager-bind-address 默认情况下，配置了端口的JMX Manager会侦听所有本地主机的地址。 您可以使用此属性配置JMX Manager将侦听的特定IP地址或主机名。 如果jmx-manager为false或jmx-manager-port为零，则忽略此属性。 如果您托管Pulse Web应用程序，此地址也适用于Geode Pulse服务器。 not set jmx-manager-hostname-for-clients 给客户端的主机名，询问定位器JMX Manager的位置。 默认情况下，使用JMX Manager的IP地址。 但是，对于不同网络上的客户端，您可以配置要为客户端提供的其他主机名。 如果jmx-manager为false或者jmx-manager-port为零，则忽略。 not set jmx-manager-password-file 默认情况下，JMX Manager允许没有凭据的客户端进行连接。 如果将此属性设置为文件名，则只允许使用与此文件中的条目匹配的凭据连接的客户端。 大多数JVM要求文件只能由所有者读取。 有关此文件格式的更多信息，请参阅Oracle的com.sun.management.jmxremote.password.file系统属性文档。 如果jmx-manager为false或jmx-manager-port为零，则忽略。 not set jmx-manager-port 此JMX Manager侦听客户端连接的端口。 如果此属性设置为零，则Geode不允许远程客户端连接。 或者，使用JVM支持的标准系统属性来配置远程JMX客户端的访问。 如果jmx-manager为false，则忽略。 默认RMI端口为1099。 1099 jmx-manager-ssl 如果为true且jmx-manager-port不为零，则JMX Manager仅接受SSL连接。 ssl-enabled属性不适用于JMX Manager，但其他SSL属性适用。 这允许仅为JMX Manager配置SSL，而无需为其他Geode连接配置SSL。 如果jmx-manager为false，则忽略。 false jmx-manager-start 如果为true，则此成员在创建缓存时启动JMX Manager。 在大多数情况下，您不应将此属性设置为true，因为在将jmx-manager设置为true的成员上需要时会自动启动JMX Manager。 如果jmx-manager为false，则忽略。 false jmx-manager-update-rate 此成员将更新推送到任何JMX管理器的速率（以毫秒为单位）。 目前该值应大于或等于statistic-sample-rate。 将此值设置得太高会导致gfsh和Geode Pulse看到过时的值。 2000 停止一个 JMX管理器 要使用gfsh停止JMX Manager，只需关闭托管JMX Manager的定位器或服务器即可。 对于定位器： gfsh>stop locator --dir=locator1 Stopping Locator running in /home/user/test2/locator1 on ubuntu.local[10334] as locator1... Process ID: 2081 Log File: /home/user/test2/locator1/locator1.log .... No longer connected to ubuntu.local[1099]. 对于服务器： gfsh>stop server --dir=server1 Stopping Cache Server running in /home/user/test2/server1 ubuntu.local[40404] as server1... Process ID: 1156 Log File: /home/user/test2/server1/server1.log .... No longer connected to ubuntu.local[1099]. 请注意，gfsh已自动断开您与已停止的JMX Manager的连接。 要使用管理API停止JMX管理器，请使用ManagementService.stopManager()方法阻止成员成为JMX Manager。 当Manager停止时，它会从其Platform MBeanServer中删除其他成员的所有联合MBean。 它还会发出通知，通知其他成员它不再被视为JMX Manager。 联邦MBean架构 Geode使用MBean来管理和监控Geode的不同部分。 Geode的联合MBean架构是可扩展的，允许您拥有Geode集群的单代理视图。 Geode MBean和MBeanServers的联合 MBeanServers的联合意味着一个成员JMX Manager Node可以提供MBeanServer托管的所有MBean的代理视图。 联合还意味着操作和通知分布在集群中。 Geode federation负责以下功能： MBean代理创建 MBean状态传播 通知传播 操作调用 MBean代理命名约定 每个Geode MBean都遵循特定的命名约定，以便于分组。 例如： GemFire:type=Member,service=LockService,name=,memberName= 在JMX Manager节点上，此MBean将作为域注册到GemFire / 。 以下是一些示例MBean名称： MemberMBean: GemFire:type=Member,member= 使用MXBeans 在其管理API中，Geode提供MXBeans以确保任何客户端（包括远程客户端）都可以使用所创建的任何MBean，而无需客户端访问特定类以访问MBean的内容。 MBean代理创建 Geode代理本质上是本地MBean。 每个Geode JMX管理器成员都托管指向每个受管节点的本地MBean的代理。 当在该受管节点中发生事件时，代理MBean还将发出受管节点中本地MBean发出的任何通知。 注意: JMX Manager节点上的聚合MBean未被代理。 Geode JMX MBean列表 本主题提供了Geode中可用的各种管理和监视MBean的说明。 下图说明了为管理和监视Apache Geode而开发的不同JMX MBean之间的关系。 JMX Manager MBeans 本节介绍JMX Manager节点上可用的MBean。 Managed Node MBeans 本节介绍所有受管节点上可用的MBean。 JMX Manager MBeans 本节介绍JMX Manager节点上可用的MBean。 JMX Manager节点包括Managed Node MBeans下列出的所有本地bean以及仅可用的以下bean 在JMX Manager节点上： ManagerMXBean DistributedSystemMXBean DistributedRegionMXBean DistributedLockServiceMXBean ManagerMXBean 表示托管成员的Geode Management层。 控制管理范围。 此MBean提供start和stop方法，以将受管节点转换为JMX Manager节点或停止节点成为JMX Manager。 对于潜在的管理者(jmx-manager=true和jmx-manager-start=false)，这个MBean是在Locator请求时创建的。 注意: 您必须配置节点以允许它成为JMX Manager。 有关配置信息，请参阅配置JMX Manager。 MBean 细节 Scope ALL Proxied No Object Name GemFire:type=Member, service=Manager,member= Instances Per Node 1 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.ManagerMXBean JavaDocs。 DistributedSystemMXBean 系统范围的聚合MBean，提供整个集群的高级视图，包括所有成员(缓存服务器，对等方，定位器)及其缓存。 在任何给定的时间点，它都可以提供完整集群及其操作的快照。 DistributedSystemMXBean提供用于执行集群范围操作的API，例如备份所有成员，关闭所有成员或显示各种集群指标。 您可以将标准JMX NotificationListener附加到此MBean以侦听整个集群中的通知。 有关详细信息，请参阅Geode JMX MBean通知。 这个MBean还提供了一些MBean模型导航APIS。 应使用这些API来浏览Geode系统公开的所有MBean。 MBean 细节 Scope Aggregate Proxied No Object Name GemFire:type=Distributed,service=System Instances Per Node 1 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.DistributedSystemMXBean JavaDocs。 DistributedRegionMXBean 系统范围的命名区域的聚合MBean。 它为托管和/或使用该区域的所有成员提供了一个区域的高级视图。 例如，您可以获取托管该区域的所有成员的列表。 某些方法仅适用于分区区域。 MBean Details Scope Aggregate Proxied No Object Name GemFire:type=Distributed,service=Region,name= Instances Per Node 0..N 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.DistributedRegionMXBean JavaDocs。 DistributedLockServiceMXBean 表示DistributedLockService的命名实例。 可以在成员中创建任意数量的DistributedLockService。 DistributedLockService的命名实例定义了一个空间，用于锁定由指定分发管理器定义的集群中的任意名称。 可以使用不同的服务名称创建任意数量的DistributedLockService实例。 对于集群中已创建具有相同名称的DistributedLockService实例的所有进程，在任何时间点，只允许一个线程拥有该实例中给定名称的锁。 此外，线程可以锁定整个服务，从而防止系统中的任何其他线程锁定服务或服务中的任何名称。 MBean Details Scope Aggregate Proxied No Object Name GemFire:type=Distributed,service=LockService,name= Instances Per Node 0..N 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.DistributedLockServiceMXBean JavaDocs。 受管节点MBean 本节介绍所有受管节点上可用的MBean。 所有受管节点上可用的MBean包括： MemberMXBean CacheServerMXBean RegionMXBean LockServiceMXBean DiskStoreMXBean AsyncEventQueueMXBean LocatorMXBean LuceneServiceMXBean JMX Manager节点将自己拥有受管节点MBean，因为它们也是集群中的可管理实体。 MemberMXBean 成员对其连接和缓存的本地视图。 它是管理特定成员的主要网关。 它公开了成员级属性和统计信息。 像createCacheServer()和createManager()这样的操作将有助于创建一些Geode资源。 任何JMX客户端都可以连接到MBean服务器，并使用此MBean开始管理Geode成员。 See MemberMXBean Notifications for a list of notifications emitted by this MBean. MBean 细节 Scope Local Proxied Yes Object Name GemFire:type=Member,member= Instances Per Node 1 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.MemberMXBean JavaDocs。 CacheServerMXBean 表示Geode CacheServer。 提供有关服务器，订阅，持久队列和索引的数据和通知。 有关此MBean发出的通知的列表，请参阅CacheServerMXBean Notifications。 MBean 细节 Scope Local Proxied Yes Object Name GemFire:type=Member,service=CacheServer,member= Instances Per Node 1 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.CacheServerMXBean JavaDocs。 RegionMXBean 成员局部区域的视角。 MBean Details Scope Local Proxied Yes Object Name GemFire:type=Member,service=Region,name=,member= Instances Per Node 0..N 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.RegionMXBean JavaDocs。 LockServiceMXBean 表示LockService的命名实例。 可以在成员中创建任意数量的LockServices。 MBean Details Scope Local Proxied Yes Object Name GemFire:type=Member,service=LockService,name=,member= Instances Per Node 0..N 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.LockServiceMXBean JavaDocs。 DiskStoreMXBean 表示为一个或多个区域提供磁盘存储的DiskStore对象 MBean 细节 Scope Local Proxied Yes Object Name GemFire:type=Member,service=DiskStore,name=,member= Instances Per Node 0..N 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.DiskStoreMXBean JavaDocs。 AsyncEventQueueMXBean AsyncEventQueueMXBean提供对AsyncEventQueue的访问，AsyncEventQueue表示将事件传递到AsyncEventListener的通道。 MBean 细节 Scope Local Proxied Yes Object Name GemFire:type=Member,service=AsyncEventQueue,queue=,member= Instances Per Node 0..N 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.AsyncEventQueueMXBean JavaDocs。 LocatorMXBean LocatorMXBean表示定位器。 MBean Details Scope Local Proxied Yes Object Name GemFire:type=Member,service=Locator,port=,member= Instances Per Node 0..1 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.LocatorMXBean JavaDocs。 LuceneServiceMXBean 成员对现有Lucene索引的本地视图。 MBean 细节 Scope Local Proxied Yes Object Name GemFire:service=CacheService,name=LuceneService,type=Member,member= Instances Per Node 0..1 有关可用MBean方法和属性的信息，请参阅org.apache.geode.cache.lucene.management.LuceneServiceMXBean JavaDocs。 GatewaySenderMXBean GatewaySenderMXBean表示网关发件人。 MBean 细节 Scope Local Proxied Yes Object Name GemFire:type=Member,service=GatewaySender,gatewaySender=,member= Instances Per Node 0..1 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.GatewaySenderMXBean JavaDocs。 GatewayReceiverMXBean GatewayReceiverMXBean表示网关接收器。 MBean 细节 Scope Local Proxied Yes Object Name GemFire:type=Member,service=GatewayReceiver,member= Instances Per Node 0..1 有关可用MBean方法和属性的信息，请参阅org.apache.geode.management.GatewayReceiverMXBean JavaDocs。 通过JConsole浏览Geode MBean 您可以使用JConsole浏览集群中的所有Geode MBean。 要通过JConsole查看Geode MBean，请执行以下步骤： 启动gfsh提示符。 通过使用嵌入式JMX Manager连接到定位器或直接连接到JMX Manager，连接到正在运行的集群。 例如： gfsh>connect --locator=locator1[10334] 或者 gfsh>connect --jmx-manager=locator1[1099] 启动 JConsole: gfsh>start jconsole 如果成功，将显示“正在运行JDK JConsole”消息。 JConsole应用程序使用RMI直接启动并连接到JMX Manager。 在JConsole屏幕上，单击MBeans选项卡。 展开GemFire。 然后展开每个MBean以浏览各个MBean属性，操作和通知。 以下是Geode集群中MBean层次结构的示例屏幕截图： Geode JMX MBean通知 Apache Geode MBean在发生特定事件或Geode系统中引发警报时发出通知。 使用标准JMX API，用户可以添加通知处理程序来侦听这些事件。 通知联邦 从受管节点发出的所有通知都将联合到系统中的所有JMX Manager。 JMX MBean通知列表 本主题列出了Geode MBeans发出的所有可用JMX通知。 通知联邦 从受管节点发出的所有通知都将联合到系统中的所有JMX Manager。 这些通知是联合的，然后由DistributedSystemMXBean发出。 如果将javax.management.NotificationListener附加到DistributedSystemMXBean，NotificationListener可以侦听来自所有MemberMXBeans和所有CacheServerMXBeans的通知。 将监听器附加到MXBeans 将通知侦听器附加到DistributedSystemMXBean时，DistributedSystemMXBean将充当整个集群的通知中心。 您不必将侦听器附加到每个单独的成员或缓存服务器MBean，以便侦听集群中的所有通知。 以下是使用JMX MBeanServer API将NotificationListener附加到MBean的示例： NotificationListener myListener = ... ObjectName mbeanName = ... MBeanServer.addNotificationListener(mbeanName, myListener, null, null); JMX Manager将为所有集群成员发出通知，但有两个例外： 如果使用cache.xml定义区域和磁盘等资源，则这些资源的通知不会联合到JMX Manager。 在这些情况下，DistributedSystemMXBean无法发出这些通知。 如果在创建资源后启动JMX Manager，则JMX Manager无法为该资源发出通知。 系统警报通知 系统警报是包含在JMX通知中的Geode警报。 JMX Manager将自身注册为系统中每个成员的警报侦听器，默认情况下，它会接收集群中任何节点使用SEVERE警报级别记录的所有消息。 因此，DistributedSystemMXBean将代表DistributedSystem发出这些警报的通知。 默认情况下，JMX Manager会自行注册以仅为SEVERE级别警报发送通知。 要更改JMX Manager将发送通知的警报级别，请使用DistributedMXBean.changeAlertLevel方法。 可设置的警报级别为WARNING，ERROR，SEVERE和NONE。 更改级别后，JMX Manager将仅发出该级别的日志消息作为通知。 通知对象包括类型，源和消息属性。 系统警报还包括userData属性。 对于系统警报，通知对象属性对应于以下内容： type: system.alert source: Distributed System ID message: alert message userData: name or ID of the member that raised the alert JMX MBean通知列表 本主题列出了Geode MBeans发出的所有可用JMX通知。 通知由以下MBean发出： MemberMXBean 通知 MemberMXBean Gateway 通知 CacheServerMXBean 通知 DistributedSystemMXBean 通知 MemberMXBean 通知 Notification Type Notification Source Message gemfire.distributedsystem.cache.region.created Member name or ID Region Created with Name gemfire.distributedsystem.cache.region.closed Member name or ID Region Destroyed/Closed with Name gemfire.distributedsystem.cache.disk.created Member name or ID DiskStore Created with Name gemfire.distributedsystem.cache.disk.closed Member name or ID DiskStore Destroyed/Closed with Name gemfire.distributedsystem.cache.lockservice.created Member name or ID LockService Created with Name gemfire.distributedsystem.cache.lockservice.closed Member name or ID Lockservice Closed with Name gemfire.distributedsystem.async.event.queue.created Member name or ID Async Event Queue is Created in the VM gemfire.distributedsystem.cache.server.started Member name or ID Cache Server is Started in the VM gemfire.distributedsystem.cache.server.stopped Member name or ID Cache Server is stopped in the VM gemfire.distributedsystem.locator.started Member name or ID Locator is Started in the VM MemberMXBean Gateway 通知 Notification Type Notification Source Message gemfire.distributedsystem.gateway.sender.created Member name or ID GatewaySender Created in the VM gemfire.distributedsystem.gateway.sender.started Member name or ID GatewaySender Started in the VM gemfire.distributedsystem.gateway.sender.stopped Member name or ID GatewaySender Stopped in the VM gemfire.distributedsystem.gateway.sender.paused Member name or ID GatewaySender Paused in the VM gemfire.distributedsystem.gateway.sender.resumed Member name or ID GatewaySender Resumed in the VM gemfire.distributedsystem.gateway.receiver.created Member name or ID GatewayReceiver Created in the VM gemfire.distributedsystem.gateway.receiver.started Member name or ID GatewayReceiver Started in the VM gemfire.distributedsystem.gateway.receiver.stopped Member name or ID GatewayReceiver Stopped in the VM gemfire.distributedsystem.cache.server.started Member name or ID Cache Server is Started in the VM CacheServerMXBean 通知 Notification Type Notification Source Message gemfire.distributedsystem.cacheserver.client.joined CacheServer MBean Name Client joined with Id gemfire.distributedsystem.cacheserver.client.left CacheServer MBean Name Client crashed with Id gemfire.distributedsystem.cacheserver.client.crashed CacheServer MBean name Client left with Id DistributedSystemMXBean 通知 Notification Type Notification Source Message gemfire.distributedsystem.cache.member.joined Name or ID of member who joined Member Joined gemfire.distributedsystem.cache.member.departed Name or ID of member who departed Member Departed has crashed = gemfire.distributedsystem.cache.member.suspect Name or ID of member who is suspected Member Suspected By system.alert.* DistributedSystem(“) Alert Message 配置RMI注册表端口和RMI连接器 Geode以编程方式模拟Java提供的开箱即用的JMX，并在所有可管理成员上创建带有RMI Registry和RMI Connector端口的JMXServiceURL。 配置JMX Manager端口和绑定地址 您可以在启动将承载Geode JMX Manager的进程时配置特定的连接端口和地址。 为此，请指定jmx-manager-bind-address的值，它指定JMX管理器的IP地址和jmx-manager-port，它定义了RMI连接端口。 默认的Geode JMX Manager RMI端口为1099.如果保留1099用于其他用途，则可能需要修改此默认值。 使用开箱即用的RMI连接器 如果由于某种原因需要在部署中使用标准JMX RMI用于其他监视目的，请在要使用标准JMX RMI的任何成员上将Geode属性jmx-manager-port设置为0。 如果您使用开箱即用的JMX RMI而不是启动嵌入式Geode JMX Manager，则在为客户应用程序启动JVM时应考虑设置-Dsun.rmi.dgc.server.gcInterval = Long.MAX_VALUE-1 和客户进程。 每个Geode进程在创建和启动JMX RMI连接器之前在内部设置此设置，以防止暂停进程完全垃圾回收。 通过Management API执行gfsh命令 您还可以使用管理API以编程方式执行gfsh命令。 注意: 如果以编程方式启动JMX Manager并希望启用命令处理，则还必须将gfsh-dependencies.jar的绝对路径(位于Geode安装的$ GEMFIRE/lib中)添加到应用程序的CLASSPATH中。 不要将此库复制到CLASSPATH，因为此库通过相对路径引用$ GEMFIRE/lib中的其他依赖项。 以下代码示例演示了如何使用Java API处理和执行gfsh命令。 首先，检索CommandService实例。 注意: CommandService API目前仅在JMX Manager节点上可用。 // Get existing CommandService instance or create new if it doesn't exist commandService = CommandService.createLocalCommandService(cache); // OR simply get CommandService instance if it exists, don't create new one CommandService commandService = CommandService.getUsableLocalCommandService(); 接下来，处理命令及其输出： // Process the user specified command String Result regionListResult = commandService.processCommand(\"list regions\"); // Iterate through Command Result in String form line by line while (regionListResult.hasNextLine()) { System.out.println(regionListResult.nextLine()); } 或者，您可以从命令字符串创建一个可以重复使用的CommandStatement对象，而不是处理该命令。 // Create a command statement that can be reused multiple times CommandStatement showDeadLocksCmdStmt = commandService.createCommandStatement (\"show dead-locks --file=deadlock-info.txt\"); Result showDeadlocksResult = showDeadLocksCmdStmt.process(); // If there is a file as a part of Command Result, it can be saved // to a specified directory if (showDeadlocksResult.hasIncomingFiles()) { showDeadlocksResult.saveIncomingFiles(System.getProperty(\"user.dir\") + \"/commandresults\"); } 管理堆和堆外内存 默认情况下，Apache Geode使用JVM堆。 Apache Geode还提供了一种从堆中存储数据的选项。 本节介绍如何管理堆和堆外内存以最好地支持您的应用程序。 调整JVM垃圾收集参数 由于Apache Geode专门用于处理内存中保存的数据，因此您可以通过调整Apache Geode使用JVM堆的方式来优化应用程序的性能。 有关可用于改进垃圾回收(GC)响应的所有特定于JVM的设置，请参阅JVM文档。 至少，请执行以下操作： 将初始和最大堆开关-Xms和-Xmx设置为相同的值。 gfsh start server选项--initial-heap和--max-heap实现了相同的目的，增加了提供资源管理器默认值的值，例如逐出阈值和临界阈值。 配置JVM以进行并发标记清除(CMS)垃圾回收。 如果您的JVM允许，请将其配置为在堆使用率比资源管理器“eviction-heap-percentage”的设置低至少10％时启动CMS收集。 您希望收集器在Geode驱逐或驱逐不会产生更多空闲内存时工作。 例如，如果eviction-heap-percentage设置为65，则将堆垃圾收集设置为在堆使用率不高于55％时启动。 JVM CMS switch flag CMS initiation (begin at heap % N) Sun HotSpot ‑XX:+UseConcMarkSweepGC ‑XX:CMSInitiatingOccupancyFraction=N JRockit -Xgc:gencon -XXgcTrigger:N IBM -Xgcpolicy:gencon N/A 对于gfsh start server命令，使用--J开关传递这些设置，例如：‑‑J=‑XX:+UseConcMarkSweepGC。 以下是为应用程序设置JVM的示例： $ java app.MyApplication -Xms=30m -Xmx=30m -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=60 注意: 启动服务器时，请勿使用-XX:+UseCompressedStrings和-XX:+UseStringCache JVM配置属性。 这些JVM选项可能会导致数据损坏和兼容性问题。 或者，使用gfsh： $ gfsh start server --name=app.MyApplication --initial-heap=30m --max-heap=30m \\ --J=-XX:+UseConcMarkSweepGC --J=-XX:CMSInitiatingOccupancyFraction=60 使用Geode资源管理器 Geode资源管理器与您的JVM终身垃圾收集器一起使用，以控制堆使用并保护您的成员免受因内存过载而导致的挂起和崩溃。 Geode资源管理器通过驱逐旧数据来防止缓存占用过多内存。 如果垃圾收集器无法跟上，则资源管理器会拒绝添加到缓存，直到收集器释放了足够的内存。 资源管理器有两个阈值设置，每个设置表示为总终端堆的百分比。 两者都默认禁用。 Eviction Threshold(驱逐阈值). 在此之上，管理器命令所有区域的驱逐，其中eviction-attributes设置为lru-heap-percentage。 这会提示专用的后台驱逐，独立于任何应用程序线程，它还告诉所有应用程序线程向区域添加数据以驱逐至少与添加的数据一样多的数据。 JVM垃圾收集器删除已逐出的数据，减少堆使用。 该驱逐继续下去，直到管理器确定堆的使用是再次跌破驱逐阈值。 资源管理器仅对LRU驱逐策略基于堆百分比的区域强制执行驱逐阈值。 基于条目计数或存储器大小的驱逐策略的区域使用其他机制来管理驱逐。 有关驱逐政策的更多详细信息，请参阅驱逐。 Critical Threshold(临界阈值). 在此之上，所有可能将数据添加到缓存的活动都将被拒绝。 该阈值设置在驱逐阈值之上，旨在使驱逐和GC工作赶上。 此JVM，集群中的所有其他JVM以及系统的所有客户端都会收到“LowMemoryException”，以查看是否会增加此关键成员的堆消耗。 允许获取或减少数据的活动。 有关拒绝操作的列表，请参阅ResourceManager方法setCriticalHeapPercentage的Javadoc。 无论LRU驱逐策略如何，都会对所有区域强制执行临界阈值，但可以将其设置为零以禁用其效果。 当堆使用在任一方向上通过逐出阈值时，管理器记录信息级消息。 当堆使用超过临界阈值时，管理器会记录错误级别的消息。 避免超过临界阈值。 一旦被识别为关键，Geode成员将成为只读成员，拒绝其所有区域的缓存更新，包括传入的分布式更新。 有关更多信息，请参阅联机API文档中的org.apache.geode.cache.control.ResourceManager。 如何进行后台驱逐 当管理器开始驱逐时： 从为本地缓存中为堆LRU驱逐配置的所有区域，后台驱逐管理器创建随机列表，其包含每个分区区域桶（主要或次要）的一个条目和每个非分区区域的一个条目。 因此，每个分区区域桶的处理方式与单个非分区区域相同。 后台逐出管理器为本地计算机上的每个处理器启动四个逐出器线程。 管理器将每个线程传递给桶/区域列表的共享。 管理器通过计数尽可能均匀地划分桶/区域列表，而不是通过内存消耗。 每个线程在其桶/区域列表上循环遍历，逐个每个桶/区域驱逐一个LRU条目，直到资源管理器发送信号以停止驱逐。 另请参见缓存数据的内存要求。 使用资源管理器控制堆使用 资源管理器行为与垃圾收集（GC）活动的触发，JVM中并发垃圾收集器的使用以及用于并发的并行GC线程数密切相关。 此处提供的使用管理器的建议假设您对Java VM的堆管理和垃圾收集服务有充分的了解。 资源管理器可用于任何Apache Geode成员，但您可能不希望在任何地方激活它。 对于某些成员而言，在挂起或OME崩溃后偶尔重启可能比驱逐数据和/或拒绝分布式缓存活动更好。 此外，没有冒险超出其内存限制的成员将无法从资源管理器消耗的开销中受益。 缓存服务器通常配置为使用管理器，因为它们通常承载更多数据并且具有比其他成员更多的数据活动，从而需要更高的数据清理和收集响应能力。 对于要激活资源管理器的成员： 为堆LRU管理配置Geode。 设置JVM GC调整参数以与Geode管理器一起处理堆和垃圾收集。 监视和调整堆LRU配置和GC配置。 在投入生产之前，请使用与目标系统近似的应用程序行为和数据加载来运行系统测试，以便您可以根据生产需要进行调整。 在生产中，不断监控和调整以满足不断变化的需求。 配置堆用于LRU管理的Geode 这里使用的配置术语是cache.xml元素和属性，但您也可以通过gfsh和org.apache.geode.cache.control.ResourceManager和RegionAPIs进行配置。 启动服务器时，将initial-heap和max-heap设置为相同的值。 设置resource-manager和client-heap-percentage阈值。 这应该尽可能接近100，同时仍然足够低，以便管理者的响应可以防止成员挂起或得到'OutOfMemoryError`。 默认情况下，阈值为零（无阈值）。 注意: 设置此阈值时，它还启用查询监视功能，以在执行查询或创建索引时防止大多数内存不足异常。 请参阅监视内存不足的查询。 将resource-manager和eviction-heap-percentage阈值设置为低于临界阈值的值。 这应该尽可能高，同时仍然足够低，以防止您的成员达到临界阈值。 默认情况下，阈值为零（无阈值）。 确定哪些区域将参与堆驱逐并将其eviction-attributes设置为“lru-heap-percentage”。 见Eviction。 您为驱逐配置的区域应具有足够的数据活动，以便驱逐有用，并且应包含应用程序可以删除或卸载到磁盘的数据。 gfsh的例子: gfsh>start server --name=server1 --initial-heap=30m --max-heap=30m \\ --critical-heap-percentage=80 --eviction-heap-percentage=60 cache.xml 例子: ... 注意: resource-manager规范必须出现在cache.xml文件中的区域声明之后。 设置JVM GC调整参数 如果您的JVM允许，请将其配置为在堆使用率比资源管理器eviction-heap-percentage的设置低至少10％时启动并发标记清除（CMS）垃圾回收。 您希望收集器在Geode驱逐或驱逐不会产生更多空闲内存时工作。 例如，如果eviction-heap-percentage设置为65，则将堆垃圾收集设置为在堆使用率不高于55％时启动。 监视和调整堆LRU配置 在调整资源管理器时，您的中心焦点应该是使成员保持在临界阈值以下。 提供关键阈值是为了避免成员挂起和崩溃，但由于其分布式更新的异常抛出行为，在关键时间中花费的时间会对整个集群产生负面影响。 为了保持低于临界值，调整以便在达到驱逐阈值时Geode驱逐和JVM的GC充分响应。 使用JVM提供的统计信息确保您的内存和GC设置足以满足您的需求。 GeodeResourceManagerStats提供有关内存使用以及管理器阈值和逐出活动的信息。 如果您的应用程序定期高于临界阈值，请尝试降低逐出阈值。 如果应用程序永远不会接近关键，您可以提高驱逐阈值以获得更多可用内存，而不会产生不必要的驱逐或GC周期的开销。 适用于您的系统的设置取决于许多因素，包括： 您存储在缓存中的数据对象的大小: 可以驱逐非常大的数据对象并相对快速地收集垃圾。 许多小对象使用相同数量的空间需要更多的处理工作来清除，并且可能需要较低的阈值以允许驱逐和GC活动跟上。 应用行为: 快速将大量数据放入缓存的应用程序可以更轻松地超越驱逐和GC功能。 驱逐速度较慢的应用程序可能更容易通过驱逐和GC工作来抵消，可能允许您将阈值设置为高于更易变的系统。 您选择的JVM: 每个JVM都有自己的GC行为，这会影响收集器的运行效率，它在需要时的速度以及其他因素。 资源管理器示例配置 这些示例将临界阈值设置为终身堆的85％，并将驱逐阈值设置为75％。 区域bigDataStore被配置为参与资源管理器的驱逐活动。 gfsh 例子: gfsh>start server --name=server1 --initial-heap=30m --max-heap=30m \\ --critical-heap-percentage=85 --eviction-heap-percentage=75 gfsh>create region --name=bigDataStore --type=PARTITION_HEAP_LRU XML: ... 注意: resource-manager规范必须出现在cache.xml文件中的区域声明之后。 Java: Cache cache = CacheFactory.create(); ResourceManager rm = cache.getResourceManager(); rm.setCriticalHeapPercentage(85); rm.setEvictionHeapPercentage(75); RegionFactory rf = cache.createRegionFactory(RegionShortcut.PARTITION_HEAP_LRU); Region region = rf.create(\"bigDataStore\"); 用例示例代码 这是示例中使用的配置的一种可能方案： 在运行Linux的4 CPU系统上具有8 Gb堆空间的64位Java VM。 数据区bigDataStore有大约2-3百万个小值，平均条目大小为512字节。 因此，大约4-6 Gb的堆用于区域存储。 托管该区域的成员还运行可能需要最多1 Gb堆的应用程序。 应用程序必须永远不会耗尽堆空间并且已经精心设计，如果由于应用程序问题导致堆空间变得有限，则该区域中的数据丢失是可接受的，因此默认的“lru-heap-percentage”操作销毁是合适的。 应用程序的服务保证使其非常不能容忍OutOfMemoryException错误。 测试表明，当使用-XX:CMSInitiatingOccupancyFraction=70配置CMS垃圾收集器时，在向区域添加数据时，将15％的头部空间留在临界阈值之上可以获得99.5％的正常运行时间而没有“OutOfMemoryException”错误。 管理 Off-Heap 内存 可以将Geode配置为在堆外内存中存储区域值，该内存是JVM中不受Java垃圾回收影响的内存。 JVM中的垃圾收集（GC）可能会成为性能障碍。 服务器无法控制JVM堆内存中的垃圾收集何时发生，并且服务器几乎无法控制调用的触发器。 堆外内存将值卸载到不受Java GC约束的存储区域。 通过利用堆外存储，应用程序可以减少受GC开销影响的堆存储量。 堆外内存与堆一起使用，它不会替换它。 密钥存储在堆内存空间中。 Geode自己的内存管理器处理堆外内存的性能优于Java垃圾收集器对某些区域数据集的性能。 资源管理器监视堆外内存的内容，并根据两个类似于监视JVM堆的阈值调用内存管理操作：eviction-off-heap-percentage和critical-off-heap-percentage。 On-heap 和 Off-heap 对象 以下对象始终存储在JVM堆中： 区域元数据 条目元数据 Keys 索引 订阅队列元素 以下对象可以存储在堆外内存中： 值 - 最大值大小为2GB 引用计数 可用内存块列表 WAN队列元素 注意: 不要将函数范围索引与堆外数据一起使用，因为它们不受支持。 尝试这样做会产生异常。 Off-heap 建议 Off-heap 存储最适合数据模式，其中： 存储的值在大小上相对均匀 存储的值大多小于128K 使用模式涉及许多创建的循环，然后是销毁或清除 这些值不需要经常反序列化 许多值都是长寿命的参考数据 请注意，Geode必须执行额外的工作来访问存储在堆外内存中的数据，因为它以序列化形式存储。 这项额外的工作可能会导致某些用例在堆外配置中运行速度较慢，即使它们使用较少的内存并避免垃圾收集开销。 但是，即使进行额外的反序列化，堆外存储也可以为您提供最佳性能。 可能增加开销的功能包括 经常更新 存储的大小各不相同的值 增量 查询 实现细节 堆外存储器管理器有效地处理大小相同或具有固定大小的区域数据值。 在堆外内存中分配固定和相同大小的数据值时，通常可以重用已释放的块，并且很少或根本不需要将周期用于碎片整理。 即使该区域配置为使用堆外内存，小于或等于8个字节的区域值也不会驻留在堆外内存中。 这些非常小的区域值驻留在JVM堆中，而不是对堆外位置的引用。 此性能增强可节省空间和加载时间。 使用资源管理器控制堆外使用 Geode资源管理器通过两个阈值控制堆外内存，与JVM堆内存的方式大致相同。 请参阅使用Geode资源管理器。 资源管理器通过驱逐旧数据来防止缓存占用过多的堆外内存。 如果堆外内存管理器无法跟上，则资源管理器会拒绝添加到缓存，直到堆外内存管理器释放足够的内存。 资源管理器有两个阈值设置，每个设置表示为总堆外内存的百分比。 两者都默认禁用。 Eviction Threshold(驱逐阈值). 驱逐应该开始的堆外记忆的百分比。 驱逐继续，直到资源管理器确定堆外内存使用再次低于驱逐阈值。 使用eviction-off-heap-percentageregion属性设置逐出阈值。 资源管理器仅对具有HEAP_LRU特征的区域强制执行驱逐阈值。 如果临界阈值不为零，则默认逐出阈值比临界阈值低5％。 如果临界阈值为零，则默认逐出阈值为总堆外内存的80％。 资源管理器仅对LRU驱逐策略基于堆百分比的区域强制执行驱逐阈值。 基于条目计数或存储器大小的驱逐策略的区域使用其他机制来管理驱逐。 有关驱逐政策的更多详细信息，请参阅驱逐。 Critical Threshold(临界阈值). 高速缓存存在无法操作风险的堆外内存百分比。 当缓存使用超过临界阈值时，将拒绝所有可能向缓存添加数据的活动。 任何会增加堆外内存消耗的操作都会抛出LowMemoryException而不是完成其操作。 使用critical-off-heap-percentage区域属性设置临界阈值。 无论LRU驱逐策略如何，都会对所有区域强制执行临界阈值，但可以将其设置为零以禁用其效果。 指定堆外内存 要使用堆外内存，请在设置服务器和区域时指定以下选项： 按调整JVM的垃圾收集参数中的说明启动JVM。 特别是，将初始和最大堆大小设置为相同的值。 当您计划使用堆外内存时，小于32GB的大小是最佳选择。 从gfsh，启动每个服务器，它将支持非堆内存，并具有非零的“off-heap-memory-size”值，以兆字节(m)或千兆字节(g)为单位。 如果您计划使用资源管理器，请指定临界阈值，逐出阈值或（在大多数情况下）两者。 例子: gfsh> start server --name=server1 -–initial-heap=10G -–max-heap=10G -–off-heap-memory-size=200G \\ -–lock-memory=true -–critical-off-heap-percentage=90 -–eviction-off-heap-percentage=80 通过将off-heapregion属性设置为true来标记其条目值应存储在堆外的区域。为托管同一区域的数据的所有成员统一配置其他区域属性。。 例子: gfsh>create region --name=region1 --type=PARTITION_HEAP_LRU --off-heap=true gfsh Off-heap支持 gfsh支持服务器和区域创建操作以及报告功能中的堆外内存： alter disk-store --off-heap=(true | false) 重置指定区域的off-heap属性。 有关详细信息，请参阅alter disk-store。 create region --off-heap=(true | false)设置指定区域的off-heap属性。 有关详细信息，请参阅create region。 describe member 显示堆外大小 describe offline-disk-store 显示离线区域是否处于堆外 describe region 显示区域的堆外属性的值 show metrics 包括堆外指标 maxMemory, freeMemory, usedMemory, objects, fragmentation 和 defragmentationTime start server 支持堆外选项--lock-memory，--off-heap-memory-size，--critical-off-heap-percentage和--eviction-off-heap-percentage请参阅 启动服务器了解详情。 资源管理 API org.apache.geode.cache.control.ResourceManager接口定义了支持堆外使用的方法： public void setCriticalOffHeapPercentage(float Percentage) public float getCriticalOffHeapPercentage() public void setEvictionOffHeapPercentage(float Percentage) public float getEvictionOffHeapPercentage() gemfire.properties文件支持一个堆外属性： off-heap-memory-size 指定堆外内存的大小，以兆字节(m)或千兆字节(g)为单位。 例如： off-heap-memory-size=4096m off-heap-memory-size=120g 有关详细信息，请参阅gemfire.properties和gfsecurity.properties(Geode Properties)。 cache.xml文件支持一个区域属性： off-heap(=true | false) Specifies that the region uses off-heap memory; defaults to false. For example: 有关详细信息，请参阅 cache.xml文件支持两个资源管理器属性： critical-off-heap-percentage=value 指定堆外内存的百分比达到或超过其缓存中成为不可操作的危险，由于内存不足异常的考虑。 有关详细信息，请参阅。 eviction-off-heap-percentage=value 指定应该开始驱逐的堆外内存的百分比。 可以为任何区域设置，但仅在为HEAP_LRU驱逐配置的区域中主动运行。 有关详细信息，请参阅。 例如: ... ... 调整堆外内存使用情况 Geode收集有关堆外内存使用情况的统计信息，您可以使用gfshshow metrics命令查看。 有关可用的堆外统计信息的说明，请参阅Off-Heap(OffHeapMemoryStats)。 默认情况下，堆外内存优化用于存储大小为128 KB的值。 此图称为“最大优化存储值大小”，我们将在此处用maxOptStoredValSize表示。 如果您的数据通常运行较大，则可以通过将OFF_HEAP_FREE_LIST_COUNT系统参数增加到大于maxOptStoredValSize/8的数字来增强性能，其中maxOptStoredValSize以KB(1024字节)表示。 因此，默认值对应于： 128 KB / 8 = (128 * 1024) / 8 = 131,072 / 8 = 16,384 -Dgemfire.OFF_HEAP_FREE_LIST_COUNT=16384 要优化最大优化存储值大小（默认值的两倍或256 KB），空闲列表计数应加倍： -Dgemfire.OFF_HEAP_FREE_LIST_COUNT=32768 在调优过程中，您可以打开和关闭off-heap区域属性，保留其他堆外设置和参数，以便比较应用程序的堆上和堆外性能。 锁定内存(仅限Linux系统) 在Linux系统上，您可以锁定内存以防止操作系统分页堆或堆外内存。 要使用此功能： 配置锁定内存的操作系统限制。 将操作系统的ulimit -l值（可能在内存中锁定的最大大小）从默认值（通常为32 KB或64 KB）增加到至少Geode用于堆栈或关闭的内存总量 堆存储。 要查看当前设置，请在shell提示符下输入ulimit -a并找到max locked memory的值： # ulimit -a ... max locked memory (kbytes, -l) 64 ... 使用ulimit -l max-size-in-kbytes来提高限制。 例如，要将锁定的内存限制设置为64 GB： # ulimit -l 64000000 以这种方式使用锁定内存会增加启动Geode所需的时间。 启动Geode所需的额外时间取决于所使用的内存总量，可以在几秒到10分钟或更长的范围内。 为了缩短启动时间并减少成员超时的可能性，请通过发出以下命令，指示内核在启动Geode成员之前释放操作系统页面缓存： $ echo 1 > /proc/sys/vm/drop_caches 使用gfsh -lock-memory=true选项启动每个Geode数据存储。 如果每个主机部署多个服务器，请先顺序启动每个服务器。 如果不小心分配了可用的RAM，则按顺序启动服务器可以避免操作系统中的竞争状况，该竞争状况可能导致故障（甚至导致机器崩溃）。 确认系统配置稳定后，即可并发启动服务器。 磁盘存储 使用Apache Geode磁盘存储，您可以将数据保存到磁盘，作为内存中副本的备份，并在内存使用过高时将数据溢出到磁盘。 磁盘存储的工作原理 溢出和持久性单独或一起使用磁盘存储来存储数据。 磁盘存储文件名和扩展名 磁盘存储文件包括存储管理文件，访问控制文件和操作日志或oplog文件，包括一个用于删除的文件和另一个用于所有其他操作的文件。 磁盘存储操作日志 在创建时，每个操作日志都在磁盘存储的max-oplog-size中初始化，其大小分为crf和drf文件。 当oplog关闭时，Apache Geode会将文件缩小到每个文件中使用的空间。 配置磁盘存储 除了您指定的磁盘存储之外，Apache Geode还有一个默认磁盘存储，它在配置磁盘使用时未使用指定磁盘存储名称时使用。 您可以修改默认磁盘存储行为。 使用磁盘存储优化系统 遵循本节中的准则，优化可用性和性能。 启动并关闭磁盘存储 本节介绍启动和关闭期间发生的情况，并提供这些操作的过程。 磁盘存储管理 gfsh命令行工具有许多选项可用于检查和管理磁盘存储。 gfsh工具，cache.xml文件和DiskStore API是在线和离线磁盘存储的管理工具。 为系统恢复和运营管理创建备份 备份是磁盘存储中持久数据的副本。 备份用于将磁盘存储还原到备份时的状态。 根据集群是联机还是脱机，相应的备份和还原过程会有所不同。 在线系统目前正在运行成员。 离线系统没有任何正在运行的成员。 磁盘存储的工作原理 溢出和持久性单独或一起使用磁盘存储来存储数据。 磁盘存储可用于以下项目： Regions. 持久化和/或从区域溢出数据。 Server’s client subscription queues. 溢出消息传递队列以控制内存使用。 Gateway sender queues. 坚持这些以获得高可用性。 这些队列总是溢出。 PDX serialization metadata. 使用Geode PDX序列化保留有关您序列化的对象的元数据。 每个成员都有自己的一组磁盘存储，它们与任何其他成员的磁盘存储完全分开。 对于每个磁盘存储，定义数据存储到磁盘的位置和方式。 您可以将来自多个区域和队列的数据存储在单个磁盘存储中。 此图显示了已定义磁盘存储D到R的成员。 该成员有两个持久区域使用磁盘存储D和溢出区域以及使用磁盘存储R的溢出队列。 Geode写入磁盘存储的内容 Geode将以下内容写入磁盘存储： 创建和配置磁盘存储时指定的持久性和溢出数据 承载存储和信息及其状态的成员，例如哪些成员在线以及哪些成员处于脱机状态和时间戳 磁盘存储标识符 磁盘存储区中的哪些区域由区域名称指定并包括所选属性 磁盘存储区域所依赖的共同定位区域的名称 记录所有区域的运营情况 Geode不会将索引写入磁盘。 磁盘存储状态 磁盘存储的文件由Geode作为一个组。 将它们视为一个单一的实体。 如果您复制它们，请将它们全部复制在一起。 不要更改文件名。 磁盘存储访问和管理根据成员是在线还是离线而不同。 当成员正在运行时，其磁盘存储在线。 当成员退出并且未运行时，其磁盘存储处于脱机状态。 Online, 磁盘存储由其成员进程拥有和管理。 要在联机磁盘存储上运行操作，请在成员进程中使用API调用，或使用gfsh命令行界面。 Offline, 磁盘存储只是主机文件系统中的文件集合。 可以根据文件系统权限访问这些文件。 您可以复制文件以进行备份或移动成员的磁盘存储位置。 您还可以使用gfsh命令行界面运行一些维护操作，例如文件压缩和验证。 脱机时，磁盘存储的信息对集群不可用。 对于分区区域，区域数据在多个成员之间分配，因此成员的启动取决于所有成员，并且必须等待所有成员联机。 尝试访问脱机成员存储在磁盘上的条目会导致PartitionOfflineException。 磁盘存储文件名和扩展名 磁盘存储文件包括存储管理文件，访问控制文件和操作日志或oplog文件，包括一个用于删除的文件和另一个用于所有其他操作的文件。 下表描述了文件名和扩展名; 它们后面是示例磁盘存储文件。 文件名 文件名有三个部分：用途标识符，磁盘存储库名称和oplog序列号。 文件名的第一部分: Usage Identifier 值 用于 例子 OVERFLOW 仅来自溢出区域和队列的Oplog数据。 OVERFLOWoverflowDS1_1.crf BACKUP 来自持久性和持久性+溢出区域和队列的Oplog数据。 BACKUPoverflowDS1.if, BACKUPDEFAULT.if DRLK_IF 访问控制-锁定磁盘存储。 DRLK_IFoverflowDS1.lk, DRLK_IFDEFAULT.lk 文件名的第二部分: Disk Store Name 值 用于 例子 非默认磁盘存储。 name=“overflowDS1” DRLK_IFoverflowDS1.lk, name=“persistDS1” BACKUPpersistDS1_1.crf DEFAULT 默认磁盘存储名称，当在区域或队列上指定持久性或溢出但未命名磁盘存储时使用。 DRLK_IFDEFAULT.lk, BACKUPDEFAULT_1.crf 文件名的第三部分: oplog Sequence Number 值 用于 例子 序列号格式为 _n 仅Oplog数据文件。 编号从1开始。 OVERFLOWoverflowDS1_1.crf, BACKUPpersistDS1_2.crf, BACKUPpersistDS1_3.crf 文件扩展名 File extension 用于 说明 if 磁盘存储元数据 存储在为存储列出的第一个磁盘目录中。 可忽略的大小-在大小控制中不考虑。 lk 磁盘存储访问控制 存储在为存储列出的第一个磁盘目录中。 可忽略的大小-在大小控制中不考虑。 crf Oplog：创建，更新和作废 在创建时预分配了最大max-oplog大小的90％。 drf Oplog: 删除操作 创建时预先分配的总最大操作日志大小的10％。 krf Oplog: 键和crf偏移量信息 在oplog达到max-oplog-size后创建。 用于提高启动时的性能。 磁盘存储的示例文件为persistDS1和overflowDS1： bash-2.05$ ls -tlr persistData1/ total 8 -rw-rw-r-- 1 person users 188 Mar 4 06:17 BACKUPpersistDS1.if -rw-rw-r-- 1 person users 0 Mar 4 06:18 BACKUPpersistDS1_1.drf -rw-rw-r-- 1 person users 38 Mar 4 06:18 BACKUPpersistDS1_1.crf bash-2.05$ ls -tlr overflowData1/ total 1028 -rw-rw-r-- 1 person users 0 Mar 4 06:21 DRLK_IFoverflowDS1.lk -rw-rw-r-- 1 person users 0 Mar 4 06:21 BACKUPoverflowDS1.if -rw-rw-r-- 1 person users 1073741824 Mar 4 06:21 OVERFLOWoverflowDS1_1.crf 持久区域的默认磁盘存储文件示例： bash-2.05$ ls -tlr total 106 -rw-rw-r-- 1 person users 1010 Mar 8 15:01 defTest.xml drwxrwxr-x 2 person users 512 Mar 8 15:01 backupDirectory -rw-rw-r-- 1 person users 0 Mar 8 15:01 DRLK_IFDEFAULT.lk -rw-rw-r-- 1 person users 107374183 Mar 8 15:01 BACKUPDEFAULT_1.drf -rw-rw-r-- 1 person users 966367641 Mar 8 15:01 BACKUPDEFAULT_1.crf -rw-rw-r-- 1 person users 172 Mar 8 15:01 BACKUPDEFAULT.if 磁盘存储操作日志 在创建时，每个操作日志都在磁盘存储的max-oplog-size中初始化，其大小分为crf和drf文件。 当oplog关闭时，Apache Geode会将文件缩小到每个文件中使用的空间。 关闭oplog之后，Geode还会尝试创建一个krf文件，其中包含键名以及crf文件中值的偏移量。 虽然启动时不需要此文件，但如果它可用，它将通过允许Geode在加载条目键后在后台加载条目值来提高启动性能。 当操作日志已满时，Geode会自动关闭它并创建一个包含下一个序列号的新日志。 这称为oplog rolling。 您还可以通过API调用DiskStore.forceRoll请求oplog滚动。 您可能希望在压缩磁盘存储之前立即执行此操作，因此最新的oplog可用于压缩。 注意: 日志压缩可以更改磁盘存储文件的名称。 通常会更改文件编号顺序，删除一些现有日志，或者使用编号较高的较新日志替换。 Geode始终以高于任何现有数字的数字开始新日志。 此示例清单显示系统中的日志，其中只有一个为存储指定的磁盘目录。 第一个日志(BACKUPCacheOverflow_1.crf和BACKUPCacheOverflow_1.drf)已关闭，系统正在写入第二个日志。 bash-2.05$ ls -tlra total 55180 drwxrwxr-x 7 person users 512 Mar 22 13:56 .. -rw-rw-r-- 1 person users 0 Mar 22 13:57 BACKUPCacheOverflow_2.drf -rw-rw-r-- 1 person users 426549 Mar 22 13:57 BACKUPCacheOverflow_2.crf -rw-rw-r-- 1 person users 0 Mar 22 13:57 BACKUPCacheOverflow_1.drf -rw-rw-r-- 1 person users 936558 Mar 22 13:57 BACKUPCacheOverflow_1.crf -rw-rw-r-- 1 person users 1924 Mar 22 13:57 BACKUPCacheOverflow.if drwxrwxr-x 2 person users 2560 Mar 22 13:57 . 系统将在所有可用磁盘目录中旋转以写入其日志。 下一个日志始终在未达到其已配置容量的目录中启动（如果存在）。 磁盘存储Oplog达到配置的磁盘容量时 如果不存在容量限制范围内的目录，Geode如何处理这取决于是否启用了自动压缩。 如果启用了自动压缩，Geode会在其中一个目录中创建一个新的oplog，超出限制，并记录一个警告，报告： Even though the configured directory size limit has been exceeded a new oplog will be created. The current limit is of XXX. The current space used in the directory is YYY. 注意: 启用自动压缩后，dir-size不会限制使用多少磁盘空间。 Geode将执行自动压缩，这应该释放空间，但系统可能会超过配置的磁盘限制。 如果禁用自动压缩，Geode不会在附加到磁盘存储块的区域中创建新的oplog操作，并且Geode会记录此错误： Disk is full and rolling is disabled. No space can be created 配置磁盘存储 除了您指定的磁盘存储之外，Apache Geode还有一个默认磁盘存储，它在配置磁盘使用时未使用指定磁盘存储名称时使用。 您可以修改默认磁盘存储行为。 设计和配置磁盘存储 您可以在缓存中定义磁盘存储，然后通过在区域和队列配置中设置disk-store-name属性将它们分配给您的区域和队列。 磁盘存储配置参数 您可以使用gfsh create disk-store命令或cache.xml中缓存声明的子元素来定义磁盘存储。 所有磁盘存储都可供所有区域和队列使用。 修改默认磁盘存储 您可以通过为名为“DEFAULT”的磁盘存储指定所需的属性来修改默认磁盘存储的行为。 设计和配置磁盘存储 您可以在缓存中定义磁盘存储，然后通过在区域和队列配置中设置disk-store-name属性将它们分配给您的区域和队列。 注意: 除了您指定的磁盘存储，Apache Geode还有一个默认磁盘存储，它在配置磁盘使用时没有指定磁盘存储名称。 默认情况下，此磁盘存储区保存到应用程序的工作目录中。 您可以更改其行为，如创建和配置磁盘存储和修改默认磁盘。 设计您的磁盘存储 创建和配置磁盘存储 配置区域，队列和PDX序列化以使用磁盘存储 在网关发件人上配置磁盘存储 设计您的磁盘存储 在开始之前，您应该了解Geode 基本配置和编程。 与您的系统设计人员和开发人员一起规划测试和生产缓存系统中预期的磁盘存储要求。 考虑空间和功能要求。 为了提高效率，仅在单独的磁盘存储中溢出的数据与持久或持久且溢出的数据分开。 区域可以溢出，持久存在，或两者兼而有之。 服务器订阅队列仅溢出。 计算磁盘需求时，请参考数据修改模式和压缩策略。 Geode以max-oplog-size创建每个oplog文件，默认为1 GB。 只有在压缩过程中才会从oplog中删除过时的操作，因此您需要足够的空间来存储压缩之间完成的所有操作。 对于混合使用更新和删除的区域，如果使用自动压缩，则所需磁盘空间的上限为 (1 / (1 - (compaction_threshold/100)) ) * data size 其中数据大小是您存储在磁盘存储中的所有数据的总大小。 因此，对于默认的压缩阈值50，磁盘空间大约是数据大小的两倍。 请注意，压缩线程可能落后于其他操作，导致磁盘使用暂时超过阈值。 如果禁用自动压缩，则所需的磁盘数量取决于手动压缩之间累积的过时操作数量。 根据预期的磁盘存储要求和主机系统上的可用磁盘，与主机系统管理员一起确定磁盘存储目录的放置位置。 确保新存储不会干扰在系统上使用磁盘的其他进程。 如果可能，请将文件存储到其他进程未使用的磁盘，包括虚拟内存或交换空间。 如果您有多个可用磁盘，为了获得最佳性能，请在每个磁盘上放置一个目录。 为不同的成员使用不同的目录。 您可以将任意数量的目录用于单个磁盘存储。 创建和配置磁盘存储 在您选择的位置，创建要为磁盘存储指定的所有目录。 如果在创建磁盘存储时指定的目录不可用，Geode会抛出异常。 您不需要用任何东西填充这些目录。 打开gfsh提示符并连接到集群。 在gfsh提示符下，创建并配置磁盘存储： 指定磁盘存储的名称（--name）。 为您的操作系统选择合适的磁盘存储名称。 磁盘存储名称用于磁盘文件名： 使用满足操作系统文件命名要求的磁盘存储名称。 例如，如果将数据存储在Windows系统中的磁盘上，则磁盘存储名称不能包含任何这些保留字符，<>：“/ \\ |？*。 不要使用很长的磁盘存储名称。 完整文件名必须符合您的操作系统限制。 例如，在Linux上，标准限制为255个字符。 gfsh>create disk-store --name=serverOverflow --dir=c:\\overflow_data#20480 配置目录位置（--dir）和用于存储的最大空间（在磁盘目录名称后面指定＃和最大数字，以兆字节为单位）。 gfsh>create disk-store --name=serverOverflow --dir=c:\\overflow_data#20480 （可选）您可以配置存储的文件压缩行为。 在这种情况，计划和方案对于任何手动压缩结合使用。 例： gfsh>create disk-store --name=serverOverflow --dir=c:\\overflow_data#20480 \\ --compaction-threshold=40 --auto-compact=false --allow-force-compaction=true 如果需要，请配置单个oplog的最大大小（以MB为单位）。 当前文件达到此大小时，系统将前滚到新文件。 使用相对较小的最大文件大小可以获得更好的性能 例： gfsh>create disk-store --name=serverOverflow --dir=c:\\overflow_data#20480 \\ --compaction-threshold=40 --auto-compact=false --allow-force-compaction=true \\ --max-oplog-size=512 如果需要，请修改队列管理参数以进行异步排队到磁盘存储。 您可以为同步或异步排队配置任何区域（区域属性disk-synchronous）。 服务器队列和网关发送方队列始终同步运行。 当达到queue-size（队列容量）或time-interval（毫秒）时，排队的数据被刷新到磁盘。 您还可以通过DiskStore flushToDisk方法同步将未写入的数据刷新到磁盘。 例： gfsh>create disk-store --name=serverOverflow --dir=c:\\overflow_data#20480 \\ --compaction-threshold=40 --auto-compact=false --allow-force-compaction=true \\ --max-oplog-size=512 --queue-size=10000 --time-interval=15 如果需要，修改用于写入磁盘的缓冲区的大小（以字节为单位）。 例： gfsh>create disk-store --name=serverOverflow --dir=c:\\overflow_data#20480 \\ --compaction-threshold=40 --auto-compact=false --allow-force-compaction=true \\ --max-oplog-size=512 --queue-size=10000 --time-interval=15 --write-buffer-size=65536 如果需要，修改disk-usage-warning-percentage和disk-usage-critical-percentagethresholds，确定将触发警告的磁盘使用百分比（默认值：90％）和百分比（默认值：99 ％）磁盘使用率将产生错误并关闭成员缓存。 例： gfsh>create disk-store --name=serverOverflow --dir=c:\\overflow_data#20480 \\ --compaction-threshold=40 --auto-compact=false --allow-force-compaction=true \\ --max-oplog-size=512 --queue-size=10000 --time-interval=15 --write-buffer-size=65536 \\ --disk-usage-warning-percentage=80 --disk-usage-critical-percentage=98 以下是完整的磁盘存储cache.xml配置示例： c:\\overflow_data d:\\overflow_data 注意: 作为在集群中的每个服务器上定义cache.xml的替代方法 - 如果启用了集群配置服务，则在gfsh中创建磁盘存储时，可以与其余集群共享磁盘存储的配置。 请参见集群配置服务概述。 修改磁盘存储 您可以使用alter disk-store命令修改脱机磁盘存储。 如果要修改默认磁盘存储配置，请使用“DEFAULT”作为磁盘存储名称。 配置区域，队列和PDX序列化以使用磁盘存储 以下是为区域，队列和PDX序列化使用已创建和命名的磁盘存储的示例。 使用磁盘存储区域持久性和溢出的示例： gfsh: gfsh>create region --name=regionName --type=PARTITION_PERSISTENT_OVERFLOW \\ --disk-store=serverPersistOverflow cache.xml 将命名磁盘存储用于服务器订阅队列溢出（cache.xml）的示例： 将命名磁盘存储用于PDX序列化元数据（cache.xml）的示例： 在网关发件人上配置磁盘存储 网关发件人队列始终溢出，可能会保留。 如果不持久，则将它们分配给溢出磁盘存储，如果这样做，则分配给持久性磁盘存储。 将命名磁盘存储用于网关发送方队列持久性的示例： gfsh: gfsh>create gateway-sender --id=persistedSender1 --remote-distributed-system-id=1 \\ --enable-persistence=true --disk-store-name=diskStoreA --maximum-queue-memory=100 cache.xml: ... 使用默认磁盘存储区进行网关发送方队列持久性和溢出的示例： gfsh: gfsh>create gateway-sender --id=persistedSender1 --remote-distributed-system-id=1 \\ --enable-persistence=true --maximum-queue-memory=100 cache.xml: ... 磁盘存储配置参数 您可以使用gfsh create disk-store命令或cache.xml中缓存声明的子元素来定义磁盘存储。 所有磁盘存储都可供所有区域和队列使用。 这些属性和子元素在org.apache.geode.cache.DiskStoreFactory和org.apachegeode.cache.DiskStoreAPI中具有相应的gfsh create disk-storecommand-line参数以及getter和setter方法。 磁盘存储配置属性和元素 disk-store 属性 描述 缺省值 name 用于标识此磁盘存储的字符串。 所有区域和队列都通过指定此名称来选择其磁盘存储。 DEFAULT allow-force-compaction 布尔值，指示是否允许通过API或命令行工具进行手动压缩。 false auto-compact 布尔值，指示文件到达时是否自动压缩 compaction-threshold. true compaction-threshold 文件在符合压缩条件之前允许的垃圾百分比。 垃圾由入口销毁，条目更新和区域销毁和创建创建。 超过此百分比不会使压缩发生 - 它使文件在压缩完成时有资格被压缩。 50 disk-usage-critical-percentage 磁盘使用率高于此阈值会生成错误消息并关闭成员的缓存。 例如，如果阈值设置为99％，则1 TB驱动器上的10 GB可用磁盘空间不足会生成错误并关闭缓存。设置为“0”（零）以禁用。 99 disk-usage-warning-percentage 磁盘使用率高于此阈值会生成警告消息。 例如，如果阈值设置为90％，则在100 GB可用磁盘空间下的1 TB驱动器上会生成警告。设置为“0”（零）以禁用。 90 max-oplog-size 允许操作日志在自动滚动到新文件之前的最大大小（以兆字节为单位）。 此大小是oplog文件的组合大小。 1024 queue-size 用于异步排队。 在自动刷新队列之前允许进入写入队列的最大操作数。 在刷新队列之前将条目添加到队列块的操作。 值为零意味着没有大小限制。 达到此限制或时间间隔限制将导致队列刷新。 0 time-interval 用于异步排队。 数据刷新到磁盘之前可以经过的毫秒数。 达到此限制或队列大小限制会导致队列刷新。 1000 write-buffer-size 用于写入磁盘的缓冲区大小（以字节为单位）。 32768 disk-storesubelement 描述 缺省值 定义写入磁盘存储的系统目录及其最大大小。 . 没有大小限制 disk-dirs元素 元素定义用于磁盘存储的主机系统目录。 它包含一个或多个单个元素，其中包含以下内容： 目录规范，作为disk-dir元素的文本提供。 一个可选的dir-size属性，指定用于目录中磁盘存储的最大空间量（以兆字节为单位）。 默认情况下，没有限制。 使用的空间计算为所有oplog文件的组合大小。 您可以为disk-dirs元素指定任意数量的disk-dir子元素。 数据均匀分布在目录中的活动磁盘文件中，并保持在您设置的任何限制范围内。 例子: /host1/users/gf/memberA_DStore /host2/users/gf/memberA_DStore /host3/users/gf/memberA_DStore 注意: 创建磁盘存储或系统抛出异常时，目录必须存在。 Geode不会创建目录。 对不同的磁盘存储使用不同的disk-dir规范。 您不能在两个不同的成员中为同一个命名磁盘存储使用相同的目录。 修改默认磁盘存储 您可以通过为名为“DEFAULT”的磁盘存储指定所需的属性来修改默认磁盘存储的行为。 无论何时使用磁盘存储而不指定要使用的磁盘存储，Geode都会使用名为“DEFAULT”的磁盘存储。 例如，这些区域和队列配置指定持久性和/或溢出，但不指定disk-store-name。 由于未指定磁盘存储，因此这些存储使用名为“DEFAULT”的磁盘存储。 使用默认磁盘存储区域持久性和溢出的示例： gfsh: gfsh>create region --name=regionName --type=PARTITION_PERSISTENT_OVERFLOW cache.xml 使用默认磁盘存储区进行服务器订阅队列溢出（cache.xml）的示例： 更改默认磁盘存储的行为 Geode使用默认磁盘存储配置设置初始化默认磁盘存储。 您可以通过为名为“DEFAULT”的磁盘存储指定所需的属性来修改默认磁盘存储的行为。 关于默认磁盘存储，您唯一无法更改的是名称。 以下示例更改默认磁盘存储以允许手动压缩并使用多个非默认目录： cache.xml: /export/thor/customerData /export/odin/customerData /export/embla/customerData 使用磁盘存储优化系统 遵循本节中的准则，优化可用性和性能。 Apache Geode建议在Linux或Solaris平台上运行时使用ext4文件系统。 ext4文件系统支持预分配，这有利于磁盘启动性能。 如果您在具有高写入吞吐量的延迟敏感环境中使用ext3文件系统，则可以通过将maxOplogSize（请参阅DiskStoreFactory.setMaxOplogSize）设置为低于默认值1 GB的值来提高磁盘启动性能。 通过在Geode进程启动时指定系统属性gemfire.preAllocateDisk=false来禁用预分配。 启动系统时，大致同时启动具有持久区域的所有成员。 创建和使用启动脚本以确保一致性和完整性。 使用gfshshutdown命令关闭系统。 这是一个有序的关闭，可以定位磁盘存储以加快启动速度。 配置磁盘的关键使用阈值（disk-usage-warning-percentage和disk-usage-critical-percentage）。 默认情况下，这些设置为80％用于警告，99％用于关闭缓存的错误。 确定文件压缩策略，并在需要时开发监视文件和执行常规压缩的过程。 确定磁盘存储的备份策略并遵循它。 您可以使用backup disk-store命令备份正在运行的系统。 如果在磁盘存储脱机时删除任何永久区域或更改其配置，请考虑同步磁盘存储中的区域。 启动并关闭磁盘存储 本节介绍启动和关闭期间发生的情况，并提供这些操作的过程。 启动 当您使用持久区域启动成员时，将从磁盘存储中检索数据以重新创建成员的持久区域。 如果成员未保存该区域的所有最新数据，则其他成员将拥有数据和区域创建块，等待其他成员。 具有共置条目的分区区域也在启动时阻塞，等待共置区域的条目可用。 永久网关发件人的处理方式与共处理区域相同，因此它也可以阻止区域创建。 使用日志级别的信息或以下信息，系统会提供有关等待的消息。 这里，server2的磁盘存储区具有该区域的最新数据，server1正在等待server2。 Region /people has potentially stale data. It is waiting for another member to recover the latest data. My persistent id: DiskStore ID: 6893751ee74d4fbd-b4780d844e6d5ce7 Name: server1 Location: /192.0.2.0:/home/dsmith/server1/. Members with potentially new data: [ DiskStore ID: 160d415538c44ab0-9f7d97bae0a2f8de Name: server2 Location: /192.0.2.0:/home/dsmith/server2/. ] Use the \"gfsh show missing-disk-stores\" command to see all disk stores that are being waited on by other members. 当最新数据可用时，系统会更新区域，记录消息并继续启动。 [info 2010/04/09 10:52:13.010 PDT CacheRunner tid=0x1] Done waiting for the remote data to be available. 如果成员的磁盘存储区包含从未创建的区域的数据，则数据将保留在磁盘存储区中。 每个成员的持久区域尽可能快地加载并上线，而不是不必要地等待其他成员完成。 出于性能原因，这些操作是异步发生的： 一旦从磁盘恢复了每个存储桶的至少一个副本，该区域就可用。 辅助存储桶将异步加载。 在考虑条目值之前，从磁盘存储区中的密钥文件加载条目密钥。 加载所有密钥后，Geode将异步加载条目值。 如果在加载之前请求了值，则将立即从磁盘存储中获取该值。 启动程序 要启动具有磁盘存储的系统： 首先使用持久数据同时启动所有成员. 具体如何执行此操作取决于您的成员。 确保启动托管共处区域的成员以及持久网关发件人。 在他们初始化他们的区域时，成员确定哪些具有最新的区域数据，并使用最新的数据初始化他们的区域。 对于仅在某些区域的主机成员中定义持久性的复制区域，请在非持久性复制成员之前启动持久性复制成员，以确保从磁盘恢复数据。 这是一个用于并行启动成员的bash脚本示例。 脚本等待启动完成。 如果其中一个作业失败，它将以错误状态退出。 #!/bin/bash ssh servera \"cd /my/directory; gfsh start server --name=servera & ssh serverb \"cd /my/directory; gfsh start server --name=serverb & STATUS=0; for job in `jobs -p` do echo $job wait $job; JOB_STATUS=$?; test $STATUS -eq 0 && STATUS=$JOB_STATUS; done exit $STATUS; 回应被阻止的成员. 当成员阻止等待来自另一个成员的更新数据时，该成员将无限期地等待而不是使用陈旧数据联机。 使用gfsh show missing-disk-stores命令检查缺少的磁盘存储。 请参阅处理丢失的磁盘存储。 如果没有磁盘存储丢失，由于某些其他原因，缓存初始化必须很慢。 在诊断系统问题中查看有关成员挂起的信息。 如果缺少您认为应该存在的磁盘存储： 确保您已启动该成员。 检查日志中是否有任何失败消息。 请参阅Logging。 确保可以访问磁盘存储文件。 如果已移动成员或磁盘存储文件，则必须更新磁盘存储配置以匹配。 如果缺少您知道丢失的磁盘存储，因为您已删除它们或其文件不可用，请撤消它们以便启动可以继续。 示例启动以说明订购 以下列出了在关闭后启动复制的持久区域的两种可能性。 假设成员A（MA）首先退出，将剩余数据留在磁盘上用于RegionP。 成员B（MB）继续在RegionP上运行操作，RegionP更新其磁盘存储并使MA的磁盘存储处于过时状态。 MB退出，将最新数据保留在RegionP的磁盘上。 重启订单1 MB首先启动。 MB标识它具有RegionP的最新磁盘数据并从磁盘初始化该区域。 MB不会阻止。 MA已启动，从磁盘恢复其数据，并根据需要从MB中的数据更新区域数据。 重启订单2 MA首先启动。 MA确定它没有最新的磁盘数据和块，等待MB在MA中重新创建RegionP之前启动。 MB已启动。 MB标识它具有RegionP的最新磁盘数据并从磁盘初始化该区域。 MA从磁盘恢复其RegionP数据，并根据需要从MB中的数据更新区域数据。 关闭 如果多个成员承载持久区域或队列，则在重新启动系统时，各个成员关闭的顺序可能很重要。 退出系统或关闭的最后一个成员具有磁盘上最新的数据。 每个成员都知道退出或关闭时哪些其他系统成员在线。 这允许成员在随后的启动时获取最新数据。 对于具有持久性的复制区域，要退出的最后一个成员具有最新数据。 对于分区区域，每个成员都会持有自己的存储桶。 使用gfsh shutdown的关闭会在退出前同步磁盘存储，因此所有磁盘存储都会保存最新的数据。 如果没有有序关闭，某些磁盘存储可能具有比其他磁盘存储更新的存储区数据。 关闭系统的最佳方法是在所有成员运行时调用gfsh shutdown命令。 所有在线数据存储将在关闭之前同步，因此所有数据存储都保留最新的数据副本。 要关闭定位器以外的所有成员： gfsh>shutdown To shut down all members, including locators: gfsh>shutdown --include-locators=true 磁盘存储管理 gfsh命令行工具有许多选项可用于检查和管理磁盘存储。 gfsh工具，cache.xml文件和DiskStore API是在线和离线磁盘存储的管理工具。 有关可用命令的列表，请参阅磁盘存储命令。 磁盘存储管理命令和操作 验证磁盘存储 在磁盘存储日志文件上运行压缩 保持磁盘存储与缓存同步 配置磁盘可用空间监视 处理丢失的磁盘存储 当缓冲区刷新到磁盘时更改 您可以将Geode配置为立即写入磁盘，您可以修改操作系统行为以更频繁地执行缓冲区刷新。 磁盘存储管理命令和操作 您可以使用gfsh命令行工具管理磁盘存储。 有关gfsh命令的更多信息，请参阅gfsh和磁盘存储命令。 注意: 这些命令中的每一个都在联机磁盘存储或脱机磁盘存储上运行，但不能同时运行。 gfsh 命令 Online or Offline 命令 参见 … alter disk-store Off 保持磁盘存储与缓存同步 compact disk-store On 在磁盘存储日志文件上运行压缩 backup disk-store On 为系统恢复和运营管理创建备份 compact offline-disk-store Off 在磁盘存储日志文件上运行压缩 export offline-disk-store Off 为系统恢复和运营管理创建备份 revoke missing-disk-store On 处理丢失的磁盘存储 show missing-disk-stores On 处理丢失的磁盘存储 shutdown On 启动并关闭磁盘存储 validate offline disk-store Off 验证磁盘存储e 要获得任何gfsh命令的完整命令语法，请在gfsh命令行中运行help 。 在线磁盘存储操作 对于在线操作，gfsh必须通过JMX管理器连接到集群，并将操作请求发送给具有磁盘存储的成员。 这些命令不会在脱机磁盘存储上运行。 脱机磁盘存储操作 对于脱机操作，gfsh对指定的磁盘存储及其指定的目录运行命令。 您必须指定磁盘存储的所有目录。 例如： gfsh>compact offline-disk-store --name=mydiskstore --disk-dirs=MyDirs 脱机操作不会在联机磁盘存储上运行。 该工具在磁盘存储运行时锁定它，因此该成员无法在操作过程中启动。 如果您尝试为联机磁盘存储运行脱机命令，则会收到如下消息： gfsh>compact offline-disk-store --name=DEFAULT --disk-dirs=s1 This disk store is in use by another process. \"compact disk-store\" can be used to compact a disk store that is currently in use. 验证磁盘存储 validate offline-disk-store命令验证脱机磁盘存储的运行状况，并为您提供有关其中区域的信息，总条目以及压缩存储时将删除的记录数。 在以下时间使用此命令： 在压缩脱机磁盘存储之前，以帮助确定它是否值得做。 在还原或修改磁盘存储之前。 任何时候你想确定磁盘存储器的状态良好。 例子: gfsh>validate offline-disk-store --name=ds1 --disk-dirs=hostB/bupDirectory 在磁盘存储日志文件上运行压缩 将缓存操作添加到磁盘存储时，同一条目的任何预先存在的操作记录都将过时，Apache Geode会将其标记为垃圾。 例如，当你创建一个条目，创建操作被添加到存储中。 如果稍后更新该条目，则会添加更新操作，并且创建操作将变为垃圾。 Geode不会删除垃圾记录，但它会跟踪每个操作日志中的垃圾百分比，并提供删除垃圾以压缩日志文件的机制。 Geode通过将所有非垃圾记录复制到当前日志并丢弃旧文件来压缩旧操作日志。 与日志记录一样，在压缩期间根据需要滚动oplog以保持在最大oplog设置内。 您可以将系统配置为在垃圾内容达到特定百分比时自动压缩任何已关闭的操作日志。 您还可以手动请求在线和离线磁盘存储的压缩。 对于联机磁盘存储，无论压缩包含多少垃圾，当前操作日志都不可用于压缩。 联机磁盘存储的日志文件压缩 脱机压缩基本上以相同的方式运行，但没有传入的缓存操作。 此外，由于当前没有打开日志，因此压缩会创建一个新的开始日志。 运行在线压缩 当旧日志文件的垃圾内容超过总文件的配置百分比时，它们就有资格进行在线压缩。 当一个记录的操作被同一个对象的更新操作取代时，该记录就是垃圾。 在压缩期间，非垃圾记录将与新的缓存操作一起添加到当前日志中。 在线压缩不会阻止当前的系统操作。 自动压缩. 当auto-compact为真时，Geode会在其垃圾内容超过compaction-threshold时自动压缩每个oplog。 这需要从其他操作开始循环，因此您可能希望禁用此操作并仅执行手动压缩，以控制时间。 手动压缩. 要运行手动压缩： 将磁盘存储属性allow-force-compaction设置为true。 这会导致Geode维护有关文件的额外数据，以便按需压缩。 默认情况下禁用此选项以节省空间。 您可以在系统运行时随时运行手动在线压缩。 有资格根据compaction-threshold进行压缩的Oplog被压缩到当前的oplog中。 根据需要运行手动压缩。 Geode有两种类型的手动压缩： 使用forceCompaction方法通过API压缩单个在线磁盘存储的日志。 此方法首先滚动oplog，然后压缩它们。 例： myCache.getDiskStore(\"myDiskStore\").forceCompaction(); 使用gfsh，使用compact disk-store命令压缩磁盘存储。 例子： gfsh>compact disk-store --name=Disk1 gfsh>compact disk-store --name=Disk1 --group=MemberGroup1,MemberGroup2 注意: 您需要连接到gfsh中的JMX Manager才能运行此命令。 运行脱机压缩 离线压缩是一个手动过程。 无论他们持有多少垃圾，所有日志文件都会尽可能地压缩。 脱机压缩为压缩的日志记录创建新的日志文件。 使用gfsh，使用compact offline-disk-store压缩各个离线磁盘存储命令： gfsh>compact offline-disk-store --name=Disk2 --disk-dirs=/Disks/Disk2 gfsh>compact offline-disk-store --name=Disk2 --disk-dirs=/Disks/Disk2 --max-oplog-size=512 -J=-Xmx1024m 注意: Do not perform offline compaction on the baseline directory of an incremental backup. 您必须提供磁盘存储中的所有目录。 如果未指定oplog max size，则Geode使用系统默认值。 离线压缩可能会占用大量内存。 如果在运行时出现“java.lang.OutOfMemory”错误，则可能需要使用-J=-Xmx参数增加堆大小。 手动压实的性能优势 如果禁用自动压缩并在较轻的系统负载期间或停机期间运行您自己的手动压缩，则可以在繁忙时间提高性能。 在应用程序执行大量数据操作后，您可以运行API调用。 当系统使用率很低时，你可以每晚运行compact disk-store命令。 要遵循这样的策略，您需要留出足够的磁盘空间来容纳所有未压缩的磁盘数据。 您可能需要增加系统监视以确保不会超出磁盘空间。 您可能只能运行离线压缩。 如果是这样，您可以将allow-force-compaction设置为false，并避免存储手动在线压缩所需的信息。 目录大小限制 压缩期间达到目录大小限制具有不同的结果，具体取决于您是运行自动压缩还是手动压缩： 对于自动压缩，系统会记录警告，但不会停止。 对于手动压缩，操作停止并向调用进程返回DiskAccessException，报告系统磁盘空间不足。 示例压缩运行 在这个离线压缩运行列表的例子中，磁盘存储压缩在*_3.*文件中没有任何关系，所以它们是独立的。 *_4.*文件有垃圾记录，因此来自它们的oplog被压缩成新的*_5.*文件。 bash-2.05$ ls -ltra backupDirectory total 28 -rw-rw-r-- 1 user users 3 Apr 7 14:56 BACKUPds1_3.drf -rw-rw-r-- 1 user users 25 Apr 7 14:56 BACKUPds1_3.crf drwxrwxr-x 3 user users 1024 Apr 7 15:02 .. -rw-rw-r-- 1 user users 7085 Apr 7 15:06 BACKUPds1.if -rw-rw-r-- 1 user users 18 Apr 7 15:07 BACKUPds1_4.drf -rw-rw-r-- 1 user users 1070 Apr 7 15:07 BACKUPds1_4.crf drwxrwxr-x 2 user users 512 Apr 7 15:07 . bash-2.05$ gfsh gfsh>validate offline-disk-store --name=ds1 --disk-dirs=backupDirectory /root: entryCount=6 /partitioned_region entryCount=1 bucketCount=10 Disk store contains 12 compactable records. Total number of region entries in this disk store is: 7 gfsh>compact offline-disk-store --name=ds1 --disk-dirs=backupDirectory Offline compaction removed 12 records. Total number of region entries in this disk store is: 7 gfsh>exit bash-2.05$ ls -ltra backupDirectory total 16 -rw-rw-r-- 1 user users 3 Apr 7 14:56 BACKUPds1_3.drf -rw-rw-r-- 1 user users 25 Apr 7 14:56 BACKUPds1_3.crf drwxrwxr-x 3 user users 1024 Apr 7 15:02 .. -rw-rw-r-- 1 user users 0 Apr 7 15:08 BACKUPds1_5.drf -rw-rw-r-- 1 user users 638 Apr 7 15:08 BACKUPds1_5.crf -rw-rw-r-- 1 user users 2788 Apr 7 15:08 BACKUPds1.if drwxrwxr-x 2 user users 512 Apr 7 15:09 . bash-2.05$ 保持磁盘存储与缓存同步 当离线数据的配置与在线数据的配置匹配时，从脱机磁盘存储中恢复数据的速度最快。 每当您更改或删除持久区域时(通过修改cache.xml或配置区域的代码)，您应该更改相应的脱机磁盘存储以匹配。 如果不这样做，则下次恢复此磁盘存储时，它将使用旧配置将该区域的所有数据恢复到临时区域。 旧配置仍将使用旧配置的资源(堆内存，堆外内存)。 如果这些资源不再可用(例如，该区域的旧配置是堆外的，但您决定不再在JVM上配置堆外内存)，则磁盘存储恢复将失败。 通常的做法是拥有多个离线磁盘存储，因为集群的每个成员通常都有自己的副本。 确保将相同的alter disk-store命令应用于磁盘存储的每个脱机副本。 更改区域配置 磁盘存储脱机时，可以使用cache.xml和API设置使其区域的配置保持最新。 磁盘存储区保留区域配置属性的子集。 (有关保留属性的列表，请参阅alter disk-store)。 如果配置在启动时不匹配，cache.xml和API将覆盖任何磁盘存储设置，磁盘存储将自动更新以匹配。 因此，您无需修改磁盘存储以保持缓存配置和磁盘存储同步，但如果这样做，您将节省启动时间和内存。 例如，要更改磁盘存储中名为“partitioned_region”的区域的初始容量： gfsh>alter disk-store --name=myDiskStoreName --region=partitioned_region --disk-dirs=/firstDiskStoreDir,/secondDiskStoreDir,/thirdDiskStoreDir --initialCapacity=20 要列出区域的所有可修改设置及其当前值，请运行不指定任何操作的命令： gfsh>alter disk-store --name=myDiskStoreName --region=partitioned_region --disk-dirs=/firstDiskStoreDir,/secondDiskStoreDir,/thirdDiskStoreDir 从缓存配置和磁盘存储中取出一个区域 如果您决定重命名区域或将其数据拆分为两个完全不同的区域，则可以从应用程序中删除区域。 任何重要的数据重组都可能导致您退出某些数据区域。 这适用于磁盘存储脱机时删除区域。 您通过API调用或gfsh销毁的区域将自动从在线成员的磁盘存储中删除。 在应用程序开发中，当您停止使用持久区域时，也要从成员的磁盘存储区中删除该区域。 注意: 请谨慎执行以下操作。 您正在永久删除数据。 您可以通过以下两种方式之一从磁盘存储区中删除该区域： 删除整个磁盘存储文件集。 您的成员将在下次启动时使用一组空文件进行初始化。 从文件系统中删除文件时请务必小心，因为可以指定多个区域使用相同的磁盘存储目录。 使用以下命令从磁盘存储中选择性地删除已停止的区域： gfsh>alter disk-store --name=myDiskStoreName --region=partitioned_region --disk-dirs=/firstDiskStoreDir,/secondDiskStoreDir,/thirdDiskStoreDir --remove 为防止意外数据丢失，Geode会在磁盘存储区域中维护该区域，直到您手动删除它为止。 磁盘存储中与应用程序中的任何区域无关的区域仍会加载到内存中的临时区域，并在成员的生命周期内保留。 系统无法检测您的API是否会在某个时刻创建缓存区域，因此它可以保持临时区域的加载和可用。 配置磁盘可用空间监视 要修改disk-usage-warning-percentage和disk-usage-critical-percentage阈值，请在执行gfsh create disk-store命令时指定参数。 gfsh>create disk-store --name=serverOverflow --dir=c:\\overflow_data#20480 \\ --compaction-threshold=40 --auto-compact=false --allow-force-compaction=true \\ --max-oplog-size=512 --queue-size=10000 --time-interval=15 --write-buffer-size=65536 \\ --disk-usage-warning-percentage=80 --disk-usage-critical-percentage=98 默认情况下，磁盘使用率高于80％会触发警告消息。 磁盘使用率高于99％会生成错误并关闭访问该磁盘存储的成员缓存。 要禁用磁盘存储监视，请将参数设置为0。 要查看为现有磁盘存储设置的当前阈值，请使用gfsh describe disk-store命令： gfsh>describe disk-store --member=server1 --name=DiskStore1 您还可以使用以下DiskStoreMXBean方法API以编程方式配置和获取这些阈值。 getDiskUsageCriticalPercentage getDiskUsageWarningPercentage setDiskUsageCriticalPercentage setDiskUsageWarningPercentage 通过访问以下统计信息，可以获取磁盘空间使用情况和磁盘空间监视性能的统计信息： diskSpace maximumSpace volumeSize volumeFreeSpace volumeFreeSpaceChecks volumeFreeSpaceTime 请参阅磁盘空间使用情况(DiskDirStatistics). 处理丢失的磁盘存储 本节适用于为至少一个区域保存最新数据副本的磁盘存储。 显示缺少的磁盘存储 使用gfsh，show missing-disk-stores命令列出所有磁盘存储，其中包含其他成员正在等待的最新数据。 对于复制区域，此命令仅列出阻止其他成员启动的缺少成员。 对于分区区域，此命令还列出所有脱机数据存储，即使该区域的其他数据存储处于联机状态，因为它们的脱机状态可能导致缓存操作中的PartitionOfflineExceptions或阻止系统满足冗余。 例子: gfsh>show missing-disk-stores Disk Store ID | Host | Directory ------------------------------------ | --------- | ------------------------------------- 60399215-532b-406f-b81f-9b5bd8d1b55a | excalibur | /usr/local/gemfire/deploy/disk_store1 注意: 您需要在gfsh中连接到JMX Manager才能运行此命令。 注意: 为缺少的磁盘存储列出的磁盘存储目录可能不是您当前为该成员配置的目录。 该列表是从其他正在运行的成员中检索的 - 即报告缺失成员的成员。 它们具有上次丢失的磁盘存储在线时的信息。 如果移动文件并更改成员的配置，则这些目录位置将过时。 磁盘存储通常会丢失，因为它们的成员无法启动。 该成员可能由于多种原因而无法启动，包括： 磁盘存储文件损坏。 您可以通过验证磁盘存储来检查这一点。 成员的集群配置不正确 网络分区 驱动器故障 撤消丢失的磁盘存储 本节适用于满足以下两个条件的磁盘存储： 具有一个或多个区域或区域存储桶的最新数据副本的磁盘存储。 磁盘存储不可恢复，例如删除它们，或者文件已损坏或磁盘发生灾难性故障时。 如果无法在线提供最新的持久化副本，请使用revoke命令告知其他成员停止等待。 撤消存储后，系统会查找剩余的最新数据副本并使用该数据。 注意: 撤消后，磁盘存储无法重新引入系统。 使用gfsh show missing-disk-stores来正确识别需要撤销的磁盘存储。 revoke命令将磁盘存储区ID作为输入，由该命令列出。 例子: gfsh>revoke missing-disk-store --id=60399215-532b-406f-b81f-9b5bd8d1b55a Missing disk store successfully revoked 当缓冲区刷新到磁盘时更改 您可以将Geode配置为立即写入磁盘，您可以修改操作系统行为以更频繁地执行缓冲区刷新。 通常，Geode将磁盘数据写入操作系统的磁盘缓冲区，操作系统会定期将缓冲区刷新到磁盘。 增加写入磁盘的频率会降低应用程序或计算机崩溃导致数据丢失的可能性，但会影响性能。 您可以使用Geode的内存中数据备份的另一个选择是提供更好的性能。 通过将数据存储在多个复制区域或配置有冗余副本的分区区域中来执行此操作。 参见地区类型. 修改操作系统的磁盘刷新 您可以更改定期刷新的操作系统设置。 您还可以从应用程序代码执行显式磁盘刷新。 有关这些选项的信息，请参阅操作系统的文档。 例如，在Linux中，您可以通过修改设置/proc/sys/vm/dirty_expire_centiseconds来更改磁盘刷新间隔。 默认为30秒。 要更改此设置，请参阅dirty_expire_centiseconds的Linux文档。 在磁盘写入上修改Geode以刷新缓冲区 您可以让Geode在每次磁盘写入时刷新磁盘缓冲区。 通过在启动Geode成员时在命令行中将系统属性gemfire.syncWrites设置为true来执行此操作。 您只能在启动成员时修改此设置。 设置此项后，Geode使用带有标记“rwd”的Java“RandomAccessFile”，这会使每个文件更新同步写入存储设备。 如果您的磁盘存储位于本地设备上，则仅保证您的数据。 请参阅Java文档中的java.IO.RandomAccessFile。 要修改Geode应用程序的设置，请在启动成员时将其添加到java命令行： -Dgemfire.syncWrites=true 要修改缓存服务器的设置，请使用以下语法： gfsh>start server --name=... --J=-Dgemfire.syncWrites=true 为系统恢复和运营管理创建备份 备份是磁盘存储中持久数据的副本。 备份用于将磁盘存储还原到备份时的状态。 根据集群是联机还是脱机，相应的备份和还原过程会有所不同。 在线系统目前正在运行成员。 离线系统没有任何正在运行的成员。 系统在线时进行备份 What a Full Online Backup Saves What an Incremental Online Backup Saves Disk Store Backup Directory Structure and Contents Offline Members—Manual Catch-Up to an Online Backup Restore Using a Backup Made While the System Was Online 系统在线时进行备份 gfsh命令backup disk-store为集群中运行的所有成员创建磁盘存储的备份。 备份通过将命令传递给正在运行的系统成员来工作; 因此，成员需要在线才能使此操作成功。 具有持久数据的每个成员都会创建自己的配置和磁盘存储的备份。 备份不会阻止集群中的任何活动，但它确实使用资源。 注意: 请勿尝试使用操作系统的文件复制命令从正在运行的系统创建备份文件。 这将创建不完整且无法使用的副本。 准备备份 在进行备份之前，请考虑压缩磁盘存储。 如果关闭自动压缩，您可能需要进行手动压缩以节省备份通过网络复制的数据量。 有关配置手动压缩的更多信息，请参阅手动压缩. 在区域操作静止时进行备份，以避免区域数据与异步事件队列（AEQ）或WAN网关发送方（使用持久队列）之间出现不一致的可能性。 导致持久写入区域的区域操作涉及磁盘操作。 关联的队列操作也会导致磁盘操作。 这两个磁盘操作不是以原子方式进行的，因此如果在两个磁盘操作之间进行备份，则备份表示区域和队列中的数据不一致。 在系统中的低活动期间运行备份。 备份不会阻止系统活动，但它会在集群中的所有主机上使用文件系统资源，并且可能会影响性能。 通过修改成员的cache.xml文件，为每个成员配置要备份的任何其他文件或目录。 应该包含在备份中的其他项目： 应用程序jar文件 启动时应用程序需要的其他文件，例如设置类路径的文件 例如，要在备份中包含文件myExtraBackupStuff，数据存储的cache.xml文件规范将包括： ./myExtraBackupStuff 目录以递归方式复制，其中包含从此用户指定的备份中排除的任何磁盘存储。 备份到SAN（推荐）或所有成员都可以访问的目录。 确保该目录存在并具有所有成员写入目录和创建子目录的适当权限。 为备份指定的目录可以多次使用。 每次进行备份时，都会在指定目录中创建一个新子目录，该新子目录的名称代表日期和时间。 您可以使用以下两个位置之一进行备份： 单个物理位置，例如网络文件服务器，例如： /export/fileServerDirectory/gemfireBackupLocation 系统中所有主机的本地目录，例如： ./gemfireBackupLocation 确保所有具有持久数据的成员都在系统中运行，因为脱机成员无法备份其磁盘存储。 备份命令的输出不会识别托管已脱机的复制区域的成员。 如何进行完整的在线备份 如果禁用自动压缩，则需要手动压缩： gfsh>compact disk-store --name=Disk1 运行gfsh backup disk-store命令，指定备份目录位置。 例如： gfsh>backup disk-store --dir=/export/fileServerDirectory/gemfireBackupLocation 输出将列出已成功备份磁盘存储的每个成员的信息。 表格信息将包含成员的名称，其UUID，备份的目录以及成员的主机名。 任何未能完成备份的在线成员都会在其最高级别的备份目录中留下名为INCOMPLETE_BACKUP的文件。 此文件的存在标识备份文件仅包含部分备份，并且不能在还原操作中使用。 验证备份以供以后恢复使用。 在命令行上，可以使用诸如以下命令检查每个备份 cd 2010-04-10-11-35/straw_14871_53406_34322/diskstores/ds1 gfsh validate offline-disk-store --name=ds1 --disk-dirs=/home/dsmith/dir1 如何进行增量备份 增量备份包含自上次备份以来已更改的项目。 要执行增量备份，请使用--baseline-dir参数指定增量备份所基于的备份目录。 例如： gfsh>backup disk-store --dir=/export/fileServerDirectory/gemfireBackupLocation --baseline-dir=/export/fileServerDirectory/gemfireBackupLocation/2012-10-01-12-30 输出将与完整在线备份的输出相同。 任何未能完成增量备份的在线成员都会在其最高级别的备份目录中留下名为“INCOMPLETE_BACKUP”的文件。 此文件的存在标识备份文件仅包含部分备份，并且不能在还原操作中使用。 下次进行备份时，将进行完整备份。 什么是完整的在线备份保存 对于具有持久数据的每个成员，完整备份包括以下内容： 包含持久区域数据的所有成员的磁盘存储文件。 cache.xml配置文件中指定的文件和目录为元素。 例如： ./systemConfig/gf.jar /users/user/gfSystemInfo/myCustomerConfig.doc 使用gfsh deploy命令部署的已部署JAR文件。 成员启动时的配置文件。 gemfire.properties, 包括成员启动的属性。 cache.xml, 如果使用。 这些配置文件不会自动恢复，以避免干扰更新的配置。 特别是，如果从masterjar文件中提取这些文件，将单独的文件复制到工作区可以覆盖jar中的文件。 如果要备份和还原这些文件，请将它们添加为自定义元素。 一个还原脚本，在Windows上称为“restore.bat”，在Linux上称为“restore.sh”。 此脚本稍后可用于执行还原。 该脚本将文件复制回原始位置。 增量在线备份保存的内容 增量备份可以保存上次备份与当前数据之间的差异。 增量备份仅复制每个成员的基准目录中尚不存在的操作日志。 对于增量备份，还原脚本包含对一个或多个先前链接的增量备份中的操作日志的显式引用。 从增量备份运行还原脚本时，它还会还原作为备份链一部分的先前增量备份的操作日志。 如果基线目录中缺少成员，因为它们处于脱机状态或在基准备份时不存在，则这些成员会将其所有文件的完整备份放入增量备份目录中。 磁盘存储备份目录结构和内容 $ cd thebackupdir $ ls -R ./2012-10-18-13-44-53: dasmith_e6410_server1_8623_v1_33892 dasmith_e6410_server2_8940_v2_45565 ./2012-10-18-13-44-53/dasmith_e6410_server1_8623_v1_33892: config diskstores README.txt restore.sh user ./2012-10-18-13-44-53/dasmith_e6410_server1_8623_v1_33892/config: cache.xml ./2012-10-18-13-44-53/dasmith_e6410_server1_8623_v1_33892/diskstores: DEFAULT ./2012-10-18-13-44-53/dasmith_e6410_server1_8623_v1_33892/diskstores/DEFAULT: dir0 ./2012-10-18-13-44-53/dasmith_e6410_server1_8623_v1_33892/diskstores/DEFAULT/dir0: BACKUPDEFAULT_1.crf BACKUPDEFAULT_1.drf BACKUPDEFAULT.if ./2012-10-18-13-44-53/dasmith_e6410_server1_8623_v1_33892/user: 离线成员 - 手动追赶在线备份 如果在联机备份期间必须使成员脱机，则可以手动备份其磁盘存储。 手动将此成员的文件带入在线备份框架，并从另一个成员的脚本的副本开始手动创建还原脚本： 复制此成员的备份成员的目录结构。 根据需要重命名目录以反映此成员的特定备份，包括磁盘存储名称。 清除除还原脚本以外的所有文件。 复制此成员的文件。 修改还原脚本以适用于此成员。 使用系统在线时进行的备份还原 restore.sh或restore.bat脚本将文件复制回原始位置。 缓存成员脱机且系统关闭时，还原磁盘存储。 查看每个还原脚本以查看它们将文件放在何处并确保目标位置准备就绪。 还原脚本将拒绝复制具有相同名称的文件。 在发起备份的主机上运行每个还原脚本。 还原将这些文件复制回原始位置： 包含持久区域数据的所有商店的磁盘存储文件。 您已配置为在cache.xml`` 元素中备份的任何文件或目录。 缓存和区域快照 快照允许您保存区域数据并在以后重新加载。 典型的用例是将数据从一个环境加载到另一个环境，例如从生产系统捕获数据并将其移动到较小的QA或开发系统中。 实际上，您可以将数据从一个集群加载到另一个集群中。 管理员导出区域或整个缓存（多个区域）的快照，然后使用RegionSnapshotService或CacheSnapshotService接口以及Region.getSnapshotService或Cache.getSnapshotService方法将快照导入另一个区域或集群。 快照文件是一个二进制文件，包含来自特定区域的所有数据。 二进制格式包含序列化的键/值对，并支持PDX类型注册表以允许PDX数据的反序列化。 快照可以直接导入区域或逐个读取，以便进一步处理或转换为其他格式。 注意: 之前的Region.loadSnapshot和Region.saveSnapshot API已被弃用。 以此格式编写的数据与新API不兼容。 用法和性能说明 通过了解缓存和区域快照的执行方式来优化缓存和区域快照功能 导出缓存和区域快照 要将Geode缓存或区域数据保存到稍后可以加载到另一个集群或区域的快照，请使用cache.getSnapshotService.save API，region.getSnapshotService.save API或gfsh命令行界面 （导出数据）。 导入缓存和区域快照 要导入先前导出到另一个集群或区域的Geode缓存或区域数据快照，请使用cache.getSnapshotService.loadAPI，region.getSnapshotService.loadAPI或gfsh命令行界面（import data）。 导入或导出期间过滤条目 您可以通过在导入或导出区域或缓存期间过滤条目来自定义快照。 以编程方式读取快照 您可以逐个条目地读取快照，以便进一步处理或转换为其他格式。 用法和性能说明 通过了解缓存和区域快照的执行方式来优化缓存和区域快照功能 缓存一致性和并发操作 导入和导出区域数据是一种管理操作，某些同时运行时条件可能导致导入或导出操作失败，例如重新平衡分区区域存储桶或遇到网络分区事件时。 此行为是预期的，您应该重试该操作。 重做导出会覆盖不完整的快照文件，并重做导入会更新部分导入的数据。 快照功能不保证一致性。 快照导入或导出期间的并发缓存操作可能导致数据一致性问题。 如果快照一致性很重要，我们建议您在导出和导入之前使应用程序脱机，以提供安静的时间段以确保快照中的数据一致性。 例如，导出期间对区域条目的修改可能会导致快照包含一些但不是所有更新。 如果在导出期间条目{A，B}更新为{A'，B'}，则快照可以包含{A，B'}，具体取决于写入顺序。 此外，导入期间对区域条目的修改可能导致缓存中的更新丢失。 如果区域包含条目{A，B}且快照包含{A'，B'}，则在导入完成后，并发更新{A ，B }可能导致包含{A *，B'}的区域。 默认行为是在调用快照操作的节点上执行所有I/O操作。 如果该区域是分区区域，这将涉及通过网络收集或分散数据。 性能注意事项 使用数据快照功能时，请注意以下性能注意事项： 导入和导出缓存或区域快照会导致额外的CPU和网络负载。 您可能需要根据应用程序和基础结构增加CPU容量或网络带宽。 此外，如果导出已配置为溢出到磁盘的区域，则可能需要其他磁盘I/O才能执行导出。 导出分区区域数据时，请分配额外的堆内存，以便执行导出的成员可以缓冲从其他缓存成员收集的数据。 除了支持应用程序或缓存所需的任何配置外，还要为每个成员分配至少10MB的堆内存。 导出缓存和区域快照 要将Geode缓存或区域数据保存到稍后可以加载到另一个集群或区域的快照，请使用cache.getSnapshotService.save API，region.getSnapshotService.save API或gfsh命令行界面 (export data)。 如果在导出期间发生错误，则导出将暂停并取消快照操作。 暂停导出的典型错误包括完整磁盘，文件权限问题和网络分区等方案。 导出缓存快照 导出整个缓存时，它会将缓存中的所有区域作为单独的快照文件导出到目录中。 如果未指定目录，则默认为当前目录。 为每个区域创建快照文件，导出操作使用以下约定自动命名每个快照文件名： snapshot-[-]* 当导出操作写入快照文件名时，它会用短划线（' - '）替换区域路径中的每个正斜杠（'/'）。 使用 Java API: File mySnapshotDir = ... Cache cache = ... cache.getSnapshotService().save(mySnapshotDir, SnapshotFormat.GEMFIRE); 可选,您可以在导出期间在快照条目上设置过滤器。 有关示例，请参阅导入或导出期间的过滤条目。 导出区域快照 您还可以使用以下API或gfsh命令导出特定区域： Java API: File mySnapshot = ... Region region = ... region.getSnapshotService().save(mySnapshot, SnapshotFormat.GEMFIRE); gfsh: 打开gfsh提示符。 连接到Geode集群后，在提示符下键入： gfsh>export data --region=Region --file=FileName.gfd --member=MemberName 其中Region对应于要导出的区域的名称，FileName（必须以.gfd结尾）对应于导出文件的名称，MemberName对应于承载该区域的成员。 例如： gfsh>export data --region=region1 --file=region1_2012_10_10.gfd --member=server1 快照文件将写在远程成员上的--fileargument指定的位置。 例如，在上面的示例命令中，region1_2012_10_10.gfd文件将写在server1的工作目录中。 有关此命令的更多信息，请参阅导出数据. 使用选项导出示例 这些示例显示如何包含用于导出分区区域的parallel选项。 请注意，parallel选项采用目录而不是文件; 见export data for details. Java API: File mySnapshotDir = ... Region region = ... SnapshotOptions options = region.getSnapshotServive.createOptions().setParallelMode(true); region.getSnapshotService().save(mySnapshotDir, SnapshotFormat.GEMFIRE, options); gfsh: 上面的Java API示例实现了与以下gfsh命令相同的目的： gfsh>export data --parallel --region=region1 --dir=region1_2012_10_10 --member=server1 导入缓存和区域快照 要导入先前导出到另一个集群或区域的Geode缓存或区域数据快照，请使用cache.getSnapshotService.loadAPI，region.getSnapshotService.load API或gfsh命令行界面 (import data)。 导入要求 在导入区域快照之前： 确保正确配置了缓存。 配置所有已注册的PdxSerializers，DataSerializers和Instantiators; 创建区域; 并确保类路径包含任何必需的类。 导入包含PDX类型的快照时，必须等到导出的类型定义导入缓存之后才能插入导致类型冲突的数据。 建议您在插入数据之前等待导入完成。 导入限制 在导入期间，不会调用CacheWriter和CacheListener回调。 如果在导入期间发生错误，则导入将暂停，并且该区域将包含一些但不是所有快照数据。 导入后，缓存客户端的状态不确定。 客户端缓存中的数据可能与导入的数据不一致。 导入期间使客户端脱机，并在导入完成后重新启动它。 导入缓存快照 导入缓存快照时，快照文件将导入到快照导出期间使用的同一区域（由名称确定的匹配）。 导入缓存时，将位于目录中的所有快照文件导入缓存。 API尝试加载指定目录中的所有文件。 Java API: File mySnapshotDir = ... Cache cache = ... cache.getSnapshotService().load(mySnapshotDir, SnapshotFormat.GEMFIRE); 导入区域快照 Java API: File mySnapshot = ... Region region = ... region.getSnapshotService().load(mySnapshot, SnapshotFormat.GEMFIRE); gfsh: 打开gfsh提示符。 连接到Geode集群后，在提示符下键入： gfsh>import data --region=Region --file=FileName.gfd --member=MemberName 其中 Region 对应于要将数据导入的区域的名称; FileName （必须以.gfd结尾）对应于要导入的文件的名称; 和 MemberName 对应一个托管该区域的成员。 例如： gfsh>import data --region=region1 --file=region1_2012_10_10.gfd --member=server2 在导入之前，快照文件必须已驻留在--file参数中指定的位置的指定成员上。 有关此命令的更多信息，请参阅导入数据. 有关如何使用其他选项调用此命令的示例，请参阅使用选项导出示例. 导入或导出期间过滤条目 您可以通过在导入或导出区域或缓存期间过滤条目来自定义快照。 例如，使用过滤器将数据导出限制到特定日期范围。 如果在导入或导出缓存时设置过滤器，则过滤器将应用于缓存中的每个区域。 以下示例按偶数键过滤快照数据。 File mySnapshot = ... Region region = ... SnapshotFilter even = new SnapshotFilter() { @Override public boolean accept(Entry entry) { return entry.getKey() % 2 == 0; } }; RegionSnapshotService snapsrv = region.getSnapshotService(); SnapshotOptions options = snapsrv.createOptions().setFilter(even); // only save cache entries with an even key snapsrv.save(mySnapshot, SnapshotFormat.GEMFIRE, options); 以编程方式读取快照 您可以逐个条目地读取快照，以便进一步处理或转换为其他格式。 以下是处理先前生成的快照文件中的条目的快照阅读器的示例。 File mySnapshot = ... SnapshotIterator iter = SnapshotReader.read(mySnapshot); try { while (iter.hasNext()) { Entry entry = iter.next(); String key = entry.getKey(); MyObject value = entry.getValue(); System.out.println(key + \" = \" + value); } } finally { iter.close(); } 区域压缩 本节介绍区域压缩，其优点和用法。 减少Geode内存消耗的一种方法是在您的区域中启用压缩。 Geode允许您使用可插拔压缩器（压缩编解码器）压缩内存中的区域值。 Geode包含Snappy压缩器作为内置压缩编解码器; 但是，您可以为每个压缩区域实现和指定不同的压缩器。 怎样得到压缩 在区域中启用压缩时，存储在该区域中的所有值都将在内存中进行压缩。 密钥和索引不会被压缩。 放入内存高速缓存时会压缩新值，并在从高速缓存读取时解压缩所有值。 持久化到磁盘时不会压缩值。 在通过线路发送给其他对等成员或客户端之前，将对值进行解压缩。 启用压缩后，将压缩区域中的每个值，并将每个区域条目压缩为单个单元。 无法压缩条目的各个字段。 您可以在同一缓存中混合使用压缩区域和非压缩区域。 使用压缩的指南 本主题描述在决定是否使用压缩时要考虑的因素。 如何在区域中启用压缩 本主题介绍如何在您所在的区域启用压缩。 使用压缩器 使用区域压缩时，您可以使用Geode附带的默认Snappy压缩器，也可以指定自己的压缩器。 压缩和非压缩区域的性能比较 压缩区域与非压缩区域的比较性能可以根据区域的使用方式以及区域是否托管在内存绑定的JVM中而变化。 使用压缩的指南 本主题描述在决定是否使用压缩时要考虑的因素。 在决定是否在您所在的地区启用压缩时，请查看以下准则： 当JVM内存使用率过高时使用压缩. 压缩允许您在内存中存储更多区域数据，并减少昂贵的垃圾收集周期数，以防止JVM在内存使用率较高时耗尽内存。 要确定JVM内存使用率是否很高，请检查以下统计信息： vmStats>freeMemory vmStats->maxMemory ConcurrentMarkSweep->collectionTime 如果可用内存量经常降至20％-25％以下或者垃圾收集周期的持续时间通常偏高，那么托管在该JVM上的区域是启用压缩的良好候选者。 考虑区域条目中字段的类型和长度. 由于压缩是分别对每个条目执行的（而不是整个区域），因此请考虑单个条目中重复数据的可能性。 重复的字节更容易压缩。 此外，由于区域条目在被压缩之前首先被序列化为字节区域，因此数据可能压缩的程度取决于整个条目中的重复字节的数量和长度，而不仅仅是单个字段。 最后，条目越大，压缩越有可能获得良好的结果，因为重复字节和一系列重复字节的可能性增加。 考虑您要压缩的数据类型. 存储的数据类型对数据压缩的程度有很大影响。 字符串数据通常比数字数据压缩得更好，因为字符串字节更有可能重复; 然而，情况可能并非总是如此。 例如，包含两个短的唯一字符串的区域条目在压缩时可能无法提供与另一个包含大量整数值的区域条目相同的内存节省。 简而言之，在评估压缩区域的潜在收益时，请考虑单个序列化区域条目具有重复字节的可能性，更重要的是一系列重复字节的长度。 此外，已经压缩的数据（例如JPEG格式文件）实际上可以使用更多内存。 如果要存储大文本值，请压缩. 如果要在Geode中存储大型文本值（如JSON或XML）或Blob，压缩将受益于压缩，这将是有益的。 考虑被查询的字段是否已编入索引. 您可以查询压缩区域; 但是，如果您要查询的字段尚未编入索引，则必须先解压缩字段，然后才能将其用于比较。 简而言之，在查询非索引字段时，可能会产生一些查询性能成本。 存储在压缩区域中的对象必须是可序列化的. 压缩仅对字节数组进行操作，因此存储在压缩区域中的对象必须是可序列化和可反序列化的。 对象可以实现Serializable接口，也可以使用其他Geode序列化机制（例如PdxSerializable）。 实施者应始终注意，当启用压缩时，放入区域的对象实例在取出时将不是同一个实例。 因此，当将包含对象放入区域并从区域中取出时，瞬态属性将失去其值。 压缩区域将默认启用克隆. 设置压缩器然后禁用克隆会导致异常。 这些选项是不兼容的，因为压缩/序列化然后解压缩/反序列化的过程将导致创建的对象的不同实例，并且可能被解释为克隆该对象。 如何在区域中启用压缩 本主题介绍如何在您所在的区域启用压缩。 要在您的区域上启用压缩，请在cache.xml中设置以下region属性： org.apache.geode.compression.SnappyCompressor ... 在Compressor元素中，指定压缩器实现的类名。 此示例指定与Geode捆绑在一起的Snappy压缩器。 您还可以指定自定义压缩器。 有关示例，请参阅使用压缩器。 可以在使用gfsh创建区域期间或以编程方式启用压缩。 使用 gfsh: gfsh>create-region --name=”CompressedRegion” --compressor=”org.apache.geode.compression.SnappyCompressor”; API: regionFactory.setCompressor(new SnappyCompressor()); 或者 regionFactory.setCompressor(SnappyCompressor.getDefaultInstance()); 如何检查压缩是否已启用 您还可以通过查询正在使用的编解码器来检查区域是否已启用压缩。 空编解码器表示没有为该区域启用压缩。 Region myRegion = cache.getRegion(\"myRegion\"); Compressor compressor = myRegion.getAttributes().getCompressor(); 使用压缩器 使用区域压缩时，您可以使用Geode附带的默认Snappy压缩器，也可以指定自己的压缩器。 压缩API由压缩提供程序必须实现的单个接口组成。 默认压缩器（SnappyCompressor）是与产品捆绑在一起的单个压缩实现。 请注意，由于Compressor是无状态的，因此任何JVM中只需要一个实例; 但是，可以毫无问题地使用多个实例。 可以使用SnappyCompressor.getDefaultInstance()静态方法检索SnappyCompressor的单个默认实例。 注意: Geode附带的Snappy编解码器不能与Solaris部署一起使用。 Snappy仅支持Geode的Linux，Windows和macOS部署。 此示例提供自定义Compressor实现： package com.mybiz.myproduct.compression; import org.apache.geode.compression.Compressor; public class LZWCompressor implements Compressor { private final LZWCodec lzwCodec = new LZWCodec(); @Override public byte[] compress(byte[] input) { return lzwCodec.compress(input); } @Override public byte[] decompress(byte[] input) { return lzwCodec.decompress(input); } } 要在区域上使用新的自定义压缩器： 确保新压缩程序包在将承载该区域的所有JVM的类路径中可用。 使用以下任一机制为该区域配置自定义压缩器： 使用 gfsh: gfsh>create-region --name=”CompressedRegion” \\ --compressor=”com.mybiz.myproduct.compression.LZWCompressor” 使用 API: 例如: regionFactory.setCompressor(new LZWCompressor()); cache.xml: com.mybiz.myproduct.compression.LZWCompressor 更改已压缩区域的压缩器 您通常在创建区域时在区域上启用压缩。 在区域联机时，您无法修改Compressor或禁用该区域的压缩。 但是，如果需要更改压缩器或禁用压缩，可以通过执行以下步骤来执行此操作： 关闭托管您要修改的区域的成员。 修改成员的cache.xml文件，指定新压缩器或从区域中删除压缩器属性。 重启成员。 压缩和非压缩区域的性能比较 压缩区域与非压缩区域的比较性能可以根据区域的使用方式以及区域是否托管在内存绑定的JVM中而变化。 在考虑启用压缩的成本时，您应该考虑读取和写入压缩数据的相对成本以及压缩成本占管理区域中条目的总时间的百分比。 作为一般规则，在区域上启用压缩将为区域创建和更新操作增加30％ - 60％的开销，而不是区域获取操作。 因此，启用压缩会对写入较重的区域产生比读取较重的区域更多的开销。 但是，在尝试评估启用压缩的性能成本时，还应考虑压缩成本相对于管理区域中条目的总成本。 可以以这样的方式调整区域，使得其针对读取和/或写入性能进行高度优化。 例如，未保存到磁盘的复制区域将具有比保存到磁盘的分区区域更好的读写性能。 对已针对读取和写入性能进行了优化的区域启用压缩将比使用未以此方式优化的区域上的压缩提供更明显的结果。 更具体地，在读/写优化区域上性能可能降低几百％，而在非优化区域上它可能仅降低5％到10％。 有关性能的最终说明与在内存绑定JVM中对区域启用压缩时的成本有关。 启用压缩通常假定封闭的JVM受内存限制，因此花费大量时间进行垃圾回收。 在这种情况下，性能可以提高几百％，因为JVM将运行更少的垃圾收集周期并且在运行周期时花费更少的时间。 监控压缩性能 以下统计信息提供对缓存压缩的监视： compressTime decompressTime compressions decompressions preCompressedBytes postCompressedBytes 请参阅缓存性能(CachePerfStats) 用于统计描述。 网络分区 Apache Geode体系结构和管理功能有助于检测和解决网络分区问题。 网络分区管理的工作原理 Geode通过使用加权系统来确定剩余的可用成员是否具有足够的仲裁以继续作为集群来处理网络中断。 故障检测和成员资格视图 Geode使用故障检测从成员资格视图中删除无响应的成员。 成员协调员，主要成员和成员加权 网络分区检测使用指定的成员资格协调器和加权系统来计算潜在客户成员以确定是否发生了网络分区。 网络分区方案 本主题描述网络分区方案以及集群的分区端发生的情况。 配置Apache Geode处理网络分区 本节列出了网络分区检测的配置步骤。 防止网络分区 本节提供了可以阻止网络分区发生的简短列表。 网络分区管理的工作原理 Geode通过使用加权系统来确定剩余的可用成员是否具有足够的仲裁以继续作为集群来处理网络中断。 为每个成员分配权重，并通过将当前响应成员的总权重与响应成员的先前总权重进行比较来确定法定人数。 当成员无法相互查看时，您的集群可以拆分为单独的运行系统。 此问题的典型原因是网络故障。 检测到分区系统时，只有系统的一侧保持运行，另一侧自动关闭。 默认情况下，网络分区检测功能启用，其中enable-network-partition-detection属性为true。 有关详细信息，请参阅配置Apache Geode以处理网络分区。 无论此配置设置如何，始终执行和记录仲裁权重计算。 检测网络分区的整个过程如下： 集群启动。 启动集群时，首先启动定位器，然后启动缓存服务器，然后启动其他成员，例如访问集群数据的应用程序或进程。 成员启动后，最老的成员（通常是定位器）承担成员协调员的角色。 成员出现时会发生对等发现，成员会为集群生成成员资格发现列表。 当每个成员进程启动时，定位器分发成员资格发现列表。 此列表通常包含有关当前成员协调员的提示。 成员加入并在必要时离开集群： 成员进程向协调器发出加入集群的请求。 如果经过身份验证，协调员将创建新的成员资格视图，将新成员资格视图交给新成员，并通过向现有成员发送视图准备消息开始发送新成员资格视图（添加新成员）的过程 在视图中。 当成员加入系统时，成员可能也会通过正常的故障检测过程离开或被移除。 故障检测会删除无响应或缓慢的成员。 请参阅管理慢速接收器和故障检测和成员资格视图，用于描述故障检测过程。 如果发出包含一个或多个失败进程的新成员资格视图，协调器将记录新的权重计算。 在任何时候，如果由于无响应的进程而检测到仲裁丢失，协调器还将记录严重级别的消息以识别失败的进程： Possible loss of quorum detected due to loss of {0} cache processes: {1} 其中{0}是失败的进程数，{1}列出进程。 每当协调器收到成员变更的警报（成员加入或离开集群）时，协调器就会生成新的成员资格视图。 成员资格视图由两阶段协议生成： 在第一阶段，成员协调员向所有成员发送视图准备消息，并等待12秒，以获得来自每个成员的视图准备确认消息。 如果协调器在12秒内未收到来自成员的ack消息，则协调器会尝试连接到该成员的故障检测套接字。 如果协调器无法连接到成员的故障检测套接字，则协调器会声明该成员已死，并从头开始再次启动成员资格视图协议。 在第二阶段，协调器将新的成员资格视图发送给承认视图准备消息或通过连接测试的所有成员。 每次成员协调员发送视图时，每个成员都会计算当前成员资格视图中成员的总权重，并将其与先前成员资格视图的总权重进行比较。 一些条件需要注意： 当第一个成员资格视图发出时，没有累积的损失。 第一个视图只有附加内容。 如果新协调员没有看到前一个（失败的）协调员发送的最后一个成员资格视图，则可能会有一个陈旧的成员资格视图。 如果在该失败期间添加了新成员，则在发送第一个新视图时可能会忽略新成员。 如果在故障转移期间将成员移除给新协调员，那么新协调员将必须在视图准备步骤中确定这些损失。 使用默认值enable-network-partition-detection，在单个成员资格视图更改（丢失仲裁）中检测到总成员资格权重降至51％以下的任何成员都会声明网络分区事件。 协调器向所有成员（甚至是非响应成员）发送网络分区检测到的UDP消息，然后使用ForcedDisconnectException关闭集群。 如果成员在协调器关闭系统之前未能收到消息，则该成员负责自行检测事件。 假设在声明网络分区时，构成仲裁的成员将继续操作。 幸存的成员选出新的协调员，指定一名主要成员，等等。 故障检测和成员资格视图 Geode使用故障检测从成员资格视图中删除无响应的成员。 故障检测 网络分区具有故障检测协议，当NIC或计算机发生故障时，该协议不会挂起。 故障检测使每个成员在成员资格视图中观察来自对等体的消息（参见下面的“成员资格视图”视图布局）。 怀疑其对等方失败的成员向可疑成员发送数据报心跳请求。 在没有来自可疑成员的回复的情况下，可疑成员向所有其他成员广播SuspectMembersMessage数据报消息。 协调器尝试连接到可疑成员。 如果连接尝试失败，则会从成员资格视图中删除可疑成员。 将向可疑成员发送消息以断开与集群的连接并关闭缓存。 在收到SuspectMembersMessage的同时，如果协调者是可疑成员，则分布式算法会促使视图中最左边的成员充当协调者。 如果在收到对消息的响应之前经过gemfire.properties ack-wait-threshold，如果无法对该成员进行TCP/IP连接，则对成员也会启动故障检测处理 （P2P）消息传递，如果没有从该成员检测到其他流量。 注意: TCP连接ping不用于连接保持活动目的; 它仅用于检测失败的成员。 有关TCP保持活动配置，请参阅TCP/IP KeepAlive配置。 如果发送包含一个或多个失败成员的新成员资格视图，协调员将记录新的仲裁权重计算。 在任何时候，如果由于无响应进程而检测到仲裁丢失，协调器还将记录严重级别的消息以识别失败的成员：pre由于{0}缓存进程丢失而检测到的仲裁可能丢失：{1} 其中{0}是失败的进程数，{1}列出成员（缓存进程）。 成员视图 以下是示例成员资格视图： [info 2012/01/06 11:44:08.164 PST bridgegemfire1 tid=0x1f] Membership: received new view [ent(5767):8700|16] [ent(5767):8700/44876, ent(5829):48034/55334, ent(5875):4738/54595, ent(5822):49380/39564, ent(8788):24136/53525] 成员资格视图的组件如下： 视图的第一部分 ( [ent(5767):8700|16] 在上面的例子中) 对应于视图ID。 它确定： 上面例子中的成员协调员的地址和processId- ent（5767）。 在上面的例子中，成员首次出现在 - 中的成员资格视图的视图号（）。 上例中的成员协调员 - 8700的成员端口。 上面例子中的view-number-16 视图的第二部分列出了当前视图中的所有成员进程。[ent(5767):8700/44876, ent(5829):48034/55334, ent(5875):4738/54595, ent(5822):49380/39564, ent(8788):24136/53525],在上面的例子中。 每个列出的成员的总体格式为：Address(processId):membership-port/distribution port。 成员协调员几乎总是视图中的第一个成员，其余的按年龄排序。 membership -port是用于发送数据报的JGroups TCP UDP端口。 分发端口是用于缓存消息传递的TCP / IP端口。 每个成员都会观察其成员的右侧以进行故障检测。 成员协调员，主要成员和成员加权 网络分区检测使用指定的成员资格协调器和加权系统来计算潜在客户成员以确定是否发生了网络分区。 成员协调员和主要成员 成员协调员是管理集群中其他成员的进入和退出的成员。 启用网络分区检测后，协调器可以是任何Geode成员，但首选定位器。 在基于定位器的系统中，如果所有定位器都处于重新连接状态，则系统继续运行，但在成功重新连接定位器之前，新成员无法加入。 定位器重新连接后，重新连接的定位器将接管协调器的角色。 当协调器关闭时，它会发出一个视图，将其从列表中删除，其他成员必须确定新协调器是谁。 主要成员由协调员确定。 任何已启用网络分区检测的成员，不托管定位器，并且不是管理员界面，只有成员才有资格被协调员指定为主要成员。 协调员选择符合标准的最长寿命成员。 主要成员角色的目的是提供额外的重量。 它不执行任何特定功能。 成员加权系统 默认情况下，为各个成员分配以下权重： 除lead成员外，每个成员的权重为10。 lead成员的权重为15。 定位器的重量为3。 您可以通过在启动时定义gemfire.member-weight系统属性来修改特定成员的默认权重。 将视图改变之前的成员的权重加在一起并与丢失的成员的权重进行比较。 丢失的成员被视为在最后一个视图和完成的视图准备消息发送之间被删除的成员。 如果在单个成员资格视图更改中成员资格减少了一定百分比，则会声明网络分区。 损失百分比阈值为51（表示51％）。 请注意，百分比计算使用标准舍入。 因此，值50.51舍入为51.如果舍入损失百分比等于或大于51％，则成员协调员启动关闭。 样本成员权重计算 本节提供了一些示例计算。 例子 1: 集群有12个成员。 2个定位器，10个缓存服务器（一个缓存服务器被指定为主要成员。）查看总权重等于111。 4个缓存服务器无法访问。 成员总权重减少40（36％）。 由于36％低于51％的损失阈值，因此集群保持不变。 1个定位器和4个缓存服务器（包括主要成员）变得无法访问。 成员减重等于48（43％）。 由于43％低于51％的损失阈值，因此集群保持不变。 5个缓存服务器（不包括主要成员），两个定位器都无法访问。 成员减重等于56（49％）。 由于49％低于51％的损失阈值，因此集群保持不变。 5个缓存服务器（包括主要成员）和1个定位器变得无法访问。 成员减重等于58（52％）。 由于52％大于51％阈值，协调器启动关闭。 6个缓存服务器（不包括主要成员），两个定位器都无法访问。 成员减重等于66（59％）。 由于59％大于51％阈值，因此新选出的协调器（缓存服务器，因为没有定位器保留）将启动关闭。 例子 2: 集群有4个成员。 2个缓存服务器（1个缓存服务器被指定为主要成员），2个定位器。 查看总权重是31。 指定为主要成员的缓存服务器变得无法访问。 成员减重等于15或48％。 集群保持工作状态。 指定为主要成员的缓存服务器和1个定位器变得无法访问。 成员减重等于18或58％。 成员协调员启动关闭。 如果无法访问的定位器是成员协调器，则另一个定位器被选为协调器，然后启动关闭。 即使未启用网络分区，如果由于无响应进程而检测到仲裁丢失，定位器也会记录严重级别的消息以识别失败的进程：pre由于{0}缓存进程丢失而检测到的仲裁可能丢失：{1} 其中{0}是失败的进程数，{1}列出进程。 启用网络分区检测只允许一个子组在拆分后继续存在。 系统的其余部分已断开连接，缓存已关闭。 发生关闭时，关闭的成员将记录以下警报消息：由于{0}缓存进程丢失导致可能的网络分区事件导致退出：{1} 其中{0}是丢失成员的计数，{1}是丢失的成员ID列表。 网络分区方案 本主题描述网络分区方案以及集群的分区端发生的情况。 失败的一面是什么 在网络分区方案中，“丢失方”构成了集群分区，其中成员协调器检测到成员的法定人数不足以继续。 成员协调员在发出其视图准备消息后计算成员权重变化。 如果在视图准备阶段之后没有剩余法定数量的成员，则“丢失方”上的协调器声明网络分区事件，并向成员发送检测到网络分区的UDP消息。 然后协调器使用ForcedDisconnectException关闭其集群。 如果成员在协调器关闭连接之前未能收到消息，则它负责自行检测事件。 当丢失方发现网络分区事件已经发生时，所有对等成员都会收到RegionDestroyedException并带有Operation：FORCED_DISCONNECT。 如果安装了CacheListener，则使用RegionDestroyedEvent调用afterRegionDestroy回调，如此示例所示，由丢失方的回调记录。 对等成员进程ID是14291（主要成员）和14296，定位器是14289。 [info 2008/05/01 11:14:51.853 PDT tid=0x4a] Invoked splitBrain.SBListener: afterRegionDestroy in client1 whereIWasRegistered: 14291 event.isReinitializing(): false event.getDistributedMember(): thor(14291):40440/34132 event.getCallbackArgument(): null event.getRegion(): /TestRegion event.isOriginRemote(): false Operation: FORCED_DISCONNECT Operation.isDistributed(): false Operation.isExpiration(): false 仍然在缓存上主动执行操作的成员可能会看到ShutdownExceptions或CacheClosedExceptions withCustsed by：ForcedDisconnectException。 孤立的成员做了什么 当成员与所有定位器隔离时，它无法接收成员资格视图更改。 它无法知道当前协调员是否存在，或者如果已经离开，是否有其他成员可以接管该角色。 在这种情况下，成员最终将检测到所有其他成员的丢失，并将使用损失阈值来确定是否应该自行关闭。 对于具有2个定位器和2个高速缓存服务器的集群，与非高速缓存服务器和两个定位器的通信丢失将导致这种情况，并且剩余的高速缓存服务器最终会自行关闭。 配置Apache Geode处理网络分区 本节列出了与网络分区检测相关的配置注意事项。 系统使用成员协调员和指定为主要成员的系统成员的组合来检测和解决网络分区问题。 网络分区检测适用于所有环境。 使用多个定位器可以减轻网络分区的影响。 请参阅配置点对点发现. 默认情况下启用网络分区检测。 gemfire.properties文件中的默认设置是 enable-network-partition-detection=true 未启用网络分区检测的进程不能成为主要成员，因此它们的失败不会触发网络分区的声明。 所有系统成员都应具有相同的enable-network-partition-detection设置。 如果他们不这样做，系统会在启动时抛出GemFireConfigException。 如果使用分区或持久区域，则enable-network-partition-detection属性必须为true。 如果您创建一个持久区域并且enable-network-partition-detection设置为false，您将收到以下警告消息： Creating persistent region {0}, but enable-network-partition-detection is set to false. Running with network partition detection disabled can lead to an unrecoverable system in the event of a network split.\" 使用范围设置为DISTRIBUTED_ACK或GLOBAL配置要防止网络分区的区域。 不要使用DISTRIBUTED_NO_ACK范围。 这可以防止在检测到网络分区之前在整个集群中执行操作。 注意：如果在启用网络分区检测时检测到DISTRIBUTED_NO_ACK区域，则Geode会发出警报： Region {0} is being created with scope {1} but enable-network-partition-detection is enabled in the distributed system. This can lead to cache inconsistencies if there is a network failure. 这些其他配置参数会影响网络分区检测或与之交互。 检查它们是否适合您的安装并根据需要进行修改。 如果启用了网络分区检测，则允许的成员资格权重丢失的阈值百分比值将自动配置为51.您无法修改此值。 注意：减重计算使用舍入到最近。 因此，值50.51舍入为51并将导致网络分区。 如果成员的ack-wait-threshold（默认为15秒）和ack-severe-alert-threshold（15秒）属性在接收到对消息的响应之前已经过了，则启动故障检测。 如果修改ack-wait-threshold配置值，则应修改ack-severe-alert-threshold以匹配其他配置值。 如果系统有客户端连接到它，客户端的'cache.xml池read-timeout应该设置为服务器的gemfire.properties文件中member-timeout`设置的至少三倍。 默认池“read-timeout”设置为10000毫秒。 您可以通过在启动时指定系统属性gemfire.member-weight来调整成员的默认权重。 例如，如果您有一些托管所需服务的虚拟机，则可以在启动时为其分配更高的权重。 默认情况下，由网络分区事件强制退出集群的成员将自动重新启动并尝试重新连接。 数据成员将尝试重新初始化缓存。 请参阅使用自动重新连接处理强制高速缓存断开连接. 防止网络分区 本节提供了可以阻止网络分区发生的简短列表。 要避免网络分区： 使用NIC组合实现冗余连接。 有关详细信息，请参阅http://www.cisco.com/en/US/docs/solutions/Enterprise/Data_Center/vmware/VMware.html#wp696452。 最好是所有服务器共享一个公共网络交换机。 具有多个网络交换机增加了发生网络分区的可能性。 如果必须使用多个交换机，则应尽可能使用冗余路由路径。 在多交换机配置中共享交换机的成员的权重将确定如果存在交换机间故障则哪个分区存活。 在Geode配置方面，考虑成员的权重。 例如，您可以为重要流程分配更高的权重。 安全 安全框架允许对集群的所有通信组件进行连接组件的身份验证和操作授权。 安全实施简介和概述 加密，SSL安全通信，身份验证和授权有助于保护集群。 安全细节考虑因素 本节在一个方便的位置收集离散的详细信息，以便更好地帮助您评估和配置环境的安全性。 使用属性定义启用安全性 认证 使用身份验证的集群禁止恶意对等方或客户端，并阻止对其缓存的无意访问。 授权 可以根据分配给客户端提交的凭据的角色和权限来限制或完全阻止缓存服务器上的客户端操作。 区域数据的后处理 SSL SSL可保护应用程序之间传输的数据。 安全实施简介和概述 安全功能 加密，SSL安全通信，身份验证和授权功能有助于保护集群。 安全功能包括： 所有组件的单一安全界面. 单一身份验证和授权机制简化了安全性实施。 它以一致的方式查看所有组件并与之交互。 全系统基于角色的访问控制. 角色团授权各个组件要求的操作。 SSL通信. 允许配置连接是基于SSL的，而不是普通的套接字连接。 您可以分别为对等，客户端，JMX，网关发件人和接收者以及HTTP连接启用SSL。 区域数据的后处理. 可以格式化返回区域值的操作的返回值。 概览 身份验证和授权机制构成了集群内部安全的核心。 通过为传输中的数据启用SSL，可以进一步保护通信。 身份验证可验证通信组件的身份，从而控制参与。 参与者的种类包括对等成员，服务器，客户端，JMX操作的发起者，Pulse，代表系统WAN成员的网关发送者和接收者，以及代表系统用户或管理员从gfsh到达的命令。 连接请求会触发身份验证回调的调用。 这个特殊用途的回调是作为应用程序的一部分编写的，它试图通过它选择的任何算法来验证请求者。 结果是返回的主体表示请求者的身份验证身份，或者是指示请求者未经过身份验证的异常。 委托人成为经营授权程序的任何操作请求的一部分。 鉴于身份验证，可以通过实现授权机制来进一步保护对缓存数据和系统状态的隔离和访问，该授权机制也作为应用程序的一部分实现为专用回调。 例如，保护可能只允许某些系统管理员启动和停止服务器。 执行此操作的权限需要限于特定的已验证帐户，以防止未经授权的帐户。 授权回调的实现将要求认证身份伴随对系统的所有请求，并且系统维护允许哪些身份完成哪些动作或高速缓存命令的表示。 安全细节考虑因素 本节在一个方便的位置收集离散的详细信息，以便更好地帮助您评估和配置环境的安全性。 外部接口，端口和服务 Geode进程使用UDP或TCP/IP端口与其他进程或客户端进行通信。 必须受到保护的资源 某些Geode配置文件应该只能由运行服务器的专用用户读取和写入。 日志文件位置 默认情况下，日志文件位于启动相应进程时使用的工作目录中。 放置安全配置设置的位置 外部接口，端口和服务 Geode进程使用UDP或TCP/IP端口与其他进程或客户端进行通信。 例如: 成员可以使用多播与对等成员进行通信。 您可以在gemfire.properties文件中指定多播地址和多播端口，或者在使用gfsh启动成员时在命令行中指定参数。 客户端连接到定位器以发现缓存服务器。 JMX客户端（例如gfsh和JConsole）可以在预定义的RMI端口1099上连接到JMX Manager和其他可管理成员。如有必要，可以配置不同的端口。 每个网关接收器通常都有一个端口范围，用于监听传入的通信。 有关Geode使用的端口的完整列表，其默认值以及如何使用，请参阅防火墙和端口,如果您不想使用默认值，请配置它们。 Geode没有任何需要启用或打开的外部接口或服务。 必须受到保护的资源 这些配置文件应该只能由运行服务器的专用用户读取和写入： gemfire.properties cache.xml gfsecurity.properties defaultConfigs目录中没有提供默认的gfsecurity.properties。 如果选择使用此属性文件，则必须手动创建它。 明文用户名和关联的明文密码可以在此文件中以进行身份验证。 依赖文件系统的访问权限来保护这些敏感信息。 gemfire.properties和cache.xml配置文件的默认位置是主安装目录的defaultConfigs子目录。 日志文件位置 默认情况下，日志文件位于启动相应进程时使用的工作目录中。 对于Geode成员（定位器和缓存服务器），还可以在启动每个进程时指定自定义工作目录位置。 有关详细信息，请参阅Logging。 日志文件如下： locator-name.log: 包含定位器进程的日志记录信息。 server-name.log: 包含缓存服务器进程的日志记录信息。 gfsh-%u_%g.log: 包含单个gfsh环境和会话的日志记录信息。 注意: 默认情况下，禁用gfsh会话日志记录。 要启用gfsh日志记录，必须设置Java系统属性-Dgfsh. log-level=desired_log_level。 有关详细信息，请参阅配置gfsh环境。 这些日志文件应该只由运行服务器的专用用户读写。 放置安全配置设置的位置 通常在gemfire.properties中配置的任何与安全相关的（以security- *开头的属性）配置属性都可以移动到单独的gfsecurity.properties文件中。 将这些配置设置放在单独的文件中允许您限制对安全配置数据的访问。 这样，您仍然可以允许对gemfire.properties文件进行读或写访问。 启动时，Geode进程将按顺序在以下位置查找gfsecurity.properties文件： 当前的工作目录 用户的主目录 类路径 如果文件中列出了任何与密码相关的安全属性但具有空值，则该过程将提示用户在启动时输入密码。 使用属性定义启用安全性 安全管理器属性 使用security-manager属性指定实现SecurityManager接口的认证回调和授权回调。 定义此属性后，将启用身份验证和授权。 security-manager属性的定义是实现SecurityManager接口的类的完全限定名。 例如： security-manager = com.example.security.MySecurityManager 要确保在集群中一致地应用security-manager属性，请遵循以下准则： 在属性文件中指定security-manager属性，例如gemfire.properties，而不是在集群配置文件（例如cluster.properties）中。 启动集群的第一个定位器时指定属性文件。 定位器会将值传播到后面的所有成员（定位器和服务器）。 如果必须为服务器指定security-manager属性（既不必要也不建议），请确保其值与为第一个定位器指定的值完全相同。 系统的所有组件都会调用相同的回调。 以下是组件及其与系统建立的连接的描述。 客户端与服务器连接并发出该服务器的操作请求。 调用的回调是由该服务器的SecurityManager接口定义的回调。 服务器与定位器连接，调用为该定位器定义的authenticate回调。 与定位器的JMX管理器通信的组件连接并发出定位器的操作请求。 调用的回调是由该定位器的SecurityManager接口定义的回调。 gfsh和Pulse都使用这种形式的通信。 通过REST API进行通信的应用程序使服务器在连接和操作请求时调用安全回调。 请求网关发件人制作定位器会调用为该定位器定义的安全回调。 security-post-processor Property(安全后处理器属性) PostProcessor接口允许定义一组回调，这些回调在获取数据的操作之后但在返回数据之前调用。 这允许回调干预并格式化要返回的数据。 回调不会修改区域数据，只会修改要返回的数据。 通过定义“security-post-processor”属性以及接口定义的路径，启用数据的后处理。 例如， security-post-processor = com.example.security.MySecurityPostProcessing 认证 身份验证可验证集群中组件的身份，例如对等方，客户端以及连接到JMX管理器的组件。 实施身份验证 集群的所有组件都通过自定义编写的方法以相同的方式进行身份验证。 验证示例 该示例演示了SecurityManager.authenticate方法的实现的基础知识。 实施身份验证 身份验证通过在组件连接到系统时验证组件的身份，为集群提供一定程度的安全性。 所有组件都使用相同的身份验证机制 身份验证如何工作 当组件启动与集群的连接时，将调用SecurityManager.authenticate方法。 该组件以属性的形式提供其凭证作为authenticate方法的参数。 证书被认为是两个属性security-username和security-password。 期望authenticate方法返回表示委托人的对象或抛出AuthenticationFailedException。 精心设计的authenticate方法将具有一组已知的用户和密码对，可以与所提供的凭证进行比较，或者有一种获得这些对的方法。 服务器如何设置其凭据 为了与进行身份验证的定位器连接，服务器需要设置其凭据，由两个属性security-username和security-password组成。 有两种方法可以实现此目的： 在服务器的gfsecurity.properties文件中设置security-username和security-password，该文件将在服务器启动时读取，如示例中所示 security-username=admin security-password=xyz1234 用户名和密码以明文形式存储，因此必须通过限制具有文件系统权限的访问来保护gfsecurity.properties文件。 为服务器实现AuthInitialize接口的getCredentials方法。 此回调的位置在属性security-peer-auth-init中定义，如示例中所示 security-peer-auth-init=com.example.security.MyAuthInitialize 然后，getCredentials的实现可以以任何方式获取属性security-username和security-password的值。 它可能会在数据库或其他外部资源中查找值。 网关发件人和接收者作为其服务器成员的组件进行通信。 因此，服务器的凭证成为网关发送者或接收者的凭证。 缓存客户端如何设置其凭据 为了与定位器或进行身份验证的服务器连接，客户端需要设置其凭证，由两个属性security-username和security-password组成。 要做到这一点： 为客户端实现AuthInitialize接口的getCredentials方法。 此回调的位置在属性security-client-auth-init中定义，如示例中所示 security-client-auth-init=com.example.security.ClientAuthInitialize 然后，getCredentials的实现可以以任何方式获取属性security-username和security-password的值。 它可能会在数据库或其他外部资源中查找值，也可能会提示输入值。 其他组件如何设置其凭据 gfsh在调用gfsh connect命令时提示输入用户名和密码。 Pulse在启动时提示输入用户名和密码。 由于REST API的无状态特性，通过REST API与服务器或定位器通信的Web应用程序或其他组件将对每个请求进行身份验证。 请求的标头需要包含定义security-username和security-password值的属性。 实现SecurityManager接口 完成这些项目以实现定位器或服务器完成的身份验证。 确定身份验证算法。 验证示例存储一组用户名和密码对，表示将连接到的组件的标识。 系统。 如果传递给authenticate方法的用户名和密码与其中一个存储对匹配，则这种简单算法将用户名作为主体返回。 定义security-manager属性。 有关此属性的详细信息，请参阅使用属性定义启用安全性。 实现SecurityManager接口的authenticate方法。 定义实现的身份验证算法所需的任何额外资源，以便做出决策。 验证示例 此示例演示了SecurityManager.authenticate方法的实现的基础知识。 该示例的其余部分可以在geode-core/src/main/java/org/apache/geode/examples/security目录中的Apache Geode源代码中找到。 当然，每个安装的安全实现都是唯一的，因此这个示例不能在生产环境中使用。 在成功进行身份验证后，将用户名用作返回的主体是一种特别糟糕的设计选择，因为发现实现的任何攻击者都可能欺骗系统。 此示例假定在初始化时已将一组表示可成功通过身份验证的用户的用户名和密码对读入数据结构中。 为用户名提供正确密码的任何组件都会成功进行身份验证，并且其身份将作为该用户进行验证。 因此，authenticate方法的实现检查credentials参数中提供的用户名是否在其数据结构中。 如果存在用户名，则将credentials参数中提供的密码与该用户名的数据结构的已知密码进行比较。 匹配时，身份验证成功。 public Object authenticate(final Properties credentials) throws AuthenticationFailedException { String user = credentials.getProperty(ResourceConstants.USER_NAME); String password = credentials.getProperty(ResourceConstants.PASSWORD); User userObj = this.userNameToUser.get(user); if (userObj == null) { throw new AuthenticationFailedException( \"SampleSecurityManager: wrong username/password\"); } if (user != null && !userObj.password.equals(password) && !\"\".equals(user)) { throw new AuthenticationFailedException( \"SampleSecurityManager: wrong username/password\"); } return user; } 授权 可以根据为各种集群组件设置的已配置访问权限来限制，拦截和修改集群和缓存操作，或者完全阻止集群和缓存操作。 实施授权 要对客户端/服务器系统使用授权，必须由其服务器对客户端连接进行身份验证。 授权示例 本主题讨论使用XmlAuthorization.java，XmlErrorHandler.java和authz6_0.dtd在templates/security下的产品中提供的授权示例。 实施授权 授权如何运作 当组件请求操作时，将调用SecurityManager.authorize方法。 它传递了操作请求者的主体和ResourcePermission，它描述了所请求的操作。 SecurityManager.authorize方法的实现决定了是否授予委托人执行操作的权限。 它返回一个布尔值，其中返回值true允许操作，返回值false阻止操作。 精心设计的authorize方法将具有或将有一种方法来获取它们被允许做的操作（以资源许可的形式）的主体映射。 资源许可 所有操作都由ResourcePermission类的实例描述。 权限包含Resource数据成员，该成员将操作分类为是否正在进行操作 cache data; value is DATA the cluster; value is CLUSTER 权限还包含Operation数据成员，该成员将操作分类为 reading; value is READ changing information; value is WRITE making administrative changes; value is MANAGE 这些操作不是分层的; MANAGE并不意味着WRITE，而WRITE并不意味着READ。 一些DATA操作进一步指定了权限中的区域名称。 这允许将该区域的操作限制为仅限那些授权的主体。 在某个区域内，某些操作可能会指定密钥。 这允许将该区域内该密钥的操作限制为仅限那些授权的主体。 一些CLUSTER操作进一步为操作指定了更细粒度的目标。 使用字符串值指定目标： DISK 定位写入磁盘存储的操作 GATEWAY 定位管理网关发件人和接收者的操作 QUERY 定位管理索引和连续查询的操作 DEPLOY 定位将代码部署到服务器的操作 LUCENE 以Lucene索引操作为目标 此表对为客户端 - 服务器交互通用的操作分配的权限进行分类。 客户操作 分配ResourcePermission get function attribute CLUSTER:READ create region DATA:MANAGE destroy region DATA:MANAGE Region.Keyset DATA:READ:RegionName Region.query DATA:READ:RegionName Region.getAll DATA:READ:RegionName Region.getAll with a list of keys DATA:READ:RegionName:Key Region.getEntry DATA:READ:RegionName Region.containsKeyOnServer(key) DATA:READ:RegionName:Key Region.get(key) DATA:READ:RegionName:Key Region.registerInterest(key) DATA:READ:RegionName:Key Region.registerInterest(regex) DATA:READ:RegionName Region.unregisterInterest(key) DATA:READ:RegionName:Key Region.unregisterInterest(regex) DATA:READ:RegionName execute function Defaults to DATA:WRITE. Override Function.getRequiredPermissions to change the permission. clear region DATA:WRITE:RegionName Region.putAll DATA:WRITE:RegionName Region.clear DATA:WRITE:RegionName Region.removeAll DATA:WRITE:RegionName Region.destroy(key) DATA:WRITE:RegionName:Key Region.invalidate(key) DATA:WRITE:RegionName:Key Region.destroy(key) DATA:WRITE:RegionName:Key Region.put(key) DATA:WRITE:RegionName:Key Region.replace DATA:WRITE:RegionName:Key queryService.newCq DATA:READ:RegionName CqQuery.stop DATA:READ 此表对为gfsh操作分配的权限进行分类。 gfsh 命令 Assigned ResourcePermission alter disk-store CLUSTER:MANAGE:DISK alter region DATA:MANAGE:RegionName alter runtime CLUSTER:MANAGE backup disk-store DATA:READ and CLUSTER:WRITE:DISK change loglevel CLUSTER:WRITE clear defined indexes CLUSTER:MANAGE:QUERY close durable-client CLUSTER:MANAGE:QUERY close durable-cq CLUSTER:MANAGE:QUERY compact disk-store CLUSTER:MANAGE:DISK configure pdx CLUSTER:MANAGE create async-event-queue CLUSTER:MANAGE:DEPLOY, plus CLUSTER:WRITE:DISK if the associated region is persistent create defined indexes CLUSTER:MANAGE:QUERY create disk-store CLUSTER:MANAGE:DISK create gateway-receiver CLUSTER:MANAGE:GATEWAY create gateway-sender CLUSTER:MANAGE:GATEWAY create index CLUSTER:MANAGE:QUERY create jndi-binding CLUSTER:MANAGE create lucene index CLUSTER:MANAGE:LUCENE create region DATA:MANAGE, plus CLUSTER:WRITE:DISK if the associated region is persistent define index CLUSTER:MANAGE:QUERY deploy CLUSTER:MANAGE:DEPLOY describe client CLUSTER:READ describe config CLUSTER:READ describe disk-store CLUSTER:READ describe jndi-binding CLUSTER:READ describe lucene index CLUSTER:READ:LUCENE describe member CLUSTER:READ describe offline-disk-store CLUSTER:READ describe region CLUSTER:READ destroy disk-store CLUSTER:MANAGE:DISK destroy function CLUSTER:MANAGE:DEPLOY destroy index CLUSTER:MANAGE:QUERY destroy jndi-binding CLUSTER:MANAGE destroy lucene index CLUSTER:MANAGE:LUCENE destroy region DATA:MANAGE execute function Defaults to DATA:WRITE. Override Function.getRequiredPermissions to change the permission. export cluster-configuration CLUSTER:READ export config CLUSTER:READ export data CLUSTER:READ export logs CLUSTER:READ export offline-disk-store CLUSTER:READ export stack-traces CLUSTER:READ gc CLUSTER:MANAGE get ‑key=key1 ‑region=region1 DATA:READ:RegionName:Key import data DATA:WRITE:RegionName import cluster-configuration CLUSTER:MANAGE list async-event-queues CLUSTER:READ list clients CLUSTER:READ list deployed CLUSTER:READ list disk-stores CLUSTER:READ list durable-cqs CLUSTER:READ list functions CLUSTER:READ list gateways CLUSTER:READ list indexes CLUSTER:READ:QUERY list jndi-binding CLUSTER:READ list lucene indexes CLUSTER:READ:LUCENE list members CLUSTER:READ list regions CLUSTER:READ load-balance gateway-sender CLUSTER:MANAGE:GATEWAY locate entry DATA:READ:RegionName:Key netstat CLUSTER:READ pause gateway-sender CLUSTER:MANAGE:GATEWAY put –key=key1 –region=region1 DATA:WRITE:RegionName:Key query DATA:READ:RegionName rebalance DATA:MANAGE remove DATA:WRITE:RegionName or DATA:WRITE:RegionName:Key resume gateway-sender CLUSTER:MANAGE:GATEWAY revoke mising-disk-store CLUSTER:MANAGE:DISK search lucene DATA:READ:RegionName show dead-locks CLUSTER:READ show log CLUSTER:READ show metrics CLUSTER:READ show missing-disk-stores CLUSTER:READ show subscription-queue-size CLUSTER:READ shutdown CLUSTER:MANAGE start gateway-receiver CLUSTER:MANAGE:GATEWAY start gateway-sender CLUSTER:MANAGE:GATEWAY start server CLUSTER:MANAGE status cluster-config-service CLUSTER:READ status gateway-receiver CLUSTER:READ status gateway-sender CLUSTER:READ status locator CLUSTER:READ status server CLUSTER:READ stop gateway-receiver CLUSTER:MANAGE:GATEWAY stop gateway-receiver CLUSTER:MANAGE:GATEWAY stop locator CLUSTER:MANAGE stop server CLUSTER:MANAGE undeploy CLUSTER:MANAGE:DEPLOY gfsh connect没有权限，因为它是调用身份验证的操作。 这些gfsh命令没有定义权限，因为它们不与集群交互： gfsh describe connection, which describes the gfsh end of the connection gfsh debug, which toggles the mode within gfsh gfsh exit gfsh help gfsh hint gfsh history gfsh run, although individual commands within the script will go through authorization gfsh set variable gfsh sh gfsh sleep validate offline-disk-store gfsh version 此表对为JMX操作分配的权限进行分类。 JMX 操作 Assigned ResourcePermission DistributedSystemMXBean.shutdownAllMembers CLUSTER:MANAGE ManagerMXBean.start CLUSTER:MANAGE ManagerMXBean.stop CLUSTER:MANAGE ManagerMXBean.createManager CLUSTER:MANAGE ManagerMXBean.shutDownMember CLUSTER:MANAGE Mbeans get attributes CLUSTER:READ MemberMXBean.showLog CLUSTER:READ DistributedSystemMXBean.changerAlertLevel CLUSTER:WRITE ManagerMXBean.setPulseURL CLUSTER:WRITE ManagerMXBean.setStatusMessage CLUSTER:WRITE CacheServerMXBean.closeAllContinuousQuery CLUSTER:MANAGE:QUERY CacheServerMXBean.closeContinuousQuery CLUSTER:MANAGE:QUERY CacheServerMXBean.executeContinuousQuery DATA:READ CqQuery.execute DATA:READ:RegionName and CLUSTER:MANAGE:QUERY CqQuery.executeWithInitialResults DATA:READ:RegionName and CLUSTER:MANAGE:QUERY DiskStoreMXBean.flush CLUSTER:MANAGE:DISK DiskStoreMXBean.forceCompaction CLUSTER:MANAGE:DISK DiskStoreMXBean.forceRoll CLUSTER:MANAGE:DISK DiskStoreMXBean.setDiskUsageCriticalPercentage CLUSTER:MANAGE:DISK DiskStoreMXBean.setDiskUsageWarningPercentage CLUSTER:MANAGE:DISK DistributedSystemMXBean.revokeMissingDiskStores CLUSTER:MANAGE:DISK DistributedSystemMXBean.setQueryCollectionsDepth CLUSTER:MANAGE:QUERY DistributedSystemMXBean.setQueryResultSetLimit CLUSTER:MANAGE:QUERY DistributedSystemMXBean.backupAllMembers DATA:READ and CLUSTER:WRITE:DISK DistributedSystemMXBean.queryData DATA:READ DistributedSystemMXBean.queryDataForCompressedResult DATA:READ GatewayReceiverMXBean.pause CLUSTER:MANAGE:GATEWAY GatewayReceiverMXBean.rebalance CLUSTER:MANAGE:GATEWAY GatewayReceiverMXBean.resume CLUSTER:MANAGE:GATEWAY GatewayReceiverMXBean.start CLUSTER:MANAGE:GATEWAY GatewayReceiverMXBean.stop CLUSTER:MANAGE:GATEWAY GatewaySenderMXBean.pause CLUSTER:MANAGE:GATEWAY GatewaySenderMXBean.rebalance CLUSTER:MANAGE:GATEWAY GatewaySenderMXBean.resume CLUSTER:MANAGE:GATEWAY GatewaySenderMXBean.start CLUSTER:MANAGE:GATEWAY GatewaySenderMXBean.stop CLUSTER:MANAGE:GATEWAY LockServiceMXBean.becomeLockGrantor CLUSTER:MANAGE MemberMXBean.compactAllDiskStores CLUSTER:MANAGE:DISK 实施授权 完成这些项目以实现授权。 确定授权算法。 授权示例存储允许哪些主体（用户）执行哪些操作的映射。 该算法的决定基于查找授予尝试操作的主体的权限。 定义security-manager属性。 有关此属性的详细信息，请参阅使用属性定义启用安全性。 实现SecurityManager接口的authorize方法。 定义实现的授权算法所需的任何额外资源，以便做出决策。 功能执行的授权 默认情况下，在服务器上执行的函数要求调用该函数的实体对所涉及的区域具有DATA:WRITE权限。 由于默认权限可能不适合所有功能，因此可能会更改所需的权限。 要实现不同的权限集，请覆盖函数类中的Function.getRequiredPermissions()方法。 该方法应该返回调用函数执行的实体所需权限的集合。 从查询调用的方法的授权 启用SecurityManager会通过限制正在运行的查询可能调用的方法来影响查询。 有关详细信息，请参阅方法调用。 授权示例 此示例演示了SecurityManager.authorize方法的实现的基础知识。 该示例的其余部分可以在geode-core/src/main/java/org/apache/geode/examples/security目录中的Apache Geode源代码中找到。 当然，每个安装的安全实现都是唯一的，因此该示例不能在生产环境中使用，因为角色和权限将无法满足任何真实分布式系统的需求。 此示例假定在JSON格式文件中描述了一组用户，用户可能在系统中执行的一组角色以及用户到其角色的映射。 角色定义为这些角色中的用户授予的一组授权资源权限。 此处未显示的代码解析文件以使用有关角色和用户的信息组成数据结构。 authorize回调拒绝任何没有表示操作请求者身份的主体的操作的权限。 给定主体，该方法遍历数据结构，搜索主体的必要权限。 找到必要的权限后，通过返回值true来授予授权。 如果在数据结构中未找到权限，则该方法返回false，拒绝授权操作。 public boolean authorize(final Object principal, final ResourcePermission context) { if (principal == null) return false; User user = this.userNameToUser.get(principal.toString()); if (user == null) return false; // this user is not authorized to do anything // check if the user has this permission defined in the context for (Role role : this.userNameToUser.get(user.name).roles) { for (Permission permitted : role.permissions) { if (permitted.implies(context)) { return true; } } } return false; } 区域数据的后处理 PostProcessor接口允许定义在任何和所有客户端和gfsh操作之后但在返回数据之前调用的回调。 它允许回调干预并格式化要返回的数据。 回调不会修改区域数据，只会修改要返回的数据。 processRegionValue方法被赋予操作请求者的主体。 该操作已经完成，这意味着委托人将被授权完成所要求的操作。 因此，后处理可以基于请求者（主体）的身份格式化返回的数据。 为这些API调用调用processRegionValue方法： Region.get Region.getAll Query.execute CqQuery.execute CqQuery.executeWithInitialResults CqListener.onEvent 来自CacheListener.afterUpdate的相关区域事件，其中有兴趣注册了Region.registerInterest 在设计实现后处理回调的系统时应该小心。 它会导致每次get操作的额外方法调用的性能损失。 实施后期处理 完成这些项目以实现后期处理。 定义security-post-processor属性。 有关此属性的详细信息，请参阅使用属性定义启用安全性。 实现PostProcessor接口的processRegionValue方法。 SSL SSL通过确保只有您标识的应用程序可以共享集群数据来保护应用程序之间传输的数据。 为了安全起见，必须在存储，分发和处理期间保护Geode系统中缓存的数据。 任何时候，集群中的数据可能位于以下一个或多个位置： 在内存里 在磁盘上 进程之间的传输(例如，在internet或intranet中) 为了保护内存或磁盘上的数据，Geode依赖于您的标准系统安全功能，例如防火墙，操作系统设置和JDK安全设置。 SSL实施可确保只有您标识的应用程序才能共享传输中的集群数据。 在此图中，集群可见部分中的数据由防火墙以及操作系统和JDK中的安全设置保护。 例如，磁盘文件中的数据受防火墙和文件权限的保护。 使用SSL进行数据分发可在防火墙内外的Geode系统成员之间提供安全通信。 配置SSL 您可以为成员之间的相互身份验证配置SSL，并在分发期间保护数据。 您可以单独使用SSL，也可以与其他Geode安全选项一起使用。 SSL示例实施 一个简单的示例演示了使用SSL配置和启动Geode系统组件。 配置SSL 您可以配置SSL以在成员之间进行身份验证，并在分发期间保护您的数据。 您可以单独使用SSL，也可以与其他Geode安全选项一起使用。 Geode SSL连接使用Java安全套接字扩展（JSSE）包，因此此处描述的属性适用于Geode服务器和基于Java的客户端。 非Java客户端中的SSL配置可能不同 - 有关详细信息，请参阅客户端的文档。 SSL可配置组件 您可以指定在系统范围内使用SSL，也可以为特定系统组件单独配置SSL。 以下列表显示了可以单独配置为使用SSL进行通信的系统组件，以及每个组件名称所涉及的通信类型： 集群 集群成员之间的点对点通信 网关 WAN网关从一个站点到另一个站点的通信 web 所有基于Web的服务都托管在配置的服务器上，其中包括Developer REST API服务，Management REST API服务（用于远程集群管理）和Pulse监控工具的基于Web的用户界面。 jmx Java管理扩展通信，包括与gfshutility的通信。 Pulse监视工具使用JMX与定位器进行服务器端通信，但仅当Pulse位于与定位器不同的应用程序服务器上时，SSL才适用于此连接。 当Pulse和定位器共同定位时，两者之间的JMX通信不涉及TCP连接，因此SSL不适用。 locator 与定位器之间的通信 server 客户端和服务器之间的通信 all 以上所有（使用SSL系统范围） 指定为SSL启用组件适用于组件的服务器套接字端及其客户端套接字端。 例如，如果为定位器启用SSL，则与定位器通信的任何进程也必须启用SSL。 SSL配置属性 您可以使用Geode配置属性来启用或禁用SSL，识别SSL密码和协议，以及提供密钥和信任存储的位置和凭据。 ssl-enabled-components 要启用SSL的组件列表。 组件列表可以是“全部”或以逗号分隔的组件列表。 ssl-endpoint-identification-enabled 一个布尔值，当设置为true时，会导致客户端使用服务器的证书验证服务器的主机名。 默认值为false。 在信任非自签名证书时，启用端点标识可防止DNS中间人攻击。 ssl-require-authentication 需要双向身份验证，适用于除Web以外的所有组件。 Boolean - 如果为true（默认值），则需要双向身份验证。 ssl-web-require-authentication 需要对Web组件进行双向身份验证。 Boolean - 如果为true，则需要双向身份验证。 默认值为false（仅限单向身份验证）。 ssl-default-alias 服务器使用一个密钥库来保存其SSL证书。 该服务器上的所有组件都可以共享由ssl-default-alias属性指定的单个证书。 如果未指定ssl-default-alias，则密钥存储区中的第一个证书将充当默认证书。 ssl-component-alias=string 您可以为任何组件配置单独的证书。 所有证书都驻留在同一个密钥库中，但可以使用此语法由包含组件名称的单独别名指定，其中component是组件的名称。 如果指定了特定于组件的别名，它将覆盖指定的component的ssl-default-alias。 例如，ssl-locator-alias将在系统密钥库中指定定位器组件的证书的名称。 ssl-ciphers 用于启用SSL的组件连接的有效SSL密码的逗号分隔列表。 any设置使用在配置的JSSE提供程序中默认启用的任何密码。 ssl-protocols 以逗号分隔的有效启用SSL的组件连接列表。 any设置使用配置的JSSE提供程序中默认启用的任何协议。 ssl-keystore, ssl-keystore-password 密钥库的路径和密钥库密码，指定为字符串 ssl-truststore, ssl-truststore-password 信任存储的路径和信任库密码，指定为字符串 ssl-keystore-type, ssl-truststore-type 密钥库和信任库的类型，指定为字符串。 两者的默认值为“JKS”，表示Java密钥库或信任库。 示例：始终保护通信 要在整个集群中实现安全的SSL通信，每个进程都应为所有组件启用SSL。 ssl-enabled-components=all ssl-endpoint-identification-enabled=true ssl-keystore=secure/keystore.dat ssl-keystore-password=changeit ssl-truststore=secure/truststore.dat ssl-truststore-password=changeit 如果密钥库具有多个证书，您可能希望指定要为每个进程使用的别名。 例如，ssl-default-alias=Hiroki。 示例：非安全集群通信，安全客户端/服务器 在此示例中，SSL用于保护客户端和服务器之间的通信： 服务器属性 集群SSL未启用。 ssl-enabled-components=server,locator ssl-server-alias=server ssl-keystore=secure/keystore.dat ssl-keystore-password=changeit ssl-truststore=secure/truststore.dat ssl-truststore-password=changeit ssl-default-alias=Server-Cert 定位器属性 集群SSL未启用。 ssl-enabled-components=locator ssl-locator-alias=locator ssl-keystore=secure/keystore.dat ssl-keystore-password=changeit ssl-truststore=secure/truststore.dat ssl-truststore-password=changeit ssl-default-alias=Locator-Cert 客户端属性 在Java客户端上，已启用组件的列表反映了服务器的配置，因此客户端知道如何与（例如）服务器和定位器进行通信。 密钥库和信任库的路径是客户端的本地路径。 在此示例中，客户端的信任存储必须信任定位器和服务器证书。 由于客户端未指定证书别名，因此SSL将在其密钥库中使用默认证书。 ssl-enabled-components=server,locator ssl-endpoint-identification-enabled=true ssl-keystore=secret/keystore.dat ssl-keystore-password=changeit ssl-truststore=secret/truststore.dat ssl-truststore-password=changeit SSL属性参考表 下表列出了可以配置为使用SSL的组件。 Table 1. SSL可配置组件 部件 通信类型 cluster 集群成员之间的点对点通信 gateway WAN网关从一个站点到另一个站点的通信 web 基于Web的通信，包括REST接口 jmx Java管理扩展通信，包括gfsh locator 与定位器之间的通信 server 客户端和服务器之间的通信 all 上述所有的 下表列出了可用于在Geode系统上配置SSL的属性。 Table 2. SSL配置属性 属性 描述 值 ssl‑enabled‑components 要启用SSL的组件列表 “all”或以逗号分隔的组件列表：cluster，gateway，web，jmx，locator，server ssl‑endpoint‑identification‑enabled 使客户端使用服务器证书验证服务器主机名 boolean - if true, does validation; defaults to false ssl-require-authentication 需要双向身份验证，适用于除Web以外的所有组件 boolean - if true (the default), two-way authentication is required ssl‑web‑require‑authentication 需要对Web组件进行双向身份验证 boolean - if true, two-way authentication is required. Default is false (one-way authentication only) ssl-default-alias 默认证书名称 string - if empty, use first certificate in key store ssl-component-alias 组件特定的证书名称 string - applies to specified component ssl-ciphers SSL密码列表 comma-separated list (default “any”) ssl-protocols SSL协议列表 comma-separated list (default “any”) ssl-keystore 密钥库的路径 string ssl-keystore-password 密钥库密码 string ssl-truststore 信任商店的路径 string ssl-truststore-password 信任商店密码 string 程序 确保您的Java安装包含JSSE API并熟悉其使用。 有关信息，请参阅Oracle JSSE网站. 根据需要为每种连接类型配置SSL： 使用定位器在集群中进行成员发现以及用于客户端发现服务器。 请参阅配置点对点发现 和 配置客户端/服务器系统. 使用上述属性，根据需要为不同的组件类型配置SSL属性。 例如，要为客户端和服务器之间的通信启用SSL，您可以在gemfire.properties文件中配置属性，类似于： ssl-enabled-components=server ssl-protocols=any ssl-ciphers=SSL_RSA_WITH_NULL_MD5, SSL_RSA_WITH_NULL_SHA ssl-keystore=/path/to/trusted.keystore ssl-keystore-password=password ssl-truststore=/path/to/trusted.keystore ssl-truststore-password=password SSL示例实施 一个简单的示例演示了使用SSL配置和启动Geode系统组件。 特定于提供者的配置文件 此示例使用Javakeytool应用程序创建的密钥库为提供程序提供正确的凭据。 要创建密钥库，请运行keytool实用程序： keytool -genkey \\ -alias self \\ -dname \"CN=trusted\" \\ -validity 3650 \\ -keypass password \\ -keystore ./trusted.keystore \\ -storepass password \\ -storetype JKS 这将创建一个稍后将使用的./ trusted.keystore文件。 gemfire.properties 文件 您可以在gemfire.properties文件中启用SSL。 在此示例中，为所有组件启用了SSL。 ssl-enabled-components=all mcast-port=0 locators=[] gfsecurity.properties 文件 您可以在gfsecurity.properties文件中指定特定于提供程序的设置，然后可以通过限制对此文件的访问来保护该文件。 以下示例配置JDK附带的默认JSSE提供程序设置。 ssl-keystore=/path/to/trusted.keystore ssl-keystore-password=password ssl-truststore=/path/to/trusted.keystore ssl-truststore-password=password security-username=xxxx security-userPassword=yyyy 定位器启动 在启动其他系统成员之前，我们使用SSL和特定于提供程序的配置设置启动了定位器。 在正确配置gemfire.properties和gfsecurity.properties之后，启动定位器并提供属性文件的位置。 如果任何密码字段留空，系统将提示您输入密码。 gfsh>start locator --name=my_locator --port=12345 \\ --properties-file=/path/to/your/gemfire.properties \\ --security-properties-file=/path/to/your/gfsecurity.properties 其他成员启动 应用程序和缓存服务器可以与定位器启动类似地启动，并在当前工作目录中放置相应的gemfire.properties文件和gfsecurity.properties文件。 您还可以在命令行上将两个文件的位置作为系统属性传递。 例如： gfsh>start server --name=my_server \\ --properties-file=/path/to/your/gemfire.properties \\ --security-properties-file=/path/to/your/gfsecurity.properties 连接到正在运行的集群 您可以使用gfsh通过指定use-ssl命令行选项并提供安全配置文件的路径来连接已启用的已启用SSL的集群： gfsh>connect --locator=localhost[10334] --use-ssl \\ --security-properties-file=/path/to/your/gfsecurity.properties 连接后，您可以发出gfsh命令来执行各种操作，包括列出成员和显示区域特征。 性能调整和配置 一组工具和控件允许您监视和调整Apache Geode性能。 禁用TCP SYN Cookie 这是Linux系统必须做的事情。 提高vSphere的性能 本主题提供有关调整承载Apache Geode部署的vSphere虚拟化环境的指南。 性能控制 本主题提供了开发人员特别感兴趣的调优建议，主要是编程技术和缓存配置。 系统成员性能 您可以修改某些配置参数以提高系统成员的性能。 带有TCP/IP的慢速接收器 您可以使用多种方法来防止可能导致数据分发接收速度缓慢的情况。 慢接收器选项仅控制使用TCP/IP的对等通信。 此讨论不适用于客户端/服务器或多站点通信，也不适用于使用UDP单播或多播协议的通信。 慢分布式确认消息 在具有分布式ack区域的系统中，突然大量的分布式非ack操作可能导致分布式ack操作需要很长时间才能完成。 套接字通信 Geode进程使用TCP/IP和UDP单播和多播协议进行通信。 在所有情况下，通信都使用可以调整的套接字来优化性能。 UDP通信 您可以进行配置调整，以提高对等通信的多播和单播UDP性能。 组播通信 您可以进行配置调整，以提高Geode系统中对等通信的UDP组播性能。 维护缓存一致性 维护分布式Geode系统中缓存之间的数据一致性对于确保其功能完整性和防止数据丢失至关重要。 禁用TCP SYN Cookies 大多数默认Linux安装使用SYN cookie来保护系统免受泛滥TCP SYN数据包的恶意攻击（例如DDOS）。 此功能与稳定和繁忙的Geode集群不兼容。 SYN Cookie保护会被正常的Geode流量错误地激活，严重限制带宽和新的连接速率，并破坏SLA。 安全实现应该通过将Geode服务器集群置于高级防火墙保护之下来寻求防止DDOS类型的攻击。 要永久禁用SYN cookie： 编辑/etc/sysctl.conf文件以包含以下行： net.ipv4.tcp_syncookies = 0 将此值设置为零将禁用SYN Cookie。 重新加载sysctl.conf： sysctl -p 提高vSphere的性能 操作系统指南 使用最新支持的客户操作系统版本，并使用Java大型分页。 使用客户机操作系统的最新受支持版本. 该指南可能是最重要的。 将客户操作系统升级到Geode支持的最新版本。 例如，对于RHEL，至少使用7.0版或SLES使用至少11.0。 对于Windows，请使用Windows Server 2012.对于RedHat Linux用户，使用RHEL 7特别有用，因为RHEL 7版本中有特定的增强功能可以改进虚拟化延迟敏感工作负载。 在客户操作系统中使用Java大型分页. 在客户操作系统上配置Java以使用大页面。 启动Java时添加以下命令行选项： -XX:+UseLargePages NUMA, CPU, 和 BIOS 设置 本节为您的硬件和虚拟机提供VMware推荐的NUMA，CPU和BIOS设置。 始终启用超线程，不要过度使用CPU。 对于大多数生产Apache Geode服务器，始终使用具有至少两个vCPU的虚拟机。 通过调整虚拟机大小以适应NUMA节点来应用非统一内存访问（NUMA）位置。 VMware建议使用以下BIOS设置： BIOS Power Management Mode: 最高性能。 CPU Power and Performance Management Mode: 最高性能。 Processor Settings:启用Turbo模式。 Processor Settings:C状态禁用. 注意: 根据您的硬件品牌和型号，设置可能略有不同。 根据需要使用上面的设置或等效设置。 物理和虚拟NIC设置 这些指南可帮助您减少延迟。 物理 NIC: VMware建议您使用以下命令禁用ESXi主机的物理网卡上的中断合并： ethtool -C vmnicX rx-usecs 0 rx-frames 1 rx-usecs-irq 0 rx-frames-irq 0 其中vmnicX是ESXi命令报告的物理网卡： esxcli network nic list 您可以通过发出命令来验证您的设置是否已生效： ethtool -C vmnicX 如果重新启动ESXi主机，则必须重新应用上述配置。 注意: 禁用中断合并可以减少虚拟机的延迟; 但是，它会影响性能并导致更高的CPU利用率。 它还会破坏大型接收卸载（LRO）的优势，因为某些物理网卡（例如Intel 10GbE NIC）会在禁用中断合并时自动禁用LRO。 有关详细信息，请参阅http://kb.vmware.com/kb/1027511。 Virtual NIC: 配置虚拟NIC时，请遵循以下准则： 将VMXNET3虚拟NIC用于对延迟敏感或其他性能关键型虚拟机。 有关为虚拟机选择适当类型的虚拟NIC的详细信息，请参阅http://kb.vmware.com/kb/1001805。 VMXNET3支持自适应中断合并，可以帮助驱动具有多个具有并行工作负载（多线程）的vCPU的虚拟机的高吞吐量，同时最大限度地减少虚拟中断交付的延迟。 但是，如果您的工作负载对延迟非常敏感，VMware建议您禁用虚拟NIC的虚拟中断合并。 您可以通过API或编辑虚拟机的.vmx配置文件以编程方式执行此操作。 有关具体说明，请参阅vSphere API参考或VMware ESXi文档。 VMware vSphere vMotion和DRS集群使用情况 本主题讨论vSphere vMotion的使用限制，包括将其与DRS一起使用。 首次调试数据管理系统时，请将VMware vSphere Distributed Resource Scheduler™（DRS）置于手动模式，以防止可能影响响应时间的自动VMwarevSpherevMotion®操作。 减少或消除使用vMotion在Geode虚拟机负载过重时迁移它们。 不允许使用Apache Geode定位器进程进行vMotion迁移，因为此进程引入的延迟可能导致Apache Geode服务器的其他成员错误地怀疑其他成员已死亡。 使用专用的Apache Geode vSphere DRS集群。 当您考虑专门调整物理NIC和虚拟NIC以在集群中的ESXi主机的每个NIC上禁用中断合并时，这一点尤为重要。 这种类型的调优有利于Geode工作负载，但它可能会损害与内存吞吐量相关的其他非Apache Geode工作负载，而不像Apache Geode工作负载那样对延迟敏感。 如果无法使用专用vSphere DRS集群，并且Apache Geode必须在共享DRS集群中运行，请确保已设置DRS规则，以便不在Geode虚拟机上执行vMotion迁移。 如果必须使用vMotion进行迁移，VMware建议在低活动和计划维护时段期间，Apache Geode成员的所有vMotion迁移活动都将超过10GbE。 虚拟机的放置和组织 本节提供有关JVM实例和缓存数据冗余副本放置的指南。 每个虚拟机都有一个JVM实例。 增加堆空间以满足对更多数据的需求比在单个虚拟机上安装第二个JVM实例要好。 如果不能增加JVM堆大小，请考虑将第二个JVM放在单独的新创建的虚拟机上，从而提高更有效的水平可伸缩性。 随着您增加Apache Geode服务器的数量，还要增加虚拟机的数量，以便在Apache Geode服务器，JVM和虚拟机之间保持1:1:1的比例。 在一个JVM实例中运行一个Apache Geode服务器的至少四个vCPU虚拟机的大小。 这允许垃圾收集器有足够的CPU周期，其余用于用户事务。 由于Apache Geode可以在任何虚拟机上放置缓存数据的冗余副本，因此可能会在同一ESX/ESXi主机上无意中放置两个冗余数据副本。 如果主机发生故障，这不是最佳选择。 要创建更强大的配置，请使用VM1到VM2反关联性规则，以向vSphere指示VM1和VM2永远不能放在同一主机上，因为它们包含冗余数据副本。 虚拟机内存预留 本节提供了调整大小和设置内存的指南。 在虚拟机级别设置内存预留，以便ESXi在虚拟机启动时提供并锁定所需的物理内存。 分配后，ESXi不允许删除内存。 不要过度使用Geode主机的内存。 在为一个虚拟机上的一个JVM内的Geode服务器调整内存大小时，虚拟机的总预留内存不应超过一个NUMA节点中可用的内存以获得最佳性能。 vSphere的高可用性和Apache的Geode 在Apache Geode虚拟机上，禁用vSphere High Availability（HA）。 如果您使用的是专用的Apache Geode DRS集群，则可以在集群中禁用HA。 但是，如果您使用的是共享集群，请从vSphere HA中排除Geode虚拟机。 此外，为了支持高可用性，您还可以在Apache Geode虚拟机之间设置反关联性规则，以防止两个Apache Geode服务器在同一DRS集群内的同一ESXi主机上运行。 存储指南 本节提供持久性文件，二进制文件，日志等的存储准则。 将PVSCSI驱动程序用于I / O密集型Apache Geode工作负载。 在VMFS和客户机操作系统级别对齐磁盘分区。 将VMDK文件设置为eagerzeroedthick以避免Apache Geode成员的延迟清零。 对Apache Geode持久性文件，二进制文件和日志使用单独的VMDK。 将专用LUN映射到每个VMDK。 对于Linux虚拟机，使用NOOP调度作为I/O调度程序而不是完全公平队列（CFQ）。 从Linux内核2.6开始，CFQ是许多Linux发行版中的默认I/O调度程序。 有关详细信息，请参阅http://kb.vmware.com/kb/2011861。 其他资源 这些较旧的VMware出版物提供了有关vSphere优化的其他资源。 “VMware vSphere 5.0的性能最佳实践” - http://www.vmware.com/pdf/Perf_Best_Practices_vSphere5.0.pdf “在vSphere虚拟机中对延迟敏感工作负载进行性能调优的最佳实践” - http://www.vmware.com/files/pdf/techpaper/VMW-Tuning-Latency-Sensitive-Workloads.pdf “VMware上的企业Java应用程序 - 最佳实践指南” - http://www.vmware.com/resources/techresources/1087 性能控制 本主题提供了开发人员特别感兴趣的调优建议，主要是编程技术和缓存配置。 在开始之前，您应该了解Apache Geode 基本配置和编程. 数据序列化 除标准Java序列化外，Geode还提供序列化选项，为数据存储，传输和语言类型提供更高的性能和更大的灵活性。 设置缓存超时 缓存超时属性可以通过gfshalter runtime命令修改（或在cache.xml文件中声明），也可以通过接口方法org.apache.geode.cache.Cache进行设置。 控制套接字使用 对于对等通信，您可以在系统成员级别和线程级别管理套接字使用。 慢速接收器的管理 您有几个选项来处理接收数据分发的慢成员。 慢接收器选项仅控制使用TCP/IP的分布式区域之间的对等通信。 本主题不适用于客户端/服务器或多站点通信，也不适用于使用UDP单播或IP多播协议的通信。 增加缓存命中率 越频繁的获取没有找到第一缓存有效值和有尝试第二高速缓存越多，整体性能受到影响。 数据序列化 除标准Java序列化外，Geode还提供序列化选项，为数据存储，传输和语言类型提供更高的性能和更大的灵活性。 在使用Apache Geode开发中，请参阅数据序列化. 设置缓存超时 缓存超时属性可以通过gfshalter runtime命令修改（或在cache.xml文件中声明），也可以通过接口方法org.apache.geode.cache.Cache进行设置。 要修改缓存超时属性，可以发出以下gfsh alter runtime命令。 例如： gfsh>alter runtime --search-timeout=150 --search-timeout参数指定netSearch操作在超时之前可以等待数据的时间。 默认值为5分钟。 您可能希望根据您对网络负载或其他因素的了解来更改此设置。 接下来的两个配置描述了在具有全局范围的区域中锁定的超时设置。 锁定操作可以在两个地方超时：等待获取锁定（锁定超时）; 并持有一个锁（锁定租约时间）。 修改全局区域中对象的操作使用自动锁定。 此外，您可以通过org.apache.geode.cache.Region手动锁定全局区域及其条目。 API提供的显式锁定方法允许您指定锁定超时参数。 隐式操作的锁定超时和隐式和显式操作的锁定租用时间由这些缓存范围的设置控制： gfsh>alter runtime --lock-timeout=30 --lock-lease=60 --lock-timeout. 对象锁定请求超时，以秒为单位指定。 该设置仅影响自动锁定，不适用于手动锁定。 默认值为1分钟。 如果锁定请求未在指定的超时期限之前返回，则会取消锁定请求并返回失败。 --lock-lease. 对象锁定租约的超时，以秒为单位指定。 该设置会影响自动锁定和手动锁定。 默认值为2分钟。 一旦获得锁定，它就可以在锁定租用时间段内保持有效，然后由系统自动清除。 控制套接字使用 对于对等通信，您可以在系统成员级别和线程级别管理套接字使用。 conserve-socket设置指示应用程序线程是否与其他线程共享套接字或使用自己的套接字进行成员通信。 此设置对服务器与其客户端之间的通信没有影响，但它确实控制服务器与其对等方的通信或网关发送方与网关接收方的通信。 特别是在客户端/服务器设置中，每个服务器可能有大量客户端，控制对等套接字使用是调整服务器性能的重要部分。 您可以在gemfire.properties中为该成员配置conserve-socket。 此外，您可以通过API更改单个线程的套接字保护策略。 当conserve-sockets设置为false时，每个应用程序线程都使用专用线程发送到每个对等体，并使用专用线程从每个对等体接收。 禁用套接字保护需要更多系统资源，但可以通过消除线程之间的套接字争用和优化分布式ACK操作来潜在地提高性能。 对于分布式区域，put操作以及区域和条目的销毁和无效都可以通过将conserve-socket设置为false来优化。 对于分区区域，将conserve-socket设置为false可以提高一般吞吐量。 注意: 当您在EMPTY，NORMAL或PARTITION区域上运行事务时，请确保将conserve-sockets设置为false以避免分布式死锁。 您可以覆盖各个线程的conserve-socket设置。 这些方法位于org.apache.geode.distributed.DistributedSystem中： setThreadsSocketPolicy. 设置调用线程的单个套接字策略，覆盖整个应用程序的策略集。 如果设置为true，则调用线程与其他线程共享套接字连接。 如果为false，则调用线程有自己的套接字。 releaseThreadsSockets. 释放调用线程持有的任何套接字。 仅当conserve-socket为false时，线程才会拥有自己的套接字。 持有自己的套接字的线程可以调用此方法以避免在套接字租用时间到期之前保持套接字。 典型的实现可能会在应用程序级别将conserve-sockets设置为true，然后覆盖执行大量分布式操作的特定应用程序线程的设置。 下面的示例显示了执行基准测试的线程中两个API调用的实现。 该示例假定该类实现了Runnable。 请注意，只有在应用程序级别将conserve-sockets设置为true时，调用setThreadsSocketPolicy（false）才有意义。 public void run() { DistributedSystem.setThreadsSocketPolicy(false); try { // do your benchmark work } finally { DistributedSystem.releaseThreadsSockets(); } } 慢速接收器的管理 您有几个选项来处理接收数据分发的慢成员。 慢接收器选项仅控制使用TCP / IP的分布式区域之间的对等通信。 本主题不适用于客户端/服务器或多站点通信，也不适用于使用UDP单播或IP多播协议的通信。 处理慢速成员的大多数选项都与系统集成和调优期间的现场配置有关。 有关此信息，请参阅使用TCP/IP的慢速接收器. 当应用程序运行多个线程，发送大消息（由于大的条目值）或混合区域配置时，更可能发生减速。 注意: 如果您遇到性能下降并且正在发送大型对象（多兆字节），则在实现这些慢速接收器选项之前，请确保您的套接字缓冲区大小足以容纳您分发的对象。 套接字缓冲区大小使用gemfire.socket-buffer-size设置。 默认情况下，系统成员之间的分配是同步执行的。 使用同步通信，当一个成员接收缓慢时，它也可能导致其生产者成员减速。 这可能导致集群中的一般性能问题。 处理缓慢接收的规范主要影响您的成员如何管理具有distributed-no-ack范围的区域的分发，但它也会影响其他分布式范围。 如果没有地区具有distributed-no-ack范围，则这种机制根本不可能发挥作用。 但是，当慢速收据处理启动时，它会影响生产者和消费者之间的所有分配，无论范围如何。 分区区域忽略范围属性，但出于本讨论的目的，您应该将它们视为具有隐式分布式确认范围。 配置选项 慢接收器选项在生成器成员的region属性，enable-async-conflation和consumer成员的async *gemfire.properties设置中设置。 投递重试 如果接收方未能收到消息，则只要接收成员仍在集群中，发送方就会继续尝试传递消息。 在重试周期中，抛出包含此字符串的警告： will reattempt 当交付最终成功时，警告后面会显示一条信息消息。 慢速接收器的异步排队 可以配置您的使用者成员，以便在消费者对缓存消息分发响应缓慢时，他们的生产者切换到异步消息传递。 当生产者切换时，它会创建一个队列来保存和管理该消费者的缓存消息。 当队列清空时，生产者切换回消费者的同步消息。 导致生产者切换的设置在gemfire.properties文件设置中在使用者端指定。 如果将消费者配置为慢速收据排队，并且您的区域范围是distributed-no-ack，则还可以配置生产者以将其中的条目更新消息混合在其队列中。 此配置选项设置为区域属性enable-async-conflation。 默认情况下，不会混合使用distributed-no-ack条目更新消息。 根据应用程序的不同，混合可以大大减少生产者需要发送给消费者的消息数量。 通过合并，当向队列添加条目更新时，如果排队等待该密钥的最后一个操作也是更新操作，则删除先前排队的更新，仅将最新更新发送给使用者。 仅汇总源自具有distributed-no-ack范围的区域的条目更新消息。 除了更新之外的区域操作和输入操作不会混淆。 可能不会发生某种混淆，因为条目更新在被混合之前会发送给消费者。 对于此示例，假设在添加密钥A的更新时不发送任何消息。 注意: 这种混合方法与服务器到客户端的混合行为相同。 您可以逐个区域启用队列压缩。 您应始终启用它，除非它与您的应用程序需求不兼容。 通过配置可减少排队和分发的数据量。 这些是为什么混淆可能对您的应用程序不起作用的原因： 通过混合，较早的条目更新将从队列中删除，并替换为稍后在队列中发送的更新。 对于依赖于条目修改的特定顺序的应用程序而言，这是有问题的。 例如，如果您的接收器具有需要了解每个状态更改的CacheListener，则应禁用混合。 如果您的队列在相当长的一段时间内仍在使用，并且您有频繁更新的条目，则可能会有一系列更新消息替换，从而导致某些条目的任何更新到达时出现显着延迟。 想象一下，更新1在发送之前被删除，以支持稍后的更新2.然后，在发送更新2之前，将其删除以支持更新3，依此类推。 这可能导致接收器上的数据无法接受。 增加缓存命中率 越频繁的获取没有找到第一缓存有效值和有尝试第二高速缓存越多，整体性能受到影响。 未命中的常见原因是条目的到期或驱逐。 如果您启用了区域的条目到期或驱逐，请监视区域和条目统计信息。 如果您看到条目上的未命中率与命中率高，请考虑增加到期时间或驱逐的最大值（如果可能）。 有关更多信息，请参阅Eviction 系统成员性能 您可以修改某些配置参数以提高系统成员的性能。 在此之前，您应该了解基本配置和编程. 成员属性 多个与性能相关的属性适用于连接到集群的缓存服务器或应用程序。 JVM内存设置和系统性能 您可以通过向java调用添加参数来为Java应用程序配置JVM内存设置。 对于缓存服务器，将它们添加到gfshstart server命令的命令行参数中。 垃圾收集和系统性能 如果您的应用程序表现出不可接受的高延迟，则可以通过修改JVM的垃圾收集行为来提高性能。 连接线程设置和性能 当并发启动许多对等进程时，可以通过将p2p.HANDSHAKE_POOL_SIZE系统属性值设置为预期的成员数来改善集群连接时间。 成员属性 多个与性能相关的属性适用于连接到集群的缓存服务器或应用程序。 statistic-sampling-enabled.关闭统计信息采样可以节省资源，但它也会为正在进行的系统调整和意外系统问题带走可能有价值的信息。 如果配置了LRU驱逐，则必须打开统计采样。 statistic-sample-rate. 提高统计信息的采样率可以减少系统资源的使用，同时仍然提供一些系统调整和故障分析的统计信息 log-level. 与统计采样率一样，降低此设置可降低系统资源消耗。 见日志. JVM内存设置和系统性能 您可以通过向java调用添加参数来为Java应用程序配置JVM内存设置。 对于缓存服务器，将它们添加到gfshstart server命令的命令行参数中。 JVM堆大小 - 您的JVM可能需要比默认分配的内存更多的内存。 例如，您可能需要增加存储大量数据的应用程序的堆大小。 您可以设置最大大小和初始大小，因此如果您知道在成员的生命周期中将使用最大值（或接近它），则可以通过将初始大小设置为最大值来加快内存分配时间。 这会将Java应用程序的最大和初始内存大小设置为1024 MB： -Xmx1024m -Xms1024m 可以在gfsh命令行上将属性传递给缓存服务器： gfsh>start server --name=server-name --J=-Xmx1024m --J=-Xms1024m MaxDirectMemorySize—JVM有一种称为直接内存的内存，它与普通的JVM堆内存不同，可以用完。 您可以通过增加最大堆大小（请参阅先前的JVM堆大小）来增加直接缓冲区内存，这会增加最大堆和最大直接内存，或者只使用-XX:MaxDirectMemorySize来增加最大直接内存。 添加到Java应用程序启动的以下参数将最大直接内存大小增加到256兆字节： -XX:MaxDirectMemorySize=256M 缓存服务器的效果相同： gfsh>start server --name=server-name --J=-XX:MaxDirectMemorySize=256M JVM堆栈大小 - Java应用程序中的每个线程都有自己的堆栈。 堆栈用于保存返回地址，函数和方法调用的参数等。 由于Geode是一个高度多线程的系统，因此在任何给定的时间点都有多个线程池和线程正在使用中。 Java中线程的默认堆栈大小设置为1MB。 堆栈大小必须在连续的块中分配，如果主机正在使用并且系统中有许多线程运行（任务管理器显示活动线程数），您可能会遇到OutOfMemory错误：无法创建新的本机 thread，即使你的进程有足够的可用堆。 如果发生这种情况，请考虑减少缓存服务器上线程的堆栈大小要求。 添加到Java应用程序启动的以下参数限制了堆栈的最大大小。 -Xss384k 特别是，我们建议在这种情况下启动堆栈大小为384k或512k的缓存服务器。 例如： gfsh>start server --name=server-name --J=-Xss384k gfsh>start server --name=server-name --J=-Xss512k Off-heap memory size—对于使用堆外内存的应用程序，指定要分配的堆外内存量。 设置off-heap-memory-size是启用各个区域的堆外功能的先决条件。 例如： gfsh>start server --name=server-name --off-heap-memory-size=200G 有关此参数的其他注意事项，请参阅使用堆外内存。 锁定内存 - 在Linux系统上，您可以通过将lock-memory参数设置为true来防止堆和堆外存储器被分页。 例如： gfsh>start server --name=server-name --off-heap-memory-size=200G --lock-memory=true 有关此参数的其他注意事项，请参阅锁定内存。 垃圾收集和系统性能 如果您的应用程序表现出不可接受的高延迟，则可以通过修改JVM的垃圾收集行为来提高性能。 必要时，垃圾收集会通过消耗应用程序可用的资源，从而将延迟引入系统。 您可以通过两种方式减少垃圾收集的影响： 优化JVM堆中的垃圾收集。 通过在堆外内存中存储值来减少暴露于垃圾回收的数据量。 注意: 垃圾收集调整选项取决于您使用的JVM。 此处给出的建议适用于Sun HotSpot JVM。 如果您使用其他JVM，请与您的供应商联系，看看您是否可以使用这些或类似的选项。 注意: 对垃圾收集的修改有时会产生意外结果。 始终在进行更改之前和之后测试您的系统，以验证系统的性能是否已得到改进。 优化垃圾收集 这里建议的两个选项可能通过引入并行性并关注最有可能为清理做好准备的数据来加速垃圾收集活动。 第一个参数导致垃圾收集器与应用程序进程并发运行。 第二个参数使它为“年轻代”垃圾收集运行多个并行线程（即，在内存中的最新对象上执行垃圾收集 - 期望获得最大好处）： -XX:+UseConcMarkSweepGC -XX:+UseParNewGC 对于应用程序，如果使用远程方法调用（RMI）Java API，则还可以通过禁用对垃圾回收器的显式调用来减少延迟。 RMI内部每60秒自动调用一次垃圾回收，以确保清理RMI活动引入的对象。 您的JVM可能能够处理这些额外的垃圾收集需求。 如果是这样，您的应用程序可能会在禁用显式垃圾收集的情 您可以尝试将以下命令行参数添加到应用程序调用中并进行测试，以查看您的垃圾收集器是否能够满足需求： -XX:+DisableExplicitGC 使用堆外内存 您可以通过将数据值存储在堆外内存中来提高某些应用程序的性能。 某些对象（如键）必须保留在JVM堆中。 有关详细信息，请参阅管理堆外内存。 连接线程设置和性能 当并发启动许多对等进程时，可以通过将p2p.HANDSHAKE_POOL_SIZE系统属性值设置为预期的成员数来改善集群连接时间。 此属性控制可用于在对等高速缓存之间建立新TCP/IP连接的线程数。 如果线程空闲60秒，则丢弃线程。 p2p.HANDSHAKE_POOL_SIZE的默认值为10.此命令行规范将线程数设置为100： -Dp2p.HANDSHAKE_POOL_SIZE=100 带有TCP/IP的慢速接收器 您可以使用多种方法来防止可能导致数据分发接收速度缓慢的情况。 慢接收器选项仅控制使用TCP/IP的对等通信。 此讨论不适用于客户端/服务器或多站点通信，也不适用于使用UDP单播或多播协议的通信。 在开始之前，您应该了解Geode 基本配置和编程. 防止慢速接收器 在系统集成期间，您可以识别并消除对等通信中慢接收器的潜在原因。 管理慢速接收器 如果接收方未能收到消息，则只要接收成员仍在集群中，发送方就会继续尝试传递消息。 防止慢速接收器 在系统集成期间，您可以识别并消除对等通信中慢接收器的潜在原因。 与网络管理员合作，消除您发现的任何问题。 当应用程序运行多个线程，发送大消息（由于大的条目值）或混合区域配置时，更可能发生减速。 问题也可能是由间歇性连接问题导致的消息传递重试引起的。 主机资源 确保运行Geode成员的计算机具有足够的CPU可用空间。 不要在同一台机器上运行任何其他重量级进程。 承载Geode应用程序和缓存服务器进程的计算机应具有可比较的计算能力和内存容量。 否则，功能较弱的机器上的成员往往难以跟上该组的其他人。 网络容量 通过重新平衡流量负载来消除网络上的拥塞区域。 与网络管理员合作，识别并消除流量瓶颈，无论是由分布式Geode系统的体系结构引起的，还是由Geode流量与网络上的其他流量之间的争用引起的。 考虑是否需要更多子网来将Geode管理流量与Geode数据传输分开，并将所有Geode流量与其余网络负载分开。 主机之间的网络连接需要具有相同的带宽。 如果没有，您最终可能会得到如下图中的多播示例之类的配置，这会在成员之间产生冲突。 例如，如果app1以7Mbps发送数据，app3和app4就可以了，但app2会遗漏一些数据。 在这种情况下，app2会联系TCP通道上的app1并发送一条日志消息，告知它正在丢弃数据。 增长计划 将基础架构升级到可接受性能所需的级别。 与网络容量相比，分析预期的Geode流量。 增加额外的增长容量和高流量峰值。 同样，评估托管Geode应用程序和缓存服务器进程的计算机是否可以处理预期的负载。 管理慢速接收器 如果接收方未能收到消息，则只要接收成员仍在集群中，发送方就会继续尝试传递消息。 在重试周期中，Geode会抛出包含此字符串的警告： will reattempt 当交付最终成功时，警告后面会显示一条信息性消息。 对于分布式区域，区域的范围确定是否需要分发确认和分布式同步。 分区区域忽略范围属性，但出于本讨论的目的，您应该将它们视为具有隐式分布式确认范围。 默认情况下，系统成员之间的分配是同步执行的。 使用同步通信，当一个成员接收缓慢时，它也可能导致其生产者减速。 当然，这可能会导致集群中的一般性能问题。 如果您遇到性能下降并且正在发送大型对象（多兆字节），则在实现这些慢速接收器选项之前，请确保您的套接字缓冲区大小适合您分发的对象的大小。 套接字缓冲区大小是使用gemfire.properties文件中的socket-buffer-size设置的。 管理慢速分布式无ACK接收器 您可以配置您的消费者成员，以便他们的消息在响应缓慢时单独排队。 当生产者检测到缓慢的收据并允许生产者继续以正常速率向其他消费者发送时，排队发生在生产者成员中。 可以按照本节中的说明配置接收数据分发的任何成员。 处理慢速接收的规范主要影响成员如何管理具有distributed-no-ack作用域的区域的分布，其中分布是异步的，但规范也会影响其他分布式作用域。 如果没有地区具有distributed-no-ack范围，则该机制根本不可能启动。 但是，当慢速收据处理启动时，它会影响生产者和该消费者之间的所有分配，而不管范围如何。 注意: 在使用SSL的系统中禁用这些慢速接收器选项。 见SSL. 每个消费者成员确定其生产者如何处理其自身的缓慢行为。 这些设置被指定为分布式系统连接属性。 本节介绍设置并列出关联的属性。 async-distribution-timeout—分发超时指定生成器在切换到与该使用者的异步消息传递之前等待使用者响应同步消息传递的时间。 当生产者切换到异步消息传递时，它会为该消费者的消息创建一个队列，并为处理通信创建一个单独的线程。 当队列清空时，生产者自动切换回与消费者的同步通信。 这些设置会影响生产者的缓存操作可能会阻塞的时间。 所有使用者的超时总和是生产者阻止缓存操作的最长时间。 async-queue-timeout—队列超时设置了异步消息传递队列可以存在的时间长度的限制，而没有成功分发到慢速接收器。 当达到超时时，生产者要求消费者离开集群。 async-max-queue-size—最大队列大小限制了异步消息传递队列可以使用的内存量。 当达到最大值时，生产者要求消费者离开集群。 配置异步队列配置 当作用域是distributed-no-ack作用域时，您可以将生产者配置为在其队列中混合条目更新消息，这可以进一步加快通信速度。 默认情况下，不会混合distributed-no-ack条目更新消息。 配置在区域级别的生产者中设置。 强制慢速接收器断开连接 如果达到队列超时或最大队列大小限制中的任何一个，则生产者向消费者发送高优先级消息（在与用于高速缓存消息传递的连接不同的TCP连接上），告知它与集群断开连接。 这可以防止在慢速接收器等待接收器赶上时对其进行排队更改的其他进程增加内存消耗。 它还允许慢速成员重新开始，可能会清除导致其缓慢运行的问题。 当生产者放弃慢速接收器时，它会记录以下类型的警告之一： 阻塞时间ms，该时间长于异步队列超时ms的最大值，因此要求慢速接收器slow_receiver_ID断开连接。 排队的字节超过asyncMaxQueueSize的最大值，因此要求慢速接收器slow_receiver_ID断开连接。 当一个进程在收到生产者的请求后断开连接时，它会记录一个这种类型的警告消息： 生产者强制断开因为我们太慢了。 如果启用了日志记录并且日志级别设置为包含警告的级别（默认情况下），则这些消息仅显示在日志中。 见日志. 如果您的消费者无法接收甚至高优先级的消息，则只有生产者的警告才会出现在日志中。 如果只看到生产者警告，则可以重新启动使用者进程。 否则，Geode故障检测代码最终将导致成员自己离开集群。 用例 这些是慢速接收器规范的主要用例： Message bursts—使用消息突发，套接字缓冲区可能会溢出并导致生成器阻塞。 要防止阻塞，首先要确保您的套接字缓冲区足够大以处理正常数量的消息（使用socket-buffer-size属性），然后将异步分发超时设置为1.使用此非常低的分发超时，当您的 套接字缓冲区确实填满，生产者快速切换到异步排队。 使用分发统计信息asyncQueueTimeoutExceeded和asyncQueueSizeExceeded来确保您的队列设置足够高，以避免在消息突发期间强制断开连接。 Unhealthy or dead members—当成员死亡或非常不健康时，他们可能无法与其他成员沟通。 缓慢的接收器规范允许您强制残缺的成员断开连接，释放资源并可能允许成员重新启动。 要为此配置，请将分发超时设置为高（一分钟），并将队列超时设置为低。 这是避免排队暂时缓慢的最佳方法，同时仍然很快告诉非常不健康的成员离开集群。 Combination message bursts and unhealthy members—要配置上述两种情况，请将分发超时设置为低，并将队列超时设置为高，与消息突发方案一样。 管理慢速分布式ack接收器 使用distributed-no-ack以外的分发范围时，会为慢速接收器发出警报。 未响应消息的成员可能生病，缓慢或缺失。 在消息传输和回复等待处理代码中检测到病态或慢速成员，首先触发警告警报。 如果成员仍未响应，则会发出严重警告警报，指示该成员可能与集群断开连接。 通过将ack-wait-threshold和ack-severe-alert-threshold设置为某个秒数来启用此警报序列。 设置ack-severe-alert-threshold时，区域配置为使用ether distributed-ack或全局作用域，或使用分区数据策略。 对于对缓存操作的响应，Geode将等待总共ack-wait-threshold秒，然后它会记录警告警报(“Membership: requesting removal of entry(#). Disconnected as a slow-receiver”)。 在达到第一个阈值后等待额外的ack-severe-alert-threshold秒后，系统还会通知故障检测机制接收器可疑并可能断开连接，如下图所示。 事件按此顺序发生： CACHE_OPERATION - 启动缓存操作的传输。 SUSPECT - 通过ack-wait-threshold识别为嫌疑人，这是在启动故障检测之前等待确认的最长时间。 I AM ALIVE - 如果进程仍然存在，则通知系统以响应故障检测查询。 如果可疑进程未能通过I AM ALIVE回答，则会向所有成员发送新的成员资格视图。 SEVERE ALERT- ack-severe-wait-threshold结果没有收到回复。 当成员未通过可疑处理时，将关闭其缓存并使用afterRegionDestroyed通知通知其CacheListener。 通过此通知传递的RegionEvent具有CACHE_CLOSED操作和FORCED_DISCONNECT操作，如FORCED_DISCONNECT示例所示。 public static final Operation FORCED_DISCONNECT = new Operation(\"FORCED_DISCONNECT\", true, // isLocal true, // isRegion OP_TYPE_DESTROY, OP_DETAILS_NONE ); 缓存由于被其他成员从集群中驱逐而关闭。 通常，当成员变得无响应并且在成员超时期限内没有响应心跳请求，或者ack-severe-alert-threshold在没有成员响应的情况下过期时，就会发生这种情况。 注意: 这被标记为区域操作。 其他成员查看离职成员的正常成员资格通知。 例如，RegionMembershipListeners接收afterRemoteRegionCrashed通知，SystemMembershipListeners接收memberCrashed通知。 慢分布式确认消息 在具有分布式ack区域的系统中，突然大量的分布式非ack操作可能导致分布式ack操作需要很长时间才能完成。 distributed-no-ack操作可以来自任何地方。 它们可能是对distributed-no-ack区域的更新，或者它们可能是在缓存中的任何区域（包括distributed-ack区域）上执行的其他distributed-no-ack操作，如销毁。 大量的distributed-no-ack消息可能会延迟distributed-ack操作的主要原因是： 对于任何单个套接字连接，所有操作都是串行执行的。 如果在发送distributed-ack时有任何其他操作被缓冲用于传输，则distributed-ack操作必须等待才能在传输之前到达行的前面。 当然，操作的调用过程也在等待。 distributed-no-ack消息在传输之前由其线程缓冲。 如果许多消息被缓冲然后立即发送到套接字，则传输线可能很长。 您可以采取以下步骤来减少此问题的影响： 如果您使用的是TCP，请检查是否为您的成员启用了套接字保护。 通过将Geode属性conserve-sockets设置为true来配置它。 如果启用，除非您在线程级别覆盖设置，否则每个应用程序的线程将共享套接字。 与应用程序编程人员一起工作，看看是否可以完全禁用共享，或者至少是执行distributed-ack操作的线程。 这些包括对distributed-ack区域的操作以及对任何分布式范围的区域执行的netSearches。 （注意：netSearch仅在数据策略为空，正常和预加载的区域上执行。）如果给每个执行distributed-ack操作的线程自己的套接字，你实际上让它在前面 在其他线程正在执行的distributed-no-ack操作之前的行。 线程级别覆盖是通过调用DistributedSystem.setThreadsSocketPolicy(false)方法完成的。 减小缓冲区大小以减慢distributed-no-ack操作。 这些更改会减慢执行distributed-no-ack操作的线程，并允许以更及时的方式发送执行distributed-ack操作的线程。 如果您正在使用UDP（您在gemfire.properties中具有多播启用区域或已将disable-tcp设置为true），请考虑将mcast-flow-control的byteAllowance减小到小于默认值3.5 MB的值。 如果您正在使用TCP / IP，请减少gemfire.properties中的socket-buffer-size。 套接字通信 Geode进程使用TCP / IP和UDP单播和多播协议进行通信。 在所有情况下，通信都使用可以调整的套接字来优化性能。 您为调整Geode通信所做的调整可能会遇到操作系统限制。 如果发生这种情况，请咨询系统管理员，了解如何调整操作系统设置。 这里讨论的所有设置都列为gemfire.properties和cache.xml设置。 它们也可以通过API配置，有些可以在命令行配置。 在开始之前，您应该了解Geode 基本配置和编程. 设置套接字缓冲区大小 确定缓冲区大小设置时，尝试在通信需求和其他处理之间取得平衡。 短暂的TCP端口限制 默认情况下，Windows的临时端口在1024-4999范围内，包括在内。您可以增加范围。 确保你有足够的Sockets 应用程序可用的套接字数量受操作系统限制的约束。 TCP/IP KeepAlive 配置 Geode支持TCP KeepAlive以防止套接字连接超时。 TCP/IP Peer-to-Peer 握手超时 您可以通过使用系统属性p2p.handshake Timeout Ms.增加连接握手超时间隔来缓解TCP / IP连接的连接握手超时。 设置套接字缓冲区大小 确定缓冲区大小设置时，必须在通信需求和其他处理之间取得平衡。 较大的套接字缓冲区允许您的成员更快地分发数据和事件，但它们也会使内存远离其他内容。 如果在缓存中存储非常大的数据对象，则为缓冲区找到正确的大小调整，同时为缓存的数据留下足够的内存，这对系统性能至关重要。 理想情况下，您应该有足够大的缓冲区来分发任何单个数据对象，这样就不会出现消息碎片，从而降低性能。 您的缓冲区应该至少与最大的存储对象及其密钥一样大，加上消息头的一些开销。 开销取决于发送和接收的人员，但100个字节就足够了。 您还可以查看进程之间通信的统计信息，以查看正在发送和接收的字节数。 如果您发现性能问题并记录指示阻塞编写器的消息，则增加缓冲区大小可能会有所帮助。 此表列出了各种成员关系和协议的设置，并说明了设置它们的位置。 Protocol / Area Affected 配置位置 属性名称 TCP / IP — — Peer-to-peer send/receive gemfire.properties socket-buffer-size Client send/receive cache.xml socket-buffer-size Server send/receive gfsh start server orcache.xml socket-buffer-size UDP Multicast — — Peer-to-peer send gemfire.properties mcast-send-buffer-size Peer-to-peer receive gemfire.properties mcast-recv-buffer-size UDP Unicast — — Peer-to-peer send gemfire.properties udp-send-buffer-size Peer-to-peer receive gemfire.properties udp-recv-buffer-size TCP/IP 缓冲区大小 如果可能，您的TCP / IP缓冲区大小设置应与Geode安装相匹配。 至少应遵循此处列出的准则。 Peer-to-peer. gemfire.properties中的socket-buffer-size设置在整个集群中应该是相同的。 Client/server. 客户端的池套接字缓冲区大小应该与池使用的服务器的设置相匹配，如这些示例中的cache.xml片段： Client Socket Buffer Size cache.xml Configuration: name=\"PoolA\" server-group=\"dataSetA\" socket-buffer-size=\"42000\"... Server Socket Buffer Size cache.xml Configuration: dataSetA UDP多播和单播缓冲区大小 通过UDP通信，一个接收器可以让许多发送器立即发送给它。 为了适应所有传输，接收缓冲区应该大于发送缓冲区的总和。 如果您的系统最多有五个成员在任何时间运行，其中所有成员都更新其数据区域，则应将接收缓冲区设置为发送缓冲区大小的至少五倍。 如果您的系统具有生产者和使用者成员，其中只有两个生产者成员一次运行，则接收缓冲区大小应设置为发送缓冲区大小的两倍以上，如下例所示： mcast-send-buffer-size=42000 mcast-recv-buffer-size=90000 udp-send-buffer-size=42000 udp-recv-buffer-size=90000 操作系统限制 您的操作系统对其允许的缓冲区大小设置限制。 如果您请求的大小超过允许的大小，则可能会在启动期间收到有关该设置的警告或例外情况。 这些是您可能会看到的消息类型的两个示例： [warning 2008/06/24 16:32:20.286 PDT CacheRunner tid=0x1] requested multicast send buffer size of 9999999 but got 262144: see system administration guide for how to adjust your OS Exception in thread \"main\" java.lang.IllegalArgumentException: Could not set \"socket-buffer-size\" to \"99262144\" because its value can not be greater than \"20000000\". 如果您认为要为缓冲区大小请求的空间大于系统允许的空间，请与系统管理员联系以了解有关调整操作系统限制的信息。 短暂的TCP端口限制 默认情况下，Windows的临时端口在1024-4999范围内。 你可以增加范围。 如果您反复收到以下异常： java.net.BindException: Address already in use: connect 如果您的系统正在经历高度的网络活动，例如众多短期客户端连接，这可能与短暂TCP端口数量的限制有关。 虽然其他操作系统可能会出现此问题，但通常情况下，由于默认限制较低，因此只能在Windows中看到此问题。 执行此过程以增加限制： 打开Windows注册表编辑器。 导航到以下键： HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameter 从“编辑”菜单中，单击“新建”，然后添加以下注册表项： Value Name: MaxUserPort Value Type: DWORD Value data: 36863 退出注册表编辑器，然后重新启动计算机。 这会影响Windows操作系统的所有版本。 关于Unix系统上的UDP的注意事项 Unix系统有一个默认的最大套接字缓冲区大小，用于接收UDP多播和单播传输，这些传输低于mcast-recv-buffer-size和udp-recv-buffer-size的默认设置。 要实现大容量多播消息传递，您应该将最大Unix缓冲区大小增加到至少一兆字节。 确保你有足够的Sockets 应用程序可用的套接字数量受操作系统限制的约束。 套接字使用文件描述符，操作系统的应用程序套接字使用视图以文件描述符表示。 有两个限制，一个是关于单个应用程序可用的最大描述符，另一个是关于系统中可用的描述符总数。 如果您收到错误消息，告诉您打开了太多文件，则可能会因使用套接字而达到操作系统限制。 您的系统管理员可能能够增加系统限制，以便您可以获得更多可用信息。 您还可以调整成员，以便为其传出连接使用更少的套接字。 本节讨论Geode中的套接字使用以及限制Geode成员中套接字消耗的方法。 套接字共享 您可以为peer-to-peer 和 client-to-server连接配置套接字共享： Peer-to-peer. 您可以配置您的成员是在应用程序级别还是在线程级别共享套接字。 要在应用程序级别启用共享，请将gemfire.properties属性conserve-sockets设置为true。 但是，为了实现最大吞吐量，我们建议您将conserve-sockets设置为false。 在线程级别，开发人员可以使用DistributedSystem API方法setThreadsSocketPolicy覆盖此设置。 您可能希望在应用程序级别启用套接字共享，然后让执行大量缓存工作的线程单独拥有其套接字。 确保使用releaseThreadsSockets方法编程这些线程以尽快释放其套接字，而不是等待超时或线程死亡。 Client. 您可以配置客户端是否与池设置为thread-local-connections的服务器共享其套接字连接。 此设置没有线程覆盖。 所有线程都有自己的套接字或者它们都共享。 套接字租约时间 您可以强制释放空闲套接字连接以进行对等和客户端到服务器连接： Peer-to-peer. 对于不共享套接字的对等线程，可以使用socket-lease-time来确保没有套接字空闲太长时间。 当属于单个线程的套接字在此时间段内保持未使用状态时，系统会自动将其返回到池中。 下一次线程需要套接字时，它会创建一个新套接字。 Client. 对于客户端连接，可以通过设置池idle-timeout来影响相同的租用时间行为。 计算连接要求 每种类型的成员都有自己的连接要求。 客户端需要连接到他们的服务器，对等端需要连接到对等端，等等。 许多成员都有复合角色。 使用这些指南来计算每个成员的套接字需求，并计算在单个主机系统上运行的成员的组合需求。 成员的套接字使用受许多因素控制，包括： 它连接了多少个对等成员 它有多少个线程来更新缓存以及线程是否共享套接字 无论是服务器还是客户端， 其他进程有多少连接 这里描述的套接字要求是最坏的情况。 通常，为您的应用程序计算确切的套接字使用是不切实际的。 套接字的使用取决于许多因素，包括运行的成员数量，线程正在做什么以及线程是否共享套接字。 要计算任何成员的套接字要求，请为适用于该成员的每个类别添加要求。 例如，在与客户端连接的集群中运行的缓存服务器具有对等和服务器套接字要求。 每位成员的Peer-to-Peer 套接字要求 集群的每个成员都维护到每个对等方的两个传出连接和两个传入连接。 如果线程共享套接字，则这些固定套接字是它们共享的套接字。 对于不共享套接字的每个线程，为每个对等体添加额外的套接字，一个输入和一个输出。 这不仅会影响成员的套接字计数，还会影响成员线程连接到的每个成员的套接字计数。 在此表中： M是集群中的成员总数。 T是拥有自己的套接字且不共享的成员中的线程数。 对等成员套接字描述 使用的数量 成员故障检测 2 传入对等连接的侦听器（服务器P2P） 1 共享套接字（2输入和2输出）共享套接字的线程使用这些。 4 * (M-1) 此成员的线程拥有的套接字（每个线程为每个对等成员1个和1个）。 (T 2) (M-1) 连接到此成员的其他成员的线程拥有的套接字（每个成员1个和1个）。 请注意，如果任何其他成员是服务器，则可能包括服务器线程（请参阅服务器）。 Summation over (M-1) other members of (T*2) 注意: 服务客户端请求的线程会为连接到其对等方的成员以及连接到此成员的对等方添加线程拥有的套接字的总数。 每服务器的服务器套接字要求 服务器为每个传入客户端连接使用一个连接。 默认情况下，每个连接都由服务器线程提供服务。 这些服务客户端请求的线程与其余服务器通信以满足请求和分布式更新操作。 这些线程中的每一个都使用自己的线程拥有的套接字进行对等通信。 所以这会增加服务器的线程拥有的套接字组。 服务器中的线程和连接计数可能受服务器配置设置的限制。 这些是cache.xml的元素中的max-connections和max-threads设置。 这些设置限制服务器接受的连接数以及可以为客户端请求提供服务的最大线程数。 这两个都限制了服务器的整体连接要求： 达到连接限制时，服务器拒绝其他连接。 这限制了服务器用于客户端的连接数。 达到线程限制时，线程开始为多个连接提供服务。 这不会限制客户端连接的数量，但会限制为客户端请求提供服务所需的对等连接数。 用于客户端的每个服务器线程都使用自己的套接字，因此它需要2个连接到每个服务器的对等端。 max-threads设置会限制服务器所需的此类对等连接的数量。 服务器为每个传入的客户端池连接使用一个套接字。 如果使用客户端订阅，则服务器会为每个启用订阅的客户端创建其他连接。 在此表中，M是集群中的成员总数。 服务器套接字描述 使用的数量 侦听传入的客户端连接 1 客户端池与服务器的连接 此服务器的池连接数 为客户端请求提供服务的线程（客户端池连接数和服务器的max-threads设置中的较小者）。 这些连接是服务器的对等方。 （2 服务客户端池连接的服务器中的线程数）（M-1）这些线程不共享套接字。 订阅连接 2 *此服务器的客户端订阅连接数 在客户端/服务器安装中，与任何单个服务器的客户端连接数量未确定，但Geode的服务器负载平衡和调节使连接在服务器之间保持相当均匀的分布。 服务器是它们自己的集群中的对等体，并具有额外的套接字要求，如上面的点对点部分所述。 每个客户的客户端套接字要求 客户端连接要求因其使用的池数而变得复杂。 使用情况因运行时客户端连接需求而异，但通常具有最大和最小设置。 在cache.xml中查找配置属性的元素。 客户端套接字描述 使用的数量 池连接 对max-connections的客户端池进行求和 订阅连接 对已启用订阅的客户端池进行2 *总结 如果您的客户端充当其自己的集群中的对等方，则它具有附加的套接字要求，如本主题的“对等”部分所述。 TCP/IP KeepAlive配置 Geode支持TCP KeepAlive以防止套接字连接超时。 gemfire.enableTcpKeepAlive系统属性可防止出现空闲的连接超时（例如，通过防火墙）。当配置为true时，Geode为各个套接字启用SO_KEEPALIVE选项。 此操作系统级设置允许套接字向远程系统发送验证检查（ACK请求），以确定是否保持套接字连接处于活动状态。 注意: 在操作系统级别配置发送第一个ACK KeepAlive请求的时间间隔，后续ACK请求以及关闭套接字之前发送的请求数。 默认情况下，此系统属性设置为true。 TCP/IP Peer-to-Peer握手超时 您可以通过使用系统属性p2p.handshake Timeout Ms增加连接握手超时间隔来缓解TCP/IP连接的连接握手超时。 默认设置为59000毫秒。 这会将Java应用程序的握手超时设置为75000毫秒： -Dp2p.handshakeTimeoutMs=75000 这些属性在gfsh命令行上传递给缓存服务器： gfsh>start server --name=server_name --J=-Dp2p.handshakeTimeoutMs=75000 在多站点（WAN）部署中配置套接字 确定缓冲区大小设置时，尝试在通信需求和其他处理之间取得平衡。 此表列出了网关关系和协议的设置，并说明了设置它们的位置。 受影响的协议/区域 配置位置 属性名称 TCP / IP — — Gateway sender gfsh create gateway-senderorcache.xml socket-buffer-size Gateway receiver gfsh create gateway-receiveror cache.xml socket-buffer-size TCP/IP缓冲区大小 如果可能，您的TCP/IP缓冲区大小设置应与您的安装相匹配。 至少应遵循此处列出的准则。 Multisite (WAN). 在使用网关的多站点安装中，如果未针对最佳吞吐量调整站点之间的链接，则可能导致消息在缓存队列中备份。 如果接收队列由于缓冲区大小不足而溢出，则它将与发送方不同步，接收方将不知道该情况。 网关发送方的socket-buffer-size属性应与发送方连接的所有网关接收方的网关接收方的socket-buffer-size属性相匹配，如下所示cache.xml片段： Gateway Sender Socket Buffer Size cache.xml Configuration: Gateway Receiver Socket Buffer Size cache.xml Configuration: 注意: WAN部署增加了Geode系统的消息传递需求。 为避免与WAN消息传递相关的挂起，请始终为参与WAN部署的GemFire成员设置conserve-sockets=false。 Multi-site (WAN) 套接字要求 每个网关发送方和网关接收方使用套接字来分发事件或侦听来自远程站点的传入连接。 Multi-site 套接字说明 使用的数量 侦听传入连接 为成员定义的网关接收器数量的总和 传入连接 配置为连接到网关接收器的远程网关发送器总数的总和 传出连接 为成员定义的网关发件人数量的总和 服务器是它们自己的集群中的对等体，并具有额外的套接字要求，如上面的点对点部分所述。 成员生成SocketTimeoutException 当客户端，服务器，网关发送器或网关接收器停止等待来自连接另一端的响应并关闭套接字时，会产生SocketTimeoutException。 此异常通常发生在握手或建立回调连接时。 响应: 增加成员的默认套接字超时设置。 对于客户端池以及网关发送方和网关接收方，可以在cache.xml文件中或通过API单独设置此超时。 对于客户端/服务器配置，请按[]http://geode.apache.org/docs/guide/17/reference/topics/client-cache.html#cc-pool )中所述调整“读取超时”值(或使用org.apache.geode.cache.client.PoolFactory.setReadTimeout方法。 有关网关发送方或网关接收方，请参阅WAN配置。 UDP 通信 您可以进行配置调整，以提高对等通信的多播和单播UDP性能。 您可以调整Geode UDP消息传递以最大化吞吐量。 有两个主要的调整目标：使用最大的合理数据报数据包大小并降低重传率。 这些操作可以减少网络上的消息传递开销和总体流量，同时仍然可以将数据放在需要的位置。 Geode还提供统计信息，以帮助您决定何时更改UDP消息传递设置。 在开始之前，您应该了解Geode 基本配置和编程。 另请参阅套接字通信和多播通信中涵盖的一般通信调优和多播特定调整。 UDP数据报大小 您可以使用Geode属性udp-fragment-size更改UDP数据报大小。 这是通过UDP单播或多播套接字传输的最大数据包大小。 如果可能，将较小的消息组合成最多为此设置大小的批次。 大多数操作系统为UDP数据报设置的最大传输大小为64k，因此该设置应保持在60k以下以允许通信头。 如果您的网络容易丢包，则将片段大小设置得过高会导致额外的网络流量，因为每次重新传输都必须重新发送更多数据。 如果在DistributionStats中出现许多UDP重新传输，您可以通过降低片段大小来获得更好的吞吐量。 UDP流量控制 UDP协议通常具有内置的流控制协议，以防止进程的no-ack消息超出进程。 Geode UDP流量控制协议是一种基于信用的系统，其中发送方具有在其接收方补充或重新充值其字节信用计数之前可以发送的最大字节数。 虽然其字节信用太低，但发件人等待。 接收器尽最大努力预测发送者的充电要求，并在需要之前提供充电。 如果发送方的信用额度过低，则明确要求其接收方进行充值。 此流控制协议用于所有多播和单播no-ack消息传递，使用三部分Geode属性mcast-flow-control进行配置。 此属性包括： byteAllowance—确定在从接收进程接收补给之前可以发送多少字节（也称为信用）。 rechargeThreshold—设置发送方剩余信用与其byteAllowance之比的下限。 当比率低于此限制时，接收器自动发送充电。 这减少了来自发件人的充值请求消息，并有助于防止发送者在等待充值时阻塞。 rechargeBlockMs—告诉发件人在明确请求之前需要等待多长时间。 在一个调整良好的系统中，缓存事件的消费者与生产者保持同步，可以将byteAllowance设置为高，以限制控制流消息和暂停。 JVM膨胀或频繁的消息重传表明生产者的缓存事件超出了消费者。 UDP重传统计 Geode存储其发送者和接收者的重传统计数据。 您可以使用这些统计信息来帮助确定流控制和片段大小设置是否适合您的系统。 重传率存储在分布式状态ucastRetransmits和mcastRetransmits中。 对于多播，还有一个接收方统计信息mcastRetransmitRequests，可用于查看哪些进程没有跟上并请求重新传输。 没有类似的方法可以判断哪些接收器在接收单播UDP消息时遇到问题。 组播通信 您可以进行配置调整，以提高Geode系统中对等通信的UDP组播性能。 在开始之前，您应该了解Geode 基本配置和编程。 另请参阅套接字通信和[UDP通信]（http://geode.apache.org/docs/guide/17/managing/monitor_tune/udp_communication.html#udp_comm）中介绍的一般通信调优和UDP调整。 为多播提供带宽 多播安装比TCP安装需要更多的规划和配置。 使用IP多播，您可以获得可扩展性，但却失去了TCP的管理便利性。 测试多播速度限制 TCP会自动将其速度调整为使用它的进程的能力，并强制执行带宽共享，以便每个进程都能获得转换。 使用多播，您必须确定并明确设置这些限制。 配置多播速度限制 确定最大传输速率后，配置并调整生产系统。 多播的运行时注意事项 使用多播进行消息传递和数据分发时，需要了解运行状况监视设置的工作原理以及如何控制内存使用。 排除多播调整过程 在多播的初始测试和调整过程中可能会出现几个问题。 为多播提供带宽 多播安装比TCP安装需要更多的规划和配置。 使用IP多播，您可以获得可扩展性，但却失去了TCP的管理便利性。 当您安装通过TCP运行的应用程序时，几乎总是为TCP设置网络，而其他应用程序已经在使用它。 当您安装要通过IP多播运行的应用程序时，它可能是网络上的第一个多播应用程序。 多播非常依赖于它运行的环境。 它的操作受到网络硬件，网络软件，Geode进程在哪些机器上运行的机器以及是否存在任何竞争应用程序的影响。 您可能会发现您的站点在TCP中具有连接但在多播中没有，因为某些交换机和网卡不支持多播。 您的网络可能存在潜在的问题，否则您将永远看不到。 要使用多播成功实现分布式Geode系统，需要系统和网络管理员的配合。 多播的有界操作 Geode系统需要组速率控制来维持缓存一致性。 如果您的应用程序向一组成员提供相同的数据，那么您的系统调优工作需要关注慢速接收器。 如果您的某些成员无法跟上传入的数据，则该组中的其他成员可能会受到影响。 充其量，慢速接收器会导致生产者使用缓冲，为慢速接收器增加延迟，并可能为所有这些接收器增加延迟。 在最坏的情况下，组的吞吐量可以完全停止，而生产者的CPU，内存和网络带宽专用于为慢速接收器提供服务。 要解决此问题，您可以实现有界操作策略，该策略为生产者的操作设置边界。 通过调整和测试确定适当的速率限制，以便尽可能快地进行操作，同时最大限度地减少消费者群体中的数据丢失和延迟。 此政策适用于需要高吞吐量，可靠交付和网络稳定性的金融市场数据等应用。 边界设置正确后，生产者的流量不会导致网络中断。 多播协议通常具有内置于其中的流控制协议，以防止进程被溢出。 Geode流控制协议使用mcast-flow-control属性为多播流操作设置生产者和消费者边界。 该属性提供以下三种配置设置： byteAllowance 无需充电即可发送的字节数 rechargeThreshold 告诉消费者，在发送充值之前，生产者的初始剩余免税额应该是多少。 rechargeBlockMs 告诉生产者在请求之前等待充电需要多长时间。 测试多播速度限制 TCP会自动将其速度调整为使用它的进程的能力，并强制执行带宽共享，以便每个进程都能获得转换。 使用多播，您必须确定并明确设置这些限制。 如果没有正确的配置，多播会尽可能快地提供流量，超出消费者处理数据和锁定等待带宽的其他进程的能力。 您可以使用gemfire.properties中的mcast-flow-control来调整多播和单播行为。j 使用Iperf Iperf是一种开源TCP/UDP性能工具，可用于查找站点通过多播进行数据分发的最大速率。 Iperf可以从诸如国家应用网络研究实验室（NLANR）的网站下载。 Iperf测量最大带宽，允许您调整参数和UDP特性。 Iperf报告有关带宽，延迟抖动和数据报丢失的统计信息。 在Linux上，您可以将此输出重定向到文件; 在Windows上，使用-o filename参数。 运行每个测试十分钟，以确保任何潜在的问题都有机会发展。 使用以下命令行启动发送方和接收方。 发送方: iperf -c 192.0.2.0 -u -T 1 -t 100 -i 1 -b 1000000000 此处: -c address 在客户端模式下运行并连接到多播地址 -u 使用UDP -T # 组播生存时间：组播数据包在路由器丢弃数据包之前可以通过的子网数量 注意: 在未咨询网络管理员的情况下，请勿将-T参数设置为1以上。 如果此数字太高，则iperf流量可能会干扰生产应用程序或继续上网。 -t 传输时间，以秒为单位 -i 定期带宽报告之间的时间，以秒为单位 -b 发送带宽，以每秒位数为单位 接收者: iperf -s -u -B 192.0.2.0 -i 1 此处: -s 在服务器模式下运行 -u 使用 UDP -B address 绑定到多播地址 -i # 定期带宽报告之间的时间，以秒为单位 注意: 如果您的Geode集群跨多个子网运行，请在每个子网上启动接收器。 在接收器的输出中，查看Lost/ Total Datagrams列中的丢失数据包的数量和百分比。 Iperf测试的输出: [ ID] Interval Transfer Bandwidth Jitter Lost/Total Datagrams [ 3] 0.0- 1.0 sec 129 KBytes 1.0 Mbits/sec 0.778 ms 61/ 151 (40%) [ 3] 1.0- 2.0 sec 128 KBytes 1.0 Mbits/sec 0.236 ms 0/ 89 (0%) [ 3] 2.0- 3.0 sec 128 KBytes 1.0 Mbits/sec 0.264 ms 0/ 89 (0%) [ 3] 3.0- 4.0 sec 128 KBytes 1.0 Mbits/sec 0.248 ms 0/ 89 (0%) [ 3] 0.0- 4.3 sec 554 KBytes 1.0 Mbits/sec 0.298 ms 61/ 447 (14%) 在不同的带宽上重新运行测试，直到找到最大有用的多播速率。 从高处开始，然后逐渐降低发送速率，直到测试运行一致且没有丢包。 例如，您可能需要连续运行五个测试，每次更改-b（每秒位数）参数，直到没有丢失： -b 1000000000 (loss) -b 900000000 (no loss) -b 950000000 (no loss) -b 980000000 (a bit of loss) -b 960000000 (no loss) 输入iperf -h以查看所有命令行选项。 有关更多信息，请参阅Iperf用户手册。 配置多播速度限制 确定最大传输速率后，配置并调整生产系统。 为了获得最佳性能，生产者和消费者应该在不同的机器上运行，每个进程应该至少有一个专用的CPU。 以下是可以提高多播性能的配置更改列表。 请咨询系统管理员，了解如何更改此处讨论的任何限制。 将运行Microsoft Windows的系统的默认数据报大小从1024字节增加到与网络的最大传输单元（MTU）匹配的值，通常为1500字节。 较高的设置应该可以提高系统的网络性能。 默认情况下，禁用堆栈时间探测的分布统计信息以提高组播性能。 要降低多播速度，可以通过将gemfire .enable-time-statistics属性设置为true来启用时间统计。 这将启用Java应用程序的时间统计信息： -Dgemfire.enable-time-statistics=true 时间统计信息属性在gfsh命令行上传递给缓存服务器： gfsh>start server --name=server_name --enable-time-statistics=true 监控接收数据的成员是否有数据丢失迹象。 在区域创建期间可能会发生一些数据丢失消息。 还可以监视多播重传请求和单播重传以检测数据丢失。 即使您看到数据丢失，问题的原因也可能与网络无关。 但是，如果它经常发生，那么你应该再次尝试测试流量控制率 如有必要，重新配置所有gemfire.properties文件，并使用较低的流量控制最大信用重复，直到找到安装的最大有效速率。 通过减少多播消息在网络中的传输速度，可能有助于降低系统性能。 通过禁用批处理来减少多播延迟。 默认情况下，Geode在区域范围为distributed-no-ack时使用批处理操作。 在应用程序上或通过gfsh命令行启动缓存服务器进程时，将disableBatching属性设置为true： gfsh>start server --name=server_name --J=-Dp2p.disableBatching=true 多播的运行时注意事项 使用多播进行消息传递和数据分发时，需要了解运行状况监视设置的工作原理以及如何控制内存使用。 多播健康监视器 Geode管理和监控系统由集群成员的maxRetransmissionRatio健康监控设置补充。 该比率是接收的重传请求数除以写入的多播数据报数。 如果比率为1.0，则成员重新发送与最初发送的数据包一样多的数据包。 重传是点对点的，许多进程可能会请求重传，因此如果出现问题，这个数字可能会很高。 maxRetransmissionRatio的默认值是0.2。 例如，考虑使用多播来传输缓存更新的具有一个生产者和两个缓存事件使用者的集群。 添加了新成员，该成员在未启用多播的计算机上运行。 结果，每次缓存更新都有重发请求，并且maxRetransmissionRatio变为1.0。 控制具有多播的Geode主机上的内存使用 内存不足会影响成员的性能并最终导致严重错误。 当数据通过多播分发时，Geode会产生为传输缓冲区保留的固定内存开销。 为每个分布式区域保留指定数量的内存。 这些生产者端缓冲区仅在接收器没有足够的CPU从生成器发送时快速读取其自己的接收缓冲区时使用。 在这种情况下，接收方抱怨数据丢失。 然后，生产者检索数据，如果它仍然存在于其缓冲区中，则重新发送给接收者。 调整传输缓冲区需要仔细平衡。 较大的缓冲区意味着更多数据可用于重传，在出现问题时提供更多保护。 另一方面，更大量的保留内存意味着可用于缓存的内存更少。 您可以通过重置gemfire.properties文件中的mcast-send-buffer-size参数来调整传输缓冲区大小： mcast-send-buffer-size=45000 注意: 最大缓冲区大小仅受系统限制的约束。 如果您没有看到可能与内存不足相关的问题，请不要更改默认值，因为它可以在出现网络问题时提供更好的保护。 排除多播调整过程 在多播的初始测试和调整过程中可能会出现几个问题。 部分或全部成员无法沟通 如果您的应用程序和缓存服务器无法相互通信，即使它们配置正确，您的网络上也可能没有多播连接。 通常具有单播连接，但不具有多播连接。 见网络管理员。 组播速度比预期慢 寻找以太网流量控制限制。 如果您的混合速度网络导致多播泛洪问题，则以太网硬件可能会尝试减慢快速流量。 确保您的网络硬件可以处理多播流量并有效地路由它。 一些用于处理多播的网络硬件性能不足以支持全面的生产系统。 组播意外失败 例如，如果您通过测试发现多播失败超过了一个整数，它可以达到100 Mbps并且无论如何都会失败，因为它超过网络速率而怀疑它是失败的。 此问题通常出现在其中一个辅助LAN比主网络慢的站点 维护缓存一致性 维护分布式Geode系统中缓存之间的数据一致性对于确保其功能完整性和防止数据丢失至关重要。 一般准则 在使用磁盘存储重新启动区域之前，请考虑整个区域的状态 注意: 如果撤消成员的磁盘存储，请不要在以后使用其磁盘存储 - 隔离 - 重新启动该成员。 Geode存储有关持久数据的信息，并阻止您在正在运行的系统中启动具有已撤销磁盘存储的成员。 但Geode无法阻止您单独启动已撤销的成员，并使用其已撤销的数据运行。 这是不太可能的情况，但可以这样做： 成员A和B正在运行，都将区域数据存储到磁盘。 成员A关闭了。 成员B关闭了。 此时，成员B具有最新的磁盘数据。 成员B不可用。 也许它的主机暂时停机或中断。 要启动并运行系统，请启动成员A，然后使用命令行工具将成员B的状态撤消为具有最新数据的成员。 系统加载成员A的数据，然后你继续前进。 成员A被停止。 此时，成员A和成员B都在其磁盘文件中包含信息，表明它们是黄金副本成员。 如果启动成员B，它将从磁盘加载其数据。 当您启动成员A时，系统将识别不兼容状态并报告异常，但此时，您在两个文件中都有良好的数据，无法将它们组合在一起。 了解缓存事务 了解Geode事务的操作可以帮助您最小化缓存可能不同步的情况。 事务在具有全局范围的分布式区域中不起作用。 事务在一个缓存中提供一致性，但结果到其他成员的分布不一致。 由于读取已提交隔离，缓存中的多个事务可能会产生不一致。 由于多个线程无法参与事务，因此大多数应用程序将运行多个事务。 直接更改键值而不执行put的就地更改可能导致缓存不一致。 对于事务，它会产生额外的困难，因为它会破坏read committed isolation。 如果可能的话，请使用copy-on-read。 在distributed-no-ack范围内，不同成员中的两个冲突事务可以同时提交，在分发更改时互相覆盖。 如果在事务期间存在缓存写入器，则每个事务写入操作都会触发缓存写入器的相关调用。 无论区域的范围如何，事务提交只能在本地缓存中调用缓存编写器，而不能在远程缓存中调用。 具有事务的高速缓存中的区域可能不与没有事务的另一高速缓存中的同名区域保持同步。 在其事务中运行相同操作序列的两个应用程序可能会得到不同的结果。 这可能是因为在其中一个成员的事务外发生的操作可能会覆盖事务，即使在提交过程中也是如此。 如果大事务的结果超出机器的内存或Geode的容量，也可能发生这种情况。 这些限制因机器而异，因此两个成员可能不同步。 多站点部署指南 优化套接字缓冲区大小 在使用网关的多站点安装中，如果未针对最佳吞吐量调整站点之间的链接，则可能导致消息在缓存队列中备份。 如果队列因缓冲区大小不足而溢出，则它将与发送方不同步，接收方将不知道该情况。 您可以通过更改cache.xml文件中的gateway-sender和gateway-receiver元素的socket-buffer-size属性来配置用于数据传输的TCP/IP连接的发送 - 接收缓冲区大小。 通过确定链路带宽来设置缓冲区大小，然后使用ping来测量往返时间。 优化套接字缓冲区大小时，请为网关发送方和网关接收方使用相同的值。 防止主要和次要网关发件人脱机 在多站点安装中，如果主网关服务器脱机，则辅助网关发件人必须接管主要职责作为故障转移系统。 现有的辅助网关发件人检测到主网关发件人已脱机，而辅助网关发件人成为新的主要发件人。 由于队列是分布式的，因此其内容可供所有网关发件人使用。 因此，当辅助网关发送方成为主要网关时，它能够开始处理前一个主网关闭的队列，而不会丢失数据。 如果主网关发件人及其所有辅助发件人都脱机并且邮件在其队列中，则可能会发生数据丢失，因为没有故障转移系统。 验证isOriginRemote是否设置为False 默认情况下，服务器或多站点网关的isOriginRemote标志设置为false，以确保将更新分发给其他成员。 在服务器或接收网关成员中将其值设置为true仅将更新应用于该成员，因此更新不会分发给对等成员。 日志 全面的日志消息可帮助您确认配置和代码中的系统配置和调试问题。 Geode日志如何工作 Apache Geode使用Apache Log4j 2作为其日志记录系统的基础。 了解日志消息及其类别 系统日志消息通常与启动有关; 日志管理; 连接和系统成员; 分配; 或缓存，区域和条目管理。 命名，搜索和创建日志文件 管理和理解日志的最佳方法是让每个成员登录到自己的文件。 设置日志记录 您可以在成员的gemfire.properties中或在启动时使用gfsh配置日志记录。 高级用户 - 为Geode配置Log4j 2 基本Geode日志记录配置是通过gemfire.properties文件配置的。 本主题适用于由于与第三方库集成而需要加强对日志记录的控制的高级用户。 Geode日志如何工作 Apache Geode使用Apache Log4j 2作为其日志记录系统的基础。 Geode使用Apache Log4j 2API和核心库作为其日志记录系统的基础。 Log4j 2 API是一种流行且功能强大的前端日志API，所有Geode类都使用它来生成日志语句。 Log4j 2 Core是一个用于记录的后端实现; 您可以路由任何前端日志记录API库以记录到此后端。 Geode使用Core后端运行两个自定义Log4j 2 Appender：AlertAppender和LogWriterAppender。 Geode已经使用Log4j 2.11进行了测试。 Geode要求log4j-api-2.11.0.jar和log4j-core-2.11.0.jar JAR文件在类路径中。 这两个JAR都分布在/lib目录中，并包含在相应的*-dependencies.jar便利库中。 AlertAppender 是生成Geode警报的组件，然后由JMX管理和监视系统管理。 有关详细信息，请参阅通知联合。 LogWriterAppender 是由所有log-*Geode属性配置的组件，例如log-file，log-file-size-limit和log-disk-space-limit。 这两个appender都是以编程方式创建和控制的。 您可以使用log-*Geode属性以及在JMX管理和监视系统中配置的警报级别来配置其行为。 这些appender目前不支持log4j2.xml配置文件中的配置。 高级用户可能希望定义自己的log4j2.xml。 有关详细信息，请参阅高级用户 - 为Geode配置Log4j 2。 了解日志消息及其类别 系统日志消息通常与启动有关; 日志管理; 连接和系统成员; 分配; 或缓存，区域和条目管理。 启动信息. 描述Java版本，Geode本机版本，主机系统，当前工作目录和环境设置。 这些消息包含有关系统和运行进程的配置的所有信息。 日志管理. 与维护日志文件本身有关。 此信息始终位于主日志文件中（请参阅日志文件名中的讨论）。 连接和系统成员资格. 报告集群成员（包括当前成员）的到达和离开以及与连接活动或故障相关的任何信息。 这包括有关分层缓存中层之间通信的信息。 分布式. 报告系统成员之间的数据分布。 这些消息包括有关区域配置，条目创建和修改以及区域和条目失效和销毁的信息。 缓存，区域和条目管理. 缓存初始化，侦听器活动，锁定和解锁，区域初始化和条目更新。 日志消息的结构 每条日志消息包含： 方括号内的消息头: 消息级别 记录消息的时间 记录消息的连接和线程的ID，可能是主程序或系统管理进程 消息本身，可以是带有异常堆栈跟踪的字符串和/或异常 [config 2005/11/08 15:46:08.710 PST PushConsumer main nid=0x1] Cache initialized using \"file:/Samples/quickstart/xml/PushConsumer.xml\". 日志文件名 在gemfire属性log-file设置中指定Geode系统成员的主日志。 Geode将此名称用于最新的日志文件，如果成员正在运行，则会主动使用，或用于上次运行。 Geode在应用程序启动时创建主日志文件。 默认情况下，主日志包含成员会话的整个日志。 如果指定log-file-size-limit，Geode会将日志记录拆分为以下文件： 主要的当前日志. 保持当前记录条目。 以您在log-file中指定的字符串命名。 子日志. 持有较旧的日志条目。 这些是通过在达到大小限制时重命名主要的当前日志来创建的。 元数据日志文件，带有元名称前缀. 用于跟踪启动，关闭，子日志管理和其他日志记录管理操作 当达到指定的大小限制时，将当前日志重命名或滚动到下一个可用子日志。 当您的应用程序连接启用日志记录时，它会创建主日志文件，如果需要，还会创建meta -日志文件。 如果成员启动时存在主日志文件，则会将其重命名为下一个可用子日志，以便为新日志记录腾出空间。 您当前的主日志文件始终具有您在log-file中指定的名称。 旧日志文件和子日志文件具有从主日志文件名派生的名称。 这些是重命名的日志或子日志文件名的片段，其中filename.extension是log-file规范 如果未使用子日志，则子文件序列号为常量00（两个零）。 对于定位器，日志文件名是固定的。 对于在gfsh中启动的独立定位器，它始终命名为 .log，其中locator_name对应于定位器启动时指定的名称。 对于在另一个成员内部运行的定位器，日志文件是成员的日志文件。 对于应用程序和服务器，您的日志文件规范可以是相对的或绝对的。 如果未指定文件，则默认值为应用程序的标准输出，对于以gfsh启动的服务器的 .log和使用旧缓存服务器脚本启动的服务器的cacheserver.log。 要找出成员最近的活动，请查看meta-日志文件，如果不存在元文件，则查看主日志文件。 系统如何重命名日志 您指定的日志文件是用于所有日志记录和日志记录存档的基本名称。 如果启动时已存在具有指定名称的日志文件，则集群会在创建当前日志文件之前自动重命名该日志文件。 这是使用log-file=system.log进行几次运行后的典型目录列表： bash-2.05$ ls -tlra system* -rw-rw-r-- 1 jpearson users 11106 Nov 3 11:07 system-01-00.log -rw-rw-r-- 1 jpearson users 11308 Nov 3 11:08 system-02-00.log -rw-rw-r-- 1 jpearson users 11308 Nov 3 11:09 system.log bash-2.05$ 第一次运行创建了system.log，时间戳为11月3日11:07。 第二次运行将该文件重命名为system-01-00.log并创建了一个新的system.log，其时间戳为11月3日11:08。 第三次运行将该文件重命名为system-02-00.log，并在此清单中创建了名为system.log的文件。 当集群重命名日志文件时，它会将下一个可用数字分配给新文件，如filename-XX-YY.extension的XX。 下一个可用的数字取决于现有的旧日志文件以及任何旧的统计信息存档。 系统分配的下一个数字高于用于统计或记录的任何数字。 这样可以保持当前日志文件和统计信息存档的配对，而不管目录中旧文件的状态如何。 因此，如果应用程序正在归档统计信息并记录到system.log和statArchive.gfs，并且它在带有这些文件的Unix目录中运行： bash-2.05$ ls -tlr stat* system* -rw-rw-r-- 1 jpearson users 56143 Nov 3 11:07 statArchive-01-00.gfs -rw-rw-r-- 1 jpearson users 56556 Nov 3 11:08 statArchive-02-00.gfs -rw-rw-r-- 1 jpearson users 56965 Nov 3 11:09 statArchive-03-00.gfs -rw-rw-r-- 1 jpearson users 11308 Nov 3 11:27 system-01-00.log -rw-rw-r-- 1 jpearson users 59650 Nov 3 11:34 statArchive.gfs -rw-rw-r-- 1 jpearson users 18178 Nov 3 11:34 system.log 运行后的目录内容如下所示（粗体中更改的文件）： bash-2.05$ ls -ltr stat* system* -rw-rw-r-- 1 jpearson users 56143 Nov 3 11:07 statArchive-01-00.gfs -rw-rw-r-- 1 jpearson users 56556 Nov 3 11:08 statArchive-02-00.gfs -rw-rw-r-- 1 jpearson users 56965 Nov 3 11:09 statArchive-03-00.gfs -rw-rw-r-- 1 jpearson users 11308 Nov 3 11:27 system-01-00.log -rw-rw-r-- 1 jpearson users 59650 Nov 3 11:34 statArchive-04-00.gfs -rw-rw-r-- 1 jpearson users 18178 Nov 3 11:34 system-04-00.log -rw-rw-r-- 1 jpearson users 55774 Nov 4 10:08 statArchive.gfs -rw-rw-r-- 1 jpearson users 17681 Nov 4 10:08 system.log 统计信息和日志文件使用两者都可用的下一个整数重命名，因此在这种情况下，日志文件序列会跳过间隙。 日志级别 日志级别越高，消息越重要和越紧急。 如果您的系统出现问题，则第一级方法是降低日志级别（从而将更多详细消息发送到日志文件）并重新创建问题。 其他日志消息通常有助于发现源。 这些是按降序排列的级别，带有示例输出： severe (highest level). 此级别表示严重故障。 通常，严重消息描述了相当重要的事件，这些事件将阻止正常的程序执行。 您可能需要关闭或重新启动至少部分系统才能纠正这种情况。 通过将系统成员配置为连接到不存在的定位器来产生此严重错误： [severe 2005/10/24 11:21:02.908 PDT nameFromGemfireProperties DownHandler (FD_SOCK) nid=0xf] GossipClient.getInfo(): exception connecting to host localhost:30303: java.net.ConnectException: Connection refused error. 此级别表示系统出现问题。 您应该能够继续运行，但错误消息中记录的操作失败。 这个错误是通过从CacheListener抛出Throwable而产生的。 在将事件分派给客户实现的缓存侦听器时，Geode会捕获侦听器抛出的任何Throwable并将其记录为错误。 这里显示的文本后面是Throwable本身的输出。 [error 2007/09/05 11:45:30.542 PDT gemfire1_newton_18222 nid=0x6d443bb0] Exception occurred in CacheListener warning. 此级别表示潜在问题。 通常，警告消息描述最终用户或系统管理员感兴趣的事件，或指示程序或系统中潜在问题的事件。 此消息是通过在没有服务器运行来创建客户端队列时启动配置了启用排队的池的客户端获得的： [warning 2008/06/09 13:09:28.163 PDT tid=0xe] QueueManager - Could not create a queue. No queue servers available 此消息是通过尝试获取客户端区域中的条目而没有服务器运行来响应客户端请求而获得的： [warning 2008/06/09 13:12:31.833 PDT tid=0x1] Unable to create a connection in the allowed time org.apache.geode.cache.client.NoAvailableServersException at org.apache.geode.cache.client.internal.pooling.ConnectionManagerImpl. borrowConnection(ConnectionManagerImpl.java:166) . . . org.apache.geode.internal.cache.LocalRegion.get(LocalRegion.java:1122 ) info. 这适用于信息性消息，通常面向最终用户和系统管理员。 这是在系统成员启动时创建的典型信息消息。 这表明集群中没有其他`DistributionManager'正在运行，这意味着没有其他系统成员正在运行： [info 2005/10/24 11:51:35.963 PDT CacheRunner main nid=0x1] DistributionManager straw(7368):41714 started on 192.0.2.0[10333] with id straw(7368):41714 (along with 0 other DMs) 当另一个系统成员加入集群时，这些信息消息由已在运行的成员输出： [info 2005/10/24 11:52:03.934 PDT CacheRunner P2P message reader for straw(7369):41718 nid=0x21] Member straw(7369):41718 has joined the distributed cache. 当另一个成员因中断或正常程序终止而离开时： [info 2005/10/24 11:52:05.128 PDT CacheRunner P2P message reader for straw(7369):41718 nid=0x21] Member straw(7369):41718 has left the distributed cache. 当另一名成员被杀时： [info 2005/10/24 13:08:41.389 PDT CacheRunner DM-Puller nid=0x1b] Member straw(7685):41993 has unexpectedly left the distributed cache. config. 这是日志记录的默认设置。 此级别提供静态配置消息，这些消息通常用于调试与特定配置相关的问题。 您可以使用此配置消息来验证启动配置： [config 2008/08/08 14:28:19.862 PDT CacheRunner tid=0x1] Startup Configuration: ack-severe-alert-threshold=\"0\" ack-wait-threshold=\"15\" archive-disk-space-limit=\"0\" archive-file-size-limit=\"0\" async-distribution-timeout=\"0\" async-max-queue-size=\"8\" async-queue-timeout=\"60000\" bind-address=\"\" cache-xml-file=\"cache.xml\" conflate-events=\"server\" conserve-sockets=\"true\" ... socket-buffer-size=\"32768\" socket-lease-time=\"60000\" ssl-ciphers=\"any\" ssl-enabled=\"false\" ssl-protocols=\"any\" ssl-require-authentication=\"true\" start-locator=\"\" statistic-archive-file=\"\" statistic-sample-rate=\"1000\" statistic-sampling-enabled=\"false\" tcp-port=\"0\" udp-fragment-size=\"60000\" udp-recv-buffer-size=\"1048576\" udp-send-buffer-size=\"65535\" fine. 此级别提供开发人员通常感兴趣的跟踪信息。 它用于最低卷，最重要的跟踪消息。 注意: 通常，您应该仅在技术支持的指示下使用此级别。 在此日志记录级别，您将看到许多可能不会表明应用程序出现问题的噪音。 此级别创建非常详细的日志，可能需要比更高级别更多的磁盘空间。 [fine 2011/06/21 11:27:24.689 PDT tid=0xe] SSL Configuration: ssl-enabled = false finer, finest, and all. 这些级别仅供内部使用。 它们会产生大量数据，因此会占用大量磁盘空间和系统资源。 注意:除非技术支持人员要求，否则请勿使用这些设置。 注意: Geode不再支持为VERBOSE日志记录设置系统属性。 要启用VERBOSE日志记录，请参阅高级用户 - 为Geode配置Log4j 2 命名，搜索和创建日志文件 管理和理解日志的最佳方法是让每个成员登录到自己的文件。 日志文件命名建议 对于在同一台机器上运行的成员，您可以让它们通过在不同的工作目录中启动它们并使用相同的相对log-file规范来登录到它们自己的文件。 例如，您可以在/gemfire.properties中设置它： log-file=./log/member.log 然后使用此命令启动每个成员在不同的目录中，该命令指向公共属性文件： java -DgemfirePropertyFile=/gemfire.properties 这样，每个成员在其自己的工作目录下都有自己的日志文件。 搜索日志文件 要获得最清晰的描述，请使用gfsh export logs命令合并日志文件： gfsh> export logs --dir=myDir --dir=myDir --merge-log=true 搜索以这些字符串开头的行： [warning [error [severe 创建自己的日志消息 除系统日志外，您还可以从Java代码中添加自己的应用程序日志。 有关向应用程序添加自定义日志记录的信息，请参阅org.apache.geode.LogWriter接口的联机Java文档。 根据您的日志记录配置设置输出和存储系统和应用程序日志记录。 设置日志记录 您可以在成员的gemfire.properties中或在启动时使用gfsh配置日志记录。 在开始之前，请确保您了解基本配置和编程. 在所有Geode主机上运行NTP等时间同步服务。 这是生成对故障排除有用的日志的唯一方法。 同步时间戳确保可以合并来自不同主机的日志消息，以准确地再现分布式运行的时间顺序历史。 使用嗅探器监视日志查找新的或意外的警告，错误或严重消息。 系统输出的日志具有各自的特征，表明您的系统配置和应用程序的特定行为，因此您必须熟悉应用程序的日志才能有效地使用它们。 根据需要在每个成员的gemfire.properties中配置成员日志记录： # Default gemfire.properties log file settings log-level=config log-file= log-file-size-limit=0 log-disk-space-limit=0 注意: 使用gfsh命令行实用程序启动成员（定位器或服务器）时，也可以指定日志记录参数。 此外，您可以在成员已经运行时使用[alter runtime]修改日志文件属性和日志级别设置(http://geode.apache.org/docs/guide/17/tools_modules/gfsh/command-pages/alter.html#topic_7E6B7E1B972D4F418CB45354D1089C2B) 命令。 设置log-level。 选项是severe（最高级别），error，warning，info，config和fine。 较低级别包括更高级别的设置，因此warning的设置将记录warning，error和severe消息。 对于一般故障排除，我们建议将日志级别设置为config或更高。 fine设置可以很快填满磁盘并影响系统性能。 仅在必要时使用fine。 在log-file中指定日志文件名。 这可以是相对的或绝对的。 如果未指定此属性，则默认值为： 应用程序的标准输出 对于服务器，默认日志文件位置为： working-directory/server-name.log 默认情况下，当通过gfsh启动服务器时，working -directory对应于缓存服务器在启动时创建的目录（以其自身命名）。 或者，您可以在启动缓存服务器时指定其他工作目录路径。 server-name对应于启动时提供的缓存服务器的名称。 对于独立定位器，默认日志文件位置为： working-directory/locator-name.log 默认情况下，当通过gfsh启动定位器时，working-directory对应于定位器启动时创建的目录（以其自身命名）。 或者，您可以在启动定位器时指定其他工作目录路径。 locator-name对应于启动时提供的定位器的名称。 如果使用共置定位器或嵌入式定位器，定位器日志将成为成员日志文件的一部分。 对于最简单的日志检查和故障排除，请将日志发送到文件而不是标准输出。 注意:确保每个成员都记录到自己的文件。 这使日志更容易破译。 在log-file-size-limit中设置单个日志文件的最大大小。 如果未设置，则使用单个主日志文件。 如果设置，则使用元数据文件，主日志和滚动子日志。 在log-disk-space-limit中设置所有日志文件的最大大小。 如果非零，则限制所有非活动日志文件的组合大小，首先删除最旧的文件以保持在限制之下。 零设置表示没有限制。 如果使用gfsh命令行界面，gfsh可以在运行gfsh或gfsh.bat脚本的目录中创建自己的日志文件。 默认情况下，gfsh不会为自己生成日志文件。 要启用gfsh日志，请在启动gfsh之前将以下系统属性设置为所需的日志级别： export JAVA_ARGS=-Dgfsh.log-level=[severe|warning|info|config|fine|finer|finest] gfsh日志文件名为gfsh-0_0.log。 高级用户 - 为Geode配置Log4j 2 基本Geode日志记录配置是通过gemfire.properties文件配置的。 本主题适用于由于与第三方库集成而需要加强对日志记录的控制的高级用户。 Geode使用的默认log4j2.xml作为log4j2-default.xml存储在geode.jar中。 可以在以下位置的产品分发中查看配置的内容：$GEMFIRE/defaultConfigs/log4j2.xml。 要指定您自己的log4j2.xml配置文件（或Log4j 2支持的任何其他内容，如.json或.yaml），请在启动JVM或Geode成员时使用以下标志： -Dlog4j.configurationFile= 如果指定了Java系统属性log4j.configurationFile，则Geode将不使用geode.jar中包含的log4j2-default.xml。 但是，如果配置了alert-level和log-fileGeode属性，Geode仍将创建并注册AlertAppender和LogWriterAppender。 然后，您可以使用Geode LogWriter记录Geode的日志，或者从客户的应用程序和所有第三方库生成警报和接收日志语句。 或者，您可以使用配置为记录到Log4j 2的任何前端日志记录API。 使用不同的前端日志API登录到Log4j2 您还可以配置Log4j 2以使用各种常用和常用的日志记录API。 要获取并配置最常用的前端日志记录API以登录到Log4j 2，请参阅Apache Log4j 2网站上的说明，网址为http://logging.apache.org/log4j/2.x/。 例如，如果您使用： Commons Logging, 下载 “Commons Logging Bridge” (log4j-jcl-2.7.jar) SLF4J, 下载 “SLFJ4 Binding” (log4j-slf4j-impl-2.7.jar) java.util.logging, 下载 “JUL adapter” (log4j-jul-2.7.jar) 有关更多示例，请参阅http://logging.apache.org/log4j/2.x/faq.html。 以上所有三个JAR文件都在Log4J 2.1的完整发行版中，可以在http://logging.apache.org/log4j/2.x/download.html下载。 下载相应的桥接器，适配器或绑定JAR，以确保Geode日志记录与各种第三方库或您自己的应用程序中使用的每个日志记录API集成在一起。 注意: Apache Geode已经使用Log4j 2.1进行了测试。 随着Log4j 2的新版本问世，您可以在该页面上的Previous Releases下找到2.1。 自定义您自己的log4j2.xml文件 高级用户可能希望完全放弃设置log-*gemfire属性，而是使用-Dlog4j.configurationFile指定自己的log4j2.xml。 Geode中的自定义Log4j 2配置附带一些注意事项和注意事项： 不要在log4j2.xml文件中使用“monitorInterval=”，因为这样做会对性能产生重大影响。 此设置指示Log4j 2在运行时监视log4j2.xml配置文件，并在文件更改时自动重新加载和重新配置。 Geode的默认log4j2.xml指定status=“FATAL”，因为当Geode停止其AlertAppender或LogWriterAppender时，Log4j 2的StatusLogger会在ERROR级别生成标准输出警告。 Geode使用大量并发线程来执行带有日志语句的代码; 这些线程可能在Geode appender停止时进行日志记录。 Geode的默认log4j2.xml指定shutdownHook=“disable”因为Geode有一个关闭钩子，它断开DistributedSystem并关闭Cache，它正在执行执行日志记录的代码。 如果Log4J2关闭挂钩在Geode完成关闭之前停止记录，则Log4j 2将尝试开始备份。 此重新启动反过来尝试注册另一个Log4j 2关闭挂钩，该挂钩失败导致Log4j 2记录了FATAL(致命)级别消息。 GEODE_VERBOSE标记（Log4J2标记在http://logging.apache.org/log4j/2.x/manual/markers.html上讨论）可用于在TRACE级别启用其他详细日志语句。 只需启用DEBUG或TRACE即可启用许多日志语句。 但是，通过使用MarkerFilter接受GEODE_VERBOSE，可以进一步启用更多日志语句。 默认的Geodelog4j2.xml使用以下行禁用GEODE_VERBOSE： 您可以通过将onMatch=“DENY”更改为onMatch=“ACCEPT”来启用GEODE_VERBOSE日志语句。 通常，在某些类或包而不是整个Geode产品上简单地启用DEBUG或TRACE更有用。 但是，如果所有其他调试方法都失败，则此设置可用于内部调试目的。 统计 集群中的每个应用程序和服务器都可以访问有关Apache Geode操作的统计数据。 您可以使用gfsh的alter runtime命令或gemfire.properties文件来配置统计信息的收集，以便于系统分析和故障排除。 统计如何运作 加入集群的每个应用程序或缓存服务器都可以收集和存档统计数据以分析系统性能。 瞬态区域和条目统计 对于复制区域，分布区域和本地区域，Geode为区域及其条目提供标准的统计信息集。 应用程序定义和自定义统计 Geode包括用于定义和维护您自己的统计信息的接口。 配置和使用统计信息 您可以通过多种不同方式配置统计信息和统计信息。 查看存档统计信息 统计如何运作 加入集群的每个应用程序或缓存服务器都可以收集和存档统计数据以分析系统性能。 可以为集群，应用程序，服务器或区域启用Geode统计信息。 为集群，应用程序或缓存服务器收集的统计信息将保存到文件中并可以存档，而区域统计信息是暂时的，只能通过API访问。 在gfsh或gemfire.properties配置文件中设置控制集群，应用程序或缓存统计信息收集的配置属性。 您还可以收集自己的应用程序定义统计信息。 当Java应用程序和服务器加入集群时，可以通过集群配置服务对其进行配置，以启用统计信息采样以及是否存档收集的统计信息。 注意: Geode统计信息使用JavaSystem.nanoTimer进行纳秒时序。 该方法提供纳秒精度，但不一定是纳秒精度。 有关更多信息，请参阅用于Geode的JRE的System.nanoTimer的联机Java文档。 统计抽样为正在进行的系统调整和故障排除提 采用默认采样率的采样统计信息（不包括基于时间的统计信息）不会影响整体集群性能。 我们建议在生产环境中启用统计抽样。 我们不建议在生产环境中启用基于时间的统计信息（使用enable-time-statistics属性配置）。 瞬态区域和条目统计 对于复制区域，分布区域和本地区域，Geode为区域及其条目提供标准的统计信息集。 当gfsh的create region命令的--enable-statistics参数设置为true或者在cache.xml中，区域属性statistics-enabled设置为true时，Geode会收集这些统计信息。 注意: 与其他Geode统计信息不同，这些区域和条目统计信息不会存档，也无法绘制。 注意: 启用这些统计信息需要每个条目额外的内存。 请参阅缓存数据的内存要求。 这些是为除分区区域以外的所有区域收集的瞬态统计信息： 命中和错过计数. 对于条目，命中计数是通过Region.get方法访问缓存条目的次数，而未命中计数是这些命中未找到有效值的次数。 对于该地区，这些计数是该地区所有条目的总数。 API为命中和未命中计数提供了`get方法，提供了返回命中率的简便方法，以及将计数归零的方法。 上次访问时间. 对于条目，这是从本地缓存条目检索有效值的最后一次。 对于该地区，这是该地区所有条目的最近“最后访问时间”。 此统计信息用于空闲超时到期活动。 上次修改时间. 对于条目，这是由于加载，创建或放置操作而最后一次更新条目值（直接或通过分发）。 对于该地区，这是该地区所有条目的最近“最后修改时间”。 此统计信息用于生存时间和空闲超时到期活动。 这些统计信息中收集的命中和未命中计数可用于微调系统的缓存。 例如，如果您启用了区域的条目到期，并且看到条目的未命中率与命中率的比例很高，则可以选择增加到期时间。 通过Region和Region.Entry对象的getStatistics方法检索区域和条目统计信息。 应用程序定义和自定义统计 Geode包括用于定义和维护您自己的统计信息的接口。 Geode包org.apache.geode包括以下用于定义和维护自己的统计信息的接口： StatisticDescriptor. 描述个人统计。 每个统计信息都有一个名称和关于它所持有的统计信息的信息，例如它的类类型（long，int等），以及它是一个总是递增的计数器，还是一个可以以任何方式变化的指标。 StatisticsType. 保存StatisticDescriptors列表并提供访问方法的逻辑类型。 StatisticsType包含的StatisticDescriptors每个都在列表中分配一个唯一的ID。 StatisticsType用于创建Statistics实例。 Statistics. 使用设置，递增，获取单个StatisticDescriptor值以及设置回调的实例来实例化现有的StatisticsType对象，该回调将在配置的采样间隔重新计算统计值。 StatisticsFactory. 创建Statistics的实例。 您还可以使用它来创建StatisticDescriptor和StatisticsType的实例，因为它实现了StatisticsTypeFactory。 DistributedSystem是StatisticsFactory的一个实例。 StatisticsTypeFactory. 创建StatisticDescriptor和StatisticsType的实例。 统计信息接口使用包中包含的统计工厂方法进行实例化。 有关编码示例，请参阅StatisticsFactory和`StatisticsTypeFactory的在线Java API文档。 例如，应用程序服务器可能会收集每个客户端会话的统计信息，以便衡量是否以令人满意的方式处理客户端请求。长请求队列或长服务器响应时间可能会提示某些容量管理操作，例如启动其他应用程序服务器。为了进行设置，在StatisticDescriptor实例中标识并定义每个会话状态数据点。一个实例可能是一个RequestsInQueue规范，一个递增和递减的非负整数。另一个可能是RequestCount计数器，一个总是递增的整数。这些描述符的列表用于实例化SessionStateStats StatisticsType。当客户端连接时，应用程序服务器使用StatisticsType对象来创建特定于会话的Statistics对象。然后，服务器使用Statistics方法来修改和检索客户端的统计信息。下图说明了统计接口之间的关系，并显示了此用例的实现。 统计接口 每个StatisticDescriptor都包含一条统计信息。 StatisticalDesriptor对象被收集到StatisticsType中。 实例化StatisticsType以创建Statistics对象。 统计实现 此处显示的StatisticDescriptor对象包含有关客户端会话状态的三条统计信息。 这些被收集到SessionStateStats StatisticsType中。 使用此类型，服务器为每个连接的客户端创建一个Statistics对象。 配置和使用统计信息 您可以通过多种方式配置统计信息和统计信息归档。 配置集群或服务器统计信息 在此过程中，假设您了解基本配置和编程. 执行以下命令以修改集群的配置并启用集群或服务器统计信息。 gfsh>start locator --name=l1 --enable-cluster-configuration=true gfsh>alter runtime --enable-statistics=true -–statistic-archive-file=myStatisticsArchiveFile.gfs 请注意，statistics-archive-file的空值仍会计算统计信息，但它们不会存档到文件中。 您还可以配置采样率和统计存档文件的文件名。 有关更多命令选项，请参阅alter runtime。 或者，如果您不使用集群配置服务，请配置gemfire.properties以进行所需的统计信息监视和归档： 为集群启用统计信息收集。 所有其他统计活动都需要这样做： statistic-sampling-enabled=true statistic-archive-file=myStatisticsArchiveFile.gfs 注意: 以默认采样率（1000毫秒）进行的统计采样不会影响系统性能，建议在生产环境中进行故障排除。 根据需要更改统计采样率。 例如： statistic-sampling-enabled=true statistic-archive-file=myStatisticsArchiveFile.gfs statistic-sample-rate=2000 要将统计信息归档到磁盘，请启用该设置并设置所需的任何文件或磁盘空间限制。 例如： statistic-sampling-enabled=true statistic-archive-file=myStatisticsArchiveFile.gfs archive-file-size-limit=100 archive-disk-space-limit=1000 如果您需要基于时间的统计信息，请启用它。 基于时间的统计数据需要统计抽样和归档。 例如： statistic-sampling-enabled=true statistic-archive-file=myStatisticsArchiveFile.gfs enable-time-statistics=true 注意: 基于时间的统计信息可能会影响系统性能，因此不建议用于生产环境。 如果启用了这些统计信息，则可以通过gfsh show metrics命令访问存档的统计信息。 配置瞬态区域和条目统计信息 在您需要的区域上启用瞬态区域和条目统计信息收集。 此配置与启用集群或服务器统计信息不同。 gfsh example: gfsh>create region --name=myRegion --type=REPLICATE --enable-statistics=true cache.xml 例子: API 例子: 注意: 区域和条目统计信息不归档，只能通过API访问。 根据需要，通过Region和Region.Entry对象的getStatistics方法检索区域和条目统计信息。 例： out.println(\"Current Region:\\n\\t\" + this.currRegion.getName()); RegionAttributes attrs = this.currRegion.getAttributes(); if (attrs.getStatisticsEnabled()) { CacheStatistics stats = this.currRegion.getStatistics(); out.println(\"Stats:\\n\\tHitCount is \" + stats.getHitCount() + \"\\n\\tMissCount is \" + stats.getMissCount() + \"\\n\\tLastAccessedTime is \" + stats.getLastAccessedTime() + \"\\n\\tLastModifiedTime is \" + stats.getLastModifiedTime()); } 配置定制统计 通过cache.xml和API创建和管理所需的任何自定义统计信息。 cache/cluster.xml 例子: // Create custom statistics Stats on the statistic sampler. Total number of samples taken by this sampler. samples Total amount of time spent taking samples. milliseconds API 例子: // Update custom stats through the API this.samplerStats.incInt(this.sampleCountId, 1); this.samplerStats.incLong(this.sampleTimeId, nanosSpentWorking / 1000000); 控制存档文件的大小 您可以使用gfshalter runtime命令为统计信息指定存档文件的限制。 这些是控制领域： 存档文件增长率 --statistic-sample-rate参数控制采样的频率，这会影响存档文件增长的速度。 --statistic-archive-file参数控制是否压缩统计文件。 如果为文件名提供一个.gz后缀，则会对其进行压缩，从而占用较少的磁盘空间。 单个存档文件的最大大小. 如果--archive-file-size-limit的值大于零，则在当前存档的大小超过限制时启动新存档。 一次只能激活一个存档。 注意: 如果在集群运行时修改--archive-file-size-limit的值，则在当前归档变为非活动状态（即启动新归档时）之前，新值不会生效。 所有存档文件的最大大小. --archive-disk-space-limit参数控制所有非活动归档文件的最大大小。 默认情况下，限制设置为0，表示存档空间不受限制。 每当存档变为非活动状态或重命名存档文件时，都会计算非活动文件的组合大小。 如果大小超过--archive-disk-space-limit，则删除具有最早修改时间的非活动归档。 这一直持续到组合尺寸小于极限。 如果--archive-disk-space-limit小于或等于--archive-file-size-limit，当活动归档因其大小而变为非活动状态时，会立即删除它。 注意: 如果在集群运行时修改--archive-disk-space-limit的值，则在当前归档变为非活动状态之前，新值不会生效。 查看存档统计信息 启用采样和存档后，您可以检查存档的历史数据以帮助诊断性能问题。 使用gfshshow metrics命令研究归档文件中的统计信息。 您可能还希望使用单独的统计信息显示实用程序。 故障排除和系统恢复 本节提供了处理常见错误和故障情况的策略。 生成用于故障排除的工件 有几种类型的文件对于故障排除至关重要。 诊断系统问题 本节提供系统问题的可能原因和建议的响应。 系统故障和恢复 本节介绍对各种系统故障的警报和适当的响应。 它还可以帮助您规划数据恢复策略。 使用自动重新连接处理强制缓存断开连接 如果成员在一段时间内没有响应，或者如果网络分区将一个或多个成员分成太小而不能充当集群的组，则可以强制断开Geode成员与集群的连接。 从应用程序和缓存服务器崩溃中恢复 当应用程序或缓存服务器崩溃时，其本地缓存将丢失，并且它所拥有的任何资源（例如，分布式锁定）都将被释放。 成员必须在恢复时重新创建其本地缓存。 从机器崩溃中恢复 当计算机因关闭，断电，硬件故障或操作系统故障而崩溃时，其所有应用程序和缓存服务器及其本地缓存都将丢失。 从冲突的持久数据异常中恢复 启动持久成员时出现ConflictingPersistentDataException表示您有一些持久数据的多个副本，并且Geode无法确定要使用哪个副本。 防止和恢复磁盘完全错误 监视Geode成员的磁盘使用情况非常重要。 如果成员缺少足够的磁盘空间用于磁盘存储，则该成员会尝试关闭磁盘存储及其关联的缓存，并记录错误消息。 由于成员磁盘空间不足而导致的关闭可能导致数据丢失，数据文件损坏，日志文件损坏以及可能对您的应用程序产生负面影响的其他错误情况。 理解和恢复网络中断 对网络中断的最安全响应是重新启动所有进程并调出新数据集。 生成用于故障排除的工件 有几种类型的文件对于故障排除至关重要。 Geode日志和统计信息是故障排除中使用的两个最重要的工件。 此外，它们是Geode系统健康验证和性能分析所必需的。 出于这些原因，应始终启用日志记录和统计信息，尤其是在生产中。 保存以下文件以进行故障排除： 日志文件. 即使在默认日志记录级别，日志也包含可能很重要的数据。 保存整个日志，而不仅仅是堆栈。 为了进行比较，请在问题发生之前，期间和之后保存日志文件。 统计存档文件。 核心文件或堆栈跟踪。 对于Linux，您可以使用gdb从核心文件中提取堆栈。 崩溃转储。 对于Windows，请保存用户模式转储文件。 有些位置要检查这些文件： C:\\ProgramData\\Microsoft\\Windows\\WER\\ReportArchive C:\\ProgramData\\Microsoft\\Windows\\WER\\ReportQueue C:\\Users*UserProfileName*\\AppData\\Local\\Microsoft\\Windows\\WER\\ReportArchive C:\\Users*UserProfileName*\\AppData\\Local\\Microsoft\\Windows\\WER\\ReportQueue 当出现涉及多个进程的问题时，最可能的原因是网络问题。 诊断问题时，请为所涉及的所有集群的每个成员创建一个日志文件。 如果您正在运行客户端/服务器体系结构，请为客户端创建日志文件。 注意: 您必须在所有主机上运行时间同步服务以进行故障排除。 同步时间戳确保可以合并不同主机上的日志消息，以准确地再现分布式运行的时间顺序历史。 对于每个流程，请完成以下步骤： 确保主机的时钟与其他主机同步。 使用时间同步工具，如网络时间协议（NTP）。 通过编辑gemfire.properties来包含以下行，启用日志记录而不是标准输出： log-file=filename 将日志级别保持在config以避免在包含配置信息时填满磁盘。 将此行添加到gemfire.properties： log-level=config 注意: 使用fine的日志级别运行可能会影响系统性能并填满磁盘。 通过修改gemfire.properties为集群启用统计信息收集： statistic-sampling-enabled=true statistic-archive-file=StatisticsArchiveFile.gfs 或者使用gfsh alter rutime命令： alter runtime --group=myMemberGroup --enable-statistics=true --statistic-archive-file=StatisticsArchiveFile.gfs 注意: 以1000毫秒的默认采样率频率收集统计信息不会产生性能开销。 再次运行该应用程序。 检查日志文件。 要获得最清晰的描述，请合并文件。 要查找日志文件中的所有错误，请搜索以这些字符串开头的行： [error [severe 有关合并日志文件的详细信息，请参阅[export logs]的--merge-log参数(http://geode.apache.org/docs/guide/17/tools_modules/gfsh/command-pages/export.html#topic_B80978CC659244AE91E2B8CE56EBDFE3)命令。 导出并分析运行应用程序的成员或成员组上的堆栈跟踪。 使用gfsh export stack-traces命令。 例如： gfsh> export stack-traces --file=ApplicationStackTrace.txt --member=member1 诊断系统问题 本节提供系统问题的可能原因和建议的响应。 定位器无法启动 应用程序或缓存服务器进程无法启动 应用程序或缓存服务器不加入集群 成员流程似乎挂了 成员进程不读取gemfire.properties文件中的设置 缓存创建失败 - 必须与模式定义根匹配 缓存配置不正确 keySetOnServer和containsKeyOnServer的意外结果 数据操作返回PartitionOfflineException 条目未按预期被逐出或过期 找不到日志文件 内存溢出错误 分区区域分布异常 分区区域存储异常 应用程序崩溃而不会产生异常 超时警报 成员生成SocketTimeoutException 成员日志强制关闭ForcedDisconnectException，Cache和DistributedSystem 成员们看不到对方 集群的一部分无法看到另一部分 虽然成员进程正在运行，但数据分发已停止 Distributed-ack操作需要很长时间才能完成 系统性能低下 无法获取Windows性能数据 64位平台上的Java应用程序挂起或使用100％CPU 定位器无法启动 使用gfsh调用定位器失败，出现如下错误： Starting a GemFire Locator in C:\\devel\\gfcache\\locator\\locator The Locator process terminated unexpectedly with exit status 1. Please refer to the log file in C:\\devel\\gfcache\\locator\\locator for full details. Exception in thread \"main\" java.lang.RuntimeException: An IO error occurred while starting a Locator in C:\\devel\\gfcache\\locator\\locator on 192.0.2.0[10999]: Network is unreachable; port (10999) is not available on 192.0.2.0. at org.apache.geode.distributed.LocatorLauncher.start(LocatorLauncher.java:622) at org.apache.geode.distributed.LocatorLauncher.run(LocatorLauncher.java:513) at org.apache.geode.distributed.LocatorLauncher.main(LocatorLauncher.java:188) Caused by: java.net.BindException: Network is unreachable; port (10999) is not available on 192.0.2.0. at org.apache.geode.distributed.AbstractLauncher.assertPortAvailable(AbstractLauncher.java:136) at org.apache.geode.distributed.LocatorLauncher.start(LocatorLauncher.java:596) ... 这表示地址中某处不匹配，用于定位器启动和配置的端口对。 用于定位器启动的地址必须与您在gemfire.properties定位器规范中为定位器列出的地址匹配。 该集群的每个成员（包括定位器本身）都必须在gemfire.properties中具有完整的定位器规范。 解答: 检查您的定位器规范是否包含用于启动定位器的地址。 如果使用绑定地址，则必须使用数字地址作为定位器规范。 绑定地址不会解析为计算机的默认地址。 如果您使用的是64位Linux系统，请检查您的系统是否遇到了闰秒错误。 有关详细信息，请参阅64位平台上的Java应用程序挂起或使用100％CPU。 应用程序或缓存服务器进程无法启动 如果进程尝试启动然后静默消失，则在Windows上这表示存在内存问题。 解答: 在Windows主机上，减小最大JVM堆大小。 此属性在gfsh命令行中指定： gfsh>start server --name=server_name --max-heap=1024m 有关详细信息，请参阅JVM内存设置和系统性能。 如果这不起作用，请尝试重新启动。 应用程序或缓存服务器不加入集群 解答: 检查这些可能的原因。 网络问题 - 最常见的原因。 首先，尝试ping其他主机。 防火墙问题。 如果分布式Geode系统的成员位于LAN外部，请检查防火墙是否阻止通信。 Geode是一个以网络为中心的分布式系统，因此如果您的计算机上运行了防火墙，则可能会导致连接问题。 例如，如果防火墙对基于Java的套接字的入站或出站权限设置了限制，则连接可能会失败。 您可能需要修改防火墙配置以允许流量到您计算机上运行的Java应用程序。 具体配置取决于您使用的防火墙。 使用多播进行成员身份时，组播端口错误。 检查此应用程序或缓存服务器的gemfire.properties文件，以查看是否正确配置了mcast-port。 如果您在站点上运行多个集群，则每个集群都必须使用唯一的多播端口。 无法连接到定位器（使用TCP进行发现时）。 检查此进程的gemfire.properties中的locators属性是否具有正确的定位器IP地址。 检查定位器进程是否正在运行。 如果没有，请参阅相关问题的说明，数据分发已停止，但成员进程正在运行。 在多宿主主机上绑定地址设置不正确。 指定绑定地址时，请使用IP地址而不是主机名。 有时，多个网络适配器配置有相同的主机名。 有关使用绑定地址的详细信息，请参阅拓扑和通信一般概念。 错误的Geode版本。 版本不匹配可能导致进程挂起或崩溃。 使用gemfire version命令检查软件版本。 成员流程似乎挂了 解答: 初始化期间—对于持久性区域，成员可能正在等待具有更新近数据的另一个成员从其磁盘存储启动和加载。 请参阅磁盘存储。 等待初始化完成或超时。 这个过程可能很忙 - 有些缓存有数百万个条目，并且它们可能需要很长时间才能加载。 特别是对于缓存服务器，请查找它，因为它们的区域通常是副本，因此存储区域中的所有条目。 另一方面，应用程序通常仅存储条目的子集。 对于分区区域，如果初始化最终超时并产生异常，则系统架构师需要重新分区数据。 对于正在运行的进程—调查另一个成员是否正在初始化。 在某些可选的集群配置下，可能需要一个进程在其进行之前等待来自其他进程的响应。 成员进程不读取gemfire.properties文件中的设置 进程无法找到配置文件，或者如果是应用程序，则可能正在进行编程配置。 解答: 检查gemfire.properties文件是否在正确的目录中。 确保该进程没有从搜索路径中较早的另一个gemfire.properties文件中获取设置。 Geode按顺序在当前工作目录，主目录和CLASSPATH中查找gemfire.properties文件。 对于应用程序，请检查文档以查看它是否进行了编程配置。 如果是这样，则无法在gemfire.properties文件中重置以编程方式设置的属性。 有关配置更改，请参阅应用程序的客户支持组。 缓存创建失败 - 必须与模式定义根匹配 系统成员启动失败，出现如下错误： Exception in thread \"main\" org.apache.geode.cache.CacheXmlException: While reading Cache XML file:/C:/gemfire/client_cache.xml. Error while parsing XML, caused by org.xml.sax.SAXParseException: Document root element \"client-cache\", must match DOCTYPE root \"cache\". Exception in thread \"main\" org.apache.geode.cache.CacheXmlException: While reading Cache XML file:/C:/gemfire/cache.xml. Error while parsing XML, caused by org.xml.sax.SAXParseException: Document root element \"cache\", must match DOCTYPE root \"client-cache\". Geode声明式缓存创建使用两个根元素对之一：cache或client-cache。 两个地方的名称必须相同。 解答: 修改cache.xml文件，使其具有正确的XML命名空间和模式定义。 对于成员和服务器: ... 对于客户端: ... 缓存配置不正确 空缓存可以是正常情况。 某些应用程序以空缓存开始并以编程方式填充，但其他应用程序则设计为在初始化期间批量加载数据。 解答: 如果您的应用程序应该以完整缓存开始但是空白，请检查以下可能的原因： 无区域—如果缓存没有区域，则进程不会读取缓存配置文件。 检查缓存配置文件的名称和位置是否与gemfire.properties中cache-xml-file属性中配置的名称和位置相匹配。 如果它们匹配，则该过程可能不会读取gemfire.properties。 请参阅成员进程不读取gemfire.properties文件中的设置. 区域没有数据—如果缓存以区域开头但没有数据，则此进程可能没有加入正确的集群。 检查日志文件以查找指示其他成员的消息。 如果您没有看到任何内容，则该进程可能在其自己的集群中单独运行。 在明显属于正确集群的过程中，没有数据的区域可能表示实现设计错误。 keySetOnServer和containsKeyOnServer的意外结果 如果您的服务器区域未配置为分区或复制区域，则客户机对keySetOnServer和containsKeyOnServer的调用可能会返回不完整或不一致的结果。 未分区的非复制服务器区域可能无法保存分布式区域的所有数据，因此这些方法将在数据集的部分视图上运行。 此外，客户端方法对每个方法调用使用负载最小的服务器，因此可以使用不同的服务器进行两次调用。 如果服务器的本地数据集中没有一致的视图，则对客户端请求的响应会有所不同。 只有通过使用分区或复制数据策略设置配置服务器区域，才能保证一致的视图。 服务器系统的非服务器成员可以使用任何允许的配置，因为它们不可用于接收客户端请求。 以下服务器区域配置会产生不一致的结果。 这些配置允许不同服务器上的不同数据。 服务器上没有其他消息传递，因此没有跨服务器的key联合或检查其他服务器的key。 正常 混合（复制，正常，空）单个分布区域。 结果不一致取决于客户端向哪个服务器发送请求 这些配置提供一致的结果： 分区服务器区域 复制的服务器区域 空服务器区域：keySetOnServer返回空集，containsKeyOnServer返回false 解答: 对服务器区域使用分区或复制数据策略。 这是为服务器数据集的客户端提供一致视图的唯一方法。 请参阅区域数据存储和分配选项. 数据操作返回PartitionOfflineException 在持久保存到磁盘的分区区域中，如果有任何成员脱机，则分区区域仍然可用，但可能只有一些存储区仅在脱机磁盘存储区中表示。 在这种情况下，访问存储区条目的方法返回PartitionOfflineException，类似于： org.apache.geode.cache.persistence.PartitionOfflineException: Region /__PR/_B__root_partitioned__region_7 has persistent data that is no longer online stored at these locations: [/192.0.2.1:/export/straw3/users/jpearson/bugfix_Apr10/testCL/hostB/backupDirectory created at timestamp 1270834766733 version 0] 解答: 如果可能的话，将失踪的成员重新联机。 这会将存储桶还原到内存中，您可以再次使用它们。 如果丢失的成员无法重新联机，或者该成员的磁盘存储已损坏，则可能需要撤消该成员，这将允许系统在新成员中创建存储桶并使用这些条目恢复操作。 请参阅处理丢失的磁盘存储. 条目未按预期被逐出或过期 检查这些可能的原因。 事务—如果它们涉及事务，则到期的条目可以保留在缓存中。 此外，事务永远不会超时，因此如果事务挂起，事务中涉及的条目将仍然停留在缓存中。 如果您有一个挂起事务的进程，则可能需要结束该进程以删除该事务。 在您的应用程序编程中，不要让事务处于开放状态。 将所有事务编程为以提交或回滚结束。 分区区域—出于性能原因，逐出区域中的逐出和过期行为会有所不同，并且可能导致条目在您预期之前被删除。 参见逐出 和过期。 找不到日志文件 没有日志文件的操作可能是正常情况，因此该过程不会记录警告。 解答: 检查gemfire.properties中是否配置了log-file属性。 如果没有，则日志记录默认为标准输出，而在Windows上可能根本不可见。 如果正确配置了log-file，则该进程可能不会读取gemfire.properties。 请参阅成员进程不读取gemfire.properties文件中的设置。 内存溢出错误 如果应用程序需要的内存超过进程能够提供的内存，则会获得OutOfMemoryError。 消息包括java.lang.OutOfMemoryError。 解答: 该过程可能正在达到其虚拟地址空间限制。 虚拟地址空间必须足够大，以容纳堆，代码，数据和动态链接库(DLLs)。 如果您的应用程序经常内存不足，您可能需要对其进行分析以确定原因。 如果您怀疑堆大小设置得太低，可以使用-Xmx重置最大堆大小来增加直接内存。 有关详细信息，请参阅JVM内存设置和系统性能. 您可能需要降低线程堆栈大小。 默认的线程堆栈大小非常大：Sparc上的512kb和Intel上的256kb（1.3和1.4 32位JVM），以及64位Sparc 1.4 JVM的1mb; 和1.2k用于1.2 JVM。 如果你有数千个线程，那么你可能会浪费大量的堆栈空间。 如果这是您的问题，则错误可能是这样的： OutOfMemoryError: unable to create new native thread 1.3和1.4中的最小设置为64kb，1.2中的最小设置为32kb。 您可以使用-Xss标志更改堆栈大小，如下所示：-Xss64k 您还可以通过设置区域的输入限制来控制内存使用。 分区区域分布异常 多次尝试完成分布式操作后Geode失败时，会出现org.apache.geode.cache.PartitionedRegionDistributionException。 此异常表示无法找到数据存储成员执行销毁，无效或获取操作。 解答: 检查网络是否存在交通拥堵或与成员断开的连接。 查看问题的整体安装，例如应用程序级别的操作设置为比Geode进程更高的优先级。 如果您一直看到PartitionedRegionDistributionException，则应评估是否需要启动更多成员。 分区区域存储异常 当Geode无法创建新条目时，将显示org.apache.geode.cache.PartitionedRegionStorageException。 此异常源于put和create操作缺少存储空间或者使用加载器进行get操作。 PartitionedRegionStorageException通常表示数据丢失或即将发生的数据丢失。 文本字符串指示异常的原因，如下例所示： Unable to allocate sufficient stores for a bucket in the partitioned region.... Ran out of retries attempting to allocate a bucket in the partitioned region.... 解答: 检查网络是否存在交通拥堵或与成员断开的连接。 看是否存在问题，如设置成比的Geode处理更高优先级的应用程序级的操作整体安装。 如果您继续看到PartitionedRegionStorageException，则应评估是否需要启动更多成员。 应用程序崩溃而不会产生异常 如果应用程序崩溃没有任何异常，这可能是由对象内存问题引起的。 该过程可能会达到其虚拟地址空间限制。 有关详细信息，请参阅OutOfMemoryError. 解答: 通过设置区域的输入限制来控制内存使用。 超时警报 如果分布式消息在指定时间内没有得到响应，它会发送一个警报，表示系统成员可能没有响应的问题。 警报将作为警告记录在发件人日志中。 超时警报可被视为正常。 解答: 如果您看到很多超时并且之前没有看过它们，请检查您的网络是否比较拥挤。 如果在正常操作期间不断看到这些警报，请考虑将ack-wait-threshold提高到默认值15秒以上。 成员生成SocketTimeoutException 当客户端和服务器停止等待来自连接另一端的响应并关闭套接字时，它会产生SocketTimeoutException。 此异常通常发生在握手或建立回调连接时。 解答: 增加成员的默认套接字超时设置。 此超时是为客户端池单独设置的。 对于客户端/服务器配置，请按 中所述调整“读取超时”值或使用org.apache.geode.cache.client.PoolFactory.setReadTimeout方法。 成员日志强制关闭ForcedDisconnectException，Cache和DistributedSystem 如果集群成员的Cache和DistributedSystem生病或者太慢而无法响应心跳请求，则会强制关闭集群成员的Cache和DistributedSystem。 发生这种情况时，侦听器会收到带有FORCED_DISCONNECT操作码的RegionDestroyed通知。 该成员的Geode日志文件显示带有该消息的ForcedDisconnectException This member has been forced out of the cluster because it did not respond within member-timeout milliseconds 解答: 为了最大限度地减少发生这种情况的可能性，可以增加DistributedSystem属性member-timeout。 但请注意，此设置还会控制注意网络故障所需的时间长度。 它不应该设置得太高。 成员们看不到对方 怀疑网络问题或在运输用于存储器和发现的结构的问题。 解答: 检查网络监视工具以查看网络是否已关闭或已泛滥。 如果您使用的是多宿主主机，请确保为所有系统成员设置绑定地址并保持一致。 有关使用绑定地址的详细信息，请参阅拓扑和通信一般概念. 检查所有应用程序和缓存服务器是否使用相同的定位器地址。 集群的一部分无法看到另一部分 这种情况可能会使您的缓存处于不一致状态。 在网络圈中，这种网络中断被称为“裂脑问题”。 解答: 重新启动所有进程以确保数据一致性。 展望未来，设置网络监控工具以快速检测这些类型的中断。 启用网络分区检测。 另请参阅了解和恢复网络中断. 虽然成员进程正在运行，但数据分发已停止 怀疑网络，定位器或多播配置存在问题，具体取决于您的集群使用的传输。 解答: 检查系统成员的运行状况。 在日志中搜索此字符串： Uncaught exception 未捕获的异常意味着严重错误，通常是OutOfMemoryError。参见见OutOfMemoryError. 检查网络监视工具以查看网络是否已关闭或已泛滥。 如果使用多播，请检查现有配置是否不适合当前网络流量。 检查定位器是否已停止。 有关正在使用的定位器的列表，请检查其中一个应用程序gemfire.properties文件中的locators属性。 如果可能，重新启动相同主机上的定位器进程。 集群开始正常运行，数据分发自动重启。 如果必须将定位器移动到其他主机或其他IP地址，请完成以下步骤： 按通常顺序关闭集群的所有成员。 在新位置重新启动定位器进程。 编辑所有gemfire.properties文件以在locators属性中更改此定位器的IP地址。 按常规顺序重新启动应用程序和缓存服务器。 在每个定位器主机上创建一个watchdog守护程序或服务，以在停止时重新启动定位器进程 Distributed-ack操作需要很长时间才能完成 在具有大量distributed-no-ack操作的系统中可能会发生此问题。 也就是说，许多非ack操作的存在可能导致ack操作需要很长时间才能完成。 解答: 有关缓解此问题的信息，请参阅Slow distributed-ack Messages. 系统性能低下 系统性能较慢有时是由于缓冲区大小太小而不能分配对象。 解答: 如果您遇到性能下降并且正在发送大对象（多兆字节），请尝试增加系统中的套接字缓冲区大小设置。 有关更多信息，请参阅套接字通信. 无法获取Windows性能数据 尝试在Windows上运行Geode的性能测量可能会产生以下错误消息： Can't get Windows performance data. RegQueryValueEx returned 5 发生此错误的原因是，当Win32应用程序使用HKEY_PERFORMANCE_DATA调用ANSI版本的RegQueryValueEx Win32 API时，会返回不正确的信息。 Microsoft知识库文章ID 226371中http://support.microsoft.com/kb/226371/en-us中描述了此错误。 解答: 若要成功获取Windows性能数据，您需要验证您是否具有系统注册表中正确的注册表项访问权限。 特别是，确保以下注册表路径中的Perflib可由Geode进程读取（KEY_READ访问）： HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Perflib 性能数据的合理安全性的一个示例是授予管理员KEY_ALL_ACCESS访问权限和交互式用户KEY_READ访问权限。 此特定配置将阻止非管理员远程用户查询性能数据。 有关如何确保Geode进程可以访问与性能相关的注册表项的说明，请参阅http://support.microsoft.com/kb/310426和http://support.microsoft.com/kb/146906。。 64位平台上的Java应用程序挂起或使用100％CPU 如果您的Java应用程序突然开始使用100％CPU，您可能会遇到闰秒错误。 这个错误可以在Linux内核中找到，并且会严重影响Java程序。 特别是，您可能会注意到使用Thread.sleep(n)进行方法调用，其中n是一个小数字，实际上会比该方法定义的时间长得多。 要验证您是否遇到此错误，请检查主机的dmesg输出以获取以下消息： [10703552.860274] Clock: inserting leap second 23:59:60 UTC 要解决此问题，请在受影响的Linux计算机上发出以下命令： prompt> /etc/init.d/ntp stop prompt> date -s \"$(date)\" 有关更多信息，请访问以下网站：http://blog.wpkg.org/2012/07/01/java-leap-second-bug-30-june-1-july-2012-fix/ 系统故障和恢复 本节介绍对各种系统故障的警报和适当的响应。 它还可以帮助您规划数据恢复策略。 如果系统成员由于成员，主机或网络出现故障而不自觉地从集群中退出，则其他成员会自动适应丢失并继续运行。 集群不会遇到任何干扰，例如超时。 规划数据恢复 在规划数据恢复策略时，请考虑以下因素： 区域是否仅配置为数据冗余分区区域。 区域的角色丢失策略配置，它控制区域在崩溃或系统故障之后的行为 - 仅针对分布式区域。 区域是否配置为持久性到磁盘。 失败的程度，涉及多个成员或网络中断。 您的应用程序的特定需求，例如更换数据的难度以及运行应用程序数据不一致的风险。 当由于网络分区或响应缓慢而生成警报时，表示某些进程可能或将要失败。 本节的其余部分提供了各种系统故障的恢复说明。 网络分区，慢响应和成员删除警报 当发生网络分区检测或响应缓慢时，会生成以下警报： 检测到网络分区 成员花了太长时间做出响应 找不到定位器 删除前的警告通知 成员被迫出局 有关配置系统成员以帮助避免出现网络故障时的网络分区配置条件或成员无法相互通信的信息，请参阅了解和恢复网络中断. 检测到网络分区 警报: Membership coordinator id has declared that a network partition has occurred. 描述: 发生网络分区时会发出此警报，然后在单个成员上发出此警报： 警报: Exiting due to possible network partition event due to loss of {0} cache processes: {1} 解答: 检查列出的缓存进程的网络连接和运行状况。 成员太长时间没有回应 警报: 15 sec have elapsed while waiting for replies: on ent(27134):60330/45855 whose current membership list is: [[ent(27134):60330/45855, ent(27130):60333/36743]] 描述: 成员（27130）：60333/36743由于可疑验证失败而面临被迫退出集群的危险。 在达到ack-wait-threshold之后，将在警告级别发出此警报。 解答: 操作员应检查过程以确定其是否健康。 在名为ent的机器上，慢响应器的进程ID是27130。 慢响应者的端口是60333/36743。 查找字符串，Starting distribution manager ent：60333/36743，并检查拥有包含此字符串的日志文件的进程。 警报: 30 sec have elapsed while waiting for replies: on ent(27134):60330/45855 whose current membership list is: [[ent(27134):60330/45855, ent(27130):60333/36743]] 描述: 由于可疑验证失败，成员（27134）有被迫离开集群的危险。 在达到ack-wait-threshold之后且经过ack-severe-alert-threshold秒后，将在严重级别发出此警报。 解答: 操作员应检查过程以确定其是否健康。 慢响应者的进程ID在名为ent的机器上是27134。 慢响应者的端口是60333/36743。 查找字符串，Starting distribution manager ent：60333/36743，并检查拥有包含此字符串的日志文件的进程。 警报: 15 sec have elapsed while waiting for replies: on ent(4592):33593/35174 whose current membership list is: [[ent(4598):33610/37013, ent(4611):33599/60008, ent(4592):33593/35174, ent(4600):33612/33183, ent(4593):33601/53393, ent(4605):33605/41831]] 描述: 当锁定授予者未在ack-wait-threshold和ack-severe-alert-threshold内响应锁定请求时，此警报由具有全局范围的分区区域和区域发出。 解答: 无. 警报: 30 sec have elapsed while waiting for replies: on ent(4598):33610/37013 whose current membership list is: [[ent(4598):33610/37013, ent(4611):33599/60008, ent(4592):33593/35174, ent(4600):33612/33183, ent(4593):33601/53393, ent(4605):33605/41831]] 描述: 当锁定授予者未在ack-wait-threshold和ack-severe-alert-threshold内响应锁定请求时，此警报由全局范围处于严重级别的分区区域和区域发出。 解答: 无. 警报: 30 sec have elapsed waiting for global region entry lock held by ent(4600):33612/33183 描述: 当锁定持有者为ack-wait-threshold + ack-severe-alert-threshold秒保持所需锁定并且可能没有响应时，此警报由全局范围处于严重级别的区域发出。 解答: 无. 警报: 30 sec have elapsed waiting for partitioned region lock held by ent(4600):33612/33183 描述: 当锁定持有者为ack-wait-threshold + ack-severe-alert-threshold秒保持所需的锁定并且可能没有响应时，此警报由严重级别的分区区域发出。 解答: 无. 找不到定位器 注意: 使用定位器的所有进程可能会使用相同的消息退出。 警报: Membership service failure: Channel closed: org.apache.geode.ForcedDisconnectException: There are no processes eligible to be group membership coordinator (last coordinator left view) 描述: 启用网络分区检测，并且存在定位器问题。 解答: 操作员应检查定位器进程和日志，然后重新启动定位器。 警报: Membership service failure: Channel closed: org.apache.geode.ForcedDisconnectException: There are no processes eligible to be group membership coordinator (all eligible coordinators are suspect) 描述: 启用网络分区检测，并且存在定位器问题。 解答: 操作员应检查定位器进程和日志，然后重新启动定位器。 警报: Membership service failure: Channel closed: org.apache.geode.ForcedDisconnectException: Unable to contact any locators and network partition detection is enabled 描述: 启用网络分区检测，并且存在定位器问题。 解答: 操作员应检查定位器进程和日志，然后重新启动定位器。 警报: Membership service failure: Channel closed: org.apache.geode.ForcedDisconnectException: Disconnected as a slow-receiver 描述: 该成员无法足够快地处理消息，并被另一个进程强制断开连接。 解答: 操作员应检查并重新启动断开连接的过程。 删除前的警告通知 警报: Membership: requesting removal of ent(10344):21344/24922 Disconnected as a slow-receiver 描述: 仅在使用慢速接收器功能时才会生成此警报。 解答: 操作员应检查定位器进程和日志。 警报: Network partition detection is enabled and both membership coordinator and lead member are on the same machine 描述: 如果成员协调员和主要成员都在同一台计算机上，则会发出此警报。 解答: 操作员可以通过将系统属性gemfire.disable-same-machine-warnings设置为true来关闭它。 但是，最好在与缓存进程不同的计算机上运行定位器进程，这些进程在启用网络分区检测时充当成员协调器。 成员被迫离开 警报: Membership service failure: Channel closed: org.apache.geode.ForcedDisconnectException: This member has been forced out of the Distributed System. Please consult GemFire logs to find the reason. 描述: 该过程发现它不在集群中，无法确定删除的原因。 成员协调员在无法响应内部“你还活着”的消息后删除了该成员。 解答: 操作员应检查定位器进程和日志。 由于内存不足错误导致重新启动失败 本节介绍停止的系统是使用持久性区域配置的系统时可能发生的重新启动失败。 特别： 恢复系统的某些区域在运行时被配置为PERSISTENT区域，这意味着它们将数据保存到磁盘。 至少一个持久区域被配置为通过将值溢出到磁盘来驱逐最近最少使用（LRU）的数据。 如何从持久区域恢复数据 重启后，数据恢复始终会恢复keys。 您可以配置系统是否以及如何恢复与这些keys关联的值以填充系统缓存。 Value 恢复 在启动期间立即恢复所有值会减慢启动时间，但在“热”缓存启动后会产生一致的读取性能。 恢复没有值意味着更快启动但是“冷”缓存，因此每个值的第一次检索将从磁盘读取。 在后台线程中异步检索值允许在“热”缓存上进行相对快速的启动，最终将恢复每个值。 检索或忽略LRU值 当具有持久LRU区域的系统关闭时，系统不记录最近使用的值。 在后续启动时，如果将值恢复到LRU区域，则它们可能是最近最少使用的而不是最近使用的。 此外，如果在堆或堆外LRU区域上恢复LRU值，则可能会超出LRU内存限制，从而在恢复期间导致OutOfMemoryException。 由于这些原因，LRU值恢复可以与非LRU值不同地处理。 持久区域的默认恢复行为 默认行为是系统恢复所有key，然后异步恢复所有数据值，使LRU值无法恢复。 此默认策略最适合大多数应用程序，因为它在恢复速度和缓存完整性之间取得了平衡。 配置持久区域的恢复 三个Java系统参数允许开发人员控制持久区域的恢复行为： gemfire.disk.recoverValues 缺省 = true, 恢复值. 如果 false, 仅仅恢复 keys, 不恢复值. 如何使用: 当'true时，值的恢复会“加热”缓存，因此数据检索将在缓存中找到它们的值，而不会导致耗时的磁盘访问。 当'false时，缩短恢复时间，以便系统可以更快地使用，但是每个key的第一次检索将需要磁盘读取。 gemfire.disk.recoverLruValues 缺省 = false, 不恢复 LRU 值. 如果 true, 恢复 LRU 值. 如果gemfire.disk.recoverValues 是 false, 则忽略 gemfire.disk.recoverLruValues ,因为没有恢复值. 如何使用: 当'false时，忽略LRU值会缩短恢复时间。 当true`时，将更多数据值恢复到缓存。 恢复LRU值会增加堆内存使用量，并可能导致内存不足错误，从而阻止系统重新启动。 gemfire.disk.recoverValuesSync 缺省=false，通过异步后台进程恢复值。 如果为true，则同步恢复值，并且在检索到所有值之前恢复不完整。 如果gemfire.disk.recoverValues为'false，则忽略gemfire.disk.recoverValuesSync`，因为没有恢复值。 如何使用: 当false时，允许系统更快地变为可用，但是在将所有值从磁盘读入高速缓冲存储器之前必须经过一段时间。 某些key检索需要磁盘访问，有些则不需要。 当'true`时，延长重启时间，但确保在可用时，缓存完全填充，数据检索时间最佳。 使用自动重新连接处理强制缓存断开连接 如果成员在一段时间内没有响应，或者如果网络分区将一个或多个成员分成太小而不能充当集群的组，则Geode成员可能被强制与Geode集群断开连接。 自动连接过程如何工作 从集群断开连接后，Geode成员将关闭，默认情况下会自动重新启动到“重新连接”状态，同时通过联系已知定位器列表定期尝试重新加入集群。 如果成员成功重新连接到已知定位器，该成员将从现有成员重建其集群视图，并接收新的分布式成员标识。 如果该成员无法连接到已知定位器，则该成员将检查它本身是否是定位器（或托管嵌入式定位器进程）。 如果该成员是定位器，则该成员执行基于仲裁的重新连接; 它将尝试在断开连接之前联系成员视图中的法定成员。 如果可以联系法定数量的成员，则允许开始启动集群。 由于重新连接成员不知道哪些成员在网络分区事件中幸存，因此处于重新连接状态的所有成员将保持其UDP单播端口打开并响应ping请求。 使用网络分区检测中使用的相同成员权重系统来确定成员仲裁。 见成员协调员，牵头成员和成员加权. 请注意，当定位器处于重新连接状态时，它不会为集群提供任何发现服务。 重新连接后重新配置缓存的默认设置假定集群配置服务具有有效（XML）配置。 如果使用API调用配置集群，则情况不会如此。 要处理这种情况，请通过将属性设置为禁用自动重新连接 disable-auto-reconnect = true 或者，通过将属性设置为禁用集群配置服务 enable-cluster-configuration = false 缓存重新连接后，应用程序必须获取对新缓存，区域，DistributedSystem和其他工件的引用。 旧引用将继续抛出取消异常，例如CacheClosedException(cause=ForcedDisconnectException)。 有关更多信息，请参阅GeodeDistributedSystem和Cache Java API文档。 管理自动连接过程 默认情况下，Geode成员将尝试重新连接，直到通过使用DistributedSystem.stopReconnecting()或Cache.stopReconnecting()方法告知它停止。 您可以通过将disable-auto-reconnect Geode属性设置为“true”来完全禁用自动重新连接。 您可以使用DistributedSystem和Cache回调方法在重新连接过程中执行操作，或者在必要时取消重新连接过程。 DistributedSystem和CacheAPI提供了几种方法，您可以在成员重新连接到集群时使用这些方法执行操作： DistributedSystem.isReconnecting() 如果成员在其他成员从系统中删除后重新连接并重新创建缓存，则返回true。 DistributedSystem.waitUntilReconnected(long, TimeUnit) 等待一段时间，然后返回一个布尔值，以指示该成员是否已重新连接到DistributedSystem。 使用-1秒的值无限期等待，直到重新连接完成或成员关闭。 使用0秒的值作为快速探测以确定成员是否已重新连接。 DistributedSystem.getReconnectedSystem() 返回重新连接的DistributedSystem。 DistributedSystem.stopReconnecting() 停止重新连接过程并确保DistributedSystem保持断开连接状态。 Cache.isReconnecting() 如果缓存尝试重新连接到集群，则返回true。 Cache.waitForReconnect(long, TimeUnit) 等待一段时间，然后返回一个布尔值，以指示DistributedSystem是否已重新连接。 使用-1秒的值无限期等待，直到重新连接完成或缓存关闭。 使用0秒的值作为快速探测以确定成员是否已重新连接。 Cache.getReconnectedCache() 返回重新连接的Cache。 Cache.stopReconnecting() 停止重新连接过程并确保DistributedSystem保持断开连接状态。 操作员干预 如果在网络连接被修复之前进程或硬件崩溃或以其他方式关闭，您可能需要干预自动连接过程。 在这种情况下，处于“重新连接”状态的成员将无法通过UDP探测器找到丢失的进程，并且在他们能够联系定位器之前不会重新加入系统。 从应用程序和缓存服务器崩溃中恢复 当应用程序或缓存服务器崩溃时，其本地缓存将丢失，并且它所拥有的任何资源（例如，分布式锁定）都将被释放。 成员必须在恢复时重新创建其本地缓存。 使用点对点配置从崩溃中恢复 当成员崩溃时，其余成员继续操作，就好像丢失的应用程序或缓存服务器从未存在过一样。 恢复过程因区域类型和范围以及数据冗余配置而异。 使用客户端/服务器配置从崩溃中恢复 在客户端/服务器配置中，首先使服务器再次作为集群的成员可用，然后尽快重新启动客户端。 客户端通过正常操作从其服务器恢复其数据。 使用点对点配置从崩溃中恢复 当成员崩溃时，其余成员继续操作，就好像丢失的应用程序或缓存服务器从未存在过一样。 恢复过程因区域类型和范围以及数据冗余配置而异。 其他系统成员被告知它已意外离开。 如果任何剩余的系统成员正在等待响应（ACK），则ACK仍然成功并返回，因为仍处于活动状态的每个成员都已响应。 如果丢失的成员拥有GLOBAL条目的所有权，则下一次获得该所有权的尝试就像没有所有者一样。 恢复取决于成员如何配置其缓存。 本节包括以下内容： 分区区域的恢复 分布式区域的恢复 局部范围区域的恢复 从磁盘恢复数据 要判断区域是分区的，分布式的还是本地的，请检查cache.xml文件。 如果文件包含本地范围设置，则该区域与任何其他成员都没有连接： 如果文件包含任何其他范围设置，则它正在配置分布式区域。 例如： 如果文件包含以下任一行，则表示正在配置分区区域。 重新分配的客户端继续顺利运行，如故障转移情况。 成功的重新平衡操作不会造成任何数据丢失。 如果重新平衡失败，则客户端将故障转移到具有正常故障转移行为的活动服务器。 使用客户端/服务器配置从崩溃中恢复 在客户端/服务器配置中，首先使服务器再次作为集群的成员可用，然后尽快重新启动客户端。 客户端通过正常操作从其服务器恢复其数据。 客户端/服务器配置从应用程序或缓存服务器崩溃中恢复的程度取决于服务器可用性和客户端配置。通常，通过在足够的机器上运行足够的服务器来使服务器高度可用，以确保在网络，机器或服务器崩溃的情况下最小的覆盖范围。客户端通常配置为连接到主服务器和一些辅助服务器或冗余服务器。辅助服务器充当主服务器的热备份。对于客户端崩溃情况下的高可用性消息传递，客户端可能与其服务器具有持久连接。如果是这种情况，则部分或全部数据和数据事件将保留在服务器内存中并自动恢复，前提是您在配置的超时内重新启动客户端。有关持久消息传递的信息，请参阅配置客户端/服务器事件消息传递。 从服务器故障中恢复 从服务器故障中恢复有两部分：服务器恢复为集群成员，然后其客户端恢复其服务。 当服务器发生故障时，将按照使用对等配置从崩溃中恢复中所述对集群的任何成员执行自己的恢复。 从客户端的角度来看，如果系统配置为高可用性，则服务器故障不会被检测到，除非有足够的服务器发生故障，服务器到客户端的比率低于可行的水平。 无论如何，您的第一个行动方案是尽快恢复服务器。 要从服务器故障中恢复： 按照使用对等配置从崩溃中恢复中的描述恢复服务器及其数据。 一旦服务器再次可用，定位器（或客户端池，如果您使用的是静态服务器列表）会自动检测其存在并将其添加到可行服务器列表中。 客户端可能需要一段时间才能开始使用已恢复的服务器。 时间部分取决于客户端的配置方式和编程方式。 请参阅客户端/服务器配置。 如果需要在新的主机/端口位置启动服务器 本节仅适用于客户端的服务器池配置使用静态服务器列表的系统。 这很不寻常，但您的系统可能就是这种情况。 如果服务器池配置为没有静态服务器列表，意味着客户端使用定位器来查找其服务器，则在新地址启动服务器不需要特殊操作，因为定位器会自动检测到新服务器。 您可以通过查看客户端cache.xml文件来确定客户端是使用定位器列表还是服务器列表。 使用静态服务器列表配置的系统在元素中列出了元素。 那些使用定位器列表的人使用元素。 如果XML文件中没有声明池，则将在应用程序代码中定义服务器或定位器。 查找API PoolFactory方法addServer或addLocator。 如果池配置了静态服务器列表，则客户端仅连接到列表中提供的特定地址的服务器。 要在新位置移动服务器或添加服务器，必须修改客户端的cache.xml文件中的规范。 此更改仅会影响新启动的客户端。 要开始使用新服务器信息，请重新启动客户端或等待新客户端启动，具体取决于系统特征以及更改生效的速度。 从客户端故障中恢复 当客户端崩溃时，以通常的方式尽快重新启动它。 客户端通过正常操作从其服务器恢复其数据。 一些数据可能会立即恢复，有些数据可能会在客户端请求时懒得恢复。 另外，服务器可以被配置为重放某些数据和某些客户端查询的事件。 这些是影响客户端恢复的不同配置： 条目立即发送给客户—如果这些条目存在于服务器缓存中，则会立即将条目发送到客户端以查找客户端注册的条目。 条目懒惰地发送给客户—条目被懒惰地发送到客户端，用于客户端注册的对于服务器高速缓存中最初不可用的条目。 事件立即发送给客户端—如果服务器一直在为客户端保存事件，则在客户端重新连接时会立即重播这些事件。 保存客户端已注册持久兴趣的条目的缓存修改事件。 如果您将持久客户端配置为连接到多个服务器，请记住，在客户端断开连接时，Geode不会维护服务器冗余。 如果丢失了所有主服务器和辅助服务器，则会丢失客户端的排队消息。 即使服务器一次失败一个，以便运行的客户端有时间进行故障转移并选择新的辅助服务器，离线持久客户端也无法做到这一点，从而丢失其排队的消息。 从机器崩溃中恢复 当计算机因关闭，断电，硬件故障或操作系统故障而崩溃时，其所有应用程序和缓存服务器及其本地缓存都将丢失。 其他计算机上的系统成员会收到通知，说明此计算机的成员已意外离开集群。 恢复程序 要从机器崩溃中恢复： 确定在此计算机上运行的进程。 重新启动机器。 如果Geode定位器在此处运行，请先启动它。 注意: 在启动任何应用程序或缓存服务器之前，必须至少运行一个定位器。 按常规顺序启动应用程序和缓存服务器。 如果必须将定位器进程移动到其他计算机，则在更新gemfire.properties文件中的定位器列表并重新启动集群中的所有应用程序和缓存服务器之前，定位器无用。 但是，如果其他定位器正在运行，则不必立即重新启动系统。 有关正在使用的定位器的列表，请检查其中一个应用程序gemfire.properties文件中的locators属性。 分区区域的数据恢复 无论数据存储重新加入的顺序如何，分区区域都会正确初始化。 应用程序和缓存服务器在返回活动工作时会自动重新创建数据。 如果分区区域配置为数据冗余，则Geode可以自动处理机器崩溃而不会丢失数据，具体取决于有多少冗余副本以及必须重新启动的成员数。 另请参见分区区域恢复. 如果分区区域没有冗余副本，则系统成员通过正常操作重新创建数据。 如果崩溃的成员是应用程序，请检查它是否设计为将其数据写入外部数据源。 如果是，请确定是否可以进行数据恢复，并且最好是从通过Geode集群生成的新数据开始。 分布式区域的数据恢复 应用程序和缓存服务器会自动重新创建数据。 通过副本，磁盘存储文件或新生成的数据进行恢复，如分布式区域恢复中所述。 如果恢复来自磁盘存储，则可能无法获取所有最新数据。 持久性取决于操作系统将数据写入磁盘，因此当计算机或操作系统意外失败时，最后的更改可能会丢失。 为了获得最大程度的数据保护，您可以在网络上设置重复的复制区域，每个复制区域都配置为将其数据备份到磁盘。 假设正确的重启顺序，这种架构显着增加了恢复每次更新的机会。 客户端/服务器配置中的数据恢复 如果崩溃的机器托管了服务器，则服务器如何恢复其数据取决于区域是分区还是分布。 请参阅分区区域的数据恢复和分布式区域的数据恢复视情况而定。 服务器崩溃对其客户端的影响取决于是否为高可用性服务器配置了安装。 有关信息，请参阅使用客户端/服务器配置从崩溃中恢复。 如果崩溃的计算机托管了客户端，请尽快重新启动客户端，并让它从服务器自动恢复其数据。 有关详细信息，请参阅从客户端故障中恢复。 从ConfictingPersistentDataExceptions中恢复 启动持久成员时出现ConflictingPersistentDataException表示您有一些持久数据的多个副本，并且Geode无法确定要使用哪个副本。 通常，Geode使用元数据自动确定要使用的持久数据副本。 除了区域数据外，每个成员还会保留托管该区域的其他成员列表以及他们的数据是否是最新的。 当两个成员比较它们的元数据并发现它不一致时，会发生ConflictingPersistentDataException。 成员要么彼此不了解，要么他们都认为其他成员有陈旧数据。 以下部分描述了可能导致Geode中出现ConflictingPersistentDataException以及如何解决冲突的场景。 独立创建的副本 尝试将两个独立创建的集群合并到一个集群中将导致ConflictingPersistentDataException。 有几种方法可以结束独立创建的系统。 通过让成员连接到彼此不了解的不同定位器来创建两个不同的集群。 关闭所有持久成员，然后启动一组不同的全新持久成员。 Geode不会自动合并同一区域的独立创建数据。 相反，您需要从其中一个系统导出数据并将其导入另一个系统。 有关如何从一个系统导出数据并将其导入的信息，请参阅缓存和区域快照 。 首先开始新成员 在使用持久数据启动旧成员之前启动没有持久数据的全新成员可能会导致ConflictingPersistentDataException。 这可能发生的一种偶然方式是关闭系统，向启动脚本添加新成员，并并行启动所有成员。 偶然的机会，新成员可能会先开始。 问题是新成员将在旧成员启动之前创建一个空的，独立的数据副本。 Geode会像独立创建的副本一样处理这种情况。 在这种情况下，修复只是移动或删除新成员的持久文件，关闭新成员，然后重新启动旧成员。 当旧成员完全恢复时，重新启动新成员。 发生网络故障并禁用网络分区检测 当enable-network-partition-detection设置为默认值true时，Geode将检测网络分区并关闭无法访问的成员，以防止发生网络分区（“裂脑”）。 系统愈合时不会发生冲突。 但是，如果enable-network-partition-detection为false，Geode将不会检测到网络分区。 相反，网络分区的每一端最终都会记录分区的另一侧有陈旧数据。 当分区被修复并且持久成员重新启动时，成员将报告冲突，因为分区的两侧都认为其他成员是陈旧的。 在某些情况下，可以在网络分区的各边之间进行选择，只需从分区的一侧保留数据即可。 否则，您可能需要抢救数据并将其导入新系统。 抢救数据 如果收到ConflictingPersistentDataException，您将无法启动所有成员并让它们加入同一个集群。 您有一些成员有冲突的数据。 首先，查看是否有部分系统可以恢复。 例如，如果您刚刚向系统添加了一些新成员，请尝试启动而不包括这些成员。 对于其余成员，您可以从这些成员上的持久性文件中提取数据并导入数据。 要从持久性文件中提取数据，请使用gfsh export offline-disk-store命令。 gfsh> export offline-disk-store --name=MyDiskStore --disk-dirs=./mydir --dir=./outputdir 这将生成一组快照文件。 可以使用以下命令将这些快照文件导入到正在运行的系统中: gfsh> import data --region=/myregion --file=./outputdir/snapshot-snapshotTest-test0.gfd --member=server1 防止和恢复磁盘完全错误 监视Geode成员的磁盘使用情况非常重要。 如果成员缺少足够的磁盘空间用于磁盘存储，则该成员会尝试关闭磁盘存储及其关联的缓存，并记录错误消息。 由于成员磁盘空间不足而导致的关闭可能导致数据丢失，数据文件损坏，日志文件损坏以及可能对您的应用程序产生负面影响的其他错误情况。 为成员提供足够的磁盘空间后，可以重新启动该成员。 您可以使用以下技术防止磁盘文件错误： 如果您使用的是ext4文件系统，我们建议您预先分配磁盘存储文件和磁盘存储元数据文件。 预分配为这些文件保留磁盘空间，并在磁盘存储区和区域关闭时使成员处于正常状态，允许您在足够的磁盘空间可用后重新启动成员。 默认情况下启用预分配。 配置磁盘的关键使用阈值（磁盘使用警告百分比和磁盘使用关键百分比）。 默认情况下，这些设置为90％用于警告，99％用于关闭缓存的错误。 按照使用磁盘存储优化系统 中的建议，了解常规磁盘管理最佳做法。 当磁盘写入因磁盘已满而导致失败时，该成员将关闭并从集群中删除。 从磁盘完全错误中恢复 如果集群成员由于磁盘已满磁盘故障而失败，请添加或使其他磁盘容量可用，并尝试正常重新启动该成员。 如果该成员未重新启动并且其他成员上的磁盘存储中存在其区域的冗余副本，则可以使用以下步骤还原该成员： 从失败的成员中删除或移动磁盘存储文件。 使用gfshshow missing-disk-stores命令识别任何丢失的数据。 您可能需要手动还原此数据。 使用revoke missing-disk-storegfsh命令撤消丢失的磁盘存储。 重启成员。 有关详细信息，请参阅处理丢失的磁盘存储 。 理解和恢复网络中断 对网络中断的最安全响应是重新启动所有进程并调出新数据集。 但是，如果您很好地了解系统的体系结构，并且确定不会恢复旧数据，则可以选择性地重新启动。 至少，您必须重新启动网络故障一侧的所有成员，因为网络中断会导致无法自动重新加入的单独集群。 网络中断期间会发生什么 当连接集群成员的网络出现故障时，系统成员会将此视为机器崩溃。 网络故障每一方的成员通过从成员列表中删除另一方的成员来做出响应。 如果启用了网络分区检测（默认设置），则包含足够仲裁（基于成员权重的大于51％）的分区将继续运行，而具有足够仲裁的其他分区将关闭。 有关此检测系统如何运行的详细说明，请参阅网络分区。 此外，通过网络分区或由于无响应而断开连接的成员将自动尝试重新连接到集群，除非另有配置。 请参阅使用自动重新连接处理强制缓存断开连接。 恢复程序 对于禁用网络分区检测和/或自动重新连接的部署，要从网络中断中恢复： 根据集群的体系结构确定要重新启动的应用程序和缓存服务器。 假设除数据源之外的任何进程都很糟糕，需要重新启动。 例如，如果外部数据馈送进入一个成员，然后将其重新分发给所有其他成员，则可以使该进程保持运行并重新启动其他成员。 关闭所有需要重新启动的进程。 按通常顺序重新启动它们。 成员在返回活动工作时重新创建数据。 有关详细信息，请参阅从应用程序和缓存服务器崩溃中恢复。 网络故障对分区域的影响 集群的两端继续运行，就好像另一侧的成员没有运行一样。 如果参与分区区域的成员位于网络故障的两侧，则分区区域的两侧也继续运行，就好像另一侧的数据存储不存在一样。 实际上，您现在有两个分区区域。 当网络恢复时，成员可能能够再次看到对方，但是他们无法一起合并到一个集群中并将他们的桶组合回一个分区区域。 您可以确定数据处于不一致状态。 无论您是否配置了数据冗余，您都不知道丢失了哪些数据，哪些数据没有丢失。 即使您有冗余副本并且它们幸存下来，条目的不同副本可能具有反映中断的工作流程和不可访问数据的不同值。 网络故障对分布式区域的影响 默认情况下，集群的两端继续运行，就好像另一侧的成员未运行一样。 但是，对于分布式区域，区域的可靠性策略配置可以更改此默认行为。 当网络恢复时，成员可能能够再次看到对方，但是他们无法一起合并到单个集群中。 网络故障对持久性区域的影响 使用持久性区域时网络故障可能会导致持久数据发生冲突。 恢复系统时，成员启动时可能会遇到ConflictingPersistentDataException。 因此，如果使用持久性区域，则必须将enable-network-partition-detection设置为true。 有关如何从ConflictingPersistentDataException错误中恢复的信息，请参阅从ConfictingPersistentDataExceptions中恢复。 网络故障对客户端/服务器安装的影响 如果客户端失去与其所有服务器的联系，则效果与崩溃时的效果相同。 您需要重新启动客户端。 请参阅从客户端故障中恢复。 如果客户端与某些服务器（但不是所有服务器）失去联系，则对客户端的影响与无法访问的服务器崩溃时的影响相同。 请参阅从服务器故障中恢复。 服务器（如应用程序）是集群的成员，因此网络故障对服务器的影响与应用程序相同。 究竟发生了什么取决于您的网站的配置。 Copyright © WS 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-12-06 11:17:07 "},"Geode_6_Developing_with_Apache_Geode.html":{"url":"Geode_6_Developing_with_Apache_Geode.html","title":"使用Apache Geode进行开发","keywords":"","body":"使用Apache Geode进行开发区域数据存储和分发存储和分配选项区域类型区域数据存储和数据访问器动态创建区域分区区域了解分区配置分区区域配置分区区域的桶数自定义分区和共享数据配置分区区域的高可用性配置对服务器分区区域的单跳客户端访问分布式和复制区域分布式如何运作区域分布式选项复制和预加载的工作原理配置分布式，复制和预加载区域锁定全局区域区域更新的一致性按地区类型检查一致性配置一致性检查一致性检查的开销一致性检查如何适用于复制区域如何解决Destroy和Clear操作 具有一致性区域的事务一般地区数据管理Persistence and Overflow（持久性和溢出） Eviction（逐出）Expiration（到期） 保持缓存与外部数据源同步数据序列化数据序列化概述Geode PDX序列化 Geode数据序列化（DataSerializable和DataSerializer） 标准Java序列化事件和事件处理事件是如何工作实现Geode事件处理程序配置点对点事件消息配置客户端服务器事件消息配置多站点（WAN）事件队列 增量传播增量传播如何工作何时避免增量传播增量传播属性实施增量传播增量传播中的错误增量传播示例查询查询常见问题和示例使用OQL查询 高级查询使用索引连续查询连续查询是如何工作的实现连续查询管理连续查询事务遵守ACID语义 代码示例设计注意事项函数执行函数执行如何工作在Apache Geode中执行一个函数 使用Apache Geode进行开发 使用Apache Geode进行开发解释了使用Apache Geode进行应用程序编程的主要概念。 它描述了如何规划和实现区域，数据序列化，事件处理，增量传播，事务等。 有关Geode REST应用程序开发的信息，请参阅为Apache Geode开发REST应用程序. 区域数据存储和分发 Apache Geode数据存储和分发模型可以在适当的时间将您的数据放在正确的位置。 在开始配置数据区域之前，您应该了解Geode中数据存储的所有选项。 分区区域 除基本区域管理外，分区区域还包括高可用性选项，数据位置控制以及跨集群的数据平衡。 分布式和复制区域 除基本区域管理外，分布式和复制区域还包括推送和分发模型，全局锁定和区域条目版本等选项，以确保Geode成员之间的一致性。 区域更新的一致性 Geode确保区域的所有副本最终在托管该区域的所有成员和客户端上达到一致状态，包括分发区域事件的Geode成员。 一般地区数据管理 对于所有区域，您可以选择控制内存使用，将数据备份到磁盘，并将过时数据保留在缓存之外。 数据序列化 您在Geode中管理的数据必须序列化和反序列化，以便在进程之间进行存储和传输。 您可以选择多个数据序列化选项。 事件和事件处理 Geode为缓存的数据和系统成员事件提供了通用且可靠的事件分发和处理。 增量传播 增量传播允许您通过仅包括对象而不是整个对象的更改来减少通过网络发送的数据量。 查询 Geode提供了一种类似SQL的查询语言OQL，允许您访问存储在Geode区域中的数据。 连续查询 连续查询会不断返回与您设置的查询匹配的事件。 事务 Geode提供了一个事务API，使用begin，commit和rollback方法。 这些方法与熟悉的关系数据库事务方法非常相似。 函数执行 函数是驻留在服务器上的代码体，应用程序可以从客户端或其他服务器调用，而无需自己发送函数代码。 调用者可以指示数据相关函数对特定数据集进行操作，或者可以指示与数据无关的函数在特定服务器，成员或成员组上操作。 区域数据存储和分发 Apache Geode数据存储和分发模型可以在适当的时间将您的数据放在正确的位置。 在配置数据区域之前，您应该了解Geode中数据存储的所有选项。 存储和分配选项 Geode提供了多种数据存储和分发模型，包括分区或复制区域以及分布式或非分布式区域（本地缓存存储）。 区域类型 区域类型定义单个集群中的区域行为。 您可以使用各种区域数据存储和分发选项。 区域数据存储和数据访问器 了解存储区域数据的成员与仅作为区域数据访问者的成员之间的区别。 动态创建区域 您可以在应用程序代码中动态创建区域，并自动在集群成员上实例化它们。 存储和分配选项 Geode提供了多种数据存储和分发模型，包括分区或复制区域以及分布式或非分布式区域（本地缓存存储）。 点对点区域存储和分发 最常见的是，数据管理意味着在应用程序需要的时间和地点提供当前数据。在正确配置的Geode安装中，您将数据存储在本地成员中，Geode会根据您的缓存配置设置自动将其分发给需要它的其他成员。您可能正在存储需要特殊考虑的非常大的数据对象，或者您可能需要仔细配置大量数据以保护应用程序的性能或内存使用。您可能需要能够在特定操作期间显式锁定某些数据。大多数数据管理功能都可以作为配置选项使用，您可以使用gfsh集群配置服务，cache.xml文件或API指定。配置完成后，Geode会自动管理数据。例如，这是您管理数据分发，磁盘存储，数据过期活动和数据分区的方式。通过API在运行时管理一些功能。 在体系结构级别，数据分发在单个群集中的对等体之间以及客户端和服务器之间运行。 点对点提供核心分发和存储模型，这些模型被指定为数据区域上的属性。 对于客户端/服务器，您可以选择在客户端和服务器层之间共享哪些数据区域。 然后，在每个区域内，您可以通过订阅子集来微调服务器自动发送到客户端的数据。 任何类型的安装中的数据存储都基于每个群集的点对点配置。 数据和事件分发基于点对点和系统到系统配置的组合。 存储和分发模型通过缓存和区域属性进行配置。 主要选择是分区，复制或仅分布式。 必须对所有服务器区域进行分区或复制。 每个区域的data-policy和subscription-attributes，如果它不是分区区域，它的scope进行交互以更好地控制数据分发。 在本地缓存中存储数据 要将数据存储在本地缓存中，请使用带有本地状态的RegionShortcut或ClientRegionShortcut的区域refid。 这些会自动将区域data-policy设置为非空策略。 没有存储的区域可以发送和接收事件分发，而无需在应用程序堆中存储任何内容。 使用其他设置，接收的所有输入操作都存储在本地。 区域类型 区域类型定义单个集群中的区域行为。 您可以使用各种区域数据存储和分发选项。 在Geode集群中，您可以定义分布式区域和非分布式区域，并且可以定义其数据分布在集群中的区域，以及其数据完全包含在单个成员中的区域。 您选择的区域类型部分取决于您运行的应用程序类型。 特别是，您需要为服务器和客户端使用特定的区域类型，以便在两个层之间进行有效通信： 服务器区域由服务器在缓存内创建，并由从服务器集群外部连接到服务器的客户端访问。 服务器区域必须具有分区或复制的区域类型。 服务器区域配置使用RegionShortcut枚举设置。 客户端区域由客户端在ClientCache内创建，并配置为在客户端和服务器层之间分发数据和事件。 客户区域必须具有区域类型local。 客户端区域配置使用ClientRegionShortcut枚举设置。 对等区域在Cache内创建。 对等区域可以是服务器区域，或者它们可以是客户端不访问的区域。 对等区域可以具有任何区域类型。 对等区域配置使用RegionShortcut枚举设置。 使用gfsh或cache.xml文件配置服务器或对等区域时，可以使用region shortcuts来定义您所在区域的基本配置。 区域快捷方式提供了一组默认配置属性，这些属性是为各种类型的缓存体系结构设计的。 然后，您可以根据需要添加其他配置属性以自定义应用程序。 有关这些区域快捷方式的更多信息和完整参考，请参阅区域快捷方式参考. 这些是每个数据区域的主要配置选择。 区域类型 描述 最适合... Partitioned 系统范围的数据集设置。 数据被划分为跨定义区域的成员的桶。 为了实现高可用性，请配置冗余副本，以便每个存储桶存储在多个成员中，其中一个成员持有主数据. 服务器区域和对等区域: 1.非常大的数据集; 2.高可用性; 3.写性能; 4.分区事件监听器和数据加载器 Replicated (distributed) 保存分布式区域中的所有数据。 来自分布区域的数据被复制到成员副本区域中。 可以与非复制混合，一些成员持有副本，一些成员持有非副本。 服务器区域和对等区域: 1.阅读繁重的小型数据集; 2.异步分配; 3.查询性能 Distributed non-replicated 数据分布在定义区域的成员之间。 每个成员只保留其表示感兴趣的数据。可以与复制混合，一些成员持有副本，一些成员持有非副本。 对等区域，但不是服务器区域和不是客户区域: 异步分配;查询性能 Non-distributed (local) 该区域仅对定义成员可见。 客户区域和对等区域: 1.应用程序之间未共享的数据 分区区域 对于非常大的服务器区域，分区是一个不错的选择。 分区区域非常适用于数百GB甚至更多的数据集。 注意: 分区区域通常需要比其他区域类型更多的JDBC连接，因为承载数据的每个成员必须具有连接。 分区区域将数据分组到存储桶中，每个存储桶都存储在所有系统成员的子集中。 存储桶中的数据位置不会影响逻辑视图 - 所有成员都会看到相同的逻辑数据集。 使用分区： 大数据集. 存储太大而无法放入单个成员的数据集，并且所有成员都将看到相同的逻辑数据集。 分区区域将数据划分为称为存储区的存储单元，这些存储区分为托管分区区域数据的成员，因此没有成员需要托管所有区域的数据。 Geode提供动态冗余恢复和分区区域的重新平衡，使其成为大规模数据容器的选择。 系统中的更多成员可以在所有主机成员之间实现更均匀的数据平衡，从而允许在添加新成员时扩展系统吞吐量（获取和放置）。 高可用性. 分区区域允许您配置Geode应该创建的数据副本数。 如果成员失败，您的数据将在不中断其他成员的情况下可用。 分区区域也可以持久保存到磁盘以获得额外的高可用性。 可扩展性. 分区区域可以扩展为大量数据，因为数据在可用于托管区域的成员之间划分。 只需添加新成员即可动态增加数据容量。 分区区域还允许您扩展处理能力。 由于您的条目分布在托管区域的成员中，因此对这些条目的读取和写入也会分散在这些成员中。 良好的写性能. 您可以配置数据的副本数量。 每次写入传输的数据量不会随着成员数量的增加而增加。 相反，对于复制区域，每个写入必须发送到具有复制区域的每个成员，因此每次写入传输的数据量随着成员数量的增加而增加。 在分区区域中，您可以在存储桶内和多个分区区域内共存keys。 您还可以控制哪些成员存储哪些数据存储桶。 复制区域 复制区域在吞吐量和延迟方面提供最高性能。 对于中小型服务器区域，复制是一个不错的选择。 使用复制区域： 集群的所有成员都需要少量数据. For example, currency rate information and mortgage rates. 可以完全包含在单个成员中的数据集. 每个复制区域都包含该区域的完整数据集 高性能数据访问. 复制保证了堆对应用程序线程的本地访问，从而为数据访问提供尽可能低的延迟。 异步分发. 所有分布式区域（复制和非复制）都提供最快的分发速度。 分布式，非复制区域 分布式区域提供与复制区域相同的性能，但每个成员仅通过订阅来自其他成员的事件或通过在其缓存中定义数据条目来仅存储其表达兴趣的数据。 使用分布式，非复制区域： 对等区域，但不是服务器区域或客户区域. 服务器的区域必须是复制或分区。 客户区域必须是本地的。 数据集，其中各个成员仅需要通知和更新数据子集的更改. 在非复制区域中，每个成员仅接收其在本地缓存中定义的数据条目的更新事件。 异步分发. 所有分布式区域（复制和非复制）都提供最快的分发速度。 本地区域 注意: 当使用ClientRegionShortcut设置创建时，客户端区域自动定义为本地，因为所有客户端分发活动都来自服务器层。 本地区域没有对等分发活动。 使用本地地区: 客户区域. 分发仅在客户端和服务器层之间进行。 定义成员的私有数据集. 对等成员看不到本地区域。 区域数据存储和数据访问器 了解存储区域数据的成员与仅作为区域数据访问者的成员之间的区别。 在大多数情况下，在成员缓存中定义数据区域时，还要指定该成员是否为数据存储。 存储区域数据的成员称为数据存储或数据主机。 不存储数据的成员称为访问者成员或空成员。 定义区域的任何成员，存储或访问者都可以访问它，将数据放入其中，并从其他成员接收事件。 要配置区域以使成员是数据访问者，请使用不为该区域指定本地数据存储的配置。 否则，该成员是该区域的数据存储。 对于服务器区域，通过在名称中指定包含术语PROXY的区域快捷方式来抑制区域创建时的本地数据存储，例如PARTITION_PROXY或REPLICATE_PROXY。 对于客户端区域，通过指定PROXY区域快捷方式来抑制区域创建时的本地数据存储。 不要使用CACHING_PROXY快捷方式，因为它允许本地数据存储。 动态创建区域 您可以在应用程序代码中动态创建区域，并自动在集群成员上实例化它们。 如果您的应用程序不需要分区区域，则可以使用org.apache.geode.cache.DynamicRegionFactory类动态创建区域，也可以使用cache.xml中的元素创建它们。 定义区域的文件。 见. 由于涉及的选项数量众多，大多数开发人员使用函数在其应用程序中动态创建区域，如本主题中所述。 也可以从gfsh命令行创建动态区域。 有关使用Geode函数的完整讨论，请参阅Function Execution。 函数使用org.apache.geode.cache.execute.FunctionService类。 例如，以下Java类定义并使用函数来创建动态区域： CreateRegionFunction类定义客户端使用FunctionService类的onServer()方法在服务器上调用的函数。 此函数调用通过将条目放入区域属性元数据区域来启动区域创建。 条目key是区域名称，value是用于创建区域的区域属性集。 #CreateRegionFunction.java import org.apache.geode.cache.Cache; import org.apache.geode.cache.CacheFactory; import org.apache.geode.cache.DataPolicy; import org.apache.geode.cache.Declarable; import org.apache.geode.cache.Region; import org.apache.geode.cache.RegionAttributes; import org.apache.geode.cache.RegionFactory; import org.apache.geode.cache.Scope; import org.apache.geode.cache.execute.Function; import org.apache.geode.cache.execute.FunctionContext; import java.util.Properties; public class CreateRegionFunction implements Function, Declarable { private final Cache cache; private final Region regionAttributesMetadataRegion; private static final String REGION_ATTRIBUTES_METADATA_REGION = \"_regionAttributesMetadata\"; public enum Status {SUCCESSFUL, UNSUCCESSFUL, ALREADY_EXISTS}; public CreateRegionFunction() { this.cache = CacheFactory.getAnyInstance(); this.regionAttributesMetadataRegion = createRegionAttributesMetadataRegion(); } public void execute(FunctionContext context) { Object[] arguments = (Object[]) context.getArguments(); String regionName = (String) arguments[0]; RegionAttributes attributes = (RegionAttributes) arguments[1]; // Create or retrieve region Status status = createOrRetrieveRegion(regionName, attributes); // Return status context.getResultSender().lastResult(status); } private Status createOrRetrieveRegion(String regionName, RegionAttributes attributes) { Status status = Status.SUCCESSFUL; Region region = this.cache.getRegion(regionName); if (region == null) { // Put the attributes into the metadata region. The afterCreate call will // actually create the region. this.regionAttributesMetadataRegion.put(regionName, attributes); // Retrieve the region after creating it region = this.cache.getRegion(regionName); if (region == null) { status = Status.UNSUCCESSFUL; } } else { status = Status.ALREADY_EXISTS; } return status; } private Region createRegionAttributesMetadataRegion() { Region metaRegion = this.cache.getRegion(REGION_ATTRIBUTES_METADATA_REGION); if (metaRegion == null) { RegionFactory factory = this.cache.createRegionFactory(); factory.setDataPolicy(DataPolicy.REPLICATE); factory.setScope(Scope.DISTRIBUTED_ACK); factory.addCacheListener(new CreateRegionCacheListener()); metaRegion = factory.create(REGION_ATTRIBUTES_METADATA_REGION); } return metaRegion; } public String getId() { return getClass().getSimpleName(); } public boolean optimizeForWrite() { return false; } public boolean isHA() { return true; } public boolean hasResult() { return true; } public void init(Properties properties) { } } CreateRegionCacheListener类是一个缓存侦听器，它实现了两个方法：afterCreate()和afterRegionCreate()。 afterCreate()方法创建区域。 afterRegionCreate()方法使每个新服务器创建元数据区域中定义的所有区域。 #CreateRegionCacheListener.java import org.apache.geode.cache.Cache; import org.apache.geode.cache.CacheFactory; import org.apache.geode.cache.Declarable; import org.apache.geode.cache.EntryEvent; import org.apache.geode.cache.Region; import org.apache.geode.cache.RegionAttributes; import org.apache.geode.cache.RegionEvent; import org.apache.geode.cache.RegionExistsException; import org.apache.geode.cache.util.CacheListenerAdapter; import java.util.Map; import java.util.Properties; public class CreateRegionCacheListener extends CacheListenerAdapter implements Declarable { private Cache cache; public CreateRegionCacheListener() { this.cache = CacheFactory.getAnyInstance(); } public void afterCreate(EntryEvent event) { createRegion(event.getKey(), event.getNewValue()); } public void afterRegionCreate(RegionEvent event) { Region region = event.getRegion(); for (Map.Entry entry : region.entrySet()) { createRegion(entry.getKey(), entry.getValue()); } } private void createRegion(String regionName, RegionAttributes attributes) { if (this.cache.getLogger().fineEnabled()) { this.cache.getLogger().fine( \"CreateRegionCacheListener creating region named: \" + regionName + \" with attributes: \" + attributes); } try { Region region = this.cache.createRegionFactory(attributes) .create(regionName); if (this.cache.getLogger().fineEnabled()) { this.cache.getLogger().fine(\"CreateRegionCacheListener created: \" + region); } System.out.println(\"CreateRegionCacheListener created: \" + region); } catch (RegionExistsException e) {/* ignore */} } public void init(Properties p) { } } 分区区域 除基本区域管理外，分区区域还包括高可用性选项，数据位置控制以及跨群集的数据平衡。 了解分区 要使用分区区域，您应该了解它们的工作方式以及管理它们的选项。 配置分区区域 规划主机和访问者成员的分区区域的配置和持续管理，并配置启动区域。 配置分区区域的桶数 确定要分配给分区区域的桶数，并相应地设置配置。 自定义分区和数据共置 您可以自定义Apache Geode如何使用自定义分区和数据同地对分区区域数据进行分组。 配置分区区域的高可用性 默认情况下，Apache Geode仅在区域的数据存储中存储分区区域数据的单个副本。 您可以配置Geode以维护分区区域数据的冗余副本，以实现高可用性。 配置对服务器分区区域的单跳客户端访问 单跳数据访问使客户端池能够跟踪分区区域的数据在服务器中的托管位置。 要访问单个条目，客户端将在一个跃点中直接联系承载key的服务器。 重新平衡分区区域数据 在对成员读取或更新并发线程的争用最小的群集中，您可以使用重新平衡来动态增加或减少数据和处理容量。 检查分区中的冗余 在某些情况下，验证分区区域数据是否为冗余并且在成员重新启动时，已跨分区区域成员正确恢复冗余非常重要。 将分区区域数据移动到另一个成员 您可以使用PartitionRegionHelper,moveBucketByKey和moveData方法将分区区域数据从一个成员显式移动到另一个成员。 了解分区 要使用分区区域，您应该了解它们的工作方式以及管理它们的选项。 在操作期间，分区区域看起来像一个大的虚拟区域，具有定义区域的所有成员保持相同的逻辑视图。 对于您定义区域的每个成员，您可以选择允许区域数据存储的空间，包括根本没有本地存储。 无论本地存储多少，该成员都可以访问所有区域数据。 群集可以具有多个分区区域，并且可以将分区区域与分布区域和局部区域混合。 除了具有局部范围的区域之外，对于唯一区域名称的通常要求仍然适用。 单个成员可以托管多个分区区域。 数据分区 Geode自动确定托管分区区域数据的成员中数据的物理位置。 Geode将分区区域数据分解为称为存储区的存储单元，并将每个存储区存储在区域主机成员中。 存储桶根据成员的区域属性设置进行分配。 创建条目时，会将其分配给存储桶。 key组合在一个桶中并始终保留在那里。 如果配置允许，则可以在构件之间移动桶以平衡负载。 您必须运行所需的数据存储以适应分区区域的存储区。 您可以动态启动新的数据存储。 当新数据存储创建区域时，它负责分区区域和成员配置允许的桶数。 您可以自定义Geode如何使用自定义分区和数据同地对分区区域数据进行分组。 分区区域操作 分区区域的运行方式与分区范围的非分区区域非常相似。 大多数标准的Region方法都是可用的，尽管一些通常是本地操作的方法成为分布式操作，因为它们作为一个整体而不是本地缓存在分区区域上工作。 例如，分区区域中的put或create实际上可能不会存储到调用该操作的成员的高速缓存中。 检索任何条目只需要成员之间不超过一跳。 与其他区域一样，分区区域支持客户端/服务器模型。 如果需要将数十个客户端连接到单个分区区域，则使用服务器可以大大提高性能。 有关分区区域的其他信息 请记住有关分区区域的以下内容： 分区区域永远不会异步运行。 分区区域中的操作始终等待来自包含原始数据条目和任何冗余副本的高速缓存的确认。 分区区域需要每个区域数据存储中的缓存加载器（local-max-memory> 0）。 Geode在存储分区区域数据的所有成员之间尽可能均匀地分布数据桶，在您使用的任何自定义分区或数据同地的限制内。 分配区域分配的桶数决定了数据存储的粒度，从而决定了数据的均匀分布。 存储桶的数量是整个群集中整个区域的总数。 在重新平衡该地区的数据时，Geode移动存储桶，但不会在存储桶内移动数据。 您可以查询分区区域，但存在某些限制。 有关详细信息，请参阅查询分区区域 。 配置分区区域 规划主机和访问者成员的分区区域的配置和持续管理，并配置启动区域。 在开始之前，请了解基本配置和编程. 使用PARTITION区域快捷键设置之一启动区域配置。 请参见区域快捷方式和自定义命名区域属性. 如果您需要分区区域的高可用性，请为此配置。 请参见为分区区域配置高可用性. 估算该地区所需的空间量。 如果使用冗余，则这是存储在成员中的所有主副本和副副本的最大值。 例如，冗余为1时，每个区域数据条目需要的空间是没有冗余的两倍，因为条目存储了两次。 请参阅缓存数据的内存要求. 配置该区域的桶总数。 对于同地区域，此数字必须相同。 请参见配置分区区域的桶数. 为区域配置成员的数据存储和数据加载： 您可以让没有本地数据存储的成员和具有不同存储量的成员。 确定此区域的不同成员类型中可用的最大内存。 这些将在partition-attributes local-max-memory中设置。 这是partition-attributes中唯一可以在成员之间变化的设置。 使用这些最大值和您对区域内存要求的估计值来帮助您计算该区域开始的成员数量。 对于存储区域数据的成员(local-max-memory大于0)，定义数据加载器。 请参阅实现数据加载器. 如果您的成员没有本地数据存储（local-max-memory设置为0），请检查系统启动/关闭过程。 当任何没有存储的成员正在运行时，请确保始终至少有一个成员具有本地数据存储。 如果要自定义对区域中的数据进行分区，或者在多个区域之间同地数据，请相应地进行编码和配置。 请参阅了解自定义分区和数据同地. 规划您的分区重新平衡策略并为其配置和编程。 请参阅重新平衡分区区域数据. 注意: 要使用gfsh配置分区区域，请参阅gfsh命令帮助. 配置分区区域的桶数 确定要分配给分区区域的桶数，并相应地设置配置。 分区区域的存储区总数决定了数据存储的粒度，从而决定了数据的均匀分布。 Geode在数据存储中尽可能均匀地分配存储桶。 区域创建后，桶的数量是固定的。 分区属性total-num-buckets设置所有参与成员的整个分区区域的编号。 使用以下之一设置它： XML: Java: RegionFactory rf = cache.createRegionFactory(RegionShortcut.PARTITION); rf.setPartitionAttributes(new PartitionAttributesFactory().setTotalNumBuckets(7).create()); custRegion = rf.create(\"customer\"); gfsh: 使用create region命令的-total-num-buckets参数。 例如： gfsh>create region --name=\"PR1\" --type=PARTITION --total-num-buckets=7 计算分区区域的桶总数 请遵循以下准则来计算分区区域的存储区总数： 使用素数。 这提供了最均匀的分布。 使其至少是您期望为该地区拥有的数据存储数量的四倍。 存储桶与数据存储的比率越大，负载在成员之间的分布越均匀。 但请注意，在负载平衡和开销之间存在折衷。 管理存储桶会带来很大的开销，尤其是冗余级别更高。 您试图避免某些成员拥有的数据条目明显多于其他成员的情况。 例如，比较接下来的两个数字。 该图显示了具有三个数据存储区和七个存储区的区域。 如果以大约相同的速率访问所有条目，则此配置在成员M3中创建热点，其具有比其他数据存储多大约50％的数据。 M3可能是一个缓慢的接收器和潜在的故障点。 配置更多存储桶可使存储桶中的条目更少，数据分布更均衡。 此图使用与以前相同的数据，但将桶数增加到13.现在数据条目的分布更均匀。 自定义分区和共享数据 您可以自定义Apache Geode如何使用自定义分区和数据同地对分区区域数据进行分组。 了解自定义分区和数据同地 自定义分区和数据同地可以单独使用，也可以相互结合使用。 标准自定义分区 默认情况下，Geode使用key上的散列策略将每个数据条目分区到一个存储桶中。 此外，键值对的物理位置从应用程序中抽象出来。 您可以通过提供标准分区解析程序来更改分区区域的这些策略，该分区解析程序将条目映射到称为分区的一组存储区。 固定的自定义分区 默认情况下，Geode使用key上的散列策略将每个数据条目分区到一个存储桶中。 此外，键值对的物理位置从应用程序中抽象出来。 您可以通过提供固定分区解析程序来更改分区区域的这些策略，该解析程序不仅将条目映射到称为分区的一组存储区，还指定哪些成员承载哪些数据存储区。 共享来自不同分区区域的数据 默认情况下，Geode为独立于任何其他分区区域的数据位置的分区区域分配数据位置。 您可以为任何分区区域组更改此策略，以便跨区域相关数据全部由同一成员托管。 某些操作需要进行同地，并通过减少对其他集群成员上托管的条目的数据访问次数来提高其他操作的性能。 了解自定义分区和数据同地 自定义分区和数据同地可以单独使用，也可以相互结合使用。 自定义分区 使用自定义分区将类似条目分组到区域内的区域存储桶中。 默认情况下，Geode根据条目键的哈希码为桶分配新条目。 通过自定义分区，您可以以任何方式将条目分配给存储桶。 如果使用自定义分区对区域内的类似数据进行分组，通常可以获得更好的性能。 例如，如果所有1月帐户数据都由单个成员托管，则在1月创建的所有帐户上运行的查询运行得更快。 为单个客户分组所有数据可以提高处理客户数据的数据操作的性能。 数据感知功能执行还利用了自定义分区。 使用自定义分区，您有两种选择： 标准自定义分区. 使用标准自定义分区，您可以将条目分组到存储区中，但不指定存储区所在的位置。 Geode始终将条目保留在您指定的存储区中，但可以移动存储区以进行负载平衡。 请参阅标准自定义分区 for implementation and configuration details. 固定的自定义分区. 使用固定的自定义分区，您可以指定每个区域条目所在的确切成员。 您将条目分配给分区，然后分配给该分区中的存储桶。 您将特定成员命名为每个分区的主要和辅助主机。 这使您可以完全控制该区域的主要和任何辅助存储桶的位置。 当您希望在特定物理机器上存储特定数据或需要将数据保持在某些硬件元素附近时，这非常有用。 固定分区具有以下要求和注意事项： Geode无法重新平衡固定分区区域数据，因为它无法在主机成员之间移动存储桶。 您必须仔细考虑您创建的分区的预期数据加载。 使用固定分区，主机成员之间的区域配置不同。 每个成员都标识它承载的命名分区，以及它是托管主副本还是主副本。 然后，您可以对固定分区解析程序进行编程以返回分区ID，因此该条目位于右侧成员上。 对于特定分区名称，只有一个成员可以是主要成员，并且该成员不能是该分区的辅助成员。 有关实现和配置细节,请参见固定自定义分区 。 区域之间的数据同地 通过数据同地，Geode在单个成员中存储跨多个数据区域相关的条目。 Geode通过将具有相同ID的所有区域桶一起存储在同一成员中来实现此目的。 在重新平衡操作期间，Geode将这些桶组移动到一起或根本不移动。 因此，例如，如果您有一个区域包含客户联系信息，另一个区域包含客户订单，您可以使用托管将单个客户的所有联系信息和所有订单保存在一个成员中。 这样，对单个客户执行的任何操作都只使用单个成员的缓存。 此图显示了具有数据同地的两个区域，其中数据按客户类型进行分区。 数据同地需要对所有同地区域使用相同的数据分区机制。 您可以使用Geode提供的默认分区或任何自定义分区策略。 您必须在同地区域中使用相同的高可用性设置。 有关实施和配置详细信息，请参阅来自不同分区区域的共存数据。 标准自定义分区 默认情况下，Geode使用key上的散列策略将每个数据条目分区到一个存储桶中。 此外，键值对的物理位置从应用程序中抽象出来。 您可以通过提供以自定义方式映射条目的标准自定义分区解析程序来更改分区区域的这些策略。 注意: 如果要同时进行区域数据和自定义分区，则所有同地区域必须使用相同的自定义分区机制。 请参阅来自不同分区区域的共存数据. 要自定义分区您的区域数据，请执行以下两个步骤： 实现接口 配置区域 实现标准自定义分区 以下列方式之一实现org.apache.geode.cache.PartitionResolver接口，在Geode使用的搜索顺序中列出： 使用自定义类. 在类中实现PartitionResolver，然后在创建区域时将类指定为分区解析器。 使用key的类. 让条目key的类实现PartitionResolver接口。 使用回调参数的类. 让实现你的回调参数的类实现PartitionResolver接口。 使用此实现时，任何和所有Region操作必须是指定回调参数的操作。 实现解析器的getName，init和close方法。 getName的简单实现是 return getClass().getName(); init方法在高速缓存启动时执行与分区解析器任务相关的任何初始化步骤。 仅当使用由gfsh或XML（在cache.xml文件中）配置的自定义类时才会调用此方法。 close方法完成在缓存关闭完成之前必须完成的任何清理。 例如，close可能会关闭分区解析器打开的文件或连接。 实现解析器的getRoutingObject方法以返回每个条目的路由对象。 返回的路由对象的哈希值确定存储桶。 因此，getRoutingObject应该返回一个对象，该对象在通过其hashCode运行时，将分组对象定向到所需的存储桶。 注意: 只有getKey返回的键应该由getRoutingObject使用。 不要在getRoutingObject的实现中使用与键相关联的值或任何其他元数据。 不要使用getOperation或getValue。 实现字符串前缀分区解析器 Geode在org.apache.geode.cache.util.StringPrefixPartitionResolver中提供了基于字符串的分区解析器的实现。 该解析器不需要任何进一步的实现。 它根据key的一部分将条目分组到存储桶中。 所有键必须是字符串，每个键必须包含一个’|’字符，用于分隔字符串。 在键中的’|’分隔符之前的子字符串将由getRoutingObject返回。 配置分区解析程序区域属性 配置区域，以便Geode找到所有区域操作的解析器。 自定义类. 使用以下方法之一指定分区解析程序区域属性： gfsh: 将选项--partition-resolver添加到gfsh create region命令，指定标准自定义分区解析程序的包和类名。 字符串前缀分区解析器的gfsh: 将--partition-resolver = org.apache.geode.cache.util.StringPrefixPartitionResolver选项添加到gfsh create region命令。 Java API: PartitionResolver resolver = new TradesPartitionResolver(); PartitionAttributes attrs = new PartitionAttributesFactory() .setPartitionResolver(resolver).create(); Cache c = new CacheFactory().create(); Region r = c.createRegionFactory() .setPartitionAttributes(attrs) .create(\"trades\"); 字符串前缀分区解析器的Java API: PartitionAttributes attrs = new PartitionAttributesFactory() .setPartitionResolver(new StringPrefixPartitionResolver()).create(); Cache c = new CacheFactory().create(); Region r = c.createRegionFactory() .setPartitionAttributes(attrs) .create(\"customers\"); XML: myPackage.TradesPartitionResolver 字符串前缀分区解析器的XML: org.apache.geode.cache.util.StringPrefixPartitionResolver 如果您的同地数据位于服务器系统中，请将PartitionResolver实现类添加到Java客户端的CLASSPATH中。 对于Java单跳访问，解析器类需要具有零参数构造函数，并且解析器类不能具有任何状态; init方法包含在此限制中。 固定的自定义分区 默认情况下，Geode使用密钥上的散列策略将每个数据条目分区到一个存储桶中。 此外，键值对的物理位置从应用程序中抽象出来。 您可以通过提供固定的自定义分区解析程序来更改分区区域的这些策略，该解析程序不仅将条目映射到称为分区的一组存储区，还指定哪些成员承载哪些数据存储区。 注意: 如果要同时进行区域数据和自定义分区，则所有同地区域必须使用相同的自定义分区机制。 请参阅来自不同分区区域的同地数据. 要自定义分区您的区域数据，请执行以下两个步骤： 实现接口 配置区域 这些步骤根据使用的分区解析程序而有所不同。 实现固定自定义分区 在以下位置之一中实现org.apache.geode.cache.FixedPartitionResolver接口，这些位置在Geode使用的搜索顺序中列出： 自定义类. 在区域创建期间将此类指定为分区解析程序。 条目 key. 对于作为对象实现的键，定义键类的接口。 在缓存回调类中. 在缓存回调的类中实现接口。 使用此实现时，任何和所有Region操作必须是将回调指定为参数的操作。 实现解析器的getName，init和close方法。 getName的简单实现是 return getClass().getName(); init方法在高速缓存启动时执行与分区解析器任务相关的任何初始化步骤。 close方法完成在缓存关闭完成之前必须完成的任何清理。 例如，close可能会关闭分区解析器打开的文件或连接。 实现解析器的getRoutingObject方法以返回每个条目的路由对象。 返回的路由对象的哈希值确定分区内的存储区。 对于每个分区只有一个存储区的固定分区，此方法可以为空。 该实现将分区分配给服务器，以便应用程序完全控制服务器上的分组条目。 注意: 创建路由对象时，只应使用key上的字段。 不要为此目的使用值或其他元数据。 实现getPartitionName方法，根据您希望条目驻留的位置，为每个条目返回分区的名称。 分区中的所有条目都将位于单个服务器上。 此示例根据日期放置数据，每个季度使用不同的分区名称，每个月使用不同的路由对象。 /** * Returns one of four different partition names * (Q1, Q2, Q3, Q4) depending on the entry's date */ class QuarterFixedPartitionResolver implements FixedPartitionResolver { @Override public String getPartitionName(EntryOperation opDetails, Set targetPartitions) { Date date = (Date)opDetails.getKey(); Calendar cal = Calendar.getInstance(); cal.setTime(date); int month = cal.get(Calendar.MONTH); if (month >= 0 && month = 3 && month = 6 && month = 9 && month opDetails) { Date date = (Date)opDetails.getKey(); Calendar cal = Calendar.getInstance(); cal.setTime(date); int month = cal.get(Calendar.MONTH); return month; } @Override public void close() { } } 配置固定自定义分区 为每个成员设置固定分区属性。 这些属性定义成员为区域存储的数据，并且对于不同的成员必须是不同的。 有关属性的定义，请参阅org.apache.geode.cache.FixedPartitionAttributes。 在区域的数据主机成员中定义每个partition-name。 对于每个分区名称，在要托管主副本的成员中，使用is-primary设置为true来定义它。 在要托管辅助副本的每个成员中，使用is-primary设置为false（默认值）来定义它。 辅助数量必须与您为该区域定义的冗余副本数相匹配。 请参见为分区区域配置高可用性. 注意: 分区的存储桶仅由已在其FixedPartitionAttributes中定义分区名称的成员托管。 这些示例将成员的分区属性设置为“Q1”分区数据的主要主机和“Q3”分区数据的辅助主机。 XML: myPackage.QuarterFixedPartitionResolver Java: FixedPartitionAttribute fpa1 = FixedPartitionAttributes .createFixedPartition(\"Q1\", true); FixedPartitionAttribute fpa3 = FixedPartitionAttributes .createFixedPartition(\"Q3\", false, 6); PartitionAttributesFactory paf = new PartitionAttributesFactory() .setPartitionResolver(new QuarterFixedPartitionResolver()) .setTotalNumBuckets(12) .setRedundantCopies(2) .addFixedPartitionAttribute(fpa1) .addFixedPartitionAttribute(fpa3); Cache c = new CacheFactory().create(); Region r = c.createRegionFactory() .setPartitionAttributes(paf.create()) .create(\"Trades\"); gfsh: 您不能使用gfsh指定固定分区解析程序。 如果您的同地数据位于服务器系统中，请将实现FixedPartitionResolver接口的类添加到Java客户端的CLASSPATH中。 对于Java单跳访问，解析器类需要具有零参数构造函数，并且解析器类不能具有任何状态; init方法包含在此限制中。 共享来自不同分区区域的数据 默认情况下，Geode为独立于任何其他分区区域的数据位置的分区区域分配数据位置。 您可以为任何分区区域组更改此策略，以便跨区域相关数据全部由同一成员托管。 某些操作需要进行同地，并通过减少对其他集群成员上托管的条目的数据访问次数来提高其他操作的性能。 分区区域之间的数据同地通常可以提高数据密集型操作的性能。 您可以减少网络跃点，以便对相关数据集进行迭代操作。 数据密集型的计算密集型应用程序可以显着提高整体吞吐量。 例如，如果所有数据都分组在一个成员中，则对患者的健康记录，保险和账单信息运行的查询会更有效。 同样，如果所有交易，风险敏感度和与单个工具相关的参考数据在一起，则金融风险分析应用程序运行得更快。 步骤 将一个区域标识为中心区域，明确地将其他区域中的数据与其区分开来。 如果对任何区域使用持久性，则必须保留中心区域。 在创建其他区域之前创建中心区域，可以在cache.xml或代码中创建。 XML中的区域是在代码中的区域之前创建的，因此如果在XML中创建任何共处区域，则必须先在XML中创建中心区域，然后再创建其他区域。 Geode将在其他人创建时验证其存在，如果中心区域不存在则返回IllegalStateException。 不要向此中心区域添加任何托管规范。 对于所有其他区域，在区域分区属性中，在colocated-with属性中提供中心区域的名称。 使用以下方法之一： XML: ... ... Java: PartitionAttributes attrs = ... Region trades = new RegionFactory().setPartitionAttributes(attrs) .create(\"trades\"); ... attrs = new PartitionAttributesFactory().setColocatedWith(trades.getFullPath()) .create(); Region trade_history = new RegionFactory().setPartitionAttributes(attrs) .create(\"trade_history\"); gfsh: gfsh>create region --name=\"trades\" type=PARTITION gfsh> create region --name=\"trade_history\" --colocated-with=\"trades\" 对于每个同地区域，对与存储区管理相关的这些分区属性使用相同的值： recovery-delay redundant-copies startup-recovery-delay total-num-buckets 如果您自定义分区您的区域数据，请为所有同地区域指定自定义解析程序。 此示例对两个区域使用相同的分区解析程序： XML: myPackage.TradesPartitionResolver myPackage.TradesPartitionResolver Java: PartitionResolver resolver = new TradesPartitionResolver(); PartitionAttributes attrs = new PartitionAttributesFactory() .setPartitionResolver(resolver).create(); Region trades = new RegionFactory().setPartitionAttributes(attrs) .create(\"trades\"); attrs = new PartitionAttributesFactory() .setColocatedWith(trades.getFullPath()).setPartitionResolver(resolver) .create(); Region trade_history = new RegionFactory().setPartitionAttributes(attrs) .create(\"trade_history\"); gfsh: 指定分区解析程序，如[自定义分区您的区域数据]的配置部分所述(https://geode.apache.org/docs/guide/17/developing/partitioned_regions/using_custom_partition_resolvers.html). 如果要在同地区域中保留数据，请保留中心区域，然后根据需要保留其他区域。 对您保留的所有共存区域使用相同的磁盘存储。 配置分区区域的高可用性 默认情况下，Apache Geode仅在区域的数据存储中存储分区区域数据的单个副本。 您可以配置Geode以维护分区区域数据的冗余副本，以实现高可用性。 了解分区区域的高可用性 凭借高可用性，为分区区域托管数据的每个成员都会获得一些主副本和一些冗余（辅助）副本。 配置分区区域的高可用性 为分区区域配置内存中高可用性。 设置其他高可用性选项，例如冗余区域和冗余恢复策略。 了解分区区域的高可用性 凭借高可用性，为分区区域托管数据的每个成员都会获得一些主副本和一些冗余（辅助）副本。 使用冗余时，如果一个成员发生故障，则操作将在分区区域继续运行，而不会中断服务： 如果托管主副本的成员丢失，Geode会将辅助副本作为主副本。 这可能会导致暂时的冗余丢失，但不会导致数据丢失。 只要没有足够的辅助副本来满足冗余，系统就会通过将另一个成员分配为辅助副本并将数据复制到其中来恢复冗余。 注意: 如果足够的成员在足够短的时间内发生故障，您仍然可以在使用冗余时丢失缓存数据。 您可以配置系统在不满足时如何恢复冗余。 您可以将恢复配置为立即执行，或者，如果您希望为替换成员提供启动机会，则可以配置等待期。 在任何分区数据重新平衡操作期间，还会自动尝试冗余恢复。 使用gemfire.MAX_PARALLEL_BUCKET_RECOVERIES系统属性配置并行恢复的最大桶数。 默认情况下，系统尝试恢复冗余时，最多可并行恢复8个存储桶。 如果没有冗余，丢失任何区域的数据存储都会导致丢失某些区域的缓存数据。 通常，当应用程序可以直接从其他数据源读取，或者写入性能比读取性能更重要时，不应使用冗余。 控制你的初级和二级居住地 默认情况下，Geode会为您放置主数据副本和辅助数据副本，从而避免在同一台物理计算机上放置两个副本。 如果没有足够的机器将不同的副本分开，Geode会将副本放在同一台物理计算机上。 您可以更改此行为，因此Geode仅将副本放在不同的计算机上。 您还可以控制哪些成员存储主数据副本和辅助数据副本。 Geode提供两种选择： 固定自定义分区. 为该区域设置此选项。 固定分区使您可以绝对控制托管区域数据的位置。 通过固定分区，您可以为Geode提供代码，该代码为区域中的每个数据条目指定存储桶和数据存储。 将此选项与冗余配合使用时，可以指定主数据存储和辅助数据存储。 固定分区不参与重新平衡，因为您固定了所有存储桶位置。 冗余区域. 此选项在成员级别设置。 冗余区域允许您按成员组或区域分隔主副本副本。 您将每个数据主机分配给区域。 然后Geode将冗余副本放在不同的冗余区域中，就像在不同的物理机器上放置冗余副本一样。 您可以使用此选项在不同的机架或网络中拆分数据副本。此选项允许您动态添加成员并使用重新平衡来重新分配数据负载，并在单独的区域中维护冗余数据。 使用冗余区域时，Geode不会在同一区域中放置两个数据副本，因此请确保您有足够的区域。 在虚拟机中运行进程 默认情况下，Geode将冗余副本存储在不同的计算机上。 在虚拟机中运行进程时，计算机的常规视图将成为VM而非物理计算机。 如果在同一台物理计算机上运行多个VM，则最终可能会将分区区域主存储区存储在单独的VM中，但与第二个存储区位于同一物理计算机上。 如果物理机出现故障，您可能会丢失数据。 在VM中运行时，可以将Geode配置为标识物理计算机并将冗余副本存储在不同的物理计算机上。 在高可用分区区域中进行读写 Geode在高可用性分区区域中对读取和写入的处理方式与在其他区域中不同，因为数据在多个成员中可用： 写操作（如put和create）转到数据键的主要操作，然后同步分发到冗余副本。 事件被发送到配置了subscription-attributes intece-policy设置为all的成员。 读操作会转到任何持有数据副本的成员，并且本地缓存很受欢迎，因此读取密集型系统可以更好地扩展并处理更高的负载。 在此图中，M1正在读取W，Y和Z.它直接从其本地副本获取W. 由于它没有Y或Z的本地副本，因此它会进入缓存，随机选择源缓存。 配置分区区域的高可用性 为分区区域配置内存中高可用性。 设置其他高可用性选项，例如冗余区域和冗余恢复策略。 以下是为分区区域配置高可用性的主要步骤。 请参阅后面的部分了解详情 设置系统应保留区域数据的冗余副本数。 请参阅设置冗余份数. （可选）如果要将数据存储成员分组到冗余区域，请相应地进行配置。 请参见为成员配置冗余区域. （可选）如果希望Geode仅将冗余副本放在不同的物理计算机上，请为此配置。 请参阅设置强制唯一主机. 决定如何管理冗余恢复并根据需要更改Geode的默认行为。 成员崩溃后. 如果要进行自动冗余恢复，请更改其配置。 请参见为分区区域配置成员崩溃冗余恢复. 成员加入后. 如果您不希望立即进行自动冗余恢复，请更改配置。 请参见为分区区域配置成员加入冗余恢复. 确定Geode在执行冗余恢复时应尝试并行恢复的桶数。 默认情况下，系统最多可并行恢复8个存储桶。 使用gemfire.MAX_PARALLEL_BUCKET_RECOVERIES系统属性可以在执行冗余恢复时增加或减少并行恢复的最大桶数。 对于除固定分区区域之外的所有区域，请查看启动重新平衡的点。 冗余恢复在任何重新平衡开始时自动完成。 如果在成员崩溃或加入后没有自动恢复运行，这是最重要的。 请参阅重新平衡分区区域数据. 在运行时，您可以通过添加区域的新成员来添加容量。 对于不使用固定分区的区域，您还可以启动重新平衡操作以在所有成员之间传播区域存储桶。 设置冗余副本数 通过指定要在区域数据存储中维护的辅助副本数，为分区区域配置内存中高可用性。 为成员配置冗余区域 将成员分组到冗余区域，以便Geode将冗余数据副本分成不同的区域。 设置强制唯一主机 将Geode配置为仅使用唯一的物理机器来分区区域数据的冗余副本。 为分区区域配置成员崩溃冗余恢复 配置成员崩溃后是否以及如何在分区区域中恢复冗余。 为分区区域配置成员加入冗余恢复 配置成员加入后是否以及如何在分区区域中恢复冗余。 设置冗余副本数 通过指定要在区域数据存储中维护的辅助副本数，为分区区域配置内存中高可用性。 在分区属性redundant-copies设置中指定分区区域数据所需的冗余副本数。 默认设置为0。 例如: XML: Java: PartitionAttributes pa = new PartitionAttributesFactory().setRedundantCopies(1).create(); gfsh: gfsh>create region --name=\"PR1\" --type=PARTITION --redundant-copies=1 为成员配置冗余区域 将成员分组到冗余区域，以便Geode将冗余数据副本分成不同的区域。 了解如何设置成员的'gemfire.properties`设置。 见参考. 使用gemfire.properties设置redundancy-zone将分区区域主机分组到冗余区域。 例如，如果将冗余设置为1，那么每个数据条目都有一个主副本和一个副副本，则可以通过为每个机架定义一个冗余区域，在两个计算机机架之间拆分主数据副本和辅助数据副本。 为此，您可以在gemfire.properties中为在一个机架上运行的所有成员设置此区域：pre redundancy-zone = rack1 你可以为另一个机架上的所有成员设置这个区域gemfire.properties：pre redundancy-zone = rack2 每个辅助副本都将托管在托管其主要副本的机架对面的机架上。 设置强制唯一主机 将Geode配置为仅使用唯一的物理机器来分区区域数据的冗余副本。 Understand how to set a member’s gemfire.properties settings. See Reference. 配置您的成员，以便Geode始终使用不同的物理机器使用gemfire.properties设置enforce-unique-host来分区区域数据的冗余副本。 此设置的默认值为false。 例子: enforce-unique-host=true 为分区区域配置成员崩溃冗余恢复 配置成员崩溃后是否以及如何在分区区域中恢复冗余。 使用partition属性recovery-delay指定成员崩溃冗余恢复。 恢复延迟分区属性 会员失败后的效果 -1 成员失败后无法自动恢复冗余。 这是默认值。 大于或等于0 在恢复冗余之前成员发生故障后要等待的毫秒数。 默认情况下，成员崩溃后不会恢复冗余。 如果您希望快速重新启动大多数崩溃的成员，将此默认设置与成员加入冗余恢复相结合可以帮助您在成员关闭时避免不必要的数据重排。 通过等待丢失的成员重新加入，使用新启动的成员完成冗余恢复，并且使用较少的处理来更好地平衡分区。 使用以下方法之一设置崩溃冗余恢复： XML: // Give a crashed member 10 seconds to restart // before recovering redundancy Java: PartitionAttributes pa = new PartitionAttributesFactory().setRecoveryDelay(10000).create(); gfsh: gfsh>create region --name=\"PR1\" type=PARTITION --recovery-delay=10000 为分区区域配置成员加入冗余恢复 本节介绍配置成员加入后是否以及如何在分区区域中恢复冗余。 使用partition属性startup-recovery-delay指定成员加入冗余恢复。 startup-recovery-delay的值 成员加入后的效果 -1 新成员上线后无法自动恢复冗余。 使用此值和默认的recovery-delay设置，冗余恢复仅通过重新平衡操作来实现。 long >= 0 成员加入恢复冗余之前等待的毫秒数。 默认值为0（零），只要承载分区区域的成员加入，就会立即执行冗余恢复。 将startup-recovery-delay设置为高于默认值0的值允许多个新成员在冗余恢复开始之前加入。 在恢复期间存在多个成员时，系统将在它们之间扩展冗余恢复。 如果没有延迟，如果紧密连续启动多个成员，则系统可以仅选择为大多数或所有冗余恢复启动的第一个成员。 注意: 满足冗余与增加容量不同。 如果满足冗余，则新成员在调用重新平衡操作之前不会获取桶。 并行恢复实施迅速恢复。 因此，在同时重新启动多个成员时，将startup-recovery-delay配置为适当的值更为重要。 将startup-recovery-delay设置为一个值，确保所有成员在冗余恢复启动之前都已启动并可用。 使用以下方法之一设置加入冗余恢复： XML: // Wait 5 seconds after a new member joins before // recovering redundancy Java: PartitionAttributes pa = new PartitionAttributesFactory().setStartupRecoveryDelay(5000).create(); gfsh: gfsh>create region --name=\"PR1\" --type=PARTITION --startup-recovery-delay=5000 配置对服务器分区区域的单跳客户端访问 单跳数据访问使客户端池能够跟踪分区区域的数据在服务器中的托管位置。 要访问单个条目，客户端将在一个跃点中直接联系承载key的服务器。 了解客户端对服务器分区区域的单跳访问 通过单跳访问，客户端连接到每个服务器，因此通常使用更多连接。 这适用于较小的安装，但是缩放的障碍。 配置客户端对服务器分区区域的单跳访问 配置客户端/服务器系统，以便直接，单跳访问服务器中的分区区域数据。 了解客户端对服务器分区区域的单跳访问 通过单跳访问，客户端连接到每个服务器，因此通常使用更多连接。 这适用于较小的安装，但是缩放的障碍。 如果您具有包含许多客户端的大型安装，则可能需要通过在池声明中将池属性pr-single-hop-enabled设置为false来禁用单跳。 如果没有单跳，客户端将使用任何可用的服务器连接，与所有其他操作相同。 接收请求的服务器确定数据位置并与主机联系，主机可能是不同的服务器。 因此，对服务器系统进行了更多的多跳请求。 注意: 单跳用于以下操作：put，get，destroy，putAll，getAll，removeAll和onRegion函数执行。 即使启用了单跳访问，您偶尔也会看到一些多跳行为。 要执行单跳数据访问，客户端会自动从服务器获取有关托管条目所在位置的元数据。 元数据是懒惰的。 它仅在单跳操作最终需要多跳之后更新，这是客户端中陈旧元数据的指示。 单跳和池最大连接设置 不要在启用单跳的情况下设置池的max-connections设置。 使用单跳限制池的连接可能会导致连接抖动，吞吐量丢失和服务器日志膨胀。 如果您需要限制池的连接，请禁用单跳或密切关注系统中的这些负面影响。 但是，对连接设置无限制可能会导致与服务器的连接过多，从而可能导致您遇到系统的文件句柄限制。 检查您预期的连接使用情况，并确保您的服务器能够容纳它。 平衡单跳服务器连接使用 当您的服务器之间的数据访问平衡良好时，单跳可带来最大的好处。 特别是，如果您将这些负载组合在一起，客户端/服务器连接的负载可能会失去平衡： 作为空数据访问器或不承载客户端通过单键操作访问的数据的服务器 来自客户的许多单键操作 如果数据访问大大失衡，客户端可能会尝试访问数据服务器。 在这种情况下，禁用单跳并通过不托管数据的服务器可能会更快。 配置客户端对服务器分区区域的单跳访问 配置客户端/服务器系统，以便直接，单跳访问服务器中的分区区域数据。 这需要在服务器上使用一个或多个分区区域的客户端/服务器安装。 验证客户端的池属性，未设置pr-single-hop-enabled或设置为true。 默认情况下是这样。 如果可能，将池的max-connections保留为默认的无限设置（-1）。 如果可能，请使用自定义数据解析程序根据客户端的数据使用模式对服务器区域数据进行分区。 请参阅自定义 - 分区您的区域数据. 在客户端的CLASSPATH中包含服务器的分区解析器实现。 服务器为每个自定义分区区域传递解析程序的名称，因此客户端使用正确的分区。 如果服务器不使用分区解析器，则服务器和客户端之间的默认分区匹配，因此单跳工作。 将单跳注意事项添加到整个服务器负载平衡计划中。 单跳使用数据位置而不是最少加载的服务器来选择服务器以进行单键操作。 不均衡的单跳数据访问会影响整体客户端/服务器负载平衡。 一些平衡是自动完成的，因为具有更多单键操作的服务器变得更加负载，并且不太可能被挑选用于其他操作。 重新平衡分区区域数据 在对成员读取或更新并发线程的争用最小的群集中，您可以使用重新平衡来动态增加或减少数据和处理容量。 重新平衡是一项成员操作。 它会影响成员定义的所有分区区域，无论成员是否承载区域的数据。 重新平衡操作执行两项任务： 如果不满足配置的分区区域冗余，则重新平衡会尽其所能来恢复冗余。 请参见为分区区域配置高可用性. 重新平衡根据需要在主机成员之间移动分区区域数据桶，以在集群中建立最公平的数据和行为平衡。 为了提高效率，在启动多个成员时，在添加所有成员后，一次触发重新平衡。 注意: 如果您的系统中正在运行事务，请务必规划重新平衡操作。 重新平衡可能会在成员之间移动数据，这可能会导致正在运行的事务失败并出现TransactionDataRebalancedException。 修复了自定义分区，完全阻止了重新平衡。 除非您在不同时间运行事务和重新平衡操作，否则所有其他数据分区策略都允许重新平衡并导致此异常。 使用以下方法之一启动重新平衡： gfsh命令。 首先，启动gfsh提示并连接到集群。 然后键入以下命令： gfsh>rebalance （可选）您可以指定要在重新平衡中包含或排除的区域，为重新平衡操作指定超时或仅模拟重新平衡操作. 输入help rebalance或查看rebalance 以获取更多信息。 API 调用: ResourceManager manager = cache.getResourceManager(); RebalanceOperation op = manager.createRebalanceFactory().start(); //Wait until the rebalance is complete and then get the results RebalanceResults results = op.getResults(); //These are some of the details we can get about the run from the API System.out.println(\"Took \" + results.getTotalTime() + \" milliseconds\\n\"); System.out.println(\"Transfered \" + results.getTotalBucketTransferBytes()+ \"bytes\\n\"); 您还可以通过API模拟重新平衡，以查看是否值得运行： ResourceManager manager = cache.getResourceManager(); RebalanceOperation op = manager.createRebalanceFactory().simulate(); RebalanceResults results = op.getResults(); System.out.println(\"Rebalance would transfer \" + results.getTotalBucketTransferBytes() +\" bytes \"); System.out.println(\" and create \" + results.getTotalBucketCreatesCompleted() + \" buckets.\\n\"); 分区区域重新平衡的工作原理 重新平衡操作以异步方式运行。 默认情况下，一次在一个分区区域上执行重新平衡。 对于具有共处置数据的区域，重新平衡作为一个组在区域上工作，维护区域之间的数据共置。 您可以选择通过设置gemfire.resource.manager.threads系统属性来并行重新平衡多个区域。 将此属性设置为大于1的值可使Geode在使用API启动重新平衡操作时并行重新平衡多个区域。 在重新平衡正在进行时，您可以继续正常使用分区区域。 数据移动时，继续执行读操作，写操作和函数执行。 如果函数正在本地数据集上执行，则在函数执行期间，如果该数据移动到另一个主机，则可能会出现性能下降。 将来的函数调用将路由到正确的成员。 Geode尝试确保每个成员具有与每个分区区域相同的可用空间百分比。 百分比在partition-attributes和local-max-memory设置中配置。 分区重新平衡： 除非通过溢出到磁盘启用LRU驱逐，否则不允许超出local-max-memory设置。 尽可能将同一存储桶的多个副本放在不同的主机IP地址上。 在存储桶迁移期间重置实时和空闲时间统计信息的输入时间。 替换离线成员。 何时重新平衡分区区域 您通常希望在成员启动，关闭或失败时增加或减少容量时触发重新平衡。 您可能还需要在以下时间重新平衡： 您使用冗余实现高可用性，并将您的区域配置为在丢失后不自动恢复冗余。 在这种情况下，Geode仅在您调用重新平衡时恢复冗余。 请参见为分区区域配置高可用性. 您有不均匀的数据散列。 如果您的key没有哈希代码方法（确保均匀分布），或者如果使用PartitionResolver来分配分区区域数据(请参阅来自不同分区区域的共存数据)，则可能会出现不均匀的哈希。在任何一种情况下，一些桶可能比其他桶接收更多数据。 通过在托管大型存储桶的成员上放置更少的存储桶，可以使用重新平衡来平衡数据存储之间的负载。 如何模拟区域重新平衡 您可以通过使用以下选项执行rebalance命令来移动任何实际数据之前模拟重新平衡操作： gfsh>rebalance --simulate 注意: 如果您使用heap_lru进行数据驱逐，您可能会注意到模拟结果与实际重新平衡结果之间存在差异。 这种差异可能是由于VM在您执行模拟后开始逐出条目。 然后，当您执行实际的重新平衡操作时，操作将根据较新的堆大小做出不同的决定。 自动重新平衡 实验自动重新平衡功能 会根据时间表触发重新平衡操作。 检查分区中的冗余 在某些情况下，验证分区区域数据是否为冗余并且在成员重新启动时，已跨分区区域成员正确恢复冗余非常重要。 您可以通过确保所有分区区域的numBucketsWithoutRedundancy统计数值为零来验证分区区域冗余。 要检查此统计信息，请使用以下gfsh命令： gfsh>show metrics --categories=partition --region=region_name 例如: gfsh>show metrics --categories=partition --region=posts Cluster-wide Region Metrics --------- | --------------------------- | ----- partition | putLocalRate | 0 | putRemoteRate | 0 | putRemoteLatency | 0 | putRemoteAvgLatency | 0 | bucketCount | 1 | primaryBucketCount | 1 | numBucketsWithoutRedundancy | 1 | minBucketSize | 1 | maxBucketSize | 0 | totalBucketSize | 1 | averageBucketSize | 1 如果为分区区域配置了start-recovery-delay=-1，则需要在重新启动群集中的任何成员后对区域执行重新平衡，以便恢复冗余。 如果将start-recovery-delay设置为较低的数字，则可能需要等待额外的时间，直到该区域恢复冗余。 将分区区域数据移动到另一个成员 您可以使用PartitionRegionHelper moveBucketByKey和moveData方法将分区区域数据从一个成员显式移动到另一个成员。 moveBucketByKey方法将包含指定键的存储桶从源成员移动到目标成员。 例如，您可以使用该方法将流行的产品项移动到新的空成员，以减少源成员的负载。 例如: Object product = ... Region r = ... DistributedSystem ds = ... String memberName = ... //Find the member that is currently hosting the product. Set sourceMembers = PartitionRegionHelper.getAllMembersForKey(r, product); //Find the member to move the product to. DistributedMember destination = ds.findDistributedMember(memberName); //In this example we assume there is always at least one source. //In practice, you should check that at least one source //for the data is available. source = sourceMembers.iterator().next(); //Move the bucket to the new node. The bucket will //be moved when this method completes. It throws an exception //if there is a problem or invalid arguments. PartitionRegionHelper.moveBucketByKey(r, source, destination, product); 有关更多详细信息，请参阅org.apache.geode.cache.partition.PartitionRegionHelper.moveBucketByKey的Java API文档。 moveData方法将数据从源成员移动到目标成员的给定百分比（以字节为单位）。 例如，您可以使用此方法将指定百分比的数据从重载成员移动到另一个成员以改进分发。 例如: Region r = ... DistributedSystem ds = ... String sourceName = ... String destName = ... //Find the source member. DistributedMember source = ds.findDistributedMember(sourceName); DistributedMember destination = ds.findDistributedMember(destName); //Move up to 20% of the data from the source to the destination node. PartitionRegionHelper.moveData(r, source, destination, 20); 有关更多详细信息，请参阅org.apache.geode.cache.partition.PartitionRegionHelper.moveData的Java API文档。 有关分区区域和重新平衡的更多信息，请参阅分区区域. 分布式和复制区域 除基本区域管理外，分布式和复制区域还包括推送和分配模型，全局锁定和区域条目版本等选项，以确保Geode成员之间的一致性。 分布式如何运作 要使用分布式和复制区域，您应该了解它们的工作方式以及管理它们的选项。 区域分布选项 您可以使用包含和不包含确认的分发，或使用区域分布的全局锁定。 配置为通过确认分发的区域也可以配置为在托管该区域的所有Geode成员之间一致地解析并发更新。 复制和预加载的工作原理 要使用复制和预加载区域，您应该了解如何在缓存中初始化和维护其数据。 配置分布式，复制和预加载区域 规划分布式，复制和预加载区域的配置和持续管理，并配置区域。 锁定全局区域 在全局区域中，系统在更新期间锁定条目和区域。 您还可以根据应用程序的需要显式锁定区域及其条目。 锁定包括系统设置，可帮助您优化性能并锁定成员之间的行为。 分布式如何运作 要使用分布式和复制区域，您应该了解它们的工作方式以及管理它们的选项。 注意: 复制和分布式区域的管理补充了基本配置和编程中提供的用于管理数据区域的一般信息。 另请参见org.apache.geode.cache.PartitionAttributes。 分布式区域自动将条目值更新发送到远程高速缓存并从它们接收更新。 分布式条目更新来自Region put和create操作（具有非null值的条目的创建被视为已经具有条目key的远程缓存的更新）。 条目更新是有选择地分发的 - 仅限于已定义条目key的高速缓存。 与您通过复制获得的推送模型相比，这提供了拉动模型。 仅分发不会导致从远程缓存复制新条目。 分布式区域跨群集共享缓存加载器和缓存编写器应用程序事件处理程序插件。 在分布式区域中，新的和更新的条目值会自动分发到已定义条目的远程缓存中。 步骤 1: 应用程序更新或创建条目。 此时，M1缓存中的条目可能尚不存在。 步骤 2: 新值自动分发给持有条目的缓存。 步骤 3: 整个群集中条目的值相同。 区域分布式选项 您可以使用包含和不包含确认的分发，或使用区域分布的全局锁定。 配置为通过确认分发的区域也可以配置为在托管该区域的所有Geode成员之间一致地解析并发更新。 每个分布式区域必须在整个群集中具有相同的范围和并发检查设置。 分布式范围分为三个级别： distributed-no-ack. 分发操作返回时无需等待其他缓存的响应。 此范围提供最佳性能并使用最少的开销，但它也最容易出现由网络问题引起的不一致。 例如，网络传输层的临时中断可能导致在将更新分发到远程机器上的缓存时失败，同时本地缓存继续更新。 distributed-ack. 发布在继续之前等待来自其他缓存的确认。 这比distributed-no-ack慢，但涵盖了简单的通信问题，例如临时网络中断。 在存在许多distributed-no-ack操作的系统中，distributed-ack操作可能需要很长时间才能完成。 群集具有可配置的时间，等待对任何distributed-ack消息的确认，然后向日志发送有关无响应成员可能出现的问题的警报。 无论等待多长时间，发送方都会等待以遵守分布式ack区域设置。 管理它的gemfire.properties属性是ack-wait-threshold。 global. 在分发操作期间，条目和区域会在群集中自动锁定。 对区域及其条目的所有加载，创建，放置，无效和销毁操作都使用分布式锁执行。 全局范围在整个集群中实施严格一致性，但它是实现一致性的最慢机制。 除了分发操作执行的隐式锁定之外，还可以通过应用程序API显式锁定具有全局范围及其内容的区域。 这允许应用程序对区域和区域条目执行原子，多步操作。 复制和预加载的工作原理 要使用复制和预加载区域，您应该了解如何在缓存中初始化和维护其数据。 通过使用REPLICATE区域快捷方式设置之一，或通过将region属性data-policy设置为replicate，persistent-replicate或preloaded来配置复制和预加载区域。 复制和预加载区域的初始化 在区域创建时，系统使用可以找到的最完整和最新的数据集初始化预加载或复制的区域。 系统使用这些数据源按照此优先顺序初始化新区域： 另一个已在集群中定义的复制区域。 仅用于持久复制。 磁盘文件，后跟分布式缓存中区域的所有副本的并集。 仅适用于预加载区域。 另一个已在集群中定义的预加载区域。 分布式缓存中区域的所有副本的并集。 在从复制或预加载区域初始化区域时，如果源区域崩溃，则初始化将重新开始。 如果区域联合用于初始化，如图所示，并且其中一个单独的源区域在初始化期间消失（由于缓存关闭，成员崩溃或区域破坏），新区域可能包含部分数据集 来自坠毁的源区域。 发生这种情况时，不会记录任何警告或抛出异常。 新区域仍然有一整套剩余的成员区域。 初始化后复制和预加载区域的行为 初始化后，预加载区域的操作类似于具有normal和data-policy数据策略的区域，仅接收它在本地缓存中定义的条目的分布。 如果区域配置为复制区域，则它将从其他成员接收分布式区域中的所有新创建。 这是推送分发模型。 与预加载区域不同，复制区域具有一个契约，表明它将保存分布式区域中任何位置的所有条目。 配置分布式，复制和预加载区域 规划分布式，复制和预加载区域的配置和持续管理，并配置区域。 在开始之前，请了解基本配置和编程. 选择与您的区域配置最匹配的区域快捷方式设置。 请参阅 org.apache.geode.cache.RegionShortcut 或Region Shortcuts. 要创建复制区域，请使用REPLICATE快捷方式设置之一。 要创建预加载区域，请将您的区域data-policy设置为preloaded。 这个cache.xml声明创建了一个复制区域： 您还可以使用gfsh配置区域。 例如： gfsh>create region --name=regionA --type=REPLICATE 参见区域类型. 选择您所在地区的分布式级别。 RegionShortcut中分布式区域的区域快捷方式使用distributed-ack范围。 如果需要不同的范围，请将region-attributes scope设置为distributed-no-ack或global。 例子: 如果您使用distributed-ack范围，则可以选择启用该区域的并发检查。 例子: 如果您正在使用global范围，除了Geode提供的自动锁定外，还需要编程您需要的任何显式锁定。 复制区域中的本地销毁和无效 在仅影响本地缓存的所有操作中，在复制区域中仅允许本地区域销毁。 其他操作不可配置或抛出异常。 例如，您不能将本地destroy用作复制区域上的到期操作。 这是因为诸如条目失效和破坏之类的本地操作仅从本地缓存中删除数据。 如果数据在本地删除但保持不变，则复制区域将不再完整。 锁定全局区域 在全局区域中，系统在更新期间锁定条目和区域。 您还可以根据应用程序的需要显式锁定区域及其条目。 锁定包括系统设置，可帮助您优化性能并锁定成员之间的行为。 在具有全局范围的区域中，锁定有助于确保缓存一致性 区域和条目的锁定有两种方式： Implicit(隐式). Geode在大多数操作期间自动锁定全局区域及其数据条目。 区域失效和销毁不会获取锁定。 Explicit(明确). 您可以使用API显式锁定区域及其条目。 这样做是为了保证具有多步分布式操作的任务的原子性。 Region方法org.apache.geode.cache.Region.getDistributedLock和org.apache.geode.cache.Region.getRegionDistributedLock为区域和指定的键返回java.util.concurrent.locks.Lock的实例。 注意: 您必须使用Region API来锁定区域和区域条目。 不要在org.apache.geode.distributed包中使用DistributedLockService。 该服务仅适用于锁定任意分布式应用程序。 它与Region的locking方法不兼容。 锁定超时 获取区域或条目的锁定是获取实体的锁定实例然后使用实例设置锁定的两步过程。 锁定后，持有它进行操作，然后将其释放给其他人使用。 您可以设置等待获取锁定所花费的时间限制以及持有锁定所花费的时间。 隐式和显式锁定操作都受超时影响： 锁定超时限制等待获取锁定。 缓存属性lock-timeout控制隐式锁请求。 对于显式锁定，通过调用从Region API返回的java.util.concurrent.locks.Lock实例来指定等待时间。 您可以等待一段特定的时间，无论是否有锁，都可以立即返回，或者无限期地等待。 gfsh: gfsh>alter runtime --lock-timeout=60 锁定租约限制锁定在自动释放之前可以保持多长时间。 定时锁允许应用程序在成员未能在租用时间内释放获得的锁时进行恢复。 对于所有锁定，此超时使用缓存属性lock-lease设置。 gfsh: gfsh>alter runtime --lock-lease=120 优化锁定性能 对于每个全局区域，将为已定义区域的成员之一分配锁定授予者的作业。 锁定授予者运行锁定服务，该服务接收来自系统成员的锁定请求，根据需要对它们进行排队，并按接收的顺序授予它们。 锁定授予者比其他成员略有优势，因为它是唯一一个不必发送消息来请求锁定的成员。 出于同样的原因，设保人的要求成本最低。 因此，您可以通过将锁定授予者状态分配给获取最多锁定的成员来优化区域中的锁定。 这可能是执行最多put的成员，因此需要最隐式锁，或者这可能是执行许多显式锁的成员。 锁定授予者分配如下： 任何具有区域定义的成员都会为其分配请求锁定授予者状态。 因此，在任何时候，发出请求的最新成员是锁定授予者。 如果没有成员请求区域的锁定授予者状态，或者当前锁定授予者消失，则系统从具有在其高速缓存中定义的区域的成员分配锁定授予者。 您可以申请锁定设备状态： 在区域创建时通过is-lock-grantor属性。 您可以通过region方法getAttributes检索此属性，以查看您是否要求成为该区域的锁定授予者。 注意: 区域创建后，is-lock-grantor属性不会更改。 通过区域becomeLockGrantor方法创建区域后。 但是，应该谨慎地更改锁定授予者，因为这样做需要从其他操作开始循环。 特别是，要小心避免创建一个成员争夺锁定授予者状态的情况。 例子 这两个示例显示了条目锁定和解锁。 注意如何获取条目的Lock对象，然后调用其锁定方法来实际设置锁。 示例程序将条目锁定信息存储在哈希表中以供将来参考。 /* Lock a data entry */ HashMap lockedItemsMap = new HashMap(); ... String entryKey = ... if (!lockedItemsMap.containsKey(entryKey)) { Lock lock = this.currRegion.getDistributedLock(entryKey); lock.lock(); lockedItemsMap.put(name, lock); } ... /* Unlock a data entry */ String entryKey = ... if (lockedItemsMap.containsKey(entryKey)) { Lock lock = (Lock) lockedItemsMap.remove(name); lock.unlock(); } 区域更新的一致性 Geode确保区域的所有副本最终在托管该区域的所有成员和客户端上达到一致状态，包括分发区域事件的Geode成员。 按地区类型检查一致性 Geode根据您配置的区域类型执行不同的一致性检查。 配置一致性检查 Geode默认启用一致性检查。 您无法禁用持久性区域的一致性检查。 对于所有其他区域，您可以通过将cache.xml中的concurrency-checks-enabled 区域属性设置为“true”或“false”来显式启用或禁用一致性检查。 一致性检查的开销 一致性检查需要额外的开销来存储和分发版本和时间戳信息，以及在一段时间内维护销毁的条目以满足一致性要求。 一致性检查如何适用于复制区域 每个区域都存储用于冲突检测的版本和时间戳信息。 在应用分布式更新之前，Geode成员使用记录的信息一致地检测和解决冲突。 如何解决Destroy和Clear操作 为区域启用一致性检查时，当应用程序销毁该条目时，Geode成员不会立即从该区域中删除条目。 相反，成员将条目保留其当前版本标记一段时间，以便检测可能与已发生的操作发生冲突。 保留的条目称为墓碑。 为了提供一致性，Geode保留了分区区域和非复制区域以及复制区域的逻辑删除。 具有一致性区域的事务 修改启用了一致性检查的区域的事务会在事务提交时生成区域更新的所有必要版本信息。 按地区类型检查一致性 Geode根据您配置的区域类型执行不同的一致性检查。 分区区域的一致性 对于分区区域，Geode通过将给定key上的所有更新路由到保存该key主副本的Geode成员来维护一致性。 该成员持有对key的锁定，同时将更新分发给承载key副本的其他成员。 由于分区区域的所有更新都在主要Geode成员上序列化，因此所有成员都以相同的顺序应用更新，并始终保持一致性。 请参阅了解分区. 复制区域一致性 对于复制区域，托管该区域的任何成员都可以更新key并将该更新分发给其他成员，而无需锁定key。 两个成员可能同时更新相同的key（并发更新）。 由于网络等待时间，一个成员的更新也可能在稍后时间分配给其他成员，之后这些成员已经对key应用了更新的更新（无序更新）。 默认情况下，Geode成员在应用区域更新之前执行冲突检查，以便检测并一致地解决并发和无序更新。 冲突检查可确保区域数据最终在托管该区域的所有成员上保持一致。 复制区域的冲突检查行为总结如下： 如果两个成员同时更新同一个key，则冲突检查会确保所有成员最终应用相同的值，即两个并发更新之一的值。 如果成员收到无序更新（在应用一个或多个最新更新后收到的更新），则冲突检查可确保丢弃无序更新，而不应用于缓存。 一致性检查如何适用于复制区域 和 如何解决Destroy和Clear操作 提供有关Geode在应用更新时如何执行冲突检查的更多详细信息。 非复制区域和客户端缓存一致性 当成员收到非复制区域中的条目的更新并应用更新时，它将以与复制区域相同的方式执行冲突检查。 但是，如果成员对区域中不存在的条目启动操作，则它首先将该操作传递给承载复制的成员。 承载副本的成员生成并提供后续冲突检查所需的版本信息。 请参见一致性检查如何为复制区域工作. 客户端缓存在收到区域条目的更新时也以相同的方式执行一致性检查。 但是，首先将源自客户端缓存的所有区域操作传递到可用的Geode服务器，该服务器生成后续冲突检查所需的版本信息。 配置一致性检查 Geode默认启用一致性检查。 您无法禁用持久性区域的一致性检查。 对于所有其他区域，您可以通过将cache.xml中的concurrency-checks-enabled 区域属性设置为“true”或“false”来显式启用或禁用一致性检查。 承载区域的所有Geode成员必须对该区域使用相同的concurrency-checks-enabled设置。 即使服务器缓存启用了对同一区域的一致性检查，客户端缓存也可以禁用区域的一致性检查。 此配置可确保客户端查看该区域的所有事件，但不会阻止客户端缓存区域与服务器缓存不同步。 参见 . 注意: 不启用一致性检查的区域仍然受竞争条件的影响。 并发更新可能导致一个或多个成员具有相同key的不同值。 网络延迟可能导致在发生更新后将旧更新应用于key。 一致性检查的开销 一致性检查需要额外的开销来存储和分发版本和时间戳信息，以及在一段时间内维护销毁的条目以满足一致性要求。 为了提供一致性检查，每个区域条目使用额外的16个字节。 删除条目时，会创建并维护大约13个字节的逻辑删除条目，直到逻辑删除过期或在成员中进行垃圾收集。 （当一个条目被销毁时，该成员临时保留该条目及其当前版本标记，以检测可能与已发生的操作的冲突。保留的条目称为墓碑。）参见如何解决销毁和清除操作. 如果您无法支持部署中的额外开销，则可以通过为每个区域设置concurrency-checks-enabled为“false”来禁用一致性检查。 请参阅区域更新的一致性. 一致性检查如何适用于复制区域 每个区域都存储用于冲突检测的版本和时间戳信息。 在应用分布式更新之前，Geode成员使用记录的信息一致地检测和解决冲突。 默认情况下，区域中的每个条目都存储上次更新条目的Geode成员的ID，以及每次更新发生时递增的条目的版本标记。 版本信息存储在每个本地条目中，并且在更新本地条目时将版本标记分发给其他Geode成员。 接收更新消息的Geode成员或客户端首先将更新版本标记与其本地高速缓存中记录的版本标记进行比较。 如果更新版本标记较大，则表示该条目的较新版本，因此接收成员在本地应用更新并更新版本信息。 较小的更新版本标记表示无序更新，将被丢弃。 相同的版本标记表示多个Geode成员同时更新了相同的条目。 要解决并发更新，Geode成员始终应用（或保留）具有最高成员身份ID的区域条目; 具有较低成员资格ID的区域条目被丢弃。 注意: 当Geode成员丢弃更新消息时（无论是无序更新还是解析并发更新），它都不会将丢弃的事件传递给该区域的事件侦听器。 您可以使用conflatedEvents统计信息跟踪每个成员的丢弃更新数。 参见Geode统计列表. 某些成员可能会在其他成员应用更新时丢弃更新，具体取决于每个成员收到更新的顺序。 因此，每个Geode成员的conflatedEvents统计信息都不同。 以下示例更详细地描述了此行为。 以下示例显示如何在三个Geode成员的集群中处理并发更新。 假设成员A，B和C的成员资格ID分别为1,2和3。 每个成员当前在其版本C2的缓存中存储条目X（该条目最后由成员C更新）： 步骤 1: 应用程序更新Geode成员A上的条目X，同时另一个应用程序更新成员C上的条目X.每个成员递增条目的版本标记，并在其本地缓存中记录带有其成员标识的版本标记。 在这种情况下，条目最初是在C2版本，因此每个成员在其本地缓存中将版本更新为3（分别为A3和C3）。 步骤 2: 成员A将其更新消息分发给成员B和C. 成员B将更新版本标记（3）与其记录的版本标记（2）进行比较，并将更新作为版本A3应用于其本地高速缓存。 在此成员中，更新将暂时应用，并传递给已配置的事件侦听器。 成员C将更新版本标记（3）与其记录的版本标记（3）进行比较，并标识并发更新。 为解决冲突，成员C接下来将更新的成员身份ID与存储在其本地缓存中的成员身份ID进行比较。 因为更新（A3）的分布式系统ID低于存储在高速缓存（C3）中的ID，所以成员C丢弃更新（并增加conflatedEvents统计信息）。 步骤 3: 成员C将更新消息分发给成员A和B. 成员A和B将更新版本标记（3）与其记录的版本标记（3）进行比较，并识别并发更新。 为了解决冲突，两个成员都将更新的成员身份ID与存储在其本地缓存中的成员身份ID进行比较。 由于缓存值中A的分布式系统ID小于更新中的C的ID，因此两个成员都会在其本地缓存中记录更新C3，从而覆盖先前的值。 此时，托管该区域的所有成员都已成为成员A和C上的并发更新的一致状态。 如何解决Destroy和Clear操作 为区域启用一致性检查时，当应用程序销毁该条目时，Geode成员不会立即从该区域中删除条目。 相反，成员将条目保留其当前版本标记一段时间，以便检测可能与已发生的操作发生冲突。 保留的条目称为墓碑。 为了提供一致性，Geode保留了分区区域和非复制区域以及复制区域的逻辑删除。 客户端缓存或非复制区域中的逻辑删除在8分钟后到期，此时逻辑删除立即从缓存中删除。 复制或分区区域的墓碑在10分钟后到期。 过期的墓碑有资格由Geode成员进行垃圾收集。 任何类型的100,000个墓碑在本地Geode成员中超时后，将自动触发垃圾收集。 您可以选择将gemfire.tombstone-gc-threshold属性设置为小于100000的值，以更频繁地执行垃圾回收。 注意: 为了避免内存不足错误，当可用内存量低于总内存的30％时，Geode成员还会启动逻辑删除的垃圾回收。 您可以使用CachePerfStats中的tombstoneCount统计信息来监视缓存中的逻辑删除总数。 tombstoneGCCount统计信息记录成员执行的逻辑删除垃圾收集周期的总数。 replicatedTombstonesSize和nonReplicatedTombstonesSize分别显示复制或分区区域和非复制区域中墓碑当前消耗的大致字节数。 参见Geode统计列表. 关于Region.clear()操作 区域条目版本标记和逻辑删除仅在单个条目被销毁时确保一致性。 但是，Region.clear()操作一次对区域中的所有条目进行操作。 为了为Region.clear()操作提供一致性，Geode获得该区域的分布式读/写锁，该锁阻止对该区域的所有并发更新。 在清除区域之前允许在清除操作之前启动的任何更新。 具有一致性区域的事务 修改启用了一致性检查的区域的事务会在事务提交时生成区域更新的所有必要版本信息。 如果事务修改了正常区域，预加载区域或空区域，则事务首先委托给保存区域复制的Geode成员。 此行为类似于分区区域的事务行为，其中分区区域事务将转发到承载分区区域更新主节点的成员。 正常，预加载或空区域上的事务限制是，当启用一致性检查时，事务不能对该区域执行localDestroy或localInvalidate操作。 在这种情况下，Geode会抛出UnsupportedOperationInTransactionException异常。 当启用一致性检查时，应用程序应使用Destroy或Invalidate操作代替localDestroy或localInvalidate。 一般地区数据管理 对于所有区域，您可以选择控制内存使用，将数据备份到磁盘，以及从缓存中丢弃过时数据。 Persistence and Overflow(持久性和溢出) 您可以将数据保留在磁盘上以进行备份，并将其溢出到磁盘以释放内存，而无需从缓存中完全删除数据。 Eviction(驱逐) 使用逐出来控制数据区域大小。 驱逐行动由基于空间的阈值触发。 Expiration(到期) 使用到期可以保持数据最新并通过删除过时条目来减小区域大小。 到期操作由基于时间的阈值触发。 保持缓存与外部数据源同步 通过编程和安装适用于您所在地区的应用程序插件，使分布式缓存与外部数据源保持同步。 Persistence and Overflow（持久性和溢出） 您可以将数据保留在磁盘上以进行备份，并将其溢出到磁盘以释放内存，而无需从缓存中完全删除数据。 注意: 这补充了基本配置和编程中提供的管理数据区域的一般步骤. 所有磁盘存储都使用Apache Geode 磁盘存储. 持久性和溢出如何工作 要使用Geode持久性和溢出，您应该了解它们如何处理您的数据。 配置区域持久性和溢出 计划数据区域的持久性和溢出并相应地进行配置。 溢出配置示例 cache.xml示例显示了区域和服务器订阅队列溢出的配置。 持久性和溢出如何工作 要使用Geode持久性和溢出，您应该了解它们如何处理您的数据。 Geode持续存在并溢出了几种类型的数据。 您可以保留或溢出您所在地区的应用程序数据。 此外，Geode持续存在并溢出消息队列，以管理内存消耗并提供高可用性。 持久性数据比区域所在的成员更长，并且可用于在创建时初始化区域。 溢出仅作为内存中区域的扩展。 根据Geode磁盘存储的配置将数据写入磁盘。 对于任何磁盘选项，您可以指定要使用的磁盘存储的名称或使用Geode默认磁盘存储。 参见磁盘存储. 数据如何保持和溢出 对于持久性，将条目键和值复制到磁盘。 对于溢出，仅复制条目值。 其他数据（如统计信息和用户属性）仅保留在内存中。 数据区域通过最近最少使用（LRU）条目溢出到磁盘，因为这些条目被认为是应用程序最不感兴趣的，因此不太可能被访问。 服务器订阅队列溢出最近使用的（MRU）条目。 这些是位于队列末尾的消息，因此最后排队发送到客户端。 Persistence(持久化) 持久性提供区域条目数据的磁盘备份。 所有条目的键和值都保存到磁盘，就像在磁盘上具有该区域的副本一样。 区域输入操作（如put和destroy）在内存和磁盘上执行。 当成员因任何原因停止时，磁盘上的区域数据仍然存在。 在分区区域中，数据存储区在成员之间划分，这可能导致某些数据仅在磁盘上，某些数据在磁盘上和内存中。 磁盘数据可以在成员启动时使用以填充相同的区域。 Overflow(溢出) 溢出通过将最近最少使用（LRU）条目的值移动到磁盘来限制内存中的区域大小。 溢出基本上使用磁盘作为条目值的交换空间。 如果请求的条目的值仅在磁盘上，则该值将被复制回内存，可能导致将不同LRU条目的值移动到磁盘。 与持久化条目一样，溢出条目在磁盘上维护，就像它们在内存中一样。 在此图中，条目X的值已移至磁盘以在内存中腾出空间。 X的键仍然在内存中。 从分布式系统的角度来看，磁盘上的值与内存中的数据一样是区域的一部分。 持久性和溢出在一起 一起使用，持久性和溢出将所有条目键和值保留在磁盘上，并且只保留内存中最活跃的条目值。 由于溢出而从内存中删除条目值对磁盘副本没有影响，因为所有条目都已在磁盘上。 持久性和多站点配置 多站点网关发送方队列溢出最近使用的（MRU）条目。 这些是队列末尾的消息，因此最后排队发送到远程站点。 您还可以配置网关发件人队列以保持高可用性。 配置区域持久性和溢出 计划数据区域的持久性和溢出并相应地进行配置。 使用以下步骤为持久性和溢出配置数据区域： 根据需要配置磁盘存储。 请参阅设计和配置磁盘存储。 缓存磁盘存储区定义数据写入磁盘的位置和方式。 指定区域的持久性和溢出条件。 如果未使用默认磁盘存储，请在区域属性配置中提供磁盘存储名称。 要异步写入磁盘，请指定disk-synchronous=“false”。 对于溢出，请在区域的'eviction-attributes`中指定溢出条件，并命名要使用的磁盘存储。 例子: gfsh: 你不能使用gfsh配置lru-memory-size。 对于持久性，将data-policy设置为persistent-replicate并命名要使用的磁盘存储。 例子: . . . 启动成员时，将使用磁盘存储和磁盘写入行为自动执行溢出和持久性。 注意: 您还可以使用gfsh命令行界面配置区域和磁盘存储。 参见地区命令 和 磁盘存储命令. 相关话题 org.apache.geode.cache.RegionAttributes 用于数据区域持久性信息 org.apache.geode.cache.EvictionAttributes 用于数据区域溢出信息 org.apache.geode.cache.server.ClientSubscriptionConfig 溢出配置示例 cache.xml示例显示了区域和服务器订阅队列溢出的配置。 根据以下因素之一配置溢出条件： 条目计数 绝对内存消耗 内存消耗占应用程序堆的百分比（不适用于服务器订阅队列） 区域溢出配置： 服务器客户端订阅队列溢出的配置： Eviction（逐出） 使用逐出来控制数据区域大小。 驱逐行动由基于空间的阈值触发。 逐出如何运作 逐出设置会导致Apache Geode通过删除最近最少使用（LRU）条目来为新条目腾出空间，从而使区域的资源在指定级别下保持使用。 配置数据逐出 配置区域的'eviction-attributes`设置以使您的区域保持在指定的限制内。 驱逐如何运作 驱逐通过删除最近最少使用（LRU）条目来为新条目让路，从而使区域的资源在指定级别下保持使用。 您可以选择过期的条目是溢出到磁盘还是已销毁。 参见持久性和溢出. 当超过基于大小的阈值时触发驱逐。 区域的逐出阈值可以基于： 条目计数 绝对内存使用量 可用堆的百分比 这些驱逐算法是互斥的; 只有一个可以对给定区域有效。 当Geode确定添加或更新条目会使区域超过指定级别时，它会溢出或删除足够的旧条目以腾出空间。 对于条目计数驱逐，这意味着较新条目的一对一交易。 对于内存设置，需要删除以创建空间的旧条目数取决于较旧和较新条目的大小。 为了提高效率，移除物品的选择不是严格的LRU，而是从该地区最古老的条目中选择驱逐候选者。 因此，逐出可能会在本地数据存储中留下该区域的旧条目。 驱逐行动 Apache Geode提供以下驱逐操作： 当地销毁 - 从本地缓存中删除条目，但不将删除操作分发给远程成员。 此操作可以应用于分区区域中的条目，但如果启用了冗余（冗余副本> 0），则不建议这样做，因为它会引入冗余存储区之间的不一致。 当应用于复制区域中的条目时，Geode会将区域类型静默更改为预加载以适应本地修改。 溢出到磁盘 - 条目的值溢出到磁盘并在内存中设置为null。 条目的key保留在缓存中。 这是分区区域唯一完全支持的驱逐操作。 分区中的驱逐 在分区区域中，Geode会删除正在执行新条目操作的存储桶中可找到的最旧条目。 Geode在逐桶的基础上维护LRU条目信息，因为跨分区区域维护信息的成本会降低系统的性能。 对于存储器和入口计数驱逐，LRU驱逐在正在执行新的条目操作的桶中完成，直到成员中的组合桶的总体大小已经下降到足以执行操作而不超过限制。 对于堆驱逐，每个分区区域桶被视为它是一个单独的区域，每个驱逐操作仅考虑桶的LRU，而不是整个分区区域。 配置数据驱逐 配置区域的'eviction-attributes`设置以使您的区域保持在指定的限制内。 配置数据驱逐如下。 您无需按所示顺序执行这些步骤。 决定是否根据以下方式逐出： 条目计数（如果您的条目大小相对均匀，则非常有用）。 使用的总字节数。 在分区区域中，使用local-max-memory设置。 在非分区区域中，它在eviction-attributes中设置。 使用的应用程序堆的百分比。 这使用Geode资源管理器。 当管理器确定需要驱逐时，管理器命令驱逐控制器开始从驱逐算法设置为lru-heap-percentage的所有区域驱逐。 驱逐出去，直到管理器停止。 Geode驱逐该成员为该地区托管的最近最少使用的条目。 请参阅管理堆和堆外内存. 确定达到限制时要采取的操作： 在本地销毁该条目。 将条目数据溢出到磁盘。 参见持久性和溢出. 确定成员中允许的最大数据量，用于指示的驱逐测量。 这是成员中区域的所有存储的最大值。 对于分区区域，这是存储在区域成员中的所有存储区的总数，包括用于冗余的任何辅助存储区。 决定是否为您所在的地区编制自定义sizer。 如果您能够提供这样的类，它可能比Geode完成的标准大小更快。 您的自定义类必须遵循定义自定义类的准则，另外，必须实现org.apache.geode.cache.util.ObjectSizer。 请参见在数据缓存中使用自定义类的要求. 例子: 设置LRU内存驱逐阈值为1000 MB。 使用自定义类来测量区域中每个对象的大小： gfsh>create region --name=myRegion --type=REPLICATE --eviction-max-memory=1000 \\ --eviction-action=overflow-to-disk --eviction-object-sizer=com.myLib.MySizer 在分区区域上创建逐出阈值，最大条目数为512： gfsh>create region --name=myRegion --type=PARTITION --eviction-entry-count=512 \\ --eviction-action=overflow-to-disk 要为堆LRU驱逐配置分区区域，首先在服务器启动时配置资源管理器，然后创建启用了驱逐的区域： gfsh>start server --name=Server1 --eviction-heap-percentage=80 ... gfsh>create region --name=myRegion --type=PARTITION --eviction-action=overflow-to-disk Expiration（到期） 使用到期可以保持数据最新并通过删除过时条目来减小区域大小。 到期操作由基于时间的阈值触发。 过期如何运作 到期删除您未使用的旧条目和条目。 您可以选择是否使过期的条目失效或销毁。 配置数据过期 配置到期类型和要使用的到期操作。 过期如何运作 到期通过删除您未使用的旧条目和条目来保持区域数据的新鲜。 您可以选择是否使过期的条目失效或销毁。 分布式区域中的过期活动可以是分布式的或本地的。 因此，一个高速缓存可以控制系统中的多个高速缓存的到期。 此图显示了客户端/服务器系统的两个基本过期设置。 服务器（右侧）从数据库填充区域，数据自动分布在整个系统中。 数据仅在一小时内有效，因此服务器对一小时的条目执行分布式销毁。 客户端应用程序是消费者。 客户端通过删除没有本地利益的条目的本地副本（空闲时间到期）来释放其缓存中的空间。 对客户端已过期的条目的请求将转发到服务器。 到期类型 Apache Geode提供两种类型的到期，每种类型都由基于时间的阈值触发。 这些可以共存; 它们不是相互排斥的。 Time to live (TTL). 在上次创建或更新后，对象可能保留在缓存中的时间量（以秒为单位）。 对于条目，对于创建和放置操作，计数器设置为零。 创建区域时以及当条目的计数器重置时，区域计数器将复位。 TTL到期属性是region-time-to-live和entry-time-to-live。 Idle timeout. 在上次访问后，对象可能保留在缓存中的时间量（以秒为单位）。 只要TTL计数器复位，对象的空闲超时计数器就会复位。 此外，只要通过get操作或netSearch访问条目，就会重置条目的空闲超时计数器。 只要为其中一个条目重置空闲超时，就会重置区域的空闲超时计数器。 空闲超时到期属性是：region-idle-time和entry-idle-time。 到期行动 Apache Geode提供以下过期操作： invalidate (default) - 数据项的值将被删除，但key仍保留在缓存中。 适用于复制数据项的所有分布式成员。 destroy - 数据项的键和值都被删除。 适用于复制数据项的所有分布式成员。 local invalidate - 删除数据项的值。 仅适用于本地成员。 local destroy - 删除数据项的键和值。 仅适用于本地成员。 您不能在复制或分区区域中使用local-destroy或local-invalidate到期操作。 您只能在分布式区域上使用本地选项，其数据策略为空，正常或预加载。 复制区域和分区区域中的条目到期 在复制区域中，条目更新在最方便可用的数据副本中执行，然后复制到其他成员，同时重置其上次更新的统计信息。 在分区区域中，始终在主副本中完成条目更新，重置主副本的上次更新和最后访问的统计信息，然后更新辅助副本以匹配。 在复制区域和分区区域中，条目检索使用最方便的可用数据副本，其可以是任何分布式副本。 检索不会传播给其他成员。 当数据项被考虑到期时，将协调上次访问时间的差异。 如果自上次更新或读取访问后经过的时间超过建立的阈值，则可以在复制区域的任何副本中触发到期。 分区区域中的到期在主副本中执行，基于主要的上次访问和最后更新的统计信息。 在这两种情况下，到期机制都会检查数据项的所有副本的最后访问日期，并将所有副本的最后访问日期更新为最近的最后访问日期。 然后，如果经过的时间仍然使数据项超过到期阈值，则根据为该区域指定的到期动作删除该项。 到期设置和netSearch之间的交互 在netSearch从远程缓存中检索条目值之前，它根据local区域的到期设置验证remote条目的统计信息。 已经过期的本地缓存中的条目将被传递。 验证后，该条目将进入本地缓存，并为本地副本更新本地访问和更新统计信息。 重置最后访问的时间，并将最后修改的时间更新为远程高速缓存中的时间，并对系统时钟差异进行更正。 因此，为本地条目分配了在集群中修改条目的真实最后时间。 netSearch操作对远程缓存中的到期计数器没有影响。 netSearch方法仅在分布式区域上运行，其数据策略为空，正常和预加载。 配置数据过期 配置到期类型和要使用的到期操作。 到期操作需要将statistics-enabled的region属性设置为true。 这可以在cache.xml文件的region元素，gfsh命令行或通过API完成。 使用到期类型设置到期属性，包括最大时间和到期操作。 查看区域属性列表中的entry-time-to-live，entry-idle-time，region-time-to-live和region-idle-time 在 . 用于到期的统计信息可通过Region和Region.Entry getStatistics方法返回的CacheStatistics对象直接提供给应用程序。 CacheStatistics对象还提供了重置统计计数器的方法。 对于分区区域: 在分区区域上，仅对区域的条目支持到期，而不支持区域本身。 区域范围的到期属性，例如region-time-to-live和region-idle-time不适用于分区区域中的数据项。 要在使用分区区域时确保可靠的读取行为，请使用entry-time-to-live属性，而不是entry-idle-time属性。 您不能在分区区域中使用local-destroy或local-invalidate到期操作。 复制区域示例: // Setting standard expiration on an entry 如果应用程序需要，请覆盖特定条目的区域范围设置。 去做这个: 编写实现org.apache.geode.cache.CustomExpiry的自定义过期类。 例如: // Custom expiration class // Use the key for a region entry to set entry-specific expiration timeouts of // 10 seconds for even-numbered keys with a DESTROY action on the expired entries // Leave the default region setting for all odd-numbered keys. public class MyClass implements CustomExpiry, Declarable { private static final ExpirationAttributes CUSTOM_EXPIRY = new ExpirationAttributes(10, ExpirationAction.DESTROY); public ExpirationAttributes getExpiry(Entry entry) { int key = (Integer)entry.getKey(); return key % 2 == 0 ? CUSTOM_EXPIRY : null; } } 在区域的到期属性设置中定义类。 例如： com.company.mypackage.MyClass 上述XML的gfsh等价物是： gfsh> create region --name=region1 --type=REPLICATE --enable-statistics \\ --entry-idle-time-expiration=60 --entry-idle-time-custom-expiry=com.company.mypackage.MyClass 当主要过期条目时，它会从辅助节点请求最后访问的统计信息。 如果有必要，主要采用最近的访问时间并重新安排到期时间。 这仅针对分布式到期操作执行，并且适用于分区和复制区域。 您还可以使用gfsh命令行界面配置区域。 参见区域命令. 配置到期的线程数 您可以使用gemfire.EXPIRY_THREADS系统属性来增加处理到期的线程数。 默认情况下，一个线程处理到期，当条目到期的速度超过线程可以使它们到期时，线程可能会变得过载。 如果单个线程处理过多的过期，则可能导致OOME。 启动缓存服务器时，将gemfire.EXPIRY_THREADS系统属性设置为所需的数字。 保持缓存与外部数据源同步 通过编程和安装适用于您所在地区的应用程序插件，使分布式缓存与外部数据源保持同步。 外部数据源概述 Apache Geode具有应用程序插件，可将数据读入缓存并将其写出。 使用JNDI配置数据库连接. 使用JNDI维护包含外部数据源的连接池。 数据加载器的工作原理 默认情况下，区域没有定义数据加载器。 通过在托管区域数据的成员上设置region属性cache-loader，将应用程序定义的加载程序插入任何区域。 实现数据加载器 编程数据加载器并配置您的区域以使用它。 外部数据源概述 Apache Geode具有应用程序插件，可将数据读入缓存并将其写出。 应用程序插件： 使用org.apache.geode.cache.CacheLoader的实现加载有关缓存未命中的数据。 当get操作无法在缓存中找到值时，将调用CacheLoader.load方法。 从加载器返回的值被放入缓存并返回到getoperation。 您可以将此与数据到期结合使用以清除旧数据和其他数据加载应用程序，这些应用程序可能由外部数据源中的事件提示。 请参阅配置数据过期. 使用缓存事件处理程序CacheWriter和CacheListener将数据写入数据源。 有关实现的详细信息，请参阅实现缓存事件处理程序. 实现缓存事件处理程序 CacheWriter 同步运行。 在对区域条目执行任何操作之前，如果为群集中的区域定义了任何缓存编写器，则系统将调用最方便的编写器。 在分区和分布式区域中，缓存编写器通常仅在包含该区域的高速缓存的子集中定义 - 通常仅在一个高速缓存中。 缓存写入器可以中止区域输入操作。 CacheListener 在更新缓存后同步运行。 此侦听器仅适用于本地缓存事件，因此请将侦听器安装在您希望它处理事件的每个缓存中。 您可以在任何缓存中安装多个缓存侦听器。 除了使用应用程序插件外，还可以在cache.xml中配置外部JNDI数据库源，并在事务中使用这些数据源。 有关详细信息，请参阅使用JNDI配置数据库连接。 使用JNDI配置数据库连接 要连接到外部数据库，例如在使用JTA事务时，可以在cache.xml中配置数据库JNDI数据源。 DataSource对象指向JDBC连接，或者更常见的是JDBC连接池。 连接池通常是首选，因为程序可以根据需要使用和重用连接，然后释放它以供另一个线程使用。 以下列表显示了JTA事务中使用的DataSource连接类型： XAPooledDataSource. XA池化SQL连接。 ManagedDataSource. J2EE连接器体系结构（JCA）ManagedConnectionFactory的JNDI绑定类型。 PooledDataSource. 池化SQL连接。 SimpleDataSource. 单个SQL连接。 没有完成SQL连接池。 连接是动态生成的，无法重复使用。 jndi-binding元素的jndi-name属性是键绑定参数。 如果jndi-name的值是DataSource，则它被绑定为java:/myDatabase**，其中myDatabase*是您为数据源指定的名称。 如果数据源无法在运行时绑定到JNDI，则Geode会记录警告。 有关DataSource接口的信息，请参阅: http://docs.oracle.com/javase/8/docs/api/javax/sql/DataSource.html Geode支持JDBC 2.0和3.0。 注意: 在CLASSPATH中包含任何数据源JAR文件。 cache.xml中的示例DataSource配置 以下部分显示为每个DataSource连接类型配置的示例cache.xml文件。 XAPooledDataSource cache.xml示例(Derby) 该示例显示了为连接到数据资源newDB的XAPooledDataSource连接池配置的cache.xml文件。 登录和阻止超时设置低于默认值。 连接信息，包括user-name和password，在cache.xml文件中设置，而不是等到连接时间。 密码未加密。 在为支持XA事务的JCA实现的数据库驱动程序指定配置属性时（换句话说，XAPooledDataSource），必须使用配置属性来定义数据源连接，而不是connection-url元素的属性。 配置属性因数据库供应商而异。 通过config-property标记指定JNDI绑定属性，如本例所示。 您可以根据需要添加尽可能多的config-property标签。 . . . Description java.lang.String pooled_transact DatabaseName java.lang.String newDB CreateDatabase java.lang.String create . . . 不同XAPooledDataSource连接的JNDI绑定配置属性 以下是不同数据库的一些示例数据源配置。 有关其他详细信息，请参阅供应商数据库的文档。 MySQL ... URL java.lang.String \"jdbc:mysql://mysql-servername:3306/databasename\" ... ... PostgreSQL ... ServerName java.lang.String postgresql-hostname DatabaseName java.lang.String postgresqldbname ... ... Oracle ... URL java.lang.String jdbc:oracle:oci8:@tc ... ... Microsoft SQL Server ... ServerName java.lang.String mysqlserver DatabaseName java.lang.String databasename SelectMethod java.lang.String cursor ... ... ManagedDataSource连接示例（Derby） JCA的ManagedConnectionFactory的ManagedDataSource连接的配置如示例所示。 这种配置类似于XAPooledDataSource连接，除了类型是ManagedDataSource，你指定managed-conn-factory-class而不是xa-datasource-class。 . . . Description java.lang.String pooled_transact DatabaseName java.lang.String newDB CreateDatabase java.lang.String create . . . PooledDataSource示例（Derby） 对于在任何事务之外执行的操作，使用PooledDataSource和SimpleDataSource连接。 此示例显示了一个cache.xml文件，该文件是为数据资源newDB的PooledDataSource连接池配置的。 对于此非事务性连接池，登录和阻止超时设置为高于前两个示例中的事务连接池。 连接信息，包括user-name和password，在cache.xml文件中设置，而不是等到连接时间。 密码未加密。 . . . Description java.lang.String pooled_transact DatabaseName java.lang.String newDB CreateDatabase java.lang.String create . . . SimpleDataSource连接示例（Derby） 下面的示例显示cache.xml文件中的一个非常基本的配置，用于与数据资源oldDB的SimpleDataSource连接。 您只需要为此连接池配置一些属性，如jndi-name，oldDB1和databaseName，oldDB。 此密码为明文。 简单的数据源连接通常不需要特定于供应商的属性设置。 如果需要，请添加config-property标签，如前面的示例所示。 . . . . . . 数据加载器的工作原理 默认情况下，区域没有定义数据加载器。 通过在托管区域数据的成员上设置region属性cache-loader，将应用程序定义的加载程序插入任何区域。 在get操作期间，加载器在高速缓存未命中时被调用，除了将值返回给调用线程之外，它还使用新的条目值填充高速缓存。 可以将加载程序配置为从外部数据存储将数据加载到Geode缓存中。 要执行反向操作，将数据从Geode缓存写入外部数据存储，请使用缓存编写器事件处理程序。 请参见实现缓存事件处理程序. 如何安装缓存加载器取决于区域的类型。 分区区域中的数据加载 由于它们可以处理大量数据，因此分区区域支持分区加载。 每个缓存加载器仅加载定义加载器的成员中的数据条目。 如果配置了数据冗余，则仅在成员拥有主副本时才加载数据。 因此，您必须在分区属性local-max-memory不为零的每个成员中安装缓存加载器。 如果依赖于JDBC连接，则每个数据存储都必须与数据源建立连接，如下图所示。 这三个成员需要三个连接。 有关如何配置数据源的信息，请参阅使用JNDI配置数据库连接。 注意: 分区区域通常需要比分布式区域更多的JDBC连接。 分布式区域中的数据加载 在非分区的分布式区域中，一个成员中定义的缓存加载器可供所有已定义区域的成员使用。 加载器通常仅定义在包含该区域的高速缓存的子集中。 当需要加载器时，将调用该区域的所有可用加载器，从最方便的加载器开始，直到加载数据或尝试所有加载器。 在下图中，一个群集的这些成员可以在不同的计算机上运行。 从M1执行对分布区域的加载。 本地区域的数据加载 对于本地区域，缓存加载器仅在定义它的成员中可用。 如果定义了加载程序，则只要在本地缓存中找不到值，就会调用它。 实现数据加载器 要使用数据加载器： 实现org.apache.geode.cache.CacheLoader接口。 配置和部署实施。 实现CacheLoader接口 对于get操作，如果键不在缓存中，则为get操作提供服务的线程将调用CacheLoader.load方法。 实现load以返回键的值，除了返回给调用者之外，它还将被放入该区域。 org.apache.geode.cache.CacheLoader继承自Declarable，因此如果你的CacheLoader实现需要用一些参数初始化，那么实现Declarable.initialize方法。 在cache.xml文件或gfshcreate region或alter region命令中指定所需的参数。 不要定义Declarable.init()方法; 它已被弃用。 这是一个示例实现： public class SimpleCacheLoader implements CacheLoader { public Object load(LoaderHelper helper) { String key = (String) helper.getKey(); // Return an entry value created from the key, assuming that // all keys are of the form \"key1\", \"key2\", \"keyN\" return \"LoadedValue\" + key.substring(3); } } 如果需要从实现中运行Region API调用，则为它们生成单独的线程。 不要从load方法直接调用Region方法，因为它可能导致缓存加载器阻塞，从而损害集群的性能。 配置和部署 使用以下三种方法之一配置和部署缓存加载器： 选项 1: 如果通过定义cache.xml文件来配置集群，则在启动服务器时通过将缓存加载器添加到类路径来进行部署。 这是cache.xml文件中的一个示例配置，它指定不带参数的加载器： myLoader 或者，这是cache.xml文件中的一个示例配置，它指定带有参数的加载器： com.company.data.DatabaseLoader jdbc:cloudscape:rmi:MyData 要部署JAR文件，请在启动服务器时将缓存加载器JAR文件添加到类路径中。 例如： gfsh>start server --name=s2 --classpath=/var/data/lib/myLoader.jar 选项 2: 如果在服务器启动时部署JAR文件，请将JAR文件添加到类路径并使用gfsh将配置应用于该区域。 要部署JAR文件，请在启动服务器时将缓存加载器JAR文件添加到类路径中。 例如： gfsh>start server --name=s2 --classpath=/var/data/lib/myLoader.jar 使用gfsh将CacheLoader实现的配置应用于具有gfsh create region或gfsh alter region的区域。 以下是不带参数的区域创建示例： gfsh>create region --name=r3 --cache-loader=com.example.appname.myCacheLoader 以下是使用参数创建区域的示例： gfsh>create region --name=r3 \\ --cache-loader=com.example.appname.myCacheLoader{'URL':'jdbc:cloudscape:rmi:MyData'} 以下是更改区域的示例： gfsh>alter region --name=r3 --cache-loader=com.example.appname.myCacheLoader 选项 3 适用于分区区域: 如果在启动服务器后使用gfsh deploy命令部署JAR文件，请使用gfsh将配置应用于该区域。 创建服务器后，使用gfsh将JAR文件部署到所有服务器。 例如： gfsh>deploy --jars=/var/data/lib/myLoader.jar 当服务器托管复制区域时，我们通常不使用gfsh deploy命令，详见数据加载器如何工作. 使用gfsh将CacheLoader实现的配置应用于具有gfsh create region或gfsh alter region的区域。 以下是不带参数的区域创建示例： gfsh>create region --name=r3 --cache-loader=com.example.appname.myCacheLoader 以下是使用参数创建区域的示例： gfsh>create region --name=r3 \\ --cache-loader=com.example.appname.myCacheLoader{'URL':'jdbc:cloudscape:rmi:MyData'} 以下是更改区域的示例： gfsh>alter region --name=r3 --cache-loader=com.example.appname.myCacheLoader 使用缓存加载器实现服务器或对等 具有嵌入式缓存的服务器和对等体可以仅在有意义的成员中配置缓存加载器。 例如，设计可以将从数据库加载的作业分配给由更多成员托管的区域的一个或两个成员。 当外部源是数据库时，可以这样做以减少连接数。 实现org.apache.geode.cache.CacheLoader接口。 区域创建配置缓存加载器，如下例所示： RegionFactory rf = cache.createRegionFactory(REPLICATE); rf.setCacheLoader(new QuoteLoader()); quotes = rf.create(\"NASDAQ-Quotes\"); 数据序列化 您在Geode中管理的数据必须序列化和反序列化，以便在进程之间进行存储和传输。 您可以选择多个数据序列化选项。 数据序列化概述 Geode提供除Java序列化之外的序列化选项，为数据存储，传输和语言类型提供更高的性能和更大的灵活性。 Geode PDX 序列化 Geode的便携式数据交换（PDX）是一种跨语言数据格式，可以降低分发和序列化对象的成本。 PDX将数据存储在您可以单独访问的命名字段中，以避免反序列化整个数据对象的成本。 PDX还允许您混合已添加或删除字段的对象版本。 Geode 数据序列化 (DataSerializable and DataSerializer) Geode的DataSerializable接口为您提供了对象的快速序列化。 标准的 Java 序列化 您可以对仅在Java应用程序之间分发的数据使用标准Java序列化。 如果在非Java客户端和Java服务器之间分发数据，则需要执行其他编程以获取各种类格式之间的数据。 数据序列化概述 Geode提供除Java序列化之外的序列化选项，为数据存储，传输和语言类型提供更高的性能和更大的灵活性。 Geode移出本地缓存的所有数据都必须是可序列化的。 但是，您不一定需要实现java.io.Serializable，因为Geode中提供了其他序列化选项。 必须可序列化的区域数据属于以下类别： 分区区域 分布式区域 持久存储或溢出到磁盘的区域 客户端/服务器安装中的服务器或客户端区域 配置了网关发件人的区域，用于在多站点安装中分发事件 从远程缓存接收事件的区域 提供函数参数和结果的区域 注意: 如果使用HTTP会话管理模块存储对象，则这些对象必须是可序列化的，因为它们在被序列化之前 存储在该地区。 为了最大限度地降低序列化和反序列化的成本，Geode尽可能避免更改数据格式。 这意味着您的数据可能以序列化或反序列化的形式存储在缓存中，具体取决于您使用它的方式。 例如，如果服务器仅充当客户端之间数据分发的存储位置，则将数据保留为序列化形式，准备传输给请求它的客户端是有意义的。 分区区域数据最初始终以序列化形式存储。 数据序列化选项 使用Geode，您可以选择自动序列化域对象或使用Geode的一个接口实现序列化。 启用自动序列化意味着域对象被序列化和反序列化，而无需对这些对象进行任何代码更改。 这种自动序列化是通过使用名为ReflectionBasedAutoSerializer的自定义PdxSerializer注册域对象来执行的，该自定义PdxSerializer使用Java反射来推断要序列化的字段。 如果autoserialization不能满足您的需求，您可以通过实现Geode接口之一，PdxSerializable或DataSerializable来序列化您的对象。 您可以使用这些接口替换任何标准Java数据序列化以获得更好的性能。 如果你不能或不想修改你的域类，每个接口都有一个备用的序列化器类，PdxSerializer和DataSerializer。 要使用这些，请创建自定义序列化程序类，然后将其与Geode缓存配置中的域类相关联。 Geode数据序列化比PDX序列化快约25％，但使用PDX序列化将帮助您避免执行反序列化的更高成本。 性能 Geode Data Serializable Geode PDX Serializable Implements Java Serializable. X 处理多个版本的应用程序域对象，通过添加或减少字段来提供不同的版本. X 提供序列化数据的单字段访问，无需完全反序列化 - 也支持OQL查询. X Geode自动移植到其他语言 X Works with .NET clients. X X Works with C++ clients. X X Works with Geode delta propagation. X X (See note below.) 表 1. 序列化选项：功能比较 注意: 默认情况下，您可以将Geode delta传播与PDX序列化一起使用。 但是，如果已将Geode属性read-serialized设置为“true”，则delta传播将不起作用。 在反序列化方面，要应用更改增量传播，需要域类实例和fromDelta方法。 如果你将read-serialized设置为true，那么你将收到一个PdxInstance而不是一个域类实例，而PdxInstance没有delta传播所需的fromDelta方法。 Geode序列化（PDX或数据可序列化）和Java序列化之间的差异 Geode序列化（PDX序列化或数据序列化）不支持循环对象图，而Java序列化则支持循环对象图。 在Geode序列化中，如果在对象图中多次引用同一对象，则为每个引用序列化对象，并且反序列化生成对象的多个副本。 相比之下，在这种情况下，Java序列化将对象序列化一次，并且在反序列化对象时，它会生成具有多个引用的对象的一个实例。 Geode PDX序列化 Geode的便携式数据交换（PDX）是一种跨语言数据格式，可以降低分发和序列化对象的成本。 PDX将数据存储在您可以单独访问的命名字段中，以避免反序列化整个数据对象的成本。 PDX还允许您混合已添加或删除字段的对象版本。 Geode PDX序列化功能 Geode PDX序列化在功能方面具有多项优势。 使用PDX序列化的高级步骤 要使用PDX序列化，您可以配置和使用Geode基于反射的自动化程序，也可以使用PDX接口和类对对象的序列化进行编程。 使用基于自动反射的PDX序列化 您可以将缓存配置为自动序列化和反序列化域对象，而无需向其添加任何额外代码。 使用PdxSerializer序列化您的域对象 对于您不能或不想修改的域对象，请使用PdxSerializer类来序列化和反序列化对象的字段。 您对整个缓存使用一个PdxSerializer实现，为您以这种方式处理的所有域对象编程。 在域对象中实现PdxSerializable 对于可以修改源的域对象，在对象中实现PdxSerializable接口，并使用其方法序列化和反序列化对象的字段。 编写应用程序以使用PdxInstances PdxInstance是PDX序列化字节周围的轻量级包装器。 它为应用程序提供对PDX序列化对象字段的运行时访问。 将JSON文档添加到Geode缓存 JSONFormatter API允许您将JSON格式的文档放入区域，然后通过将文档作为PdxInstances存储在内部来检索它们。 使用PdxInstanceFactory创建PdxInstances 当域类在服务器上不可用时，您可以使用PdxInstanceFactory接口从原始数据创建PdxInstance。 将PDX元数据保留到磁盘 Geode允许您将PDX元数据持久保存到磁盘并指定要使用的磁盘存储。 使用PDX对象作为区域条目键 Using PDX objects as region entry keys is highly discouraged. Geode PDX序列化功能 Geode PDX序列化在功能方面具有多项优势。 PDX域对象的应用程序版本控制 域对象随应用程序代码一起发展。 您可以创建一个具有两个地址行的地址对象，然后稍后实现某些情况下需要第三行。 或者您可能会意识到某个特定字段未被使用并且想要摆脱它。 使用PDX，如果版本因添加或删除字段而不同，则可以在群集中一起使用旧版本和新版本的域对象。 通过此兼容性，您可以逐步将已修改的代码和数据引入群集，而无需关闭群集。 Geode维护PDX域对象元数据的中央注册表。 无论字段是否已定义，Geode都使用注册表保留每个成员缓存中的字段。 当成员收到具有该成员不知道的注册字段的对象时，该成员不会访问该字段，而是保留该字段并将其与整个对象一起传递给其他成员。 当成员根据成员的版本收到缺少一个或多个字段的对象时，Geode会将字段类型的Java默认值分配给缺少的字段。 PDX可序列化对象的可移植性 使用PDX序列化对象时，Geode将对象的类型信息存储在中央注册表中。 信息在客户端和服务器，对等端和集群之间传递。 对象类型信息的这种集中对于客户端/服务器安装是有利的，其中客户端和服务器以不同语言编写。 客户端在存储PDX序列化对象时会自动将注册表信息传递给服务器。 客户端可以针对服务器中的数据运行查询和功能，而无需服务器和存储对象之间的兼容性。 一个客户端可以将数据存储在服务器上以供另一个客户端检索，而服务器部分没有要求。 减少序列化对象的反序列化 PDX序列化对象的访问方法允许您检查域对象的特定字段，而无需反序列化整个对象。 根据您的对象使用情况，您可以显着降低序列化和反序列化成本。 Java和其他客户端可以针对服务器缓存中的对象运行查询和执行函数，而无需反序列化服务器端的整个对象。 查询引擎自动识别PDX对象，检索对象的PdxInstance并仅使用它需要的字段。 同样，对等体只能访问序列化对象中的必要字段，从而使对象以序列化形式保存在缓存中。 使用PDX序列化的高级步骤 要使用PDX序列化，您可以配置和使用Geode基于反射的自动化程序，也可以使用PDX接口和类对对象的序列化进行编程。 （可选）对应用程序代码进行编程，以便对序列化对象的PDX表示中的各个字段进行反序列化。 您可能还需要将PDX元数据保留到磁盘以便在启动时进行恢复。 步骤 对于要使用PDX序列化序列化的每种对象类型，请使用以下序列化选项之一： 使用基于自动反射的PDX序列化 使用PdxSerializer序列化您的域对象 在域对象中实现PdxSerializable 要确保服务器不需要加载应用程序类，请将pdx read-serialized属性设置为true。 在gfsh中，在启动服务器之前执行以下命令： gfsh>configure pdx --read-serialized=true 通过使用gfsh，此配置可以通过集群配置服务在群集中传播。 或者，您需要在每个服务器的cache.xml文件中配置pdx read-serialized。 如果要将任何Geode数据存储在磁盘上，则必须配置PDX序列化以使用持久性。 有关详细信息，请参阅将PDX元数据保留到磁盘 。 （可选）无论您在何处运行显式应用程序代码来检索和管理缓存条目，您都可能希望在不使用完全反序列化的情况下管理数据对象。 要执行此操作，请参阅编写应用程序以使用Pdx实例. PDX和多站点（WAN）部署 仅对于多站点（WAN）安装 - 如果要在任何启用WAN的区域中使用PDX序列化，则对于每个群集，必须选择介于0（零）和255之间的唯一整数并设置distributed-system-id 在每个成员的gemfire.properties文件中。 请参见配置多站点（WAN）系统. 使用基于自动反射的PDX序列化 您可以将缓存配置为自动序列化和反序列化域对象，而无需向其添加任何额外代码。 您可以自动序列化和反序列化域对象，而无需编写PdxSerializer类。 您可以通过使用名为ReflectionBasedAutoSerializer的自定义PdxSerializer注册域对象来执行此操作，该自定义PdxSerializer使用Java反射来推断要序列化的字段。 您还可以扩展ReflectionBasedAutoSerializer以自定义其行为。 例如，您可以为BigInteger和BigDecimal类型添加优化的序列化支持。 有关详细信息，请参阅扩展ReflectionBasedAutoSerializer 。 注意: 您的自定义PDX autoserializable类不能使用org.apache.geode包。 如果是这样，PDX自动序列化器将忽略这些类。 先决条件 一般了解如何配置Geode缓存。 了解PDX序列化的工作原理以及如何配置应用程序以使用PdxSerializer。 步骤 在从缓存管理数据的应用程序中，根据需要提供以下配置和代码： 在您希望自动化的域类中，确保每个类都有一个零参数构造函数。 例如： public PortfolioPdx(){} 使用以下方法之一，将PDX序列化程序设置为ReflectionBasedAutoSerializer。 在gfsh中，在启动托管数据的任何成员之前执行以下命令： gfsh>configure pdx --auto-serializable-classes=com\\.company\\.domain\\..* 通过使用gfsh，此配置可以通过[Cluster Configuration Service]在群集中传播(https://geode.apache.org/docs/guide/17/configuring/cluster_config/gfsh_persist.html). 或者，在cache.xml中： org.apache.geode.pdx.ReflectionBasedAutoSerializer com.company.domain.DomainObject ... 参数classes采用逗号分隔的类模式列表来定义要序列化的域类。 如果您的域对象是其他域类的聚合，则需要明确注册域对象和每个域类，以便完全序列化域对象。 使用 Java API: Cache c = new CacheFactory() .setPdxSerializer(new ReflectionBasedAutoSerializer(\"com.company.domain.DomainObject\")) .create(); 使用以下机制之一自定义ReflectionBasedAutoSerializer的行为： 通过使用类模式字符串来指定要自动序列化的类，并自定义类的序列化方式。 可以通过将字符串传递给ReflectionBasedAutoSerializer构造函数或在cache.xml中指定类模式字符串来指定类模式字符串。 有关详细信息，请参阅使用类模式字符串自定义序列化。 通过创建ReflectionBasedAutoSerializer的子类并覆盖特定方法。 有关详细信息，请参阅扩展ReflectionBasedAutoSerializer。 如果需要，配置ReflectionBasedAutoSerializer以检查它在尝试自动化之前传递的对象的可移植性。 当此标志设置为true时，ReflectionBasedAutoSerializer将在尝试自动化非可移植对象时抛出NonPortableClassException错误。 要设置此项，请使用以下配置： 在gfsh中，使用以下命令： gfsh>configure pdx --portable-auto-serializable-classes=com\\.company\\.domain\\..* 通过使用gfsh，此配置可以通过Cluster Configuration Service在群集中传播。 在cache.xml中: org.apache.geode.pdx.ReflectionBasedAutoSerializer com.company.domain.DomainObject true ... 使用 Java API: Cache c = new CacheFactory() .setPdxSerializer(new ReflectionBasedAutoSerializer(true,\"com.company.domain.DomainObject\")) .create(); 对于您提供的每个域类，除了那些定义为static或transient的字段以及使用类模式字符串明确排除的字段外，所有字段都被视为序列化。 注意: ReflectionBasedAutoSerializer遍历给定域对象的类层次结构，以检索要考虑进行序列化的所有字段。 因此，如果DomainObjectB继承自DomainObjectA，则只需注册DomainObjectB即可将所有DomainObjectB序列化。 使用类模式字符串自定义序列化 使用类模式字符串命名要使用Geode基于反射的自动传感器序列化的类，并指定对象标识字段并指定要从序列化中排除的字段。 用于配置ReflectionBasedAutoSerializer的类模式字符串是标准正则表达式。 例如，此表达式将选择com.company.domain包及其子包中定义的所有类： com\\.company\\.domain\\..* 您可以使用特殊符号扩充模式字符串，以定义要从序列化中排除的字段，并定义要标记为PDX标识字段的字段。 模式字符串的完整语法是： [# (identity|exclude) = ]... [, ...] 以下示例模式字符串设置这些PDX序列化条件： 名称与模式com.company.DomainObject.*匹配的类被序列化。 在这些类中，以id开头的字段标记为标识字段，名为creationDate的字段未标记为序列化。 类com.company.special.Patient被序列化。 在类中，字段ssn被标记为标识字段 com.company.DomainObject.*#identity=id.*#exclude=creationDate, com.company.special.Patient#identity=ssn 注意: identity和exclude选项之间没有关联，因此上面的模式也可以表示为： com.company.DomainObject.*#identity=id.*, com.company.DomainObject.*#exclude=creationDate, com.company.special.Patient#identity=ssn 注意: 模式的顺序无关紧要。 在确定字段是应该被视为标识字段还是应该被排除时，使用所有定义的类模式。 例子: 此XML使用上面显示的示例模式： com.company.DomainObject.*#identity=id.*#exclude=creationDate, com.company.special.Patient#identity=ssn 此应用程序代码设置相同的模式： classPatterns.add(\"com.company.DomainObject.*#identity=id.*#exclude=creationDate, com.company.special.Patient#identity=ssn\"); 此应用程序代码具有相同的效果： Cache c = new CacheFactory().set(\"cache-xml-file\", cacheXmlFileName) .setPdxSerializer(new ReflectionBasedAutoSerializer(\"com.foo.DomainObject*#identity=id.*\", \"com.company.DomainObject.*#exclude=creationDate\",\"com.company.special.Patient#identity=ssn\")) .create(); 扩展ReflectionBasedAutoSerializer 您可以扩展ReflectionBasedAutoSerializer以自定义方式处理序列化。 本节概述了可用的基于方法的自定义选项以及扩展序列化程序以支持BigDecimal和BigInteger类型的示例。 扩展ReflectionBasedAutoSerializer的原因 扩展ReflectionBasedAutoSerializer的主要用例之一是，您希望它处理当前需要由标准Java序列化处理的对象。 必须使用标准Java序列化有几个问题，可以通过扩展PDXReflectionBasedAutoSerializer来解决。 每次我们从Geode序列化对象转换为将被Java I/O序列化的对象时，必须序列化额外数据。 这可能会导致大量的序列化开销。 这就是为什么值得扩展ReflectionBasedAutoSerializer以处理通常必须是Java I/O序列化的任何类的原因。 当遇到对象图时，扩展可以使用ReflectionBasedAutoSerializer的类的数量是有益的。 在对象上使用Java I/O序列化之后，对象图中该对象下的任何对象也必须是Java I/O序列化的。 这包括通常使用PDX或DataSerializable序列化的对象。 如果在对象上完成标准Java I/O序列化并且您启用了检查可移植性，则将引发异常。 即使您不关心对象的可移植性，也可以使用此标志来查找哪些类将使用标准Java序列化（通过获取它们的异常），然后增强自动序列化程序来处理它们。 覆盖ReflectionBasedAutoSerializer行为 您可以通过覆盖以下方法来自定义ReflectionBasedAutoSerializer中的特定行为： isClassAutoSerialized 自定义要自动化的类。 isFieldIncluded 指定要自动化的类的哪些字段。 getFieldName 定义将在autoserialization期间生成的特定字段名称。 isIdentifyField 控制哪个字段标记为标识字段。 当PdxInstance计算其哈希码以确定它是否等于另一个对象时，将使用标识字段。 getFieldType 确定自动化给定字段时将使用的字段类型。 transformFieldValue 控制是否可以在序列化期间转换PDX对象的特定字段值。 writeTransform 控制在自动序列化期间写入的字段值。 readTransform 控制在自动反序列化期间读取的字段值。 这些方法仅在ReflectionBasedAutoSerializer第一次看到新类时调用。 结果会被记住和使用的下一次同样的类被看见。 有关这些方法及其默认行为的详细信息，请参阅[ReflectionBasedAutoSerializer]上的JavaDocs(https://geode.apache.org/releases/latest/javadoc/org/apache/geode/pdx/ReflectionBasedAutoSerializer.html) 以获取详细信息。 优化BigInteger和BigDecimal类型的自动化的示例 本节提供了扩展ReflectionBasedAutoSerializer以优化BigInteger和BigDecimal类型的自动序列化的示例。 下面的代码示例说明了ReflectionBasedAutoSerializer的子类，它优化了BigInteger和BigDecimal autoserialization： public static class BigAutoSerializer extends ReflectionBasedAutoSerializer { public BigAutoSerializer(Boolean checkPortability, string… patterns) { super(checkPortability, patterns); } @Override public FieldType get FieldType(Field f, Class clazz) { if (f.getType().equals(BigInteger.class)) { return FieldType.BYTE_ARRAY; } else if (f.getType().equals(BigDecimal.class)) { return FieldType.STRING; } else { return super.getFieldType(f, clazz); } } @Override public boolean transformFieldValue(Field f, Class clazz) { if (f.getType().equals(BigInteger.class)) { return true; } else if (f.getType().equals(BigDecimal.class)) { return true; } else { return super.transformFieldValue(f, clazz); } } @Override public Object writeTransform(Field f, Class clazz, Object originalValue) { if (f.getType().equals(BigInteger.class)) { byte[] result = null; if (originalValue != null) { BigInteger bi = (BigInteger)originalValue; result = bi.toByteArray(); } return result; } else if (f.getType().equals(BigDecimal.class)) { Object result = null; if (originalValue != null) { BigDecimal bd = (BigDecimal)originalValue; result = bd.toString(); } return result; } else { return super.writeTransform(f, clazz, originalValue); } } @Override public Object readTransform(Field f, Class clazz, Object serializedValue) { if (f.getType().equals(BigInteger.class)) { BigInteger result = null; if (serializedValue != null) { result = new BigInteger((byte[])serializedValue); } return result; } else if (f.getType().equals(BigDecimal.class)) { BigDecimal result = null; if (serializedValue != null) { result = new BigDecimal((String)serializedValue); } return result; } else { return super.readTransform(f, clazz, serializedValue); } } } 使用PdxSerializer序列化您的域对象 对于您不能或不想修改的域对象，请使用PdxSerializer类来序列化和反序列化对象的字段。 您对整个缓存使用一个PdxSerializer实现，为您以这种方式处理的所有域对象编程。 使用PdxSerializer，您可以按原样保留域对象，并在单独的序列化程序中处理序列化和反序列化。 您在缓存PDX配置中注册序列化程序。 对序列化程序进行编程以处理所需的所有域对象。 如果您编写自己的PdxSerializer并且还使用ReflectionBasedAutoSerializer，那么PdxSerializer需要拥有ReflectionBasedAutoSerializer并委托给它。 Cache只能有一个PdxSerializer实例。 注意: PdxSerializer的toData和fromData方法与PdxSerializable的方法不同。 它们具有不同的参数和结果。 步骤 在您希望PDX序列化的域类中，确保每个类都有一个零参数构造函数。 例如： public PortfolioPdx(){} 如果您还没有为其他域对象实现PdxSerializer，请执行以下步骤： 创建一个新类作为缓存范围的序列化程序，并使其实现PdxSerializer。 如果要在cache.xml文件中声明新类，请让它实现Declarable。 例子: import org.apache.geode.cache.Declarable; import org.apache.geode.pdx.PdxReader; import org.apache.geode.pdx.PdxSerializer; import org.apache.geode.pdx.PdxWriter; public class ExamplePdxSerializer implements PdxSerializer, Declarable { ... 在高速缓存pdx配置中，在高速缓存的 属性中注册序列化器类。 例子: // Configuration setting PDX serializer for the cache com.company.ExamplePdxSerializer ... 或者使用CacheFactory.setPdxSerializer API。 Cache c = new CacheFactory .setPdxSerializer(new ExamplePdxSerializer()) .create(); 注意: 您不能使用gfsh指定自定义pdx-serializer类，但configure pdx命令会自动配置org.apache.geode.pdx.ReflectionBasedAutoSerializer类。 见configure pdx. 编程PdxSerializer.toData来识别，强制转换和处理你的域对象： 使用PdxWriter写入方法编写域类的每个标准Java数据字段。 为你希望Geode用来识别你的对象的每个字段调用PdxWriter markIdentityField方法。 把它放在字段的写方法之后。 Geode使用此信息来比较不同查询等操作的对象。 如果你没有设置至少一个身份字段，那么equals和hashCode方法将使用所有PDX字段来比较对象，因此也不会执行。 重要的是，equals和hashCode实现使用的字段与您标记为标识字段的字段相同。 对于类的特定版本，您需要每次始终写入相同的命名字段。 对于相同的类版本，字段名称或字段数不得从一个实例更改为另一个实例。 为获得最佳性能，首先是固定宽度字段，然后是可变长度字段。 如果需要，可以在序列化之前检查对象的可移植性，方法是在使用ppxWriter writeObject，writeObjectArray和writeField方法时添加checkPortability参数。 示例toData代码: public boolean toData(Object o, PdxWriter writer) { if(!(o instanceof PortfolioPdx)) { return false; } PortfolioPdx instance = (PortfolioPdx) o; writer.writeInt(\"id\", instance.id) //identity field .markIdentityField(\"id\") .writeDate(\"creationDate\", instance.creationDate) .writeString(\"pkid\", instance.pkid) .writeObject(\"positions\", instance.positions) .writeString(\"type\", instance.type) .writeString(\"status\", instance.status) .writeStringArray(\"names\", instance.names) .writeByteArray(\"newVal\", instance.newVal) return true; } 编写PdxSerializer.fromData来创建类的实例，使用PdxReader读取方法将序列化表单中的数据字段读入对象的字段，并返回创建的对象。 提供与toData中相同的名称，并以与调用toData实现中的写操作相同的顺序调用读操作。 Geode为fromData方法提供了域类类型和PdxReader。 示例fromData代码: public Object fromData(Class clazz, PdxReader reader) { if(!clazz.equals(PortfolioPdx.class)) { return null; } PortfolioPdx instance = new PortfolioPdx(); instance.id = reader.readInt(\"id\"); instance.creationDate = reader.readDate(\"creationDate\"); instance.pkid = reader.readString(\"pkid\"); instance.positions = (Map)reader.readObject(\"positions\"); instance.type = reader.readString(\"type\"); instance.status = reader.readString(\"status\"); instance.names = reader.readStringArray(\"names\"); instance.newVal = reader.readByteArray(\"newVal\"); return instance; } 如果需要，您还可以在使用PdxWriter时启用额外验证。 您可以通过将系统属性gemfire.validatePdxWriters设置为true来设置此项。 请注意，如果要调试新代码，则只应设置此选项，因为此选项会降低系统性能。 在域对象中实现PdxSerializable 对于可以修改源的域对象，在对象中实现PdxSerializable接口，并使用其方法序列化和反序列化对象的字段。 步骤 在您的域类中，实现PdxSerializable，导入所需的org.apache.geode.pdx类。 例如: import org.apache.geode.pdx.PdxReader; import org.apache.geode.pdx.PdxSerializable; import org.apache.geode.pdx.PdxWriter; public class PortfolioPdx implements PdxSerializable { ... 如果您的域类没有零参数构造函数，请为其创建一个。 例如: public PortfolioPdx(){} 程序PdxSerializable.toData 使用PdxWriter写入方法编写域类的每个标准Java数据字段。 Geode自动为PdxSerializable对象的toData方法提供PdxWriter。 为你希望Geode用来识别你的对象的每个字段调用PdxWriter markIdentifyField方法。 把它放在字段的写方法之后。 Geode使用此信息来比较不同查询等操作的对象。 如果你没有设置至少一个身份字段，那么equals和hashCode方法将使用所有PDX字段来比较对象，因此也不会执行。 重要的是，equals和hashCode实现使用的字段与您标记为标识字段的字段相同。 对于类的特定版本，您需要每次始终写入相同的命名字段。 对于相同的类版本，字段名称或字段数不得从一个实例更改为另一个实例。 为获得最佳性能，首先是固定宽度字段，然后是可变长度字段。 示例toData代码： // PortfolioPdx fields private int id; private String pkid; private Map positions; private String type; private String status; private String[] names; private byte[] newVal; private Date creationDate; ... public void toData(PdxWriter writer) { writer.writeInt(\"id\", id) // The markIdentifyField call for a field must // come after the field's write method .markIdentityField(\"id\") .writeDate(\"creationDate\", creationDate) //fixed length field .writeString(\"pkid\", pkid) .writeObject(\"positions\", positions) .writeString(\"type\", type) .writeString(\"status\", status) .writeStringArray(\"names\", names) .writeByteArray(\"newVal\", newVal) } 编程PdxSerializable.fromData使用PdxReader读取方法将序列化形式的数据字段读入对象的字段。 提供与toData中相同的名称，并以与调用toData实现中的写操作相同的顺序调用读操作。 Geode自动为PdxSerializableobjects的fromData方法提供PdxReader。 示例fromData代码： public void fromData(PdxReader reader) { id = reader.readInt(\"id\"); creationDate = reader.readDate(\"creationDate\"); pkid = reader.readString(\"pkid\"); position1 = (PositionPdx)reader.readObject(\"position1\"); position2 = (PositionPdx)reader.readObject(\"position2\"); positions = (Map)reader.readObject(\"positions\"); type = reader.readString(\"type\"); status = reader.readString(\"status\"); names = reader.readStringArray(\"names\"); newVal = reader.readByteArray(\"newVal\"); arrayNull = reader.readByteArray(\"arrayNull\"); arrayZeroSize = reader.readByteArray(\"arrayZeroSize\"); } 接下来做什么 根据需要，配置和编程Geode应用程序以使用PdxInstance进行选择性对象反序列化。 请参阅编写应用程序以使用Pdx实例. 编写应用程序以使用PdxInstances PdxInstance是PDX序列化字节周围的轻量级包装器。 它为应用程序提供对PDX序列化对象字段的运行时访问。 您可以将缓存配置为在反序列化PDX序列化对象时返回PdxInstance，而不是将对象反序列化为域类。 然后，您可以编写读取条目的应用程序代码，以处理从缓存中获取的PdxInstance。 注意: 这仅适用于使用诸如EntryEvent.getNewValue和Region.get之类的方法显式编码的条目检索，就像在函数内部或缓存侦听器代码中一样。 这不适用于查询，因为查询引擎会检索条目并为您处理对象访问。 如果将高速缓存配置为允许PDX序列化读取，则从高速缓存中获取将以找到的形式返回数据。 如果对象未序列化，则fetch返回域对象。 如果对象是序列化的，则fetch返回对象的PdxInstance。 注意: 如果您使用的是PdxInstance，则无法使用增量传播将更改应用于PDX序列化对象。 例如，在编程和配置为处理来自客户端的所有数据活动的客户端/服务器应用程序中，在服务器端完成的PDX序列化读取将始终返回PdxInstance。 这是因为所有数据都被序列化以便从客户端传输，并且您没有执行任何服务器端活动来反序列化服务器缓存中的对象。 在混合情况下，例如从客户端操作填充服务器缓存以及在服务器端完成的数据加载，在服务器上完成的提取可以返回PdxInstance和域对象的混合。 在启用PDX序列化读取的高速缓存中获取数据时，最安全的方法是编码以处理这两种类型，从获取操作接收对象，检查类型并在适当时进行转换。 但是，如果您知道该类在JVM中不可用，则可以避免执行类型检查。 PdxInstance会覆盖您为对象的equals和hashcode方法编写的任何自定义实现。 编写PDX序列化对象时，请确保至少标记了一个标识字段。 如果您没有设置至少一个标识字段，那么PdxInstanceequals和hashCode方法将使用所有PDX字段来比较对象，因此也不会执行。 先决条件 一般了解如何配置Geode缓存。 参见基本配置和编程. 步骤 在从缓存中获取数据的应用程序中，根据需要提供以下配置和代码： 在运行条目提取的成员的cache.xml文件中，将 read-serialized属性设置为true。 不必在您为其编码的成员上访问数据。 例如，如果客户端应用程序在服务器上运行某个函数，则实际的数据访问是在服务器上完成的，因此您在服务器上将read-serialized设置为true。 例如: // Cache configuration setting PDX read behavior ... 编写从缓存中获取数据的应用程序代码来处理PdxInstance。 如果您确定只从缓存中检索PdxInstance，则只能为此编码。 在许多情况下，可能会从缓存条目检索操作返回PdxInstance或域对象，因此您应检查对象类型并处理每种可能的类型。 例如: // put/get code with serialized read behavior // put is done as normal myRegion.put(myKey, myPdxSerializableObject); // get checks Object type and handles each appropriately Object myObject = myRegion.get(myKey); if (myObject instanceof PdxInstance) { // get returned PdxInstance instead of domain object PdxInstance myPdxInstance = (PdxInstance)myObject; // PdxInstance.getField deserializes the field, but not the object String fieldValue = myPdxInstance.getField(\"stringFieldName\"); // Update a field and put it back into the cache // without deserializing the entire object WritablePdxInstance myWritablePdxI = myPdxInstance.createWriter(); myWritablePdxI.setField(\"fieldName\", fieldValue); region.put(key, myWritablePdxI); // Deserialize the entire object if needed, from the PdxInstance DomainClass myPdxObject = (DomainClass)myPdxInstance.getObject(); } else if (myObject instanceof DomainClass) { // get returned instance of domain object // code to handle domain object instance ... } ... 注意: 由于PDX的限制，如果启用PDX的缓存包含TreeSet域对象，则应实现可以处理域对象和PdxInstance对象的Comparator。 您还需要在服务器上提供域类。 将JSON文档添加到Geode缓存 JSONFormatter API允许您将JSON格式的文档放入区域，然后通过将文档作为PdxInstances存储在内部来检索它们。 Geode本身支持使用JSON格式的文档。 将JSON文档添加到Geode缓存时，可以调用JSONFormatter API将它们转换为PDX格式（作为PdxInstance），这使Geode能够在字段级别理解JSON文档。 在查询和索引方面，由于文档在内部存储为PDX，因此应用程序可以对JSON文档中包含的任何字段（包括任何嵌套字段（在JSON对象或JSON数组中）进行索引。）对这些存储文档运行的任何查询都将返回PdxInstances 作为结果。 要更新存储在Geode中的JSON文档，可以在PdxInstance上执行一个函数。 然后，您可以使用JSONFormatter将PdxInstance结果转换回JSON文档。 JSONFormatter使用流解析器（Jackson，JSON处理器）将JSON文档转换为优化的PDX格式。 要使用JSONFormatter，请确保应用程序的CLASSPATH中有lib/geode-dependencies.jar。 JSONFormatter类有四个静态方法，用于将JSON文档转换为PdxInstances，然后将这些PdxInstances转换回JSON文档。 在将任何JSON文档放入Geode区域之前，需要调用以下方法： fromJSON. 从JSON字节数组创建PdxInstance。 返回PdxInstance。 fromJSON. 从JSON字符串创建PdxInstance。 返回PdxInstance。 将JSON文档作为PdxInstance放入区域后，您可以执行标准Geode查询并在JSON文档上创建索引，方法与查询或索引任何其他Geode PdxInstance的方式相同。 执行Geode查询或调用region.get后，您可以使用以下方法将PdxInstance转换回JSON格式： toJSON. 读取PdxInstance并返回JSON字符串。 toJSONByteArray. 读取PdxInstance并返回JSON字节数组。 有关使用JSONFormatter的更多信息，请参阅org.apache.geode.pdx.JSONFormatter的Java API文档。 序列化JSON字段的排序行为 默认情况下，Geode序列化为每个唯一的JSON文档创建唯一的pdx typeID，即使JSON文档之间的唯一区别是其字段的指定顺序。 如果您希望仅按指定字段顺序不同的JSON文档映射到相同的typeID，请将属性gemfire.pdx.mapper.sort-json-field-names设置为“true”。 这告诉系统在序列化之前对JSON字段进行排序，允许系统识别匹配的条目，并有助于减少序列化机制生成的pdx typeID的数量。 使用PdxInstanceFactory创建PdxInstances 当域类在服务器上不可用时，您可以使用PdxInstanceFactory接口从原始数据创建PdxInstance。 当您需要一个域类的实例来插入代码（如函数或加载器）时，这可能特别有用。 如果您拥有域对象的原始数据（类名和每个字段的类型和数据），那么您可以显式创建PdxInstance。 PdxInstanceFactory与PdxWriter非常相似，只是在写完每个字段后，需要调用create方法返回创建的PdxInstance。 创建工厂调用RegionService.createPdxInstanceFactory。 工厂只能创建单个实例。 要创建多个实例，请创建多个工厂或使用PdxInstance.createWriter()来创建后续实例。 使用PdxInstance.createWriter()通常更快。 创建PdxInstance时，使用markIndentityField方法设置至少一个标识字段。 如果不标记标识字段，则PdxInstanceequals和hashCode方法将使用所有PDX字段来比较对象，因此也不会执行。 重要的是，equals和hashCode实现使用的字段与您标记为标识字段的字段相同。 以下是使用PdxInstanceFactory的代码示例： PdxInstance pi = cache.createPdxInstanceFactory(\"com.company.DomainObject\") .writeInt(\"id\", 37) .markIdentityField(\"id\") .writeString(\"name\", \"Mike Smith\") .writeObject(\"favoriteDay\", cache.createPdxEnum(\"com.company.Day\", \"FRIDAY\", 5)) .create(); 有关更多信息，请参阅Java API文档中的PdxInstanceFactory。 枚举对象为PdxInstances 您现在可以使用枚举对象作为PdxInstances。 从缓存中获取枚举对象时，现在可以将其反序列化为PdxInstance。 要检查PdxInstance是否为枚举，请使用PdxInstance.isEnum方法。 枚举PdxInstance将有一个名为name的字段，其值是与枚举常量名称对应的String。 枚举PdxInstance不可写; 如果你调用createWriter它将抛出异常。 RegionService有一个方法，允许你创建一个表示枚举的PdxInstance。 请参阅Java API文档中的RegionService.createPdxEnum。 将PDX元数据保留到磁盘 Geode允许您将PDX元数据持久保存到磁盘并指定要使用的磁盘存储。 先决条件 一般了解如何配置Geode缓存。 参见基本配置和编程. 了解Geode磁盘存储的工作原理。 参见磁盘存储. 步骤 在缓存配置中将属性persistent设置为true。 对于将PDX与持久区域一起使用的缓存以及使用网关发送方通过WAN分发事件的区域，这是必需的。否则，它是可选的。 （可选）如果要使用不是Geode默认磁盘存储的磁盘存储，请将属性disk-store-name设置为非默认磁盘存储的名称。 注意:如果您使用PDX序列化对象作为区域条目键并且您使用的是持久区域，则必须将PDX磁盘存储配置为与持久区域使用的磁盘存储不同。 （可选）如果以后要重命名持久保存到磁盘的PDX类型，则可以通过执行pdx rename命令在脱机磁盘存储上执行此操作。 见pdx 重命名. 示例cache.xml： 此示例cache.xml启用PDX持久性并在服务器缓存配置中设置非默认磁盘存储： pdxSerialization.defaultSerializer 使用PDX对象作为区域输入键 强烈建议不要将PDX对象用作区域条目键。 创建区域条目键的最佳做法是使用简单的键; 例如，使用String或Integer。 如果key必须是域类，则应使用非PDX序列化类。 如果必须使用PDX序列化对象作为区域条目键，请确保不要将read-serialized设置为true。 此配置设置将导致分区区域出现问题，因为分区区域要求key的哈希码在分布式系统中的所有JVM上都相同。 当键是PdxInstance对象时，其哈希码可能与域对象的哈希码不同。 如果您使用PDX序列化对象作为区域条目键并且您使用的是持久区域，则必须将PDX磁盘存储配置为与持久区域使用的磁盘存储不同。 Geode数据序列化（DataSerializable和DataSerializer） Geode的DataSerializable接口为您提供了对象的快速序列化。 使用DataSerializable接口进行数据序列化 Geode的DataSerializable接口为您提供比标准Java序列化或Geode PDX序列化更快，更紧凑的数据序列化。 然而，虽然GeodeDataSerializable接口通常比Geode的'PdxSerializable`更高性能，但它需要在服务器上进行完全反序列化，然后再进行重新序列化以将数据发送回客户端。 您可以通过Instantiator注册DataSerializable类的实例化器来进一步加速序列化，从而无需反射来找到正确的序列化器。 您可以通过API提供自己的序列化。 注册自定义Instantiator的推荐方法是在cache.xml的serialization-registration元素中指定它。 有关更多信息，请参阅DataSerializable和DataSerializer的在线Java文档。 例子 cache.xml: 以下提供了如何使用cache.xml注册实例化器的示例。 com.package.MyClass 除了加速标准对象序列化之外，您还可以使用DataSerializable接口来序列化存储在缓存中的任何自定义对象。 使用DataSerializer序列化您的域对象 您还可以使用DataSerializer来序列化域对象。 它以与DataSerializable相同的方式序列化数据，但允许您在不修改域类代码的情况下序列化类。 请参阅[DataSerializable]上的JavaDocs(https://geode.apache.org/releases/latest/javadoc/org/apache/geode/DataSerializable.html)和[DataSerializer](https://geode.apache.org/releases/latest/javadoc/org/apache/geode/DataSerializer.html) 了解更多信息。 标准Java序列化 您可以对仅在Java应用程序之间分发的数据使用标准Java序列化。 如果在非Java客户端和Java服务器之间分发数据，则需要执行其他编程以获取各种类格式之间的数据。 根据定义，标准Java类型是可序列化的。 对于您的域类，实现java.io.Serializable，然后确保根据对象标记瞬态和静态变量。 有关信息，请参阅Java版本的java.io.Serializable的联机文档。 将DataSerializable与Serializable或PdxSerializable混合使用在相同的数据上会导致内存使用量增加，吞吐量低于仅对整个数据使用Serializable，特别是如果Serializable条目在集合中。 数据收集越大，吞吐量越低，因为使用DataSerializable时不会共享集合条目的元数据。 事件和事件处理 Geode为缓存的数据和系统成员事件提供了通用且可靠的事件分发和处理。 事件是如何工作 集群中的成员通过缓存事件从其他成员接收缓存更新。 其他成员可以是成员，客户端或服务器或其他集群的对等成员。 实现Geode事件处理程序 您可以为区域和区域条目操作以及管理事件指定事件处理程序。 配置点对点事件消息 您可以从集群对等方接收非本地区域的任何区域的事件。 本地区域仅接收本地缓存事件。 配置客户端/服务器事件消息 您可以从服务器接收服务器端缓存事件和查询结果更改的事件。 配置多站点（WAN）事件队列 在多站点（WAN）安装中，Geode使用网关发件人队列来为使用网关发件人配置的区域分发事件。 AsyncEventListeners还使用异步事件队列来分配已配置区域的事件。 本节介绍用于配置网关发件人或AsyncEventListener实现使用的事件队列的其他选项。 事件是如何工作 Geode集群中的成员通过缓存事件从其他成员接收缓存更新。 其他成员可以是成员，客户端或服务器或其他集群的对等成员。 事件特征 这些是Geode事件的主要特征： 基于内容的事件 带有混合的异步事件通知 低延迟的同步事件通知 通过冗余消息队列实现高可用性 事件排序和一次且仅一次交付 分布式事件通知 持久的订阅 持续查询 事件类型 有两类事件和事件处理程序。 缓存API中的缓存事件由具有缓存的应用程序使用。 缓存事件为数据更改提供详细级别的通知。 连续查询事件属于此类别。 管理API中的管理事件由没有缓存的管理应用程序使用。 两种事件都可以由单个成员操作生成。 注意: 您可以在单个系统成员中处理这些类别的事件之一。 您无法在单个成员中处理缓存和管理事件。 由于Geode分别维护管理事件的顺序和缓存事件的顺序，因此在单个进程中使用缓存事件和管理事件可能会导致意外结果。 事件周期 以下步骤描述了事件周期: 操作开始，例如数据放入或缓存关闭。 操作执行生成以下对象： Operation类型的对象，描述触发事件的方法。 描述事件的事件对象，例如操作源自的成员和区域。 可以处理事件的事件处理程序被调用并传递事件对象。 不同的事件类型需要不同位置的不同处理程序类型 如果没有匹配的事件处理程序，则不会改变操作的效果，这通常会发生。 当处理程序收到事件时，它会触发此事件的处理程序的回调方法。 回调方法可以将事件对象作为另一个方法的输入切换。 根据事件处理程序的类型，可以在操作之前或之后触发回调。 时间取决于事件处理程序，而不是事件本身。 注意:对于事务，事务后监听器在事务提交后收到事件。 如果操作是分布式的，那么它会导致其他成员的后续操作，那些操作会生成他们自己的事件，这些事件可以由他们的侦听器以相同的方式处理。 事件对象 事件对象有多种类型，具体取决于操作。 某些操作会生成多个不同类型的对象。 所有事件对象都包含描述事件的数据，每个事件类型都包含适合其匹配操作的略微不同类型的数据。 事件对象是稳定的。 例如，如果将其传递给另一个线程上的方法，则其内容不会更改。 对于缓存事件，事件对象描述在本地缓存中执行的操作。 如果事件是远程发起的，则它描述远程输入操作的本地应用程序，而不是远程操作本身。 唯一的例外是本地区域有空数据策略; 然后事件携带远程（始发）高速缓存操作的信息。 事件分发 成员在其本地缓存中处理事件后，会根据成员的配置和远程缓存的配置将其分发到远程缓存。 例如，如果客户端更新其缓存，则更新将转发到客户端的服务器。 服务器将更新分发给其对等方，并根据它们对数据条目的兴趣将其转发给任何其他客户端。 如果服务器系统是多站点部署的一部分并且数据区域配置为使用网关发送方，则网关发送方还将更新转发到远程站点，在该站点中进一步分发和传播更新。 事件处理程序和区域数据存储 您可以为没有本地数据存储的区域配置区域，并仍然发送和接收该区域的事件。 相反，如果您在区域中存储数据，则无论您是否安装了任何事件处理程序，都会使用事件中的数据更新缓存。 多个监听器 安装多个侦听器时，可以使用缓存侦听器，按照添加到区域或缓存的顺序依次调用侦听器。 监听器一次执行一个。 因此，除非您将侦听器编程为将处理传递给另一个线程，否则您可以在以后的侦听器中使用一个侦听器的工作。 事件排序 在高速缓存操作期间，在操作的各个阶段调用事件处理程序。 在区域更新之前调用一些事件处理程序，在区域更新操作之后调用一些事件处理程序。 根据被调用的事件处理程序的类型，事件处理程序可以按顺序或无序接收它们在Region上应用的事件。 CacheWriter和AsyncEventListener总是按照它们在区域上应用的顺序接收事件。 CacheListener和CqListener可以按照与在区域上应用它们的顺序不同的顺序接收事件。 注意: EntryEvent包含条目的旧值和新值，这有助于指示由特定键上的缓存操作替换的值。 点对点事件分发 执行区域或条目操作时，Geode会根据系统和缓存配置在集群中分配关联的事件。 为每个系统成员中需要接收区域和条目更改通知的区域安装缓存侦听器。 分区区域中的事件 分布式操作遵循此序列在分区区域中： 如果适用，将操作应用于具有主数据条目的缓存。 根据其他成员的订阅属性兴趣策略进行分发。 在接收分发的缓存中调用任何侦听器。 使用主数据条目在缓存中调用侦听器。 在下图中： 成员M1中的API调用创建一个条目。 分区区域在M2中的缓存中创建新条目。 M2，主副本的持有者，驱动程序的其余部分。 这两个操作同时发生： 分区区域在M3中的高速缓存中创建条目的辅助副本。 创建辅助副本不会调用M3上的侦听器。 M2将事件分发给M4。 向其他成员的分配基于他们的利益政策。 M4拥有所有人的利益政策，因此它接收该地区任何地方的所有事件的通知。 由于M1和M3具有缓存内容的兴趣策略，并且此事件不会影响其本地缓存中的任何预先存在的条目，因此它们不会收到该事件。 M4上的缓存侦听器处理M2上的远程事件的通知。 一旦其他成员上的所有内容都成功完成，M2上的原始创建操作就会成功并调用M2上的缓存侦听器。 分布式区域中的事件 分布式操作遵循此序列在分布式区域中： 如果适用，将操作应用于本地缓存。 调用本地侦听器。 做分发。 接收分发的每个成员在响应中执行其自己的操作，其调用任何本地侦听器。 在下图中： 通过成员M1上的直接API调用创建条目。 create在M1上调用缓存侦听器。 M1将事件分发给其他成员。 M2和M3通过自己的本地操作应用远程更改。 M3执行创建，但M2执行更新，因为该条目已存在于其缓存中。 M2上的缓存侦听器接收本地更新的回调。 由于M3上没有缓存侦听器，因此不会处理来自M3上的create的回调。 成员M1中的API调用创建一个条目。 管理多线程应用程序中的事件 对于分区区域，Geode保证跨线程排序事件，但对于分布式区域，它不会。 对于创建分布式区域的多线程应用程序，您需要使用应用程序同步以确保在下一个操作开始之前完成一个操作。 如果将conserve-sockets属性设置为true，则通过distributed-no-ack队列进行分发可以使用多个线程。 然后线程共享一个队列，保留分布区域中事件的顺序。 不同的线程可以调用相同的侦听器，因此如果允许不同的线程发送事件，则可能导致侦听器的并发调用。 仅当线程具有某种共享状态时才会出现此问题 - 例如，如果它们正在递增序列号，或者将其事件添加到日志队列中。 然后，您需要使您的代码线程安全。 客户端到服务器事件分发 客户端和服务器根据客户端活动并根据客户端在服务器端缓存更改中注册的兴趣来分发事件。 当客户端更新其缓存时，对客户端区域的更改会自动转发到服务器端。 然后，服务器端更新将传播到已连接的其他客户端并启用订阅。 服务器不会将更新返回给发送客户端。 更新将传递到服务器，然后通过该值传递给已注册对条目key感兴趣的其他每个客户端。 此图显示了如何传播客户端的条目更新。 该图显示了以下过程： 通过Client1上的直接API调用在区域A中更新或创建条目X. 对该区域的更新将传递到该区域中指定的池。 池将事件传播到缓存服务器，更新区域。 服务器成员将事件分发给其对等体，并将其放入Client2的预订队列中，因为该客户端先前已注册对条目X的兴趣。 条目X的事件从队列发送到Client2。 当这种情况发生时是不确定的。 客户端到服务器分发使用客户端池连接将更新发送到服务器。 具有命名池的任何区域都会自动将更新转发给服务器。 客户端缓存修改首先通过客户端CacheWriter（如果已定义），然后通过客户端池传递到服务器，最后传递到客户端缓存本身。 客户端或服务器端的缓存写入器可能会中止操作。 更改客户端缓存 对服务器缓存的影响 条目创建或更新 创建或更新条目。 分布式条目销毁 条目销毁。 即使条目不在客户端缓存中，destroy调用也会传播到服务器。 分布式区域销毁/清除（仅分布式） 区域销毁/清除 注意: 客户端的失效不会转发到服务器。 服务器到客户端事件分发 服务器仅针对客户端已注册的key自动发送条目修改事件。 在兴趣注册中，客户端指示是为服务器端条目创建和更新发送新值还是仅发送无效。 如果使用了无效，则客户端会根据需要懒惰地更新值。 此图显示了兴趣注册的完整事件订阅事件分发，请求了值收据（receiveValues = true）且没有。 更改服务器缓存 对客户端缓存的影响 条目创建/更新 对于receiveValues设置为true的订阅，条目创建或更新。对于receiveValues设置为false的订阅，如果条目已存在于客户端缓存中，则条目无效; 否则，没有效果。 下一个客户端获取的条目将转发到服务器。 条目无效/销毁（仅限分布式） 条目无效/销毁 区域销毁/清除（仅限分布式） 区域破坏或局部区域清除 服务器端分布式操作是在服务器或其中一个对等体中作为分布式操作发起的所有操作。 服务器中的区域失效不会转发到客户端。 注意: 要在服务器中维护统一的数据集，请不要在服务器区域中执行本地条目失效。 服务器到客户端的消息跟踪 服务器使用异步消息传递队列将事件发送到其客户端。 队列中的每个事件都源自客户端，服务器中的线程或服务器或某个其他集群中的应用程序执行的操作。 事件消息具有唯一标识符，该标识符由始发线程的ID与其成员的分布式系统成员ID以及操作的顺序ID组成。 因此，源自任何单个线程的事件消息可以按时间从最低序列ID到最高序列进行分组和排序。 服务器和客户端跟踪每个成员线程ID的最高顺序ID。 单个客户端线程接收并处理来自服务器的消息，跟踪收到的消息以确保它不处理重复发送。 它使用来自原始线程的进程ID来完成此操作。 客户端的消息跟踪列表保存为每个始发线程接收的任何消息的最高序列ID。 在有许多不同线程进出并在缓存上工作的系统中，该列表可能变得非常大。 线程死亡后，不需要跟踪条目。 为了避免维护已经死亡的线程的跟踪信息，客户端会使没有活动的条目超过subscription-message-tracking-timeout。 在服务器上注册客户端兴趣 系统按照以下步骤处理客户兴趣注册： 客户区域中可能受此注册影响的条目将被静默销毁。 其他key是独自留下的。 对于registerInterest方法，系统会销毁所有指定的key，只留下客户区域中的其他key。 因此，如果您有一个带有键A，B和C的客户区，并且您在registerInterest操作开始时注册了对键列表A，B的兴趣，系统会破坏客户端缓存中的键A和B，但是 不要碰键C. 对于registerInterestRegex方法，系统以静默方式销毁客户区域中的所有key。 兴趣规范被发送到服务器，并将其添加到客户端的兴趣列表中。 该列表可以指定在注册兴趣时不在服务器区域中的条目。 如果在调用的InterestResultPolicy参数中请求批量加载，则在将控制返回到调用方法之前，服务器将发送当前满足兴趣规范的所有数据。 使用下载的数据自动更新客户端的区域。 如果服务器区域已分区，则整个分区区域将用于批量加载。 否则，仅使用服务器的本地缓存区域。 兴趣结果政策选项包括： KEYS—客户端接收与兴趣注册标准匹配的所有可用key的批量加载。 KEYS_VALUES—客户端接收所有可用key的批量加载和与兴趣注册标准匹配的值。 这是默认的兴趣结果政策。 NONE—客户端没有立即收到批量加载。 一旦注册了兴趣，服务器就会持续监控区域活动并将事件发送给符合兴趣的客户。 注册器兴趣调用不会生成任何事件，即使它们将值加载到客户端缓存中也是如此。 服务器维护所有兴趣注册的联合，因此如果客户注册对密钥'A'的兴趣，然后注册对正则表达式“B*”的兴趣，服务器将发送带有key'A'或以字母'B'开头key的所有条目的更新 。 服务器将兴趣注册列表与区域分开。 该列表可以包含当前不在服务器区域中的条目的规范。 registerInterestRegex方法使用标准的java.util.regex方法来解析key规范。 服务器故障转移 当托管订阅队列的服务器失败时，排队职责将传递给另一台服务器。 如何发生这取决于新服务器是否是辅助服务器。 在任何情况下，所有故障转移活动都由Geode系统自动执行。 非HA故障转移: 如果未配置冗余，或者在初始化新辅助节点之前所有辅助节点都失败，则客户端在没有高可用性的情况下进行故障转移。只要它可以连接到服务器，客户端就会进行自动重新初始化过程。在此过程中，客户端上的故障转移代码以静默方式销毁客户端感兴趣的所有条目，并从新服务器中重新获取它们，实质上是从新服务器的缓存中重新初始化客户端缓存。对于notify all配置，这将清除并重新加载连接到服务器的客户端区域的所有条目。对于按订阅通知，它仅清除并重新加载区域兴趣列表中的条目。为了减少故障转移噪声，由本地条目销毁和重新获取引起的事件被故障转移代码阻止，并且不会到达客户端缓存侦听器。因此，您的客户端可能会在服务器故障转移期间和之后收到一些无序事件。例如，故障转移期间，故障服务器上存在而不是其替换的条目将被销毁，并且永远不会重新创建。由于销毁事件被阻止，因此客户端最终会从其缓存中删除条目而没有关联的销毁事件。 HA 故障转移: 如果客户端池配置了冗余，并且主服务器出现故障时辅助服务器可用，则客户端将无法访问故障转移。 一旦检测到主要丢失，辅助服务器就会恢复排队活动。 辅助节点可能会重新发送一些事件，这些事件会被客户端邮件跟踪活动自动丢弃。 注意: 在HA服务器故障转移期间，消息丢失的可能性非常小。 故障转移到已完全初始化其订阅队列数据的辅助节点的风险不存在。 在使用至少两台辅助服务器的健康系统中，风险极低。 在服务器经常出现故障的不稳定系统中，以及辅助设备在成为初选之前没有时间初始化其订阅队列数据的风险更高。 为了最小化风险，故障转移逻辑选择寿命最长的辅助节点作为新的主节点。 注意: 冗余管理由客户端处理，因此当持久客户端与服务器断开连接时，不会维护客户端事件冗余。 即使服务器一次失败一个，以便运行的客户端有时间进行故障转移并选择新的辅助服务器，脱机持久客户端也无法进行故障转移。 结果，客户端丢失其排队的消息。 多站点（WAN）事件分发 Geode在集群之间分配缓存事件的子集，对每个系统的性能影响最小。 仅为您配置为使用网关发件人进行分发的区域分发事件。 为分发排队事件 在使用一个或多个网关发件人（gateway-sender-ids属性）配置的区域中，事件会自动添加到网关发件人队列以分发到其他站点。 放置在网关发送方队列中的事件将异步分发到远程站点。 对于串行网关队列，可以使用order-policy属性保留站点之间发送的事件的顺序。 如果队列变得太满，它会溢出到磁盘以防止成员内存不足。 您可以选择将队列配置为持久保存到磁盘（使用enable-persistence gateway-sender属性）。 使用持久性，如果管理队列的成员发生故障，成员将在重新启动后从中断处继续。 来自网关发件人的操作分配 多站点安装旨在最大限度地降低对群集性能的影响，因此只有最远的入口操作才会在站点之间分配。 这些操作分布在： 条目创建 条目放置 条目分布式销毁，提供的操作不是到期操作 这些操作不分发： 获取 作废 当地销毁 任何类型的到期行为 区域操作 网关发件人如何处理其队列 每个主网关发送器都包含一个处理器线程，该线程从队列中读取消息，对其进行批处理，并将批处理分发到远程站点中的网关接收器。 要处理队列，网关发送方线程将执行以下操作： 从队列中读取消息 创建一批消息 同步将批处理分发到其他站点并等待回复 在另一个站点成功回复后，从队列中删除批处理 因为在其他站点回复之前，批处理不会从队列中删除，所以该消息不会丢失。 另一方面，在此模式下，可以多次处理消息。 如果站点在处理一批消息的过程中脱机，则一旦站点重新联机，将再次发送该批次。 您可以配置消息的批处理大小以及批处理时间间隔设置。 当达到批量大小或时间间隔时，网关发件人处理来自队列的一批消息。 在活动网络中，很可能在时间间隔之前达到批量大小。 在空闲网络中，最有可能在批量大小之前达到时间间隔。 这可能导致一些与时间间隔相对应的网络延迟。 网关发件人如何处理批处理失败 批处理期间的不同点可能会发生异常： 网关接收器可能会因确认而失败。 如果在网关接收器处理批处理时处理失败，则接收方将回复包含异常的失败确认，包括失败消息的标识以及成功处理的最后一条消息的ID。 然后，网关发件人从队列中删除成功处理的消息和失败的消息，并使用失败的消息信息记录异常。 然后，发送方继续处理队列中剩余的消息。 网关接收器可能无法确认而失败。 如果网关接收方未确认已发送的批次，则网关发件人不知道哪些消息已成功处理。 在这种情况下，网关发件人重新发送整批。 没有网关接收器可用于处理。 如果由于没有可用的远程网关接收器而发生批处理异常，则批处理仍保留在队列中。 网关发件人等待一段时间，然后尝试重新发送批次。 尝试之间的时间间隔为五秒。 现有服务器监视器不断尝试连接到网关接收器，以便可以建立连接并继续进行队列处理。 消息在队列中累积，并可能在等待连接时溢出到磁盘。 事件处理程序和事件列表 Geode提供了许多类型的事件和事件处理程序，可帮助您管理不同的数据和应用程序需求。 事件处理程序 在任何单个应用程序中使用缓存处理程序或成员资格处理程序。 不要同时使用两者。 除非另有说明，否则此表中的事件处理程序是缓存处理程序。 处理程序API 收到的事件 描述 AsyncEventListener AsyncEvent 跟踪区域中的更改以进行后写处理。 扩展CacheCallback接口。 您将回写缓存侦听器安装到AsyncEventQueue实例。 然后，您可以将“AsyncEventQueue”实例添加到一个或多个区域以进行后写处理。 请参阅实现用于后写高速缓存事件处理的AsyncEventListener。 CacheCallback 所有缓存事件侦听器的超级接口。 仅用于清除回调分配的资源的函数。 CacheListener RegionEvent, EntryEvent 跟踪区域及其数据条目的更改。 同步响应。 扩展CacheCallback接口。 安装在地区。 仅接收本地缓存事件。 在您希望此侦听器处理事件的每个成员中安装一个。 在分区区域中，缓存侦听器仅在主数据存储中触发。 辅助听众不会被解雇。 CacheWriter RegionEvent, EntryEvent 接收该区域及其成员或其中一个对等方中的区域及其数据条目的待定更改事件。 是否有能力中止有问题的操作。 扩展CacheCallback接口。 安装在地区。 从分布式区域中的任何位置接收事件，因此您可以为整个分布式区域安装一个成员。 仅在分区区域中的主数据存储中接收事件，因此在每个数据存储中安装一个事件。 ClientMembershipListener ClientMembershipEvent 替换已弃用的Admin API的接口之一。 您可以使用ClientMembershipListener仅接收有关客户端的成员资格事件。 当此进程检测到客户端的连接更改时，将调用此侦听器的回调方法。 回调方法包括memberCrashed，memberJoined，memberLeft（graceful exit）。 CqListener CqEvent 从服务器缓存接收满足客户端指定查询的事件。 扩展CacheCallback接口。 安装在CqQuery里面的客户端。 GatewayConflictResolver TimestampedEntryEvent 决定是否将可能存在冲突的事件应用于通过WAN配置分发的区域。 仅当更新事件的分布式系统ID与上次更新区域条目的ID不同时，才会调用此事件处理程序。 MembershipListener MembershipEvent 使用此接口仅接收有关对等方的成员资格事件。 当对等成员加入或离开集群时，将调用此侦听器的回调方法。 回调方法包括memberCrashed，memberJoined和memberLeft（graceful exit）。 RegionMembershipListener RegionEvent 当在另一个成员中创建了具有相同名称的区域以及托管该区域的其他成员加入或离开集群时，提供事件后通知。 扩展CacheCallback和CacheListener。 作为CacheListener安装在区域中。 TransactionListener TransactionEvent with embedded list of EntryEvent 跟踪事务的结果和事务中数据条目的更改。注意:同一缓存上的多个事务可能导致并发调用TransactionListener方法，因此实现为多个线程进行适当同步以进行线程安全操作的方法。扩展CacheCallback接口。 使用事务管理器安装在缓存中。 如果需要，可以使用区域级侦听器。 TransactionWriter TransactionEvent with embedded list of EntryEvent 接收 pending 事务提交的事件。 有能力中止交易。 扩展CacheCallback接口。 使用事务管理器安装在缓存中。 每个事务最多调用一个编写器。 在每个事务主机中安装writer。 UniversalMembershipListenerAdapter MembershipEvent and ClientMembershipEvent 替换已弃用的Admin API的接口之一。 为客户端和对等端的MembershipListener和ClientMembershipListener回调提供包装器。 事件 除非另有说明，否则此表中的事件是缓存事件。 事件 传递给处理程序 … 描述 AsyncEvent AsyncEventListener 提供有关异步，后写处理的高速缓存中单个事件的信息。 CacheEvent 超级接口到RegionEvent和EntryEvent。 这定义了常见的事件方法，并包含诊断事件环境所需的数据，包括正在执行的操作的描述，有关事件源自何处的信息，以及传递给生成此事件的方法的任何回调参数。 ClientMembershipEvent ClientMembershipListener 当此进程检测到对服务器或客户端的连接更改时，会将事件传递给ClientMembershipListener。 CqEvent CqListener 提供有关代表客户端在服务器上运行的连续查询结果的更改的信息。 CqEvents在客户端上处理。 EntryEvent CacheListener, CacheWriter, TransactionListener(inside the TransactionEvent) 为入口事件扩展CacheEvent。 包含有关影响缓存中数据条目的事件的信息。 信息包括key，此事件之前的值以及此事件之后的值。 EntryEvent.getNewValue返回数据条目的当前值。 EntryEvent.getOldValue返回此事件之前的值（如果可用）。 对于分区区域，如果本地缓存包含条目的主副本，则返回旧值。 EntryEvent提供Geode事务ID（如果可用）。您可以使用getSerialized *方法从EntryEvent检索序列化值。 如果从一个区域的事件中获取值只是为了将它们放入单独的缓存区域，这将非常有用。 没有对应的put函数，因为put识别该值被序列化并绕过序列化步骤。 MembershipEvent(membership event) MembershipListener 描述发起此事件的成员的事件。 当成员加入或离开集群时，会将此实例传递给MembershipListener。 RegionEvent CacheListener, CacheWriter, RegionMembershipListener 为区域事件扩展CacheEvent。 提供有关影响整个区域的操作的信息，例如在销毁后重新初始化该区域。 TimestampedEntryEvent GatewayConflictResolver 扩展EntryEvent以包括与事件关联的时间戳和分布式系统ID。 冲突解决程序可以将事件中的时间戳和ID与存储在条目中的值进行比较，以确定本地系统是否应该应用潜在冲突的事件。 TransactionEvent TransactionListener, TransactionWriter 描述事务中完成的工作。 此事件可能用于挂起或已提交的事务，也可能用于显式回滚或失败提交放弃的工作。 该工作由EntryEvent实例的有序列表表示。 条目事件按事务中执行操作的顺序列出。在执行事务操作时，条目事件被混合，每个条目的最后一个事件仅保留在列表中。 因此，如果修改了条目A，然后是条目B，那么条目A，该列表将包含条目B的事件，后面是条目A的第二个事件。 实现Geode事件处理程序 您可以为区域和区域条目操作以及管理事件指定事件处理程序。 实现缓存事件处理程序 根据您的安装和配置，缓存事件可以来自本地操作，对等方，服务器和远程站点。 事件处理程序在一个或多个事件中注册其兴趣，并在事件发生时得到通知。 为Write-Behind Cache事件处理实现AsyncEventListener AsyncEventListener”在将批量事件应用于区域后异步处理这些事件。 您可以使用AsyncEventListener实现作为后写缓存事件处理程序，以将区域更新与数据库同步。 如何从事件处理程序回调安全地修改缓存 事件处理程序是同步的。 如果需要更改缓存或从事件处理程序回调执行任何其他分布式操作，请小心避免可能阻止并影响整体系统性能的活动。 缓存事件处理程序示例 缓存事件处理程序的一些示例。 实现缓存事件处理程序 根据您的安装和配置，缓存事件可以来自本地操作，对等方，服务器和远程站点。 事件处理程序在一个或多个事件中注册其兴趣，并在事件发生时得到通知。 对于每种类型的处理程序，Geode为接口回调方法提供了一个带有空存根的便捷类。 注意: 通过扩展AsyncEventListener接口创建后写高速缓存侦听器，并且它们配置有您分配给一个或多个区域的AsyncEventQueue。 步骤 确定应用程序需要处理哪些事件。 对于每个区域，确定要处理的事件。 对于缓存，决定是否处理事务事件。 对于每个事件，决定使用哪些处理程序。 org.apache.geode.cache.util中的*Listener和*Adapter类显示选项。 编程每个事件处理程序: 扩展处理程序的适配器类。 如果要在cache.xml中声明处理程序，也要实现org.apache.geode.cache.Declarable接口。 根据应用程序的需要实现处理程序的回调方法。 注意: 编程不正确的事件处理程序可能会阻止您的分布式系统。 缓存事件是同步的。 要根据事件修改缓存或执行分布式操作，请遵循如何从事件处理程序回调安全地修改缓存中的准则来避免阻塞系统. 例子: package myPackage; import org.apache.geode.cache.Declarable; import org.apache.geode.cache.EntryEvent; import org.apache.geode.cache.util.CacheListenerAdapter; import java.util.Properties; public class MyCacheListener extends CacheListenerAdapter implements Declarable { /** Processes an afterCreate event. * @param event The afterCreate EntryEvent received */ public void afterCreate(EntryEvent event) { String eKey = event.getKey(); String eVal = event.getNewValue(); ... do work with event info } ... process other event types } 通过API或cache.xml安装事件处理程序。 XML Region事件处理程序安装： myPackage.MyCacheListener Java Region事件处理程序安装： tradesRegion = cache.createRegionFactory(RegionShortcut.PARTITION) .addCacheListener(new MyCacheListener()) .create(\"trades\"); XML事务编写器和监听器安装： com.company.data.MyTransactionListener jdbc:cloudscape:rmi:MyData . . . com.company.data.MyTransactionWriter jdbc:cloudscape:rmi:MyData . . . 启动成员时，在区域创建期间会自动初始化事件处理程序。 在区域上安装多个侦听器 XML: . . . myCacheListener1 myCacheListener2 myCacheListener3 API: CacheListener listener1 = new myCacheListener1(); CacheListener listener2 = new myCacheListener2(); CacheListener listener3 = new myCacheListener3(); Region nr = cache.createRegionFactory() .initCacheListeners(new CacheListener[] {listener1, listener2, listener3}) .setScope(Scope.DISTRIBUTED_NO_ACK) .create(name); 为Write-Behind Cache事件处理实现AsyncEventListener AsyncEventListener在将批量事件应用于区域后异步处理这些事件。 您可以使用AsyncEventListener实现作为后写缓存事件处理程序，以将区域更新与数据库同步。 AsyncEventListener的工作原理 AsyncEventListener实例由其自己的专用线程提供服务，其中调用了一个回调方法。 更新区域的事件放在内部的AsyncEventQueue中，并且一个或多个线程一次将一批事件分派给侦听器实现。 您可以将AsyncEventQueue配置为串行或并行。 串行队列部署到一个Geode成员，它按发生顺序将所有区域事件传递给已配置的AsyncEventListener实现。 并行队列部署到多个Geode成员，并且队列的每个实例都可以同时将区域事件传递给本地的AsyncEventListener实现。 虽然并行队列为写入事件提供了最佳吞吐量，但它对订购这些事件提供的控制较少。 使用并行队列时，您无法保留整个区域的事件排序，因为多个Geode服务器会同时排队并传递区域的事件。 但是，可以保留给定分区（或分布式区域的给定队列）的事件顺序。 对于串行和并行队列，您可以控制每个队列使用的最大内存量，以及处理队列中批次的批量大小和频率。 您还可以将队列配置为持久保存到磁盘（而不是简单地溢出到磁盘），以便后续缓存可以在成员关闭并稍后重新启动时从中断处获取。 （可选）队列可以使用多个线程来分派排队事件。 为串行队列配置多个线程时，Geode成员上托管的逻辑队列将分为多个物理队列，每个队列都有一个专用的调度程序线程。 然后，您可以配置线程是按键，按线程还是按照将事件添加到队列的相同顺序来调度排队事件。 为并行队列配置多个线程时，托管在Geode成员上的每个队列都由调度程序线程处理; 创建的队列总数取决于托管该区域的成员数。 可以在AsyncEventQueue上放置一个GatewayEventFilter来控制是否将特定事件发送到选定的AsyncEventListener。 例如，可以检测与敏感数据相关联的事件而不排队。 有关更多详细信息，请参阅GatewayEventFilter的Javadoc。 GatewayEventSubstitutionFilter可以指定事件是完整传输还是以更改的表示形式传输。 例如，要减小要序列化的数据的大小，仅通过其键表示完整对象可能更有效。 有关更多详细信息，请参阅GatewayEventSubstitutionFilter的Javadoc。 来自AsyncEventQueue的分布式操作 AsyncEventQueue分发这些操作： Entry 创建 Entry 放置 Entry 分布式销毁，提供的操作不是到期操作 如果forward-expiration-destroy属性设置为'true，则到期销毁。 默认情况下，此属性为false，但您可以使用cache.xml或gfsh将其设置为true。 要在Java API中设置此属性，请使用AsyncEventQueueFactory.setForwardExpirationDestroy()`。 有关详细信息，请参阅javadocs。 这些操作不是分布式的： 获取 失效 本地销毁 区域操作 过期操作 如果forward-expiration-destroy属性设置为false，则到期销毁。 默认值为false。 使用AsyncEventListener的准则 在使用AsyncEventListener之前，请查看以下准则： 如果使用AsyncEventListener来实现后写缓存侦听器，则代码应检查由于先前的异常而可能已关闭现有数据库连接的可能性。 例如，在catch块中检查Connection.isClosed()并在执行进一步操作之前根据需要重新创建连接。 如果在向侦听器实现传递事件时需要保留线程中区域事件的顺序，请使用序列AsyncEventQueue。 当线程内的事件顺序不重要时，以及处理事件时需要最大吞吐量时，请使用并行队列。 在串行和并行两种情况下，给定键的操作顺序都保留在线程的范围内。 您必须在承载要处理其事件的区域的Geode成员上安装AsyncEventListener实现。 如果配置并行AsyncEventQueue，请在承载该区域的每个Geode成员上部署队列。 如果具有活动AsyncEventListener的成员关闭，您可以在多个成员上安装侦听器以提供高可用性并保证事件的传递。 在任何给定时间，只有一个成员具有用于调度事件的主动侦听器。 其他成员的监听器仍处于备用状态以实现冗余。 为了获得最佳性能和最有效的内存使用，请仅安装一个备用侦听器（最多一个冗余）。 出于性能和内存原因，安装不超过一个备用侦听器（最多一个冗余）。 要通过成员关闭保留挂起事件，请将Geode配置为将AsyncEventListener的内部队列持久保存到可用磁盘存储中。 默认情况下，如果活动侦听器的成员关闭，则驻留在AsyncEventListener的内部队列中的任何挂起事件都将丢失。 要确保事件的高可用性和可靠传递，请将事件队列配置为持久和冗余。 实现AsyncEventListener 要接收要处理的区域事件，可以创建一个实现AsyncEventListener接口的类。 侦听器中的processEvents方法接收每个批处理中排队的AsyncEvent对象的列表。 每个AsyncEvent对象都包含有关区域事件的信息，例如事件发生的区域的名称，区域操作的类型以及受影响的键和值。 实现后写事件处理程序的基本框架包括迭代批处理事件并将每个事件写入数据库。 例如： class MyAsyncEventListener implements AsyncEventListener { public boolean processEvents(List events) { // Process each AsyncEvent for(AsyncEvent event: events) { // Write the event to a database } } } 处理AsyncEvents 使用AsyncEventListener.processEvents方法处理AsyncEvents。 当事件排队等待处理时，将异步调用此方法。 列表的大小反映了在AsyncEventQueueFactory中定义批量大小的批处理事件的数量。 processEventsmethod返回一个布尔值; 如果正确处理了AsyncEvents，则为true;如果任何事件处理失败，则为false。 只要processEvents返回false，Geode就会继续重新尝试处理事件。 您可以使用getDeserializedValue方法获取已更新或创建的条目的缓存值。 由于getDeserializedValue方法将为已销毁的条目返回null值，因此应使用getKey方法获取对已销毁的缓存对象的引用。 这是处理AsyncEvents的示例： public boolean processEvents(@SuppressWarnings(\"rawtypes\") List list) { logger.log (Level.INFO, String.format(\"Size of List = %s\", list.size())); List newEntries = new ArrayList(); List updatedEntries = new ArrayList(); List destroyedEntries = new ArrayList(); int possibleDuplicates = 0; for (@SuppressWarnings(\"rawtypes\") AsyncEvent ge: list) { if (ge.getPossibleDuplicate()) possibleDuplicates++; if ( ge.getOperation().equals(Operation.UPDATE)) { updatedEntries.add((JdbcBatch) ge.getDeserializedValue()); } else if ( ge.getOperation().equals(Operation.CREATE)) { newEntries.add((JdbcBatch) ge.getDeserializedValue()); } else if ( ge.getOperation().equals(Operation.DESTROY)) { destroyedEntries.add(ge.getKey().toString()); } } 配置AsyncEventListener 要配置后写高速缓存侦听器，首先要配置异步队列以分派区域事件，然后使用侦听器实现创建队列。 然后，您可以将队列分配给某个区域，以便处理该区域的事件。 步骤 使用侦听器实现的名称配置唯一的AsyncEventQueue。 您可以选择为并行操作，持久性，批量大小和最大内存大小配置队列。 有关详细信息，请参阅WAN配置 。 gfsh配置 gfsh>create async-event-queue --id=sampleQueue --persistent --disk-store=exampleStore --listener=com.myCompany.MyAsyncEventListener --listener-param=url#jdbc:db2:SAMPLE,username#gfeadmin,password#admin1 The parameters for this command uses the following syntax: create async-event-queue --id=value --listener=value [--group=value] [--batch-size=value] [--persistent(=value)?] [--disk-store=value] [--max-queue-memory=value] [--listener-param=value(,value)*] 有关更多信息，请参阅create async-event-queue. cache.xml 配置 MyAsyncEventListener jdbc:db2:SAMPLE gfeadmin admin1 ... Java 配置 Cache cache = new CacheFactory().create(); AsyncEventQueueFactory factory = cache.createAsyncEventQueueFactory(); factory.setPersistent(true); factory.setDiskStoreName(\"exampleStore\"); factory.setParallel(false); AsyncEventListener listener = new MyAsyncEventListener(); AsyncEventQueue asyncQueue = factory.create(\"sampleQueue\", listener); 如果您使用并行的AsyncEventQueue，则上面的gfsh示例不需要更改，因为gfsh适用于所有成员。 如果使用cache.xml或Java API来配置AsyncEventQueue，请在将托管该区域的每个Geode成员中重复上述配置。 为每个队列配置使用相同的ID和配置设置。 注意:您可以使用gfsh中提供的群集配置服务确保其他成员使用示例配置。 请参见群集配置服务概述. 在托管AsyncEventQueue的每个Geode成员上，将队列分配给要与AsyncEventListener实现一起使用的每个区域。 gfsh 配置 gfsh>create region --name=Customer --async-event-queue-id=sampleQueue 请注意，您可以在逗号分隔的列表中的命令行上指定多个队列。 cache.xml 配置 ... Java 配置 RegionFactory rf1 = cache.createRegionFactory(); rf1.addAsyncEventQueue(sampleQueue); Region customer = rf1.create(\"Customer\"); // Assign the queue to multiple regions as needed RegionFactory rf2 = cache.createRegionFactory(); rf2.addAsyncEventQueue(sampleQueue); Region order = rf2.create(\"Order\"); 使用Java API，您还可以向已创建的区域添加和删除队列： AttributesMutator mutator = order.getAttributesMutator(); mutator.addAsyncEventQueueId(\"sampleQueue\"); 有关详细信息，请参阅Geode API文档。 （可选）为队列配置持久性和混合。注意: 如果使用持久数据区域，则必须将AsyncEventQueue配置为持久性。 不支持使用具有持久区域的非持久队列。 （可选）使用配置调度程序线程和事件分发的顺序策略中的说明配置多个调度程序线程和队列的排序策略。 AsyncEventListener从配置有关联的AsyncEventQueue的每个区域接收事件。 如何从事件处理程序回调安全地修改缓存 事件处理程序是同步的。 如果需要更改缓存或从事件处理程序回调执行任何其他分布式操作，请小心避免可能阻止并影响整体系统性能的活动。 在事件处理程序中避免的操作 不要直接从事件处理程序执行任何类型的分布式操作。 Geode是一个高度分布式的系统，许多操作似乎在本地调用分布式操作。 这些是常见的分布式操作，可能会让您陷入麻烦： 在事件的区域或任何其他区域调用Region方法。 使用GeodeDetributedLockService。 修改区域属性。 通过GeodeFunctionService执行一个函数。 为了安全起见，请不要直接从事件处理程序中调用Geode API。 从单独的线程或执行程序中进行所有Geode API调用。 如何基于事件执行分布式操作 如果您需要使用处理程序中的Geode API，请使您的工作与事件处理程序异步。 您可以生成一个单独的线程或使用像java.util.concurrent.Executor接口这样的解决方案。 此示例显示了一个串行执行程序，其中回调创建一个Runnable，可以从队列中拉出并由另一个对象运行。 这保留了事件的顺序。 public void afterCreate(EntryEvent event) { final Region otherRegion = cache.getRegion(\"/otherRegion\"); final Object key = event.getKey(); final Object val = event.getNewValue(); serialExecutor.execute(new Runnable() { public void run() { try { otherRegion.create(key, val); } catch (org.apache.geode.cache.RegionDestroyedException e) { ... } catch (org.apache.geode.cache.EntryExistsException e) { ... } } }); } 有关Executor的其他信息，请参阅Oracle Java Web站点上的SerialExecutor示例。 缓存事件处理程序示例 缓存事件处理程序的一些示例。 使用参数声明和加载事件处理程序 这为cache.xml中的区域声明了一个事件处理程序。 处理程序是一个缓存侦听器，旨在将更改传递给DB2数据库。 声明包括侦听器的参数，即数据库路径，用户名和密码。 . . . JDBCListener jdbc:db2:SAMPLE gfeadmin admin1 此代码清单显示了cache.xml中声明的JDBCListener的部分实现。 这个监听器实现了Declarable接口。 在缓存中创建条目时，将触发此侦听器的afterCreate回调方法以更新数据库。 这里，cache.xml中提供的监听器属性被传递到Declarable.init方法并用于创建数据库连接。 . . . public class JDBCListener extends CacheListenerAdapter implements Declarable { public void afterCreate(EntryEvent e) { . . . // Initialize the database driver and connection using input parameters Driver driver = (Driver) Class.forName(DRIVER_NAME).newInstance(); Connection connection = DriverManager.getConnection(_url, _username, _password); System.out.println(_connection); . . . } . . . public void init(Properties props) { this._url = props.getProperty(\"url\"); this._username = props.getProperty(\"username\"); this._password = props.getProperty(\"password\"); } } 通过API安装事件处理程序 此清单使用RegionFactory方法addCacheListener定义缓存侦听器。 Region newReg = cache.createRegionFactory() .addCacheListener(new SimpleCacheListener()) .create(name); You can create a cache writer similarly, using the RegionFactory method setCacheWriter, like this: Region newReg = cache.createRegionFactory() .setCacheWriter(new SimpleCacheWriter()) .create(name); Installing Multiple Listeners on a Region XML: . . . myCacheListener1 myCacheListener2 myCacheListener3 API: CacheListener listener1 = new myCacheListener1(); CacheListener listener2 = new myCacheListener2(); CacheListener listener3 = new myCacheListener3(); Region nr = cache.createRegionFactory() .initCacheListeners(new CacheListener[] {listener1, listener2, listener3}) .setScope(Scope.DISTRIBUTED_NO_ACK) .create(name); 安装Write-Behind 缓存 监听器 //AsyncEventQueue with listener that performs WBCL work MyAsyncListener jdbc:db2:SAMPLE gfeadmin admin1 // Add the AsyncEventQueue to region(s) that use the WBCL 配置点对点事件消息 您可以从集群对等方接收任何非本地区域的事件。 本地区域仅接收本地缓存事件。 对等分发根据区域的配置完成。 复制区域始终从对等方接收所有事件，无需进一步配置。 使用REPLICATE区域快捷方式设置配置复制区域。 对于非复制区域，请确定是要从分布式缓存接收所有条目事件，还是仅接收本地存储的数据的事件。 要配置： 要接收所有事件，请将subscription-attributes intece-policy设置为all： 要仅为本地存储的数据接收事件，请将subscription-attributes interest-policy设置为cache-content或不设置它（cache-content是默认值）： 对于分区区域，这仅影响事件的接收，因为数据是根据区域分区存储的。 具有all的兴趣策略的分区区域可以创建网络瓶颈，因此如果可以，则在托管分区区域数据的每个成员中运行侦听器并使用cache-content兴趣策略。 注意: 您还可以使用gfsh命令行界面配置区域。 参见区域命令. 配置客户端服务器事件消息 您可以从服务器接收服务器端缓存事件和查询结果更改的事件。 对于缓存更新，您可以配置为接收条目键和值，或只是输入键，并在请求时懒惰地检索数据。 查询针对服务器缓存事件持续运行，服务器发送查询结果集的增量。 在开始之前，请设置客户端/服务器安装并配置和编写基本事件消息。 服务器接收客户端客户区域中所有条目事件的更新。 要从服务器接收客户端中的条目事件： 将客户端池subscription-enabled设置为true。 参见 . 对客户进行编程以注册您所需条目的兴趣。 注意: 这必须通过API完成。 注册对所有键，键列表，单个键或通过将键字符串与正则表达式进行比较的兴趣。 默认情况下，未注册任何条目来接收更新。 指定服务器是否要发送带有条目更新事件的值。 兴趣注册仅通过API提供。 获取您要注册兴趣的区域的实例。 使用区域的registerInterest*方法指定所需的条目。 例子： // Register interest in a single key and download its entry // at this time, if it is available in the server cache Region region1 = . . . ; region1.registerInterest(\"key-1\"); // Register Interest in a List of Keys but do not do an initial bulk load // do not send values for creater/update events - just send key with invalidation Region region2 = . . . ; List list = new ArrayList(); list.add(\"key-1\"); list.add(\"key-2\"); list.add(\"key-3\"); list.add(\"key-4\"); region2.registerInterestForKeys(list, InterestResultPolicy.NONE, false); // Register interest in all keys and download all available keys now Region region3 = . . . ; region3.registerInterestForAllKeys(InterestResultPolicy.KEYS); // Register Interest in all keys matching a regular expression Region region1 = . . . ; region1.registerInterestRegex(\"[a-zA-Z]+_[0-9]+\"); 您可以为单个区域多次调用注册兴趣方法。 每个兴趣注册都会添加到服务器的客户注册兴趣标准列表中。 因此，如果客户注册对键'A'的兴趣，然后注册对正则表达式“B*”的兴趣，服务器将发送所有带有键'A'或以字母'B'开头的键的更新。 对于高可用性事件消息，请配置服务器冗余。 请参阅配置高可用性服务器. 要在客户端停机期间为客户端排队事件，请配置持久的客户端/服务器消息传递。 编写要运行的任何连续查询（CQs），以持续接收客户端查询的流式更新。 CQ事件不更新客户端缓存。 如果您在CQ和/或兴趣注册之间存在依赖关系，那么您希望两种类型的订阅事件在客户端上紧密地一起到达，请为所有内容使用单个服务器池。 使用不同的池可能会导致事件传递的时间差异，因为池可能使用不同的服务器来处理和传递事件消息。 配置高可用服务器 实施持久的客户端/服务器消息传递 调整客户端/服务器事件消息 配置高可用性服务器 使用高可用性服务器，如果客户端的主服务器崩溃，其中一个备份将介入并接管消息，而不会中断服务。 要配置高可用性，请在客户端池配置中设置subscription-redundancy。 此设置指示要使用的辅助服务器的数量。 例如： 启用冗余后，辅助服务器会在主服务器将事件推送到客户端时维护队列备份。 如果主服务器发生故障，其中一个辅助服务器将作为主服务器进入，以向客户端提供不间断的事件消息传递。 下表描述了subscription-redundancy设置的不同值： subscription-redundancy 描述 0 未配置辅助服务器，因此禁用高可用性。 > 0 设置用于备份到主服务器的辅助服务器的精确数量。 -1 每个不是主服务器的服务器都将用作辅助服务器。 高度可用的客户端/服务器事件消息 高度可用的客户端服务器事件消息 使用服务器冗余，每个池都有一个主服务器和一些辅助服务器。 初选和辅助是基于每个池分配的，并且通常分散用于负载平衡，因此具有多个池的单个客户端可以在多个服务器中具有主队列。 主服务器将事件推送到客户端，辅助服务器维护队列备份。 如果主服务器发生故障，其中一个辅助服务器将成为主服务器以提供不间断的事件消息传递。 例如，如果有六台服务器正在运行且subscription-redundancy设置为2，则一台服务器是主服务器，两台服务器是辅助服务器，其余三台服务器不主动参与客户端的HA。 如果主服务器出现故障，系统会将其中一个辅助服务器指定为新主服务器，并尝试将另一个服务器添加到辅助池以保留初始冗余级别。 如果未找到新的辅助服务器，则不满足冗余级别，但故障转移过程成功完成。 只要有另一个辅助辅助设备，就会添加辅助辅助设备。 启用高可用性时： 主服务器将事件消息发送到客户端。 客户端定期将收到的消息发送到服务器，服务器从队列中删除发送的消息。 主服务器定期与其辅助服务器同步，通知它们可以丢弃的消息，因为它们已经被发送和接收。 通知存在延迟，因此辅助服务器仅与主服务器保持大致同步。 辅助队列包含主队列中包含的所有消息以及可能已发送到客户端的一些消息。 在主服务器发生故障的情况下，其中一个辅助服务器成为主服务器，并开始从其队列向客户端发送事件消息。 故障转移后，新主服务器通常会重新发送旧主服务器已发送的一些消息。 客户端将这些视为重复项并将其丢弃。 在该图的阶段1中，主设备向客户端发送事件消息，并向其辅助设备发送同步消息。 在阶段2，辅助和客户端已更新其队列和消息跟踪信息。 如果主服务器在第二阶段失败，则辅助服务器将从消息A10开始从其队列开始发送事件消息。 客户端将丢弃重新发送消息A10，然后照常处理后续消息。 更改服务器队列同步频率 默认情况下，主服务器每秒向辅助节点发送队列同步消息。 您可以使用gfsh alter runtime命令更改此间隔 设置队列同步消息的时间间隔如下： gfsh: gfsh>alter runtime --message-sync-interval=2 XML: Java: cache = CacheFactory.create(); cache.setMessageSyncInterval(2); 此间隔的理想设置在很大程度上取决于您的应用程序行为。 这些是更短和更长间隔设置的好处： 较短的间隔在辅助服务器中需要较少的内存，因为它减少了同步之间的队列建立。 此外，辅助队列中较少的旧消息意味着在故障转移后减少重新发送的消息。 对于具有高数据更新速率的系统，这些考虑因素最为重要。 较长的间隔需要较少的主要和次要之间的分发消息，这有利于整体系统性能。 设置从辅助队列中删除孤立的频率 通常，根据主要的同步消息从辅助订阅队列中删除所有事件消息。 但是，有时候，某些消息在辅助队列中是孤立的。 例如，如果主节点在向其辅助节点发送同步消息的过程中失败，则某些辅助节点可能会收到该消息，而某些辅助节点可能不会。 如果故障转移到达确实收到消息的辅助服务器，则系统将具有包含不再位于主队列中的消息的辅助队列。 新主服务器永远不会在这些消息上同步，将它们孤立在辅助队列中。 为了确保最终删除这些消息，辅助节点使所有已排队的消息超过服务器的message-time-live所指示的时间。 设置生存时间如下： XML: Java: Cache cache = ...; CacheServer cacheServer = cache.addCacheServer(); cacheServer.setPort(41414); cacheServer.setMessageTimeToLive(200); cacheServer.start(); 实施持久的客户端服务器消息传递 即使客户端关闭或断开连接，也需要为客户端维护的订阅使用持久消息传递。 您可以将任何事件订阅配置为持久。 当客户端断开连接时，持久查询和订阅的事件将保存在队列中，并在客户端重新连接时播放。 其他查询和订阅将从队列中删除。 对使用事件订阅的客户端/服务器安装使用持久消息传递。 这些是本主题中描述的高级任务： 将您的客户端配置为持久 确定哪些订阅应该是持久的并相应地进行配置 对客户端进行编程，以管理断开连接，重新连接和事件处理的持久消息传递 将客户端配置为持久 使用以下方法之一： gemfire.properties 文件: durable-client-id=31 durable-client-timeout=200 Java: Properties props = new Properties(); props.setProperty(\"durable-client-id\", \"31\"); props.setProperty(\"durable-client-timeout\", \"\" + 200); CacheFactory cf = new CacheFactory(props); durable-client-id表示客户端是持久的，并为服务器提供一个标识符，用于将客户端与其持久消息相关联。 对于非持久客户端，此id是空字符串。 ID可以是连接到同一群集中的服务器的客户端中唯一的任何数字。 durable-client-timeout告诉服务器等待客户端重新连接多长时间。 达到此超时后，服务器将停止存储到客户端的消息队列并丢弃所有存储的消息。 默认值为300秒。 这是一个调整参数。 如果更改它，请考虑应用程序的正常活动，消息的平均大小以及可以处理的风险级别，包括丢失的消息和服务器存储排队消息的容量。 假设没有消息从队列中删除，服务器在队列达到最大容量之前可以运行多长时间？ 服务器可以处理多少持久客户端？ 为了协助调整，请通过断开连接和重新连接周期为持久客户端使用Geode消息队列统计信息。 配置持久订阅和连续查询 注册器兴趣和查询创建方法都有一个可选的布尔参数，用于指示持久性。 默认情况下，所有都是非持久的。 // Durable registration // Define keySpecification, interestResultPolicy, durability exampleRegion.registerInterest(keySpecification, interestResultPolicySpecification, true); // Durable CQ // Define cqName, queryString, cqAttributes, durability CqQuery myCq = queryService.newCq(cqName, queryString, cqAttributes, true); 通过仅指示关键订阅和CQ的持久性，在客户端断开连接时仅保存关键消息。 当客户端连接到其服务器时，它会接收所有键和已重新注册的查询的消息。 当客户端断开连接时，非持久兴趣注册和CQ将停止，但队列中已存在的所有消息仍然存在。 注意: 对于单个持久客户端ID，您必须在客户端运行之间保持相同的注册和查询持久性。 对客户端进行编程以管理持久消息传递 将持久客户端编程为在断开连接，重新连接和处理来自服务器的事件时具有持久消息感知能力。 通过使用带有布尔值keepalive参数的Pool.close或ClientCache.close来断开与队列保持活动的请求。 clientCache.close(true); 要在客户端停机期间保留，必须在断开连接时执行持久连续查询（CQ）。 将持久客户端的重新连接编程为： 如果需要，检测先前注册的订阅队列是否在持久客户端重新连接时可用以及队列中的挂起事件计数。 根据结果，您可以决定是否接收剩余事件，或者如果数字太大则关闭缓存。 例如，对于仅创建了默认池的客户端： int pendingEvents = cache.getDefaultPool().getPendingEventCount(); if (pendingEvents == -2) { // client connected for the first time … // continue } else if (pendingEvents == -1) { // client reconnected but after the timeout period … // handle possible data loss } else { // pendingEvents >= 0 … // decide to invoke readyForEvents() or ClientCache::close(false)/pool.destroy() } 对于具有多个池的客户端： int pendingEvents = 0; int pendingEvents1 = PoolManager.find(“pool1”).getPendingEventCount(); pendingEvents += (pendingEvents1 > 0) ? pendingEvents1 : 0; int pendingEvents2 = PoolManager.find(“pool2”).getPendingEventCount(); pendingEvents += (pendingEvents2 > 0) ? pendingEvents2 : 0; // process individual pool counts separately. getPendingEventCount API可以返回以下可能的值： 表示服务器上待处理事件计数的值。 请注意，此计数是基于持久客户端池连接或重新连接到服务器的时间的近似值。 任意数量的调用都将返回相同的值。 如果此服务器池的服务器上没有待处理事件，则为零值 负值表示服务器上没有可用于客户端池的队列。 -1表示客户端池在持久性客户端超时期限过后已重新连接到服务器。 池的订阅队列已被删除，可能导致数据丢失。 值-2表示此客户端池第一次连接到服务器。 连接，初始化客户端缓存，区域和任何缓存侦听器，并创建和执行任何持久的连续查询。 运行所有兴趣注册调用。 注意: 使用InterestResultPolicy.KEYS_VALUES注册兴趣会使用指定键的current值初始化客户端缓存。 如果为区域启用了并发检查，则会忽略重播到客户端的任何早期（较旧）区域事件，并且不会将其发送到已配置的侦听器。 如果您的客户端必须处理区域的所有重播事件，请在重新连接时注册InterestResultPolicy.KEYS或InterestResultPolicy.NONE。 或者，禁用客户端缓存中区域的并发检查。 请参阅区域更新的一致性. 调用ClientCache.readyForEvents，以便服务器重放存储的事件。 如果先前发送就绪消息，则客户端可能会丢失事件。 ClientCache clientCache = ClientCacheFactory.create(); // Here, create regions, listeners that are not defined in the cache.xml . . . // Here, run all register interest calls before doing anything else clientCache.readyForEvents(); 编写持久客户端CacheListener时： 实现回调方法，以便在重放存储的事件时正常运行。 持久客户端的CacheListener必须能够处理事后播放的事件。 通常，侦听器在事件发生时接收非常接近的事件，但持久客户端可能会接收事件发生在几分钟之前并且与当前缓存状态无关的事件。 考虑是否使用CacheListener回调方法afterRegionLive，它专门用于持久事件重放的结束。 您可以在恢复正常事件处理之前使用它来执行特定于应用程序的操作。 如果您不希望使用此回调，并且您的侦听器是CacheListener（而不是CacheListenerAdapter）的实例，则将afterRegionLive实现为空方法。 初步操作 持久客户端的初始启动类似于任何其他客户端的启动，除了当客户端上的所有区域和侦听器都准备好处理来自服务器的消息时，它专门调用ClientCache.readyForEvents方法。 断开 客户端和服务器断开连接时，其操作会根据具体情况而有所不同。 正常断开. 当客户端关闭其连接时，服务器停止向客户端发送消息并释放其连接。 如果客户端请求它，则服务器会维护队列和持久兴趣列表信息，直到客户端重新连接或超时。 非持久兴趣列表将被丢弃。 服务器继续为持久兴趣列表上的条目排队传入消息。 客户端断开连接时队列中的所有消息都保留在队列中。 如果客户端请求不维护其订阅，或者没有持久订阅，则服务器取消注册客户端并执行与非持久客户端相同的清理。 异常断开. 如果客户端崩溃或丢失与所有服务器的连接，则服务器会自动维护其消息队列和持久订阅，直到它重新连接或超时。 客户断开但运营正常. 如果客户端在断开连接时运行，它将从本地客户端缓存中获取数据。 由于不允许更新，因此数据可能会过时。 如果尝试更新，则会发生UnconnectedException。 客户端在超时期限内保持断开状. 服务器根据durable-client-timeout设置跟踪保持持久订阅队列活动的时间。 如果客户端保持断开连接的时间超过超时，则服务器将注销客户端并执行为非持久客户端执行的相同清理。 服务器还会记录警报。 当超时客户端重新连接时，服务器将其视为新客户端进行初始连接。 重新连接 在初始化期间，不会阻止客户端缓存执行操作，因此您可能会在更多当前事件更新客户端缓存的同时从服务器接收旧的存储事件。 这些是可以同时作用于缓存的事情： 服务器返回的结果以响应客户的兴趣注册。 应用程序的客户端缓存操作。 通过从队列重放旧事件触发的回调 Geode处理应用程序和兴趣注册之间的冲突，因此它们不会创建缓存更新冲突。 但是您必须对事件处理程序进行编程，以使它们不与当前操作冲突。 这适用于所有事件处理程序，但对于持久客户端中使用的那些事件尤为重要。 您的处理程序可能会在事后很好地接收事件，您必须确保您的编程考虑到这一点。 该图显示了初始化过程中的三个并发过程。 应用程序立即在客户端上开始操作（步骤1），而客户端的缓存就绪消息（也是步骤1）在服务器上触发一系列队列操作（从主服务器上的步骤2开始）。 同时，客户端注册兴趣（客户端上的步骤2）并从服务器接收响应。 消息B2适用于区域A中的条目，因此缓存侦听器处理B2的事件。 由于B2位于标记之前，因此客户端不会将更新应用于缓存。 持久的事件重播 当持久客户端在超时期限之前重新连接时，服务器会重放客户端消失时存储的事件，然后将正常的事件消息传递回客户端。 为避免使用旧数据覆盖当前条目，存储的事件不会应用于客户端缓存。 通过在重放所有旧事件后发送到客户端的标记将存储事件与新正常事件区分开。 当客户端重新连接时，具有此客户端队列的所有服务器都会在其队列中放置标记。 主服务器将排队的消息发送到客户端，直到标记。 客户端接收消息但不对其高速缓存应用通常的自动更新。 如果安装了缓存侦听器，它们将处理事件。 客户端接收标记消息，指示已经播放了所有过去的事件。 服务器发送当前活动区域列表。 对于客户端上每个活动区域中的每个CacheListener，标记事件触发afterRegionLive回调。 在回调之后，客户端开始从服务器正常处理事件并将更新应用于其缓存。 即使新客户端第一次启动，客户端缓存就绪标记也会插入队列中。 如果消息在服务器插入标记之前开始进入新队列，则在客户端断开连接时会认为这些消息已发生，并且它们的事件的重放方式与重新连接情况相同。 兴趣注册期间的申请操作 应用程序操作优先于兴趣注册响应。 客户端可以在收到其兴趣注册响应时执行操作。 将注册兴趣响应添加到客户端缓存时，将应用以下规则： 如果条目已存在于具有有效值的缓存中，则不会更新。 如果条目无效，并且寄存器兴趣响应有效，则将有效值放入缓存中。 如果条目被标记为已销毁，则不会更新。 在注册兴趣响应完成后，将从系统中删除被破坏的条目。 如果兴趣响应不包含任何结果，因为服务器缓存中不存在所有这些键，则客户端的缓存可以从空开始。 如果队列包含与这些键相关的旧消息，则事件仍在客户端的缓存中重播。 调整客户端服务器事件消息 服务器使用异步消息传递队列将事件发送到其客户端。 队列中的每个事件都源自客户端，服务器中的线程或服务器或某个其他集群中的应用程序执行的操作。 事件消息具有唯一标识符，该标识符由始发线程的ID与其成员的分布式系统成员ID以及操作的顺序ID组成。 因此，源自任何单个线程的事件消息可以按时间从最低序列ID到最高序列进行分组和排序。 服务器和客户端跟踪每个成员线程ID的最高顺序ID。 单个客户端线程接收并处理来自服务器的消息，跟踪收到的消息以确保它不处理重复发送。 它使用来自原始线程的进程ID来完成此操作。 客户端的消息跟踪列表保存为每个始发线程接收的任何消息的最高序列ID。 在有许多不同线程进出并在缓存上工作的系统中，该列表可能变得非常大。 线程死亡后，不需要跟踪条目。 为了避免维护已经死亡的线程的跟踪信息，客户端会使没有活动的条目超过subscription-message-tracking-timeout。 配置服务器订阅队列 限制服务器的订阅队列内存使用 调整客户端的订阅邮件跟踪超时 配置服务器订阅队列 配置服务器订阅队列可以节省服务器空间和消息处理时间。 在服务器区域配置中的服务器级别启用协调： 根据需要，在客户端的gemfire.properties中覆盖服务器设置： conflate-events=false 有效的conflate-events设置是： - server，它使用服务器设置 - true，它将发送给客户端的所有内容混为一起 - false，它不会混淆发送给该客户端的任何内容 通过配置可以提高性能并减少服务器上排队所需的内存量。 客户端仅接收队列中针对特定条目键的最新可用更新。 默认情况下禁用配置。 当经常更新单个条目并且中间更新不需要客户端处理时，配置特别有用。 通过合并，如果条目已更新且队列中已存在其键更新，则会删除现有更新，并将新更新置于队列末尾。 仅在未发送到客户端的消息上进行协调。 注意: 这种合并方法与用于多站点网关发送方队列合并的方法不同。 它与用于在单个集群内合并对等分发消息的方法相同。 限制服务器的订阅队列内存使用 这些是用于限制订阅队列消耗的服务器内存量的选项。 可选的: 合并订阅队列消息。 可选的: 增加队列同步的频率。 这仅适用于将服务器冗余用于高可用性的配置。 增加客户端的池配置，subscription-ack-interval。 客户端定期向服务器发送批量消息确认，而不是单独确认每条消息。 较低的设置可以加快邮件传递速度，并且通常可以减少服 较高的设置有助于包含服务器队列大小。 例： ... 如果您的系统非常繁忙，并且希望减少订阅队列服务器所需的空间，则可能需要降低时间间隔。 更频繁的确认意味着等待确认的服务器队列中保存的事件更少。 可选的: 限制队列大小。 使用溢出或阻塞来限制服务器队列大小。 这些选项有助于避免在客户端较慢的情况下服务器上出现内存不足错误。 慢速客户端会降低服务器发送消息的速率，从而导致消息在队列中备份，从而可能导致服务器内存不足。 您可以使用这些选项中的一个或另一个，但不能同时使用两者： 可选的: 溢出到磁盘。 通过设置服务器的client-subscription属性来配置订阅队列溢出。 通过溢出，最近使用的（MRU）事件被写入磁盘，保留最旧的事件，即下一行发送到客户端的事件，在内存中可用。 例： 可选的: 队列满时阻止。 将服务器的maximum-message-count设置为阻止传入消息之前任何单个订阅队列中允许的最大事件消息数。 您只能限制消息计数，而不是为消息分配的大小。 例子： XML: API: Cache cache = ...; CacheServer cacheServer = cache.addCacheServer(); cacheServer.setPort(41414); cacheServer.setMaximumMessageCount(50000); cacheServer.start(); 注意: 使用此设置，一个慢速客户端可以减慢服务器及其所有其他客户端的速度，因为这会阻止写入队列的线程。 将消息添加到队列块的所有操作，直到队列大小降至可接受的水平。 如果为这些队列提供的区域被分区或具有distributed-ack或global范围，则对它们的操作将保持阻塞状态，直到它们的事件消息可以添加到队列中。 如果您使用此选项并且看到服务器区域操作停滞，则您的队列容量可能太低而不适合您的应用程序行为。 调整客户端的订阅消息跟踪超时 如果客户端池的subscription-message-tracking-timeout设置得太低，您的客户端将丢弃实时线程的跟踪记录，从而增加处理来自这些线程的重复事件的可能性。 此设置对于避免或大大减少重复事件至关重要的系统尤其重要。 如果您检测到客户端正在处理重复的消息，则增加超时可能会有所帮助。 设置subscription-message-tracking-timeout可能无法完全消除重复条目，但仔细配置可以帮助最小化出现次数。 通过跟踪来自操作源的源线程的消息序列ID来监视重复项。 对于长时间运行的系统，您不希望长时间跟踪此信息，或者信息可能保留足够长的时间以便回收线程ID。 如果发生这种情况，来自新线程的消息可能被错误地丢弃为来自具有相同ID的旧线程的消息的重复。 此外，为旧线程维护此跟踪信息会使用可能为其他事物释放的内存。 要最大限度地减少重复项并减小邮件跟踪列表的大小，请将客户端subscription-message-tracking-timeout设置为高于这些时间总和的两倍： 原始线程可能在操作之间等待的最长时间 对于冗余服务器添加： 服务器的message-sync-interval 故障转移所需的总时间（通常为7-10秒，包括检测故障的时间） 如果将值设置为低于此值，则可能会丢失活动线程跟踪记录。 这可能导致客户端将重复的事件消息处理到其关联线程的高速缓存中。 值得努力将subscription-message-tracking-timeout设置为合理的最低值。 ... 配置多站点（WAN）事件队列 在多站点（WAN）安装中，Geode使用网关发件人队列来分配使用网关发件人配置的区域的事件。 AsyncEventListeners还使用异步事件队列来分配已配置区域的事件。 本节介绍用于配置网关发件人或AsyncEventListener实现使用的事件队列的其他选项。 在开始之前，请设置多站点（WAN）安装或配置异步事件队列和AsyncEventListener实现。 请参阅配置多站点（WAN）系统 或为后写缓存事件实现AsyncEventListener处理。 持久化事件队列 您可以配置网关发件人队列或异步事件队列以将数据持久保存到磁盘，类似于复制区域的持久方式。 为事件分发配置Dispatcher线程和顺序策略 默认情况下，Geode使用多个调度程序线程在网关发送方队列中同时处理区域事件，以便在站点之间进行分配，或者在异步事件队列中用于分发事务以进行后写式高速缓存。 使用串行队列，您还可以配置用于分派这些事件的排序策略。 配置队列中的事件 配置队列可提高分发性能。 启用合并后，仅为特定键发送最新排队值。 持久化事件队列 您可以配置网关发件人队列或异步事件队列以将数据持久保存到磁盘，类似于复制区域的持久方式。 保留队列可为发件人执行的事件消息传递提供高可用性。 例如，如果持久网关发送方队列因任何原因退出，则当承载发送方的成员重新启动它时，它会自动重新加载队列并继续发送消息。 如果异步事件队列因任何原因退出，则回写缓存可以在队列重新联机时从中断处继续。 如果将enable-persistence属性设置为true，Geode会持久保存事件队列。 队列将持久保存到队列的disk-store-name属性中指定的磁盘存储区，如果未指定存储名称，则保留到默认磁盘存储区。 如果使用持久性区域，则必须将事件队列配置为使用持久性。 不支持使用具有持久区域的非持久性事件队列。 为队列启用持久性时，maximum-queue-memory属性确定队列在溢出到磁盘之前可以消耗多少内存。 默认情况下，此值设置为100MB。 注意: 如果配置并行队列和/或为队列配置多个调度程序线程，则maximum-queue-memory和disk-store-name属性中定义的值将应用于队列的每个实例。 在下面的示例中，网关发送方队列使用“diskStoreA”进行持久性和溢出，并且队列的最大队列内存为100MB： XML 例子: ... API 例子: Cache cache = new CacheFactory().create(); GatewaySenderFactory gateway = cache.createGatewaySenderFactory(); gateway.setParallel(false); gateway.setPersistenceEnabled(true); gateway.setDiskStoreName(\"diskStoreA\"); gateway.setMaximumQueueMemory(100); GatewaySender sender = gateway.create(\"persistedsender1\", \"1\"); sender.start(); gfsh: gfsh>create gateway-sender --id=\"persistedsender1 --parallel=false --remote-distributed-system-id=1 --enable-persistence=true --disk-store-name=diskStoreA --maximum-queue-memory=100 如果要为串行网关发送方配置10个调度程序线程，则每个承载发送方的Geode成员的网关发送方队列的总最大内存为1000MB，因为Geode会为每个线程创建一个单独的队列副本。 以下示例显示了异步事件队列的类似配置： XML 例子: MyAsyncEventListener jdbc:db2:SAMPLE gfeadmin admin1 ... API 例子: Cache cache = new CacheFactory().create(); AsyncEventQueueFactory factory = cache.createAsyncEventQueueFactory(); factory.setPersistent(true); factory.setDiskStoreName(\"diskStoreA\"); factory.setParallel(true); AsyncEventListener listener = new MyAsyncEventListener(); AsyncEventQueue persistentAsyncQueue = factory.create(\"customerWB\", listener); gfsh: gfsh>create async-event-queue --id=\"persistentAsyncQueue\" --persistent=true --disk-store=\"diskStoreA\" --parallel=true --listener=MyAsyncEventListener --listener-param=url#jdbc:db2:SAMPLE --listener-param=username#gfeadmin --listener-param=password#admin1 为事件分发配置Dispatcher线程和顺序策略 默认情况下，Geode使用多个调度程序线程在网关发送方队列中同时处理区域事件，以便在站点之间进行分配，或者在异步事件队列中用于分发事务以进行后写式高速缓存。 使用串行队列，您还可以配置用于分派这些事件的排序策略。 默认情况下，网关发送方队列或异步事件队列每个队列使用5个调度程序线程。 这为那些能够同时处理排队事件以便分发给另一个Geode站点或监听器的应用程序提供支持。 如果您的应用程序不需要并发分发，或者您没有足够的资源来支持多个调度程序线程的要求，那么您可以配置单个调度程序线程来处理队列。 使用多个Dispatcher线程来处理队列 性能和内存注意事项 配置串行队列的订购策略 示例 - 为串行网关发送器队列配置Dispatcher线程和排序策略 使用多个Dispatcher线程来处理队列 当为并行队列配置多个调度程序线程时，Geode只使用多个线程来处理每个单独队列的内容。 创建的队列总数仍由托管该区域的Geode成员数决定。 为串行队列配置多个调度程序线程时，Geode会为承载队列的每个成员上的每个线程创建一个队列的附加副本。 要获得最大吞吐量，请增加调度程序线程数，直到网络饱和为止。 下图说明了使用多个调度程序线程配置的串行网关发送方队列。 性能和内存注意事项 当串行网关发送方或异步事件队列使用多个调度程序线程时，请考虑以下事项： 对于为调度程序线程创建的队列的每个副本，都会重复队列属性。 也就是说，每个并发队列指向同一磁盘存储，因此使用相同的磁盘目录。 如果启用了持久性并发生溢出，则将条目插入队列的线程将竞争磁盘。 这适用于应用程序线程和调度程序线程，因此它可能会影响应用程序性能。 maximum-queue-memory设置适用于串行队列的每个副本。 如果配置10个调度程序线程并且最大队列内存设置为100MB，则队列队列的每个成员上队列的总最大队列内存为1000MB。 配置串行队列的排序策略 当使用带有串行事件队列的多个dispatcher-threads（大于1）时，您还可以配置这些线程用于从队列分发事件的order-policy。 有效的排队策略值为： key (default). 对同一key的所有更新都按顺序分发。 Geode通过将相同key的所有更新放在同一个调度程序线程队列中来保留key排序。 当条目更新彼此没有关系时，通常使用key排序，例如对于使用单个馈送器将库存更新分发给其他几个系统的应用程序。 thread. 来自给定线程的所有区域更新按顺序分布。 Geode通过将来自同一线程的所有区域更新放入同一个调度程序线程队列来保留线程排序。 通常，当对一个区域条目的更新影响对另一个区域条目的更新时，请使用线程排序。 partition. 共享相同分区键的所有区域事件按顺序分布。 当应用程序使用PartitionResolver实现自定义分区时，指定分区顺序。 使用分区排序，共享相同“分区键”（RoutingObject）的所有条目都放在同一个调度程序线程队列中。 您无法为并行事件队列配置order-policy，因为并行队列无法保留区域的事件排序。 只能保留给定分区（或分布式区域的给定队列）中事件的顺序。 示例 - 为串行网关发送器队列配置Dispatcher线程和排序策略 要增加调度程序线程数并为串行网关发送方设置排序策略，请使用以下机制之一。 cache.xml 配置 ... Java API 配置 Cache cache = new CacheFactory().create(); GatewaySenderFactory gateway = cache.createGatewaySenderFactory(); gateway.setParallel(false); gateway.setPersistenceEnabled(true); gateway.setDiskStoreName(\"gateway-disk-store\"); gateway.setMaximumQueueMemory(200); gateway.setDispatcherThreads(7); gateway.setOrderPolicy(OrderPolicy.KEY); GatewaySender sender = gateway.create(\"NY\", \"1\"); sender.start(); gfsh: gfsh>create gateway-sender -d=\"NY\" --parallel=false --remote-distributed-system-id=\"1\" --enable-persistence=true --disk-store-name=\"gateway-disk-store\" --maximum-queue-memory=200 --dispatcher-threads=7 --order-policy=\"key\" 以下示例显示如何为异步事件队列设置调度程序线程和排序策略： cache.xml 配置 MyAsyncEventListener jdbc:db2:SAMPLE gfeadmin admin1 ... Java API 配置 Cache cache = new CacheFactory().create(); AsyncEventQueueFactory factory = cache.createAsyncEventQueueFactory(); factory.setPersistent(true); factory.setDiskStoreName(\"async-disk-store\"); factory.setParallel(false); factory.setDispatcherThreads(7); factory.setOrderPolicy(OrderPolicy.KEY); AsyncEventListener listener = new MyAsyncEventListener(); AsyncEventQueue sampleQueue = factory.create(\"customerWB\", listener); Entry updates in the current, in-process batch are not eligible for conflation. gfsh: gfsh>create async-event-queue --id=\"sampleQueue\" --persistent=true --disk-store=\"async-disk-store\" --parallel=false --dispatcher-threads=7 order-policy=\"key\" --listener=myAsycEventListener --listener-param=url#jdbc:db2:SAMPLE --listener-param=username#gfeadmin --listener-param=password#admin1 合并队列中的事件 配置队列可提高分发性能。 启用合并后，仅为特定key发送最新排队值。 注意: 如果您的接收应用程序依赖于条目修改的特定顺序，或者如果需要通知他们对条目的每次更改，请不要使用合并。 当频繁更新单个条目时，合并最有用，但其他站点只需要知道条目的当前值（而不是每个更新的值）。 将更新添加到启用了混淆的队列时，如果条目队列中已存在更新消息，则现有消息将采用新更新的值并删除新更新，如下所示 键A. 注意: 这种合并方法不同于用于服务器到客户端订阅队列协调和群集内对等分发的方法。 示例 - 为网关发件人队列配置合并 要为网关发件人队列启用合并，请使用以下机制之一： cache.xml 配置 ... Java API 配置 Cache cache = new CacheFactory().create(); GatewaySenderFactory gateway = cache.createGatewaySenderFactory(); gateway.setParallel(true); gateway.setPersistenceEnabled(true); gateway.setDiskStoreName(\"gateway-disk-store\"); gateway.setBatchConflationEnabled(true); GatewaySender sender = gateway.create(\"NY\", \"1\"); sender.start(); 当前进程中批处理中的条目更新不符合合并条件。 gfsh: gfsh>create gateway-sender --id=\"NY\" --parallel=true --remote-distributed-system-id=\"1\" --enable-persistence=true --disk-store-name=\"gateway-disk-store\" --enable-batch-conflation=true 以下示例显示如何为异步事件队列配置conflation： cache.xml 配置 MyAsyncEventListener jdbc:db2:SAMPLE gfeadmin admin1 ... Java API 配置 Cache cache = new CacheFactory().create(); AsyncEventQueueFactory factory = cache.createAsyncEventQueueFactory(); factory.setPersistent(true); factory.setDiskStoreName(\"async-disk-store\"); factory.setParallel(false); factory.setBatchConflationEnabled(true); AsyncEventListener listener = new MyAsyncEventListener(); AsyncEventQueue sampleQueue = factory.create(\"customerWB\", listener); 当前进程中批处理中的条目更新不符合合并条件。 gfsh: gfsh>create async-event-queue --id=\"sampleQueue\" --persistent=true --disk-store=\"async-disk-store\" --parallel=\"false\" --listener=myAsyncEventListener --listener-param=url#jdbc:db2:SAMPLE --listener-param=username#gfeadmin --listener-param=password#admin1 增量传播 增量传播允许您通过仅包括对象而不是整个对象的更改来减少通过网络发送的数据量。 增量传播如何工作 增量传播减少了您通过网络发送的数据量。 您只需发送有关对象的更改或增量信息，而不是发送整个更改的对象。 如果在应用增量时不使用克隆，则还可以期望在接收JVM中生成更少的垃圾。 何时避免增量传播 通常，对象越大，增量越小，使用增量传播的好处就越大。 具有较高冗余级别的分区区域通常受益于增量传播。 但是，在某些应用场景中，增量传播并未显示任何显着优势。 有时它会导致性能下降。 增量传播属性 本主题描述可用于配置增量传播的属性。 实施增量传播 默认情况下，集群中启用了增量传播。 启用时，增量传播用于实现org.apache.geode.Delta的对象。 您可以对方法进行编程，以存储和提取条目的增量信息，并应用收到的增量信息。 增量传播中的错误 本主题列出了使用增量传播时可能发生的错误。 增量传播示例 本主题提供了增量传播的示例。 增量传播如何工作 增量传播减少了您通过网络发送的数据量。 您只需发送有关对象的更改或增量信息，而不是发送整个更改的对象。 如果在应用增量时不使用克隆，则还可以期望在接收JVM中生成更少的垃圾。 在大多数分布式数据管理系统中，存储在系统中的数据往往会被创建一次，然后经常更新。 这些更新通常会发送给其他成员，以实现事件传播，冗余管理和缓存一致性。 仅跟踪更新对象中的更改并仅发送增量意味着更低的网络传输成本和更低的对象序列化/反序列化成本。 性能改进可能很重要，尤其是当对象的更改相对于其整体大小较小时。 Geode使用您编程的方法传播对象增量。 这些方法位于Delta接口中，您可以在缓存对象的类中实现。 如果您的任何类是普通的旧Java对象，则需要将它们包装为此实现。 此图显示了使用键，k和值对象v更改条目的增量传播。 get 操作. get像往常一样工作：缓存从本地缓存返回完整的条目对象，如果在那里不可用，则从远程缓存或加载器返回。 update 方法. 您需要向对象的更新方法添加代码，以便除了已经完成的工作外，还可以保存对象更新的增量信息。 put 操作. put在本地缓存中照常工作，使用完整值，然后调用hasDelta查看是否有增量和toDelta来序列化信息。 根据成员和区域配置，分配与完整值相同。 收到远程成员的delta. fromDelta提取由toDelta序列化的delta信息，并将其应用于本地缓存中的对象。 增量将直接应用于现有值或克隆，具体取决于您为区域配置它的方式。 额外的分布式. 与完整分布式一样，接收成员根据其配置和与其他成员的连接转发增量。 例如，如果VM1是客户端而VM2是服务器，则VM2根据需要将增量转发给其对等端及其他客户端。 接收成员不会重新创建增量; toDelta只在原始成员中调用。 增量传播的一般特征 要使用增量传播功能，区域中键的所有更新都必须具有实现Delta接口的值类型。 您不能为某些类型实现delta的条目键混合对象类型，而有些类型则不能。 这是因为，当接收到实现增量接口的类型以进行更新时，将键的现有值强制转换为Delta类型以应用接收的增量。 如果现有类型也没有实现Delta接口，则操作会抛出ClassCastException。 注意: 只有放置在缓存中的对象本身才能实现Delta接口并传播更改。 缓存对象的任何子对象都不会传播其更改。 有时fromDelta无法调用，因为没有对象将delta应用于接收缓存。 发生这种情况时，系统会自动对接收器进行完整的值分配。 以下是可能的情况：1。如果系统可以事先确定接收方没有本地副本，则会发送带有完整值的初始消息。 当区域配置为没有本地数据存储时，例如区域快捷方式设置为PARTITION_PROXY和REPLICATE_PROXY，这是可能的。 这些配置用于完成诸如向侦听器提供数据更新信息以及将更新传递给客户端之类的事情。 2.在不太明显的情况下，例如当一个条目被本地删除时，首先发送增量，然后接收方请求一个完整的值并发送。 每当收到完整值时，对接收者的对等体或客户端的任何进一步分发都使用完整值。 Geode也不会传播增量： 事务提交 putAll 操作 运行不支持增量传播的Geode版本的JVM（6.0及更早版本） 支持的拓扑和限制 以下拓扑支持增量传播（有一些限制）： Peer-to-peer(点对点) . Geode系统成员使用delta传播来分发和接收条目更改，具有以下要求和注意事项： 必须对区域进行分区或将其范围设置为distributed-ack或global。 分布式区域的区域快捷方式设置使用distributed-ack``范围。 Delta传播对于具有`distributed-no-ack``范围的区域不起作用，因为如果在应用delta时发生异常，则接收器无法恢复。 对于分区区域，如果接收对等方未保留条目的主副本或副本，但仍需要值，则系统会自动发送完整值。 要接收增量，区域必须是非空的。 系统自动将完整值发送到空白区域。 空区域可以发送增量。 Client/server(客户端/服务器) . Geode客户端总是可以向服务器发送增量，服务器通常可以向客户端发送增量。 这些配置要求服务器将完整值发送到客户端，而不是增量： 当客户端的gemfire.properties设置conflate-events设置为true时，服务器会为所有区域发送完整值。 当服务器区域属性enable-subscription-conflation设置为true并且客户端gemfire.properties设置conflate-events设置为server时，服务器会发送该区域的完整值。 当客户端区域配置了PROXY客户端区域快捷方式设置（空客户端区域）时，服务器将发送完整值。 多站点（WAN）. 网关发件人不发送Deltas。 始终发送完整值。 何时避免增量传播 通常，对象越大，增量越小，使用增量传播的好处就越大。 具有较高冗余级别的分区区域通常受益于增量传播。 但是，在某些应用场景中，增量传播并未显示任何显着优势。 有时它会导致性能下降。 默认情况下，集群中启用了增量传播。 这些是可能降低使用增量传播的性能优势的主要因素： 反序列化对象以增加应用增量的成本。 应用增量需要反序列化条目值。 完成此操作后，对象将以反序列化的形式存储在缓存中。 如果由于其他原因（例如索引和查询或侦听器操作）尚未对对象进行反序列化，则delta传播的这一方面仅会对您的系统产生负面影响。 一旦以反序列化的形式存储，就会有将对象发送到成员之外的操作的重新编码成本，例如来自网关发送者的分发，响应于netSearch或客户端请求而发送的值以及存储到磁盘。 需要重新编译的操作越多，反序列化对象的开销就越高。 与所有序列化工作一样，您可以通过为对象提供DataSerializable的自定义实现来提高序列化和反序列化的性能。 应用delta时克隆。 使用克隆会影响性能并产生额外的垃圾。 但是，不使用克隆是有风险的，因为您正在修改缓存值。 如果没有克隆，请确保同步您的条目访问权限以防止缓存变得不一致。 应用delta的问题导致系统返回到发起者的完整条目值。 发生这种情况时，整体操作的成本高于首先发送完整的条目值。 如果将delta发送给多个收件人，其中全部或大部分请求完整值，并且完整值发送需要将对象序列化，则可能会进一步加剧这种情况。 与溢出区域相关的磁盘I / O开销。 如果使用带有溢出到磁盘的驱逐，则必须将磁盘上的值带入内存才能应用增量。 这比仅删除对磁盘副本的引用要昂贵得多，就像对缓存中的完整值分配一样。 增量传播属性 本主题描述可用于配置增量传播的属性。 增量传播属性可以通过API和gemfire.properties和cache.xml文件进行配置。 delta-propagation(增量传播) 一个gemfire.properties布尔值，用于启用或禁用增量传播。 如果为false，则为每次更新发送完整的条目值。 默认设置为true，启用增量传播。 禁用增量传播如下： gemfire.properties: delta-propagation=false API: Properties props = new Properties(); props.setProperty(\"delta-propagation\", false); this.cache = new ClientCacheFactory(props).create(); cloning-enabled(启用克隆) 区域属性boolean影响fromDelta如何将增量应用于本地缓存。 如果为true，则将更新应用于值的克隆，然后将克隆保存到缓存中。 如果为false，则在缓存中就地修改该值。 默认值为false。 此行为的例外情况： 如果Cache属性copy-on-read为true，则启用克隆，无论该属性设置为什么。 如果Region属性off-heap为true，则启用克隆，无论此属性设置为什么。 克隆可能很昂贵，但它确保在任何应用程序代码看到之前，使用delta完全初始化新对象。 启用克隆后，默认情况下，Geode使用序列化对对象执行深层复制。 您可以通过实现java.lang.Cloneable然后实现clone方法来提高性能，对可以应用delta的任何内容进行深层复制。 目标是显着减少复制对象的开销，同时仍保留增量所需的隔离。 没有克隆： 应用程序代码可以在修改时读取条目值，可能会看到处于中间不一致状态的值，只应用部分delta。 您可以选择通过使应用程序代码在读取和写入上同步来解决此问题。 Geode丢失对旧值的任何引用，因为旧值已在适当位置转换为新值。 因此，你的CacheListener看到了为EntryEvent.getOldValue和EntryEvent.getNewValue返回的相同新值。 从fromDelta抛出的异常可能会使缓存处于不一致状态。 如果没有克隆，delta应用程序的任何中断都可能使您的缓存对象中的某些字段发生更改而其他字段保持不变。 如果您不使用克隆，请在编译fromDelta实现中的错误处理时记住这一点。 伴随着克隆： fromDelta方法在内存中生成更多垃圾。 性能降低。 启用克隆如下： cache.xml: API: RegionFactory rf = cache.createRegionFactory(REPLICATE); rf.setCloningEnabled(true); custRegion = rf.create(\"customer\"); gfsh: gfsh>create region --name=\"region_with_cloning\" --type=REPLICATE --enable-cloning=true 实施增量传播 默认情况下，集群中启用了增量传播。 启用时，增量传播用于实现org.apache.geode.Delta的对象。 您可以对方法进行编程，以存储和提取条目的增量信息，并应用收到的增量信息。 使用以下过程在集群中实现增量传播。 研究对象类型和预期的应用程序行为，以确定哪些区域可以从使用增量传播中受益。 增量传播不会提高所有数据和数据修改方案的性能。 参见何时避免Delta传播. 对于使用增量传播的每个区域，选择是否使用增量传播属性cloning-enabled启用克隆。 默认情况下禁用克隆。 参见Delta传播属性. 如果您不启用克隆，请查看所有关联的侦听器代码以查看EntryEvent.getOldValue的依赖项。 如果没有克隆，Geode就会修改条目，因此失去对旧值的引用。 对于delta事件，EntryEvent方法getOldValue和getNewValue都返回新值。 对于您想要增量传播的每个类，请实现下面的接口 org.apache.geode.Delta 并更新您的方法以支持增量传播。 具体如何执行此操作取决于您的应用程序和对象需求，但这些步骤描述了基本方法： 如果该类是普通的旧Java对象（POJO），请将其包装为此实现并更新代码以使用包装类。 将用于管理增量状态的任何额外对象字段定义为瞬态。 这可以在分发完整对象时提高性能。 每当使用标准Java序列化时，transient关键字指示Java不对该字段进行序列化。 研究对象内容以决定如何处理增量变化。 Delta传播与分布式并发控制具有相同的问题，就像完整对象的分布一样，但是在更详细的层面上。 对象的某些部分可能能够彼此独立地更改，而其他部分可能总是需要一起更改。 发送足够大的增量以保持数据在逻辑上一致。 例如，如果字段A和字段B相互依赖，则delta分布应更新两个字段或两者都不更新。 与常规更新一样，数据区域上的生产者越少，并发问题的可能性就越低。 在放置条目的应用程序代码中，将完全填充的对象放入本地缓存中。 即使您计划仅发送增量，接收端上的错误也可能导致Geode请求完整对象，因此您必须将其提供给原始put方法。 即使在空的生产者中也要这样做，区域配置为没有本地数据存储。 这通常意味着要进行输入，除非您确定它在分布式区域中的任何位置都不存在。 更改每个字段的更新方法以记录有关更新的信息。 该信息必须足以让toDelta在调用delta时对delta和任何其他所需的delta信息进行编码。 写hasDelta告知delta是否可用。 编写toDelta来创建一个带有对象更改的字节流，并且任何其他信息fromDelta将需要应用更改。 在从toDelta返回之前，重置delta状态以指示没有等待发送的delta更改。 写fromDelta来解码'toDelta`创建的字节流并更新对象。 确保为对象提供足够的同步以维持一致的对象状态。 如果不使用克隆，则可能需要同步读取和写入以避免从缓存中读取部分写入的更新。此同步可能涉及toDelta，fromDelta，toData，fromData和其他方法 访问或更新对象。 此外，您的实现应考虑并发调用fromDelta和一个或多个对象的更新方法的可能性。 增量传播中的错误 本主题列出了使用增量传播时可能发生的错误。 增量传播中的错误根据系统处理方式分为两类： 应用delta的问题可以通过请求全部值代替delta来补救。 您的put操作没有看到与此类delta传播失败相关的错误或异常。 系统会自动执行从发送方到发生问题的接收方的完整值分配。 此类错误包括： 接收缓存中的条目值不可用，原因是条目缺失或其值为null。 在这两种情况下，都没有应用delta的任何内容，必须发送完整值。 如果您通过应用程序调用或通过驱逐或条目到期等已配置的操作在本地销毁或使您的条目无效，则最有可能发生这种情况。 fromDelta方法抛出的InvalidDeltaException，由你编程。 此异常使您可以避免应用违反数据一致性检查或其他应用程序要求的增量。 在服务器到客户端传播中在客户端中应用增量的任何错误。 除了从服务器检索完整值之外，客户端还会记录警告。 创建或分发无法通过分配完整值来修复的增量的问题。 在这些情况下，您的put操作会失败并出现异常。 此类错误包括： hasDelta或toDelta中的错误或异常。 服务器或对等接收器中的错误或异常超出上述第一类中描述的情况。 增量传播示例 本主题提供了增量传播的示例。 在此示例中，馈线客户端连接到第一服务器，接收器客户端连接到第二服务器。 服务器彼此对等。 该示例演示了以下操作： 在Feeder客户端中，应用程序更新条目对象并放入条目。 响应put，Geode调用hasDelta，返回true，因此Geode调用toDelta并将提取的delta转发给服务器。 如果hasDelta返回false，Geode将分配完整的条目值。 在Server1中，Geode将增量应用于缓存，将收到的增量分发给服务器的对等体，并将其转发给对该条目感兴趣的任何其他客户端（在此示例中没有其他客户端到Server1） 在Server2中，Geode将增量应用于缓存并将其转发给感兴趣的客户端，在这种情况下，客户端只是接收客户端。 此示例显示了编写Delta实现的基本方法。 package delta; import org.apache.geode.Delta; import org.apache.geode.InvalidDeltaException; import java.io.DataInput; import java.io.DataOutput; import java.io.IOException; import java.io.Serializable; /** * Sample implementation of Delta * * @author GemStone Systems, Inc. * @since 6.1 */ public class SimpleDelta implements Delta, Serializable { // Original object fields private int intVal; private double doubleVal; // Added for delta - one boolean per field to track changed status private transient boolean intFldChd = false; private transient boolean dblFldChd = false; public SimpleDelta(){} public SimpleDelta(int i, double d){ this.intVal = i; this.doubleVal = d; } public boolean hasDelta() { return this.intFldChd || this.dblFldChd; } public void toDelta(DataOutput out) throws IOException { System.out.println(\"Extracting delta from \" + this.toString()); // Write information on what has changed to the // data stream, so fromDelta knows what it's getting out.writeBoolean(intFldChd); if (intFldChd) { // Write just the changes into the data stream out.writeInt(this.intVal); // Once the delta information is written, reset the delta status field this.intFldChd = false; System.out.println(\" Extracted delta from field 'intVal' = \" + this.intVal); } out.writeBoolean(dblFldChd); if (dblFldChd) { out.writeDouble(this.doubleVal); this.dblFldChd = false; System.out.println(\" Extracted delta from field 'doubleVal' = \" + this.doubleVal); } } public void fromDelta(DataInput in) throws IOException, InvalidDeltaException { System.out.println(\"Applying delta to \" + this.toString()); // For each field, read whether there is a change if (in.readBoolean()) { // Read the change and apply it to the object this.intVal = in.readInt(); System.out.println(\" Applied delta to field 'intVal' = \" + this.intVal); } if (in.readBoolean()) { this.doubleVal = in.readDouble(); System.out.println(\" Applied delta to field 'doubleVal' = \" + this.doubleVal); } } // In the setter methods, add setting of delta-related // fields indicating what has changed public void setIntVal(int anIntVal) { this.intFldChd = true; this.intVal = anIntVal; } public void setDoubleVal(double aDoubleVal) { this.dblFldChd = true; this.doubleVal = aDoubleVal; } public String toString() { return \"SimpleDelta [ hasDelta = \" + hasDelta() + \", intVal = \" + this.intVal + \", doubleVal = {\" + this.doubleVal + \"} ]\"; } } 查询 Geode提供了一种类似SQL的查询语言OQL，允许您访问存储在Geode区域中的数据。 由于Geode区域是键值存储，其值可以从简单字节数组到复杂嵌套对象，因此Geode使用基于OQL（对象查询语言）的查询语法来查询区域数据。 OQL与SQL非常相似，但OQL允许您查询复杂对象，对象属性和方法。 查询常见问题和示例 本主题回答有关查询功能的一些常见问题。 它提供了一些示例来帮助您开始使用Geode查询。 使用OQL查询 本节提供Geode查询的高级介绍，例如构建查询字符串和描述查询语言功能。 高级查询 本节包括高级查询主题，例如使用查询索引，使用查询绑定参数，查询分区区域和查询调试。 使用索引 Geode查询引擎支持索引。 索引可以为查询执行提供显着的性能提升。 查询常见问题和示例 本主题回答有关查询功能的一些常见问题。 它提供了一些示例来帮助您开始使用Geode查询。 有关Geode查询的其他信息，请参阅查询. 如何针对Geode区域编写和执行查询？ 我可以查看按查询类型列出的查询字符串示例吗？ 我应该使用哪些API来编写查询？ 如何在查询中调用对象的方法？ 我可以在查询中的对象上调用静态方法吗？ 如何编写可重用的查询？ 我应该何时创建要在查询中使用的索引？ 如何创建索引？ 我可以查询分区区域吗？ 我可以在分区区域上执行连接查询吗？ 如何提高分区区域查询的性能？ Geode支持哪些查询语言元素？ 我如何调试查询？ 我可以在查询中使用隐式属性或方法吗？ 如何在OQL中对字段执行不区分大小写的搜索？ 如何针对Geode区域编写和执行查询？ 要在Geode中编写和执行查询，可以使用以下任何机制。 示例查询代码如下。 Geode查询API gfsh 命令行界面; 特别是查询 命令 REST API query endpoints 示例Geode查询代码(Java) // Identify your query string. String queryString = \"SELECT * FROM /exampleRegion\"; // Get QueryService from Cache. QueryService queryService = cache.getQueryService(); // Create the Query Object. Query query = queryService.newQuery(queryString); // Execute Query locally. Returns results set. SelectResults results = (SelectResults)query.execute(); // Find the Size of the ResultSet. int size = results.size(); // Iterate through your ResultSet. Portfolio p = (Portfolio)results.iterator().next(); /* Region containing Portfolio object. */ 我可以查看按查询类型列出的查询字符串示例吗？ 以下示例查询字符串使用/exampleRegion，其键是项目组合ID，其值对应于以下类定义中显示的汇总数据： class Portfolio implements DataSerializable { int ID; String type; String status; Map positions; } class Position implements DataSerializable { String secId; double mktValue; double qty; } 基本WHERE子句示例 在以下示例中，status字段的类型为String，ID字段的类型为int。 有关Geode查询支持的文字的完整列表，请参阅支持的文字 。 选择所有有效投资组合 SELECT * FROM /exampleRegion WHERE status = 'active' 选择状态以activ开头的所有投资组合。 SELECT * FROM /exampleRegion p WHERE p.status LIKE 'activ%' 选择ID大于100的所有投资组合。 SELECT * from /exampleRegion p WHERE p.ID > 100 使用 DISTINCT 从满足status ='active'的where子句条件的区域中选择不同的对象。 SELECT DISTINCT * FROM /exampleRegion WHERE status = 'active' 别名和同义词 在查询字符串中，可以使用别名定义路径表达式（区域及其对象）。 可以在查询的其他位置使用或引用此别名。 SELECT DISTINCT * FROM /exampleRegion p WHERE p.status = 'active' SELECT p.ID, p.status FROM /exampleRegion p WHERE p.ID > 0 使用NOT运算符 有关支持的运算符的完整列表，请参阅运算符 。 SELECT DISTINCT * FROM /exampleRegion WHERE NOT (status = 'active') AND ID = 2 SELECT * FROM /exampleRegion WHERE NOT (ID IN SET(1,2)) 使用AND和OR运算符 有关支持的运算符的完整列表，请参阅运算符。 SELECT * FROM /exampleRegion WHERE ID > 4 AND ID 0 使用不等于 SELECT * FROM /exampleRegion portfolio WHERE portfolio.ID <> 2 SELECT * FROM /exampleRegion portfolio WHERE portfolio.ID != 2 投影属性示例 SELECT p.get('account') FROM /exampleRegion p 查询嵌套集合 以下查询使用HashMap类型的位置。 SELECT p, pos FROM /exampleRegion p, p.positions.values pos WHERE pos.secId = 'VMW' 使用 LIMIT SELECT * FROM /exampleRegion p WHERE p.ID > 0 LIMIT 2 使用 COUNT 有关详细信息，请参阅COUNT。 SELECT COUNT(*) FROM /exampleRegion WHERE ID > 0 SELECT COUNT(*) FROM /exampleRegion WHERE ID > 0 LIMIT 50 SELECT COUNT(*) FROM /exampleRegion WHERE ID > 0 AND status LIKE 'act%' SELECT COUNT(*) FROM /exampleRegion WHERE ID IN SET(1,2,3,4,5) SELECT COUNT(*) FROM /exampleRegion p, p.positions.values pos WHERE p.ID > 0 AND pos.secId 'IBM' SELECT DISTINCT COUNT(*) FROM /exampleRegion p, p.positions.values pos WHERE p.ID > 0 OR p.status = 'active' OR pos.secId OR pos.secId = 'IBM' 使用 LIKE SELECT * FROM /exampleRegion ps WHERE ps.pkid LIKE '_bc' SELECT * FROM /exampleRegion ps WHERE ps.status LIKE '_b_' OR ps.pkid = '2' SELECT * FROM /exampleRegion ps WHERE ps.status LIKE '%b% 使用区域输入键和值 SELECT * FROM /exampleRegion.keys k WHERE k.ID = 1 SELECT entry.value FROM /exampleRegion.entries entry WHERE entry.key = '1' SELECT key, positions FROM /exampleRegion.entrySet, value.positions.values positions WHERE positions.mktValue >= 25.00 SELECT DISTINCT entry.value FROM /exampleRegion.entries entry WHERE entry.key = '1' SELECT * FROM /exampleRegion.entries entry WHERE entry.value.ID > 1 SELECT * FROM /exampleRegion.keySet key WHERE key = '1' SELECT * FROM /exampleRegion.values portfolio WHERE portfolio.status = 'active' 嵌套查询 IMPORT \"query\".Portfolio; SELECT * FROM /exampleRegion, (SELECT DISTINCT * FROM /exampleRegion p TYPE Portfolio, p.positions WHERE value!=null) SELECT DISTINCT * FROM (SELECT DISTINCT * FROM /exampleRegion portfolios, positions pos) WHERE pos.value.secId = 'IBM' SELECT * FROM /exampleRegion portfolio WHERE portfolio.ID IN (SELECT p2.ID FROM /exampleRegion2 p2 WHERE p2.ID > 1) SELECT DISTINCT * FROM /exampleRegion p, (SELECT DISTINCT pos FROM /exampleRegion x, x.positions.values pos WHERE x.ID = p.ID ) AS itrX 查询FROM子句表达式的结果 SELECT DISTINCT * FROM (SELECT DISTINCT * FROM /Portfolios ptf, positions pos) p WHERE p.get('pos').value.secId = 'IBM' Hash Map 查询 使用hashmap查询。 在以下示例中，'version'是hashmap中的键之一。 SELECT * FROM /exampleRegion p WHERE p['version'] = '1.0' SELECT entry.key, entry.value FROM /exampleRegion.entries entry WHERE entry.value['version'] = '100' 映射示例“map”是嵌套的HashMap对象 SELECT DISTINCT * FROM /exampleRegion p WHERE p.portfolios['key2'] >= 3 获取数组值的示例查询 SELECT * FROM /exampleRegion p WHERE p.names[0] = 'aaa' SELECT * FROM /exampleRegion p WHERE p.collectionHolderMap.get('1').arr[0] = '0' 使用 ORDER BY (and ORDER BY with LIMIT) 必须将DISTINCT关键字与ORDER BY查询一起使用。 SELECT DISTINCT * FROM /exampleRegion WHERE ID 连接查询 SELECT * FROM /exampleRegion portfolio1, /exampleRegion2 portfolio2 WHERE portfolio1.status = portfolio2.status SELECT portfolio1.ID, portfolio2.status FROM /exampleRegion portfolio1, /exampleRegion2 portfolio2 WHERE portfolio1.status = portfolio2.status SELECT * FROM /exampleRegion portfolio1, portfolio1.positions.values positions1, /exampleRegion2 portfolio2, portfolio2.positions.values positions2 WHERE positions1.secId = positions1.secId SELECT * FROM /exampleRegion portfolio1, portfolio1.positions.values positions1, /exampleRegion2 portfolio2, portfolio2.positions.values positions2 WHERE portfolio1.ID = 1 AND positions1.secId = positions1.secId SELECT DISTINCT a, b.price FROM /exampleRegoin1 a, /exampleRegion2 b WHERE a.price = b.price 使用 AS SELECT * FROM /exampleRegion p, p.positions.values AS pos WHERE pos.secId != '1' 使用 TRUE SELECT DISTINCT * FROM /Portfolios WHERE TRUE 使用 IN 和 SET 参见 IN 和 SET. SELECT * FROM /exampleRegion portfolio WHERE portfolio.ID IN SET(1, 2) SELECT * FROM /exampleRegion portfolio, portfolio.positions.values positions WHERE portfolio.Pk IN SET ('1', '2') AND positions.secId = '1' SELECT * FROM /exampleRegion portfolio, portfolio.positions.values positions WHERE portfolio.Pk IN SET ('1', '2') OR positions.secId IN SET ('1', '2', '3') SELECT * FROM /exampleRegion portfolio, portfolio.positions.values positions WHERE portfolio.Pk IN SET ('1', '2') OR positions.secId IN SET ('1', '2', '3') AND portfolio.status = 'active' 查询Set值 在以下查询中，sp的类型为Set。 SELECT * FROM /exampleRegion WHERE sp = set('20', '21', '22') 如果Set（sp）仅包含20和21，则查询将评估为false。 查询比较两组并查找两组中元素的存在。 对于像list这样的其他集合类型（sp是List类型），查询可以写成如下： SELECT * FROM /exampleRegion WHERE sp.containsAll(set('20', '21', '22')) 在对象上调用方法 有关详细信息，请参阅方法调用 。 SELECT * FROM /exampleRegion p WHERE p.length > 1 SELECT DISTINCT * FROM /exampleRegion p WHERE p.positions.size >= 2 SELECT DISTINCT * FROM /exampleRegion p WHERE p.positions.isEmpty SELECT DISTINCT * FROM /exampleRegion p WHERE p.name.startsWith('Bo') 使用查询级调试 要在查询级别设置调试，请在查询之前添加 关键字。 （如果您使用的是IMPORT语句，请在IMPORT之前包含它）。 SELECT * from /exampleRegion, positions.values TYPE myclass 在查询中使用保留字 要访问与查询语言保留字同名的任何方法，属性或命名对象，请将该名称括在双引号内。 SELECT * FROM /exampleRegion WHERE status = 'active' AND \"type\" = 'XYZ' SELECT DISTINCT \"type\" FROM /exampleRegion WHERE status = 'active' 使用 IMPORT 在同一个类名存在于两个不同的名称范围（包）中的情况下，需要有一种引用同名的不同类的方法。 IMPORT语句用于在查询中为类建立名称范围。 IMPORT package.Position; SELECT DISTINCT * FROM /exampleRegion, positions.values positions TYPE Position WHERE positions.mktValue >= 25.00 使用 TYPE 指定对象类型有助于查询引擎以最佳速度处理查询。 除了在配置期间指定对象类型（使用键约束和值约束）之外，还可以在查询字符串中显式指定类型。 SELECT DISTINCT * FROM /exampleRegion, positions.values positions TYPE Position WHERE positions.mktValue >= 25.00 使用 ELEMENT 使用ELEMENT(expr)从集合或数组中提取单个元素。 如果参数不是只包含一个元素的集合或数组，则此函数抛出FunctionDomainException。 ELEMENT(SELECT DISTINCT * FROM /exampleRegion WHERE id = 'XYZ-1').status = 'active' 我应该使用哪些API来编写查询？ 如果要查询Java应用程序的本地缓存或查询其他成员，请使用org.apache.geode.cache.Cache.getQueryService. 如果要将Java客户端编写到服务器查询，请使用org.apache.geode.cache.client.Pool.getQueryService. 如何在查询中调用对象的方法？ 要在查询中使用方法，请使用映射到要调用的公共方法的属性名称。 例如： /*valid method invocation*/ SELECT DISTINCT * FROM /exampleRegion p WHERE p.positions.size >= 2 - maps to positions.size() 我可以在查询中的对象上调用静态方法吗？ 不，您无法在对象上调用静态方法。 例如，以下查询无效。 /*invalid method invocation*/ SELECT DISTINCT * FROM /exampleRegion WHERE aDay = Day.Wednesday 要解决此限制，请编写可重用查询，该查询使用查询绑定参数来调用静态方法。 然后在查询运行时，将参数设置为静态方法调用（Day.Wednesday）。 例如： SELECT DISTINCT * FROM /exampleRegion WHERE aDay = $1 如何编写可重用的查询？ 使用查询API，您可以设置在查询运行时传递值的查询绑定参数。 例如： // specify the query string String queryString = \"SELECT DISTINCT * FROM /exampleRegion p WHERE p.status = $1\"; QueryService queryService = cache.getQueryService(); Query query = queryService.newQuery(queryString); // set a query bind parameter Object[] params = new Object[1]; params[0] = \"active\"; // Execute the query locally. It returns the results set. SelectResults results = (SelectResults) query.execute(params); // use the results of the query; this example only looks at the size int size = results.size(); 如果使用查询绑定参数代替路径表达式中的区域路径，则参数值必须引用集合（而不是字符串，例如区域路径的名称）。 有关详细信息，请参阅使用查询绑定参数。 我应该何时创建要在查询中使用的索引？ 确定查询的性能是否会从索引中受益。 例如，在以下查询中，pkid上的索引可以加快查询速度。 SELECT DISTINCT * FROM /exampleRegion portfolio WHERE portfolio.pkid = '123' 如何创建索引？ 可以使用API或使用xml以编程方式创建索引。 这是两个例子： 示例代码 QueryService qs = cache.getQueryService(); qs.createIndex(\"myIndex\", \"status\", \"/exampleRegion\"); qs.createKeyIndex(\"myKeyIndex\", \"id\", \"exampleRegion\"); 有关使用此API的更多信息，请参阅JavaDocs. 示例XML 有关索引的更多详细信息，请参阅使用索引. 我可以在溢出区域创建索引吗？ 您可以在溢出区域上创建索引，但是您受到一些限制。 例如，索引本身包含的数据不能溢出到磁盘。 有关详细信息，请参阅使用具有溢出区域的索引 。 我可以查询分区区域吗？ 我可以在分区区域上执行连接查询吗？ 您可以查询分区区域，但存在一些限制。 您不能对分区区域执行连接查询，但是您可以通过在本地数据集上执行函数来对共置的分区区域执行等连接查询。 有关限制的完整列表，请参阅分区区域查询限制. 如何提高分区区域查询的性能？ 如果您知道需要查询的数据，则可以通过使用FunctionService执行查询来定位查询中的特定节点（从而减少查询需要访问的服务器数量）。 有关详细信息，请参阅在单个节点上查询分区区域。 如果要查询已由键或特定字段分区的数据，则应首先创建键索引，然后使用FunctionService以键或字段作为过滤器执行查询。 请参阅优化对按键或字段值分区的数据的查询。 Geode支持哪些查询语言元素？ 支持的元素 AND LIMIT TO_DATE AS LIKE TYPE COUNT NOT WHERE DISTINCT NVL ELEMENT OR FROM ORDER BY SELECT IMPORT SET IN IS_DEFINED TRUE IS_UNDEFINED 有关使用每个受支持关键字的更多信息和示例，请参阅支持的关键字. 我如何调试查询？ 您可以在查询级别调试特定查询，方法是在要调试的查询字符串之前添加关键字。 这是一个例子： SELECT * FROM /exampleRegion 你也可以写： SELECT * FROM /exampleRegion 执行查询时，Geode将在$GEMFIRE_DIR/system.log中记录一条消息，其中包含以下信息： [info 2011/08/29 11:24:35.472 PDT CqServer tid=0x1] Query Executed in 9.619656 ms; rowCount = 99; indexesUsed(0) \"select * from /exampleRegion\" 如果要为所有查询启用调试，可以通过在启动期间在命令行上设置System属性来启用查询执行日志记录： gfsh>start server --name=server_name -–J=-Dgemfire.Query.VERBOSE=true 或者您可以以编程方式设置属性： System.setProperty(\"gemfire.Query.VERBOSE\",\"true\"); 我可以在查询中使用隐式属性或方法吗？ 如果隐式属性或方法名称只能与一个无类型迭代器关联，则Geode查询处理器将假定它与该迭代器关联。 但是，如果多个非类型化迭代器在范围内，则查询将失败并出现TypeMismatchException。 以下查询失败，因为查询处理器未完全键入表达式： select distinct value.secId from /pos , getPositions(23) 但是，以下查询成功，因为迭代器是使用变量显式命名的，或者是键入的： select distinct e.value.secId from /pos , getPositions(23) e 我可以指示查询引擎在查询中使用特定索引吗？ 使用HINT indexname可以指示查询引擎优先选择并过滤指定索引的结果。 如果提供多个索引名称，则查询引擎将使用所有可用索引，但更喜欢指定的索引。 SELECT * FROM /Portfolios p WHERE p.ID > 10 AND p.owner = 'XYZ' SELECT * FROM /Portfolios p WHERE p.ID > 10 AND p.owner = 'XYZ' AND p.value 如何在OQL中对字段执行不区分大小写的搜索？ 您可以使用Java String类方法toUpperCase和toLowerCase来转换要执行不区分大小写搜索的字段。 例如： SELECT entry.value FROM /exampleRegion.entries entry WHERE entry.value.toUpperCase LIKE '%BAR%' 或者 SELECT * FROM /exampleRegion WHERE foo.toLowerCase LIKE '%bar%' 使用OQL查询 本节提供Geode查询的高级介绍，例如构建查询字符串和描述查询语言功能。 Geode提供类似SQL的查询语言，允许您访问存储在Geode区域中的数据。 由于Geode区域是键值存储，其值可以从简单字节数组到复杂嵌套对象，因此Geode使用基于OQL（对象查询语言）的查询语法来查询区域数据。 OQL和SQL有许多语法上的相似之处，但是它们有很大的不同。 例如，虽然OQL不像聚合那样提供SQL的所有功能，但OQL允许您对复杂对象图执行查询，查询对象属性并调用对象方法。 典型的Geode OQL查询的语法是： [IMPORT package] SELECT [DISTINCT] projectionList FROM collection1, [collection2, …] [WHERE clause] [ORDER BY order_criteria [desc]] 因此，一个简单的Geode OQL查询类似于以下内容： SELECT DISTINCT * FROM /exampleRegion WHERE status = ‘active’ Geode查询要注意的一个重要特征是，默认情况下，Geode会查询区域的值而不是键。 要从区域获取键，必须在查询区域上使用keySet路径表达式。 例如，/exampleRegion.keySet。 对于Geode查询的新手，请参阅Geode查询常见问题和示例. OQL的优点 以下列表描述了使用基于OQL的查询语言的一些优点： 您可以查询任意对象 您可以导航对象集合 您可以调用方法并访问对象的行为 支持数据映射 您不需要声明类型。 由于您不需要类型定义，因此可以使用多种语言 您不受架构约束 在Geode中编写和执行查询 Geode QueryService提供了创建Query对象的方法。 然后，您可以使用Query对象执行与查询相关的操作。 您应该使用的QueryService实例取决于您是查询应用程序的本地缓存还是希望应用程序查询服务器缓存。 查询本地缓存 要查询应用程序的本地缓存或查询其他成员，请使用org.apache.geode.cache.Cache.getQueryService。 示例代码 // Identify your query string. String queryString = \"SELECT DISTINCT * FROM /exampleRegion\"; // Get QueryService from Cache. QueryService queryService = cache.getQueryService(); // Create the Query Object. Query query = queryService.newQuery(queryString); // Execute Query locally. Returns results set. SelectResults results = (SelectResults)query.execute(); // Find the Size of the ResultSet. int size = results.size(); // Iterate through your ResultSet. Portfolio p = (Portfolio)results.iterator().next(); /* Region containing Portfolio object. */ 从客户端查询服务器缓存 要执行客户端到服务器查询，请使用org.apache.geode.cache.client.Pool.getQueryService。 示例代码 // Identify your query string. String queryString = \"SELECT DISTINCT * FROM /exampleRegion\"; // Get QueryService from client pool. QueryService queryService = pool.getQueryService(); // Create the Query Object. Query query = queryService.newQuery(queryString); // Execute Query locally. Returns results set. SelectResults results = (SelectResults)query.execute(); // Find the Size of the ResultSet. int size = results.size(); // Iterate through your ResultSet. Portfolio p = (Portfolio)results.iterator().next(); /* Region containing Portfolio object. */ 有关特定API，请参阅以下JavaDocs： Query package QueryService 注意: 您还可以使用gfshquery命令执行查询。 见查询. 构建查询字符串 查询字符串是完全形成的OQL语句，可以传递给查询引擎并针对数据集执行。 要构建查询字符串，请组合支持的关键字，表达式和运算符，以创建返回所需信息的表达式。 查询字符串遵循查询语言和语法指定的规则。 它可以包括： Namescopes. 例如，IMPORT语句。 请参阅IMPORT声明。 Path expressions. 例如，在查询SELECT * FROM /exampleRegion中，/exampleRegion是路径表达式。 参见[FROM Clause](https://geode.apache.org/docs/guide/17/developing/query_select/the_from_clause.html#the_from_clause。 Attribute names. 例如，在查询SELECT DISTINCT * FROM /exampleRegion p WHERE p.position1.secId ='1'中，我们访问Position对象的secId属性。 请参阅WHERE子句。 Method invocations. 例如，在查询SELECT DISTINCT * FROM /exampleRegion p WHERE p.name.startsWith('Bo')中，我们在Name对象上调用startsWith方法。 请参阅WHERE子句。 Operators. 例如，比较运算符（=，，<>），一元运算符（NOT），逻辑运算符（AND，OR）等。 有关完整列表，请参阅操作员 。 Literals. 例如，布尔值，日期，时间等。 有关完整列表，请参阅支持的文字 。 Query bind parameters. 例如，在查询SELECT DISTINCT * FROM $1 p WHERE p.status = $2中，$1和$2是可以在运行时传递给查询的参数。 有关详细信息，请参阅使用查询绑定参数。 Preset query functions. 例如，ELEMENT(expr)和IS_DEFINED(expr)。 有关其他可用功能，请参阅SELECT Statement 。 SELECT statements. 例如，在上面的SELECT *或SELECT DISTINCT *的示例查询中。 有关其他可用功能，请参阅SELECT Statement 。 Comments. OQL允许在查询字符串中附加额外的字符，而不更改字符串的定义。 通过将注释主体包含在/ *和* /分隔符中来形成多行注释; OQL不允许嵌套注释。 单行注释正文是-- （两个连字符）右边的所有字符，直到行尾。 上面列出的组件都可以是查询字符串的一部分，但不需要任何组件。 查询字符串至少包含可以根据指定数据计算的表达式。 以下部分提供了编写典型Geode查询时使用的查询语言构建块的准则。 IMPORT Statement(IMPORT语句) FROM Clause(FROM子句) WHERE Clause(WHERE子句) SELECT Statement(SELECT语句) IMPORT Statement（IMPORT语句） 有时OQL查询需要引用对象的类。 如果相同的类名存在于两个不同的名称范围（包）中，则必须能够区分具有相同名称的类。 IMPORT语句用于在查询中为类建立名称。 IMPORT package.Position; SELECT DISTINCT * FROM /exampleRegion, positions.values positions TYPE Position WHERE positions.mktValue >= 25.00 FROM Clause（FROM子句） 使用FROM子句将所需的数据放入查询的其余部分的范围内。 FROM子句还包括对象类型和迭代器变量。 查询引擎根据查询中当前范围内的名称空间解析名称和路径表达式。 路径表达式 任何查询的初始名称空间由以下内容组成： 区域. 在查询的上下文中，区域的名称由其完整路径指定，以正斜杠（/）开头，并由区域名称之间的正斜杠分隔。 例如，/exampleRegion或/root/exampleRegion。 区域查询属性. 从区域路径，您可以访问Region对象的公共字段和方法，在查询时称为区域的属性。 例如，/exampleRegion.size。 顶级区域数据。 您可以通过区域路径访问输入键和输入数据。 /exampleRegion.keySet 返回区域中的输入键集 /exampleRegion.entryset 返回Region.Entry对象的Set /exampleRegion.values 返回条目值集合 /exampleRegion 返回条目值集合 新名称空间根据SELECT语句中的FROM子句进入作用域。 例子: 查询所有不同值的区域。 从区域返回一组唯一条目值： SELECT DISTINCT * FROM /exampleRegion 使用entrySet查询顶级区域数据。 返回mktValue属性大于25.00的Region.Entry对象的键和位置： SELECT key, positions FROM /exampleRegion.entrySet, value.positions.values positions WHERE positions.mktValue >= 25.00 查询区域的条目值。 从Region.Entry对象返回一组唯一值，这些对象的键等于1： SELECT DISTINCT entry.value FROM /exampleRegion.entries entry WHERE entry.key = '1' 查询区域的条目值。 返回ID字段大于1000的所有条目值的集合： SELECT * FROM /exampleRegion.entries entry WHERE entry.value.ID > 1000 查询区域中的条目键。 返回键为1的区域中的一组输入键： SELECT * FROM /exampleRegion.keySet key WHERE key = '1' 查询区域中的值。 返回状态属性值为active的区域中的条目值集合： SELECT * FROM /exampleRegion.values portfolio WHERE portfolio.status = 'active' 别名和同义词 在查询字符串中，您可以在路径表达式（区域及其对象）中使用别名，以便您可以引用查询中其他位置的区域或对象。 您还可以使用AS关键字为连接的路径表达式提供标签。 例子: SELECT DISTINCT * FROM /exampleRegion p WHERE p.status = 'active' SELECT * FROM /exampleRegion p, p.positions.values AS pos WHERE pos.secId != '1' 对象类型 在FROM子句中指定对象类型有助于查询引擎以最佳速度处理查询。 除了在配置期间指定对象类型（使用键约束和值约束）之外，还可以在查询字符串中显式指定类型。 例子: SELECT DISTINCT * FROM /exampleRegion, positions.values positions TYPE Position WHERE positions.mktValue >= 25.00 WHERE Clause（WHERE子句） 每个FROM子句表达式必须解析为一组对象。 然后，该集合可用于WHERE子句中的查询表达式中的迭代。 例如: SELECT DISTINCT * FROM /exampleRegion p WHERE p.status = 'active' 条目值集合由WHERE子句迭代，将状态字段与字符串'active'进行比较。 找到匹配项后，条目的值对象将添加到返回集。 在下一个示例查询中，第一个FROM子句表达式中指定的集合由SELECT语句的其余部分使用，包括第二个FROM子句表达式。 SELECT DISTINCT * FROM /exampleRegion, positions.values p WHERE p.qty > 1000.00 实现equals和hashCode方法 如果要对对象执行ORDER BY和DISTINCT查询，则必须在自定义对象中实现equals和hashCode方法。 这些方法必须符合java.lang.Object的在线Java API文档中记录的属性和行为。 如果不存在这些方法，则可能会出现查询结果不一致的情况。 如果在自定义对象中实现了equals和hashCode方法，则必须提供这些方法的详细实现，以便查询对对象正确执行。 例如，假设您已使用以下变量定义了自定义对象（CustomObject）： int ID int otherValue 让我们将两个CustomObjects（我们称之为CustomObjectA和CustomObjectB）放入缓存中： CustomObjectA: ID=1 otherValue=1 CustomObjectB: ID=1 otherValue=2 如果已实现equals方法以简单地匹配ID字段（ID == ID），则查询将产生不可预测的结果。 以下查询： SELECT * FROM /CustomObjects c WHERE c.ID > 1 AND c.ID 0 AND c.otherValue 返回两个对象，但对象将是CustomObjectA或CustomObjectB中的两个。 或者，以下查询： SELECT * FROM /CustomObjects c WHERE c.ID > 1 AND c.ID 1 AND c.otherValue 返回0结果或2个CustomObjectB结果，具体取决于最后评估的条目。 为了避免不可预测的查询行为，请实现equals和hashCode方法的详细版本。 如果要比较WHERE子句中对象的非原始字段，请使用equals方法而不是=运算符。 例如，使用nonPrimitiveObj.equals（objToBeCompared）代替nonPrimitiveObj = objToBeCompared。 查询序列化的对象 如果要查询分区区域，或者要执行客户机-服务器查询，则对象必须实现serializable。 如果使用PDX序列化，可以访问各个字段的值，而不必反序列化整个对象。 这是通过使用PdxInstance实现的，它是序列化流的包装器。 PdxInstance提供了一个助手方法，该方法接受字段名并返回值，而不反序列化对象。 在评估查询时，查询引擎将通过调用getField方法访问字段值，从而避免反序列化。 要在查询中使用pdxinstance，请确保在服务器的缓存中启用了PDX序列化读取。 在gfsh中，在启动数据成员之前执行以下命令: gfsh>configure pdx --read-serialized=true 有关更多信息，请参见配置 pdx。 在cache.xml，设置如下: // Cache configuration setting PDX read behavior ... 属性可见性 您可以访问查询的当前范围内可用的任何对象或对象属性。 在查询中，对象的属性是可以映射到对象中的公共字段或方法的任何标识符。 在FROM规范中，作用域中的任何对象都是有效的。 因此，在查询开始时，所有本地缓存区域及其属性都在范围内。 对于属性的位置。secId是公共的，有getter方法“getSecId()”，查询可以写成如下: SELECT DISTINCT * FROM /exampleRegion p WHERE p.position1.secId = '1' SELECT DISTINCT * FROM /exampleRegion p WHERE p.position1.SecId = '1' SELECT DISTINCT * FROM /exampleRegion p WHERE p.position1.getSecId() = '1' 查询引擎尝试使用公共字段值计算值。如果没有找到公共字段值，则使用字段名进行get调用(注意第一个字符是大写的)。 连接 如果FROM子句中的集合彼此不相关，则可以使用WHERE子句连接它们。 下面的语句从 /exampleRegion和 /exampleRegion2区域返回所有具有相同状态的投资组合。 SELECT * FROM /exampleRegion portfolio1, /exampleRegion2 portfolio2 WHERE portfolio1.status = portfolio2.status 要为区域连接创建索引，您需要为连接条件的两边创建单区域索引。这些在连接条件的查询执行期间使用。分区区域不支持区域连接。有关索引的更多信息，请参见使用索引。 例子: 查询两个区域。返回具有相同状态的投资组合的ID和状态。 SELECT portfolio1.ID, portfolio2.status FROM /exampleRegion portfolio1, /exampleRegion2 portfolio2 WHERE portfolio1.status = portfolio2.status 查询两个区域，遍历每个投资组合中的所有头寸。返回所有4元组，包括来自两个区域的值和来自位置的secId字段匹配的两个区域的位置映射的值部分。 SELECT * FROM /exampleRegion portfolio1, portfolio1.positions.values positions1, /exampleRegion2 portfolio2, portfolio2.positions.values positions2 WHERE positions1.secId = positions2.secId 与前一个示例相同的查询，具有匹配的附加约束的ID将为1。 SELECT * FROM /exampleRegion portfolio1, portfolio1.positions.values positions1, /exampleRegion2 portfolio2, portfolio2.positions.values positions2 WHERE portfolio1.ID = 1 AND positions1.secId = positions2.secId LIKE(好像) Geode对LIKE谓词提供了有限的支持。LIKE可以用来表示等于。如果您使用通配符(' % ')终止字符串，它的行为类似于以...开始。您还可以将通配符(%或_)放置在比较字符串中的任何其他位置。可以转义通配符来表示字符本身。 注意: 类似谓词的OQL中不支持通配符*。 当有索引时，还可以使用LIKE谓词。 例子: 查询该地区。返回status = active的所有对象: SELECT * FROM /exampleRegion p WHERE p.status LIKE 'active' 使用通配符查询区域以进行比较。返回状态以activ开头的所有对象: SELECT * FROM /exampleRegion p WHERE p.status LIKE 'activ%' 不区分大小写字段 您可以使用Java字符串类方法toUpperCase和toLowerCase转换要执行不区分大小写搜索的字段。例如: SELECT entry.value FROM /exampleRegion.entries entry WHERE entry.value.toUpperCase LIKE '%BAR%' 或者 SELECT * FROM /exampleRegion WHERE foo.toLowerCase LIKE '%bar%' 方法调用 若要在查询中使用方法，请使用映射到要调用的公共方法的属性名。 SELECT DISTINCT * FROM /exampleRegion p WHERE p.positions.size >= 2 - maps to positions.size() 当通过查询处理器调用时，声明返回void evaluate为null的方法。 您不能调用静态方法。有关更多信息，请参见Enum对象。 方法没有参数 如果属性名映射到不接受参数的公共方法，只需将方法名作为属性包含在查询字符串中。例如,emps.isEmpty等价于emps.isEmpty()。 在下面的例子中，查询对position调用isEmpty，并返回没有position的所有投资组合的集合: SELECT DISTINCT * FROM /exampleRegion p WHERE p.positions.isEmpty 带参数方法 若要使用参数调用方法，请将查询字符串中的方法名称作为属性包含，并在圆括号中提供方法参数。 这个示例将参数“Bo”传递给公共方法，并返回所有以“Bo”开头的名称。 SELECT DISTINCT * FROM /exampleRegion p WHERE p.name.startsWith('Bo') 对于重载的方法，查询处理器通过将运行时参数类型与方法所需的参数类型匹配来决定调用哪个方法。如果只有一个方法的签名与提供的参数匹配，则调用该方法。查询处理器使用运行时类型来匹配方法签名。 如果可以调用多个方法，查询处理器将选择参数类型对给定参数最特定的方法。例如，如果重载的方法包含具有相同数量参数的版本，但是一个以Person类型作为参数，另一个以从Person派生的Employee类型作为参数，则Employee是更特定的对象类型。如果传递给方法的参数与这两种类型兼容，查询处理程序将使用具有Employee参数类型的方法。 查询处理器使用参数和接收器的运行时类型来确定要调用的适当方法。由于使用了运行时类型，具有null值的参数没有类型信息，因此可以与任何对象类型参数匹配。当使用null参数时，如果查询处理器不能根据非空参数确定要调用的正确方法，它将抛出一个AmbiguousNameException。 启用SecurityManager的方法调用 当SecurityManager被启用时，Geode会在调用白名单之外的任何方法时抛出一个NotAuthorizedException: On a Map, Collection, or Region object: keySet, entrySet, values, containsKey or get On a Region.Entry object: getKey or getValue On a Date or Timestamp object: after, before, getNanos, or getTime On a String object: any method On any Number object: intValue, longValue, shortValue, etc. On any Boolean object: booleanValue On any object: equals, compareTo, or toString 要禁用授权检查，请使用添加的系统属性gemfire.QueryService.allowUntrustedMethodInvocation启动所有服务器。例如: gfsh>start server --name=Server1 \\ --J=-Dgemfire.QueryService.allowUntrustedMethodInvocation=true 枚举对象 要基于枚举对象字段的值编写查询，必须使用枚举对象的toString方法或使用查询绑定参数。 例如，以下查询无效: //INVALID QUERY select distinct * from /QueryRegion0 where aDay = Day.Wednesday 它无效的原因是调用到 Day.Wednesday 涉及不支持的静态类和方法调用。 枚举类型可以通过枚举对象的toString方法或使用bind参数来查询。当您使用toString方法查询时，您必须已经知道希望查询的约束值。在下面的第一个示例中，已知值是active。 例子: 查询枚举类型使用toString方法: // eStatus is an enum with values 'active' and 'inactive' select * from /exampleRegion p where p.eStatus.toString() = 'active' 使用绑定参数查询枚举类型。期望的Enum字段(Day.Wednesday)的值作为执行参数传递: select distinct * from /QueryRegion0 where aDay = $1 IN 和 SET IN表达式是一个布尔值，指示在兼容类型的表达式集合中是否存在一个表达式。该决定基于表达式的equals语义。 如果e1和e2是表达式，e2是集合，e1是类型为e2的子类型或元素类型相同的对象或文字，那么e2中的e1是布尔类型的表达式。 表达式返回: 如果e1不是未定义的并且包含在集合e2中，则为TRUE 如果e1不是未定义的，且集合e2中不包含e1，则为FALSE 如果e1没有定义怎返回UNDEFINED 例如，集合(1,2,3)中的2为真。 另一个例子是，您正在查询的集合是由一个子查询定义的。这个查询寻找的公司有一个活跃的投资组合文件: SELECT name, address FROM /company WHERE id IN (SELECT id FROM /portfolios WHERE status = 'active') 内部SELECT语句返回状态为活动的所有/portfolio条目的id集合。外部选择在/company上迭代，将每个条目的id与此集合进行比较。对于每个条目，如果IN表达式返回TRUE，那么相关的名称和地址将添加到外部SELECT的集合中。 比较 Set 值 下面是一个集合值类型比较的例子，其中sp是集合类型: SELECT * FROM /exampleRegion WHERE sp = set('20','21','22') 在这种情况下，如果sp只包含 '20’和'21’，那么查询将求值为false。查询比较这两个集合，并查找这两个集合中的所有元素。 对于list等其他集合类型，查询可以写成: SELECT * FROM /exampleRegion WHERE sp.containsAll(set('20','21','22)) 其中sp为List类型。 为了将其用于Set值，查询可以写成: SELECT * FROM /exampleRegion WHERE sp IN SET (set('20','21','22'),set('10',11','12')) 在集合中搜索集合值。 一个问题是不能在集合类型或列表类型(集合类型)上创建不可比较的索引。要解决这个问题，可以在实现Comparable的自定义集合类型上创建索引。 Double.NaN 和 Float.NaN 比较 Double.NaN 和 Float.NaN的比较行为,在Geode查询中的NaN遵循JDK方法Float.compareTo和Double.compareTo的语义。 综上所述，当Java语言的数值比较运算符(= >)应用于原语double [float]值时，其比较的不同之处在于: Double.NaN [Float.NaN] 被认为等于它本身，并且大于所有其他double [float]值(包括Double.POSITIVE_INFINITY [Float.POSITIVE_INFINITY])。 该方法认为0.0d [0.0f]大于-0.0d [-0.0f]。 因此,Double.NaN[Float.NaN]被认为大于Double.POSITIVE_INFINITY[Float.POSITIVE_INFINITY]。下面是一些示例查询和预期结果。 如果 p.value 是 NaN, 下面的查询: 计算结果为: 出现在结果集中? SELECT * FROM /positions p WHERE p.value = 0 false no SELECT * FROM /positions p WHERE p.value > 0 true yes SELECT * FROM /positions p WHERE p.value >= 0 true yes SELECT * FROM /positions p WHERE p.value false no SELECT * FROM /positions p WHERE p.value false no 如果 p.value 和 p.value1 都是 NaN, 下面的查询: 计算结果为: 出现在结果集中: SELECT * FROM /positions p WHERE p.value = p.value1 true yes 如果在代码中定义以下查询时将值组合在一起，那么在执行查询时，解析值本身被认为是未定义的，不会在结果集中返回。 String query = \"SELECT * FROM /positions p WHERE p.value =\" + Float.NaN 执行此查询时，解析后的值本身被认为是未定义的，不会在结果集中返回。 要检索NaN值而不需要另一个字段已经存储为NaN，可以在代码中定义以下查询: String query = \"SELECT * FROM /positions p WHERE p.value > \" + Float.MAX_VALUE; 算术运算 算术运算符可以用在任何表达式中。 例如，该查询选择体重指数小于25的所有人: String query = \"SELECT * FROM /people p WHERE p.height * p.height/p.weight SELECT Statement（SELECT语句） SELECT语句允许您从WHERE搜索操作返回的对象集合中筛选数据。投影列表可以指定为*，也可以指定为以逗号分隔的表达式列表。 对于*，WHERE子句的临时结果将从查询中返回。 例子: 使用*查询区域中的所有对象。返回投资组合的集合(exampleRegion将投资组合包含为值)。 SELECT * FROM /exampleRegion 从位置查询secid。从活动投资组合的头寸中返回secid集合: SELECT secId FROM /exampleRegion, positions.values TYPE Position WHERE status = 'active' 返回活动投资组合的struct的集合。结构的第二个字段是Map (java .utils)。对象，其中包含位置映射作为值: SELECT \"type\", positions FROM /exampleRegion WHERE status = 'active' 返回活动投资组合 的结构体集合: SELECT * FROM /exampleRegion, positions.values TYPE Position WHERE status = 'active' 返回活动投资组合的结构体集合: SELECT * FROM /exampleRegion portfolio, positions positions TYPE Position WHERE portfolio.status = 'active' SELECT语句的结果 SELECT语句的结果要么是未定义的，要么是实现SelectResults接口的集合。 从SELECT语句返回的SelectResults是: 为这两种情况返回的对象集合: 当投影列表只指定一个表达式且该表达式未使用字段名:表达式语法显式指定时 当SELECT列表为*且FROM子句中指定了单个集合时 包含对象的结构的集合 当返回结构体时，结构体中每个字段的名称按照以下优先顺序确定: 如果使用字段名:表达式语法显式指定字段，则使用字段名。 如果SELECT投影列表是*，并且FROM子句中使用显式迭代器表达式，则迭代器变量名用作字段名。 如果字段与区域或属性路径关联，则使用该路径中的最后一个属性名。 如果不能根据这些规则决定名称，查询处理器将生成任意惟一的名称。 DISTINCT(独特的) 如果希望将结果设置为唯一的行，请使用DISTINCT关键字。注意，在Geode的当前版本中，您不再需要在SELECT语句中使用DISTINCT关键字。 SELECT DISTINCT * FROM /exampleRegion 注意: 如果使用DISTINCT查询，则必须为查询的对象实现equals和hashCode方法。 LIMIT(限制) 您可以在查询字符串的末尾使用LIMIT关键字来限制返回的值的数量。 例如，这个查询最多返回10个值: SELECT * FROM /exampleRegion LIMIT 10 ORDER BY(排序) 可以使用order by子句按升序或降序排列查询结果。在编写ORDER BY查询时，必须使用DISTINCT。 SELECT DISTINCT * FROM /exampleRegion WHERE ID 以下查询按升序对结果进行排序: SELECT DISTINCT * FROM /exampleRegion WHERE ID 以下查询按降序对结果进行排序: SELECT DISTINCT * FROM /exampleRegion WHERE ID 注意: 如果使用ORDER BY查询，则必须为查询的对象实现equals和hashCode方法。 预设的查询功能 Geode提供了几个内置函数来评估或过滤查询返回的数据。其中包括: 函数 描述 例子 ELEMENT(expr) 从集合或数组中提取单个元素。如果参数不是只有一个元素的集合或数组，则该函数抛出一个FunctionDomainException。 ELEMENT(SELECT DISTINCT * FROM /exampleRegion WHERE id = 'XYZ-1').status = 'active' IS_DEFINED(expr) 如果表达式的值不为UNDEFINED，则返回TRUE。不等式查询在查询结果中包含未定义的值。使用IS_DEFINED函数，您可以将结果限制为只有那些具有定义值的元素。 IS_DEFINED(SELECT DISTINCT * FROM /exampleRegion p WHERE p.status = 'active') IS_UNDEFINED (expr) 如果表达式计算结果为UNDEFINED，则返回TRUE。除不等式查询外，大多数查询的查询结果中不包含未定义的值。IS_UNDEFINED函数允许包含未定义的值，因此可以使用未定义的值标识元素。 SELECT DISTINCT * FROM /exampleRegion p WHERE IS_UNDEFINED(p.status) NVL(expr1, expr2) 如果expr1为空，则返回expr2。表达式可以是查询参数(绑定参数)、路径表达式或文本。 TO_DATE(date_str, format_str) 返回一个Java数据类对象。参数必须是字符串S, date_str表示日期，format_str表示date_str使用的格式。您提供的format_str是使用java.text.SimpleDateFormat解析的。 COUNT COUNT关键字返回与WHERE子句中指定的查询选择条件匹配的结果数。使用COUNT可以确定结果集的大小。COUNT语句总是返回一个整数作为结果。 以下查询是返回区域项的示例计数查询: SELECT COUNT(*) FROM /exampleRegion SELECT COUNT(*) FROM /exampleRegion WHERE ID > 0 SELECT COUNT(*) FROM /exampleRegion WHERE ID > 0 LIMIT 50 SELECT COUNT(*) FROM /exampleRegion WHERE ID >0 AND status LIKE 'act%' SELECT COUNT(*) FROM /exampleRegion WHERE ID IN SET(1,2,3,4,5) 下面的COUNT查询返回与查询的选择条件匹配的结构类型的总数。 SELECT COUNT(*) FROM /exampleRegion p, p.positions.values pos WHERE p.ID > 0 AND pos.secId 'IBM' 下面的COUNT查询使用不同的关键字，并从结果的数量中消除重复。 SELECT DISTINCT COUNT(*) FROM /exampleRegion p, p.positions.values pos WHERE p.ID > 0 OR p.status = 'active' OR pos.secId OR pos.secId = 'IBM' OQL聚合函数 支持针对不同表达式的聚合函数MIN、MAX、AVG、AVG、SUM、COUNT和COUNT。在适当的情况下，还支持GROUP BY扩展。 MIN函数的作用是:返回所选表达式中最小的一个。表达式的类型必须计算为java.lang.Comparable。 MAX函数的作用是:返回所选表达式中最大的一个。表达式的类型必须计算为java.lang.Comparable。 AVG函数的作用是:返回所选表达式的算术平均值。表达式的类型必须计算为java.lang.Number。对于分区区域，每个节点的bucket为执行查询的节点提供一个和和元素的数量，这样就可以计算出正确的平均值。 有DISTINCT限定符的AVG函数的作用是:返回一组唯一值(不同值)的算术平均值。表达式的类型必须计算为java.lang.Number。对于分区区域，节点bucket中的不同值返回给执行查询的节点。然后，在消除来自不同节点的重复值之后，查询节点可以计算跨节点的唯一值的平均值。 SUM函数的作用是:返回选定表达式形成的集合的和。表达式的类型必须计算为java.lang.Number。对于分区区域，每个节点的bucket计算该节点上的和，并将该和返回到执行查询的节点，然后计算所有节点上的和。 将DISTINCT修饰符应用于表达式的SUM函数返回对一组惟一(不同)值的和。表达式的类型必须计算为java.lang.Number。对于分区区域，节点bucket中的不同值返回给执行查询的节点。然后，在消除来自不同节点的重复值之后，查询节点可以计算节点间惟一值的总和。 COUNT函数的作用是:返回所选表达式在集合中形成的值的数量。例如，返回销售额为正的员工数量: SELECT count(e.sales) FROM /employees e WHERE e.sales > 0.0 应用DISTINCT修饰符的' COUNT '函数返回所选表达式形成的集合中唯一(不同)值的数量。 通过扩展对聚合函数进行GROUP BY 当聚合函数与其他选定项组合使用时，需要GROUP BY。它允许排序。例如, SELECT ID, MAX(e.sales) FROM /employees e GROUP BY ID OQL语法和语义 本节介绍以下查询语言特性: 支持的字符集 支持的关键字 区分大小写 查询字符串中的注释 查询语言语法 操作符 保留字 支持的文字 支持的字符集 Geode查询语言支持完整的ASCII和Unicode字符集。 支持的关键字 查询语言关键字 描述 例子 AND 逻辑运算符，用于通过组合两个或多个表达式来生成布尔结果来创建复杂表达式。当您使用AND运算符组合两个条件表达式时，两个条件的值都必须为true，才能使整个表达式为真。 See Operators AS 用于为路径表达式提供标签，以便稍后可以通过标签引用路径。 See Aliases and Synonyms COUNT 返回与提供的条件匹配的结果的数量。 See COUNT DISTINCT 将select语句限制为唯一的结果(消除重复)。 See DISTINCT ELEMENT 查询功能。从集合或数组中提取单个元素。如果参数不是只有一个元素的集合或数组，则该函数抛出一个FunctionDomainException。 See Preset Query Functions FROM 您可以访问查询的当前范围内可用的任何对象或对象属性。 See FROM Clause 指示查询引擎优先选择某些索引的关键字。 See Using Query Index Hints IMPORT 用于建立对象的名称库。 See IMPORT Statement IN IN表达式是一个布尔值，指示一个表达式是否存在于兼容类型的表达式集合中。 See IN and SET IS_DEFINED 查询功能。如果表达式的值不为UNDEFINED，则返回TRUE。不等式查询在查询结果中包含未定义的值。使用IS_DEFINED函数，您可以将结果限制为只有那些具有定义值的元素。 See Preset Query Functions IS_UNDEFINED 查询功能。如果表达式计算结果为UNDEFINED，则返回TRUE。除不等式查询外，大多数查询的查询结果中不包含未定义的值。IS_UNDEFINED函数允许包含未定义的值，因此可以使用未定义的值标识元素。 See Preset Query Functions LIMIT 限制返回结果的数量。如果使用limit关键字，还不能对执行任何类型的汇总活动的查询结果集运行操作。例如，试图从带有LIMIT子句的查询中运行add或addAll或SelectResult会抛出异常。 See LIMIT LIKE LIKE可以用来表示等于，或者如果您以通配符(%)结束字符串，它的行为类似于以开头。请注意，通配符只能在比较字符串的末尾使用。可以转义通配符来表示%字符。如果有索引，还可以使用LIKE谓词。 See LIKE NOT 该示例返回具有头寸的投资组合集。注意NOT不能使用索引。 See Operators NVL 如果expr1为空，则返回expr2。表达式可以是查询参数(绑定参数)、路径表达式或文本。参见预设置查询函数 OR 如果表达式同时使用AND和OR运算符，则AND表达式的优先级高于OR。 See Operators ORDER BY 允许您对查询结果进行排序(升序或降序)。 See ORDER BY SELECT 允许您从WHERE搜索操作返回的对象集合中筛选数据。 See SELECT Statement SET 指定可与查询的返回值进行比较的值的集合。 See IN and SET 启用对以下查询字符串的调试。 See Query Debugging TO_DATE 返回一个Java数据类对象。参数必须是字符串S, date_str表示日期，format_str表示date_str使用的格式。您提供的format_str是使用java.text.SimpleDateFormat解析的。 See Preset Query Functions TYPE 在FROM子句中指定对象类型有助于查询引擎以最佳速度处理查询。 See Object Typing WHERE 解析为对象的集合。然后集合可以在WHERE子句后面的查询表达式中进行迭代。 See WHERE Clause 区分大小写 查询语言关键字(如SELECT、NULL、DATE和)不区分大小写。属性名、方法名和路径表达式等标识符是区分大小写的。 在查询字符串和区域条目匹配方面，如果希望对特定字段执行不区分大小写的搜索，可以在查询中使用Java字符串类toUpperCase和toLowerCase方法。例如: SELECT entry.value FROM /exampleRegion.entries entry WHERE entry.value.toUpperCase LIKE '%BAR%' 或者 SELECT * FROM /exampleRegion WHERE foo.toLowerCase LIKE '%bar%' 查询字符串中的注释 注释行使用--(双破折号)。注释块以/*开头，以*/结尾。例如: SELECT * --my comment FROM /exampleRegion /* here is a comment */ WHERE status = ‘active’ 查询语言语法 语言的语法 语法中使用的符号:n 一种非终结符，必须出现在语法中规则左侧的某个位置。所有非终结符号都必须被派生为终结符号。 t 终端符号(以斜体粗体显示)。 x y x followed by y x | y x or y (x | y) x or y [ x ] x or empty { x } A possibly empty sequence of x. 备注 描述性的文本 语法列表: symbol ::= expression query_program ::= [ imports semicolon ] query [semicolon] imports ::= import { semicolon import } import ::= IMPORT qualifiedName [ AS identifier ] query ::= selectExpr | expr selectExpr ::= SELECT DISTINCT projectionAttributes fromClause [ whereClause ] projectionAttributes ::= * | projectionList projectionList ::= projection { comma projection } projection ::= field | expr [ AS identifier ] field ::= identifier colon expr fromClause ::= FROM iteratorDef { comma iteratorDef } iteratorDef ::= expr [ [ AS ] identifier ] [ TYPE identifier ] | identifier IN expr [ TYPE identifier ] whereClause ::= WHERE expr expr ::= castExpr castExpr ::= orExpr | left_paren identifier right_paren castExpr orExpr ::= andExpr { OR andExpr } andExpr ::= equalityExpr { AND equalityExpr } equalityExpr ::= relationalExpr { ( = | <> | != ) relationalExpr } relationalExpr ::= additiveExpr { ( | >= ) additiveExpr } additiveExpr ::= multiplicativeExpr { (+ | -) multiplicativeExpr } multiplicativeExpr ::= inExpr { (MOD | % | / | *) inExpr} inExpr ::= unaryExpr { IN unaryExpr } unaryExpr ::= [ NOT ] unaryExpr postfixExpr ::= primaryExpr { left_bracket expr right_bracket } | primaryExpr { dot identifier [ argList ] } argList ::= left_paren [ valueList ] right_paren qualifiedName ::= identifier { dot identifier } primaryExpr ::= functionExpr | identifier [ argList ] | undefinedExpr | collectionConstruction | queryParam | literal | ( query ) | region_path functionExpr ::= ELEMENT left_paren query right_paren | NVL left_paren query comma query right_paren | TO_DATE left_paren query right_paren undefinedExpr ::= IS_UNDEFINED left_paren query right_paren | IS_DEFINED left_paren query right_paren collectionConstruction ::= SET left_paren [ valueList ] right_paren valueList ::= expr { comma expr } queryParam ::= $ integerLiteral region_path ::= forward_slash region_name { forward_slash region_name } region_name ::= name_character { name_character } identifier ::= letter { name_character } literal ::= booleanLiteral | integerLiteral | longLiteral | doubleLiteral | floatLiteral | charLiteral | stringLiteral | dateLiteral | timeLiteral | timestampLiteral | NULL | UNDEFINED booleanLiteral ::= TRUE | FALSE integerLiteral ::= [ dash ] digit { digit } longLiteral ::= integerLiteral L floatLiteral ::= [ dash ] digit { digit } dot digit { digit } [ ( E | e ) [ plus | dash ] digit { digit } ] F doubleLiteral ::= [ dash ] digit { digit } dot digit { digit } [ ( E | e ) [ plus | dash ] digit { digit } ] [ D ] charLiteral ::= CHAR single_quote character single_quote stringLiteral ::= single_quote { character } single_quote dateLiteral ::= DATE single_quote integerLiteral dash integerLiteral dash integerLiteral single_quote timeLiteral ::= TIME single_quote integerLiteral colon integerLiteral colon integerLiteral single_quote timestampLiteral ::= TIMESTAMP single_quote integerLiteral dash integerLiteral dash integerLiteral integerLiteral colon integerLiteral colon digit { digit } [ dot digit { digit } ] single_quote letter ::= any unicode letter character ::= any unicode character except 0xFFFF name_character ::= letter | digit | underscore digit ::= any unicode digit 以下表达式均为终端字符: dot ::= . left_paren ::= ( right_paren ::= ) left_bracket ::= [ right_bracket ::= ] single_quote ::= ’ underscore ::= _ forward_slash ::= / comma ::= , semicolon ::= ; colon ::= : dash ::= - plus ::= + 语言附录 查询语言关键字(如SELECT、NULL和DATE)不区分大小写。属性名、方法名和路径表达式等标识符是区分大小写的。 注释行以--(双破折号)开头。 注释块以/开头，以/结尾。 字符串文字由单引号分隔。嵌入单引号加倍。 例子: 'Hello' value = Hello 'He said, ''Hello''' value = He said, 'Hello' 字符文字以CHAR关键字开头，后跟单引号中的字符。单引号字符本身表示为`CHAR ''''(带有四个单引号)。 在时间戳文本中，小数点后最多有9位数字。 操作符 Geode支持比较、逻辑、一元、算术、映射、索引、点和右箭头操作符。 比较运算符 比较运算符比较两个值并返回结果，要么为真，要么为假。 以下是支持的比较运算符: 操作符 含义 less than less than or equal to > greater than >= greater than or equal to = equal to != not equal to <> not equal to 关于等式和不等式运算符: 等式和不等式运算符的优先级低于其他比较运算符。 等式和不等式运算符可以与null一起使用。 不等式查询返回搜索字段为UNDEFINED。的结果 要执行与UNDEFINED相等或不相等的比较，使用IS_DEFINED和IS_UNDEFINED预置查询函数，而不是这些比较运算符。 逻辑运算符 逻辑运算符AND 和 OR 允许您通过组合表达式来生成布尔结果来创建更复杂的表达式。当您使用AND运算符组合两个条件表达式时，两个条件的值都必须为true，才能使整个表达式为真。当您使用OR运算符组合两个条件表达式时，如果其中一个或两个条件都为真，则表达式的计算结果为真。您可以通过使用AND和OR操作符组合多个简单条件表达式来创建复杂表达式。当表达式使用AND和或运算符时，且具有比OR更高的优先级。 一元操作符 一元运算符操作单个值或表达式，在表达式中优先级低于比较运算符。Geode不支持一元运算符。NOT是否定运算符，它将操作数的值更改为相反的值。例如，如果表达式的计算结果为TRUE，则不将其更改为FALSE。操作数必须是布尔值。 算术运算符 算术运算符操作两个值或表达式。任何预期的算术异常都可能导致溢出或除以0。QueryInvocationTargetException将被抛出，getCause()将声明ArithmeticException。 以下是支持的算术运算符: 操作符 含义 + addition - subtraction * multiplication / division % modulus MOD modulus 映射和索引操作符 映射和索引操作符访问键/值集合(如映射和区域)和有序集合(如数组、列表和String)中的元素。操作符由紧挨着集合名称的一组方括号([])表示。这些括号中提供了映射或索引规范。 数组、列表和字符串元素使用索引值进行访问。索引从第一个元素的0开始，从第二个元素的1开始，依此类推。如果myList是一个数组、列表或String，而index是一个计算结果为非负整数的表达式，那么myList[index]表示myList的第(index+1)个元素。字符串的元素是组成字符串的字符列表。 Map和region值通过键使用相同的语法进行访问。关键字可以是任何对象。对于区域，map操作只在本地缓存中执行非分布式的get，不使用netSearch。因此，myRegion[keyExpression]等价于myRegion. getentry(keyExpression).getvalue。 点，右箭头和正斜杠运算符 点运算符(' . ')分隔路径表达式中的属性名，并指定通过对象属性的导航。右箭头(' -> ')是与圆点等价的另一个替代符号。当导航到子区域时，正斜杠用于分隔区域名称。 保留字 这些词是为查询语言保留的，不能用作标识符。Geode目前不使用后面带有星号(*)的单词，而是为将来的实现保留。 abs* all and andthen* any* array as asc avg* bag* boolean by byte char collection count date declare* define* desc dictionary distinct double element enum* except* exists* false first* flatten* float for* from group* having* import in int intersect* interval* is_defined is_undefined last* like limit list* listtoset* long map max* min* mod nil not null nvl octet or order orelse* query* select set short some* string struct* sum* time timestamp to_date true type undefine* undefined union* unique* where 若要访问与查询语言保留字具有相同名称的任何方法、属性或命名对象，请将名称用双引号括起来。 例子: SELECT DISTINCT \"type\" FROM /portfolios WHERE status = 'active' SELECT DISTINCT * FROM /region1 WHERE emps.\"select\"() 支持文字 Geode支持以下文字类型: boolean 一个布尔值， TRUE 或者 FALSE int 和 long 如果一个整数的后缀是ASCII字母l，那么它的类型是long，否则它的类型是int。 浮点 如果浮点文字的后缀是ASCII字母F，则它的类型为float。否则，它的类型是double。可选地，它可以有ASCII字母D的后缀。双精度字面值或浮点字面值可以选择性地包含指数后缀E或e，后跟有符号或无符号数字。 string 字符串文字由单引号分隔。嵌入的单引号加倍。例如，字符串'Hello'的值为Hello，而字符串'He said, ''Hello'''的值为He said, 'Hello'。嵌入的换行符保留为字符串文本的一部分。 char 如果一个字面值是以关键字char为前缀的字符串字面值，则它是char类型，否则它是string类型。单引号字符的 CHAR 文字是CHAR ''''(四个单引号)。 date java.sql.Date对象，该对象使用以Date关键字DATE yyyy-mm-dd为前缀的JDBC格式。在Date中，yyyy代表年份，mm代表月份，dd代表日子。年份必须用四位数表示;不允许用两位数的缩写来表示年份。 time java.sql.Time对象，该对象使用JDBC格式(基于24小时时钟)，前缀为Time关键字:TIME hh:mm:ss。在Time中，hh代表小时，mm代表分钟，ss代表秒。 timestamp java.sql.Timestamp对象，该对象使用带有时间戳前缀的JDBC格式:TIMESTAMP yyyy-mm-dd hh:mm:ss.fffffffff。在Timestamp中，“yyyy-mm-dd”表示日期，hh:mm:ss表示时间，fffffff表示分数秒(最多9位)。 NIL NULL的等效替换。 NULL 与Java中的null相同。 UNDEFINED 任何数据类型的一个特殊的文本有效值，指示没有为给定的数据项指定任何值(甚至不为空)。 NULL和UNDEFINED之间的区别 与Java一样，在OQL中，NULL是指示“无值”的可分配实体(对象)。 在OQL中，UNDEFINED是一种类型。没有等效的Java。在OQL搜索结果中，可以在两种情况下返回未定义的值: 搜索不存在的键或值的结果 作为访问空值属性的属性的结果。 搜索不等式会返回结果中未定义的值。 请注意，如果您访问一个显式值为NULL的属性，那么它不是未定义的。 例如，如果查询访问address.city而address是NULL，那么结果是UNDEFINED。如果查询访问address，那么结果不是UNDEFINED，它是NULL。 与java.util.Date比较值 您可以将时态文字值DATE、TIME和TIMESTAMP与java.util.Date值进行比较。查询语言中的日期中,没有java.util.Date字面值。 类型转换 Geode查询处理器在某些情况下执行隐式类型转换和提升，以计算包含不同类型的表达式。查询处理器执行二进制数字提升、方法调用转换和时间类型转换。 二进制数字提升 查询处理器对以下运算符的操作数进行二进制数值提升: 比较运算符 , 和 >= 等算子 = 和 <> 二进制数字提升将数字表达式中的操作数扩展到任何操作数所使用的最宽表示形式。在每个表达式中，查询处理器按照规定的顺序应用以下规则，直到进行转换: 如果任一操作数类型为double，则另一个操作数转换为double 如果任一操作数类型为float，则将另一个操作数转换为float 如果任一操作数类型为long，则将另一个操作数转换为long 两个操作数都转换为类型int char 方法调用转换 查询语言中的方法调用转换遵循与Java方法调用转换相同的规则，只是查询语言使用运行时类型而不是编译时类型，并且处理空参数的方式与Java中不同。使用运行时类型的一个方面是，具有null值的参数没有类型信息，因此可以与任何类型参数匹配。当使用null参数时，如果查询处理器不能根据非空参数确定要调用的适当方法，它将抛出一个AmbiguousNameException 时间类型转换 查询语言支持的时态类型包括Java类型 java.util.Date、java.sql.Date、java.sqlTime和java.sqlTimestamp，它们都被同等对待，可以在索引中进行比较和使用。与其他类型相比，这些类型都被视为纳秒量。 枚举转换 枚举不会自动转换。要在查询中使用枚举值，必须使用枚举对象的toString方法或使用查询绑定参数。有关更多信息，请参见Enum对象。 Float.NaN 和 Double.NaN Float.NaN and Double.NaN不作为原语计算;相反，它们的比较方式与JDK方法Float.compareTo和Double.compareTo相同。参见Double.NaN and Float.NaN Comparisons 以获取更多信息。 查询语言限制和不受支持的特性 在高级别上，Geode不支持以下查询特性: 不支持针对跨多个区域的连接的索引 静态方法调用。例如，以下查询无效: SELECT DISTINCT * FROM /QueryRegion0 WHERE aDay = Day.Wednesday 不能使用不可比较的Set/List类型(集合类型)在字段上创建索引。OQL索引实现希望字段具有可比性。要解决这个问题，可以创建实现Comparable的自定义集合类型。 ORDER BY只支持DISTINCT的查询。 此外，分区区域查询还有一些特定的限制。参见分区区域查询限制。 高级查询 本节包括高级查询主题，如使用查询索引、使用查询绑定参数、查询分区区域和查询调试。 性能考虑 本主题讨论了改进查询性能的考虑事项。 查询时监视内存不足 查询监视功能防止在执行查询或创建索引时发生内存不足异常。 长时间运行查询的超时 为长时间运行的查询配置一个超时值，以便它们不完成，当查询运行的时间超过配置的值时，Geode将抛出异常。 使用查询绑定参数 在Geode查询中使用查询绑定参数类似于在SQL中使用预置语句，在SQL中可以在查询执行期间设置参数。这允许您一次构建查询，并在运行时通过传递查询条件多次执行查询。 查询分区的区域 Geode允许您使用分区区域跨分布式节点管理和存储大量数据。分区区域的基本存储单元是bucket，它驻留在Geode节点上，包含映射到单个hashcode的所有条目。在典型的分区区域查询中，系统将查询分布到所有节点上的所有bucket中，然后合并结果集并发回查询结果。 查询调试 通过在要调试的查询字符串之前添加 关键字，可以在查询级别调试特定的查询。 性能考虑 本主题讨论了改进查询性能的考虑事项。 一些一般的性能提示: 通过创建索引尽可能地提高查询性能。有关使用索引的一些场景，请参见关于使用索引的提示和指南 。 为经常使用的查询使用绑定参数。当使用绑定参数时，查询只编译一次。这提高了查询在重新运行时的后续性能。有关详细信息，请参见使用查询绑定参数。 在查询分区区域时，使用FunctionService执行查询。该函数允许您针对特定的节点，这将通过避免查询分布大大提高性能。有关更多信息，请参见在单个节点上查询分区区域。 查询按键或字段值分区的数据时，请使用键索引。参见对按键或字段值分区的数据进行优化查询。 查询结果集的大小取决于查询的限制性和整个数据集的大小。分区区域可以容纳比其他类型的区域多得多的数据，因此分区区域查询的结果集更大的可能性更大。如果结果集非常大，这可能导致接收结果的成员耗尽内存。 查询时监视内存不足 查询监视功能防止在执行查询或创建索引时发生内存不足异常。 当您在cache.xml文件中给资源管理器元素设置一个critical-heap-percentage属性时，您将启用此功能。或者使用cache.getResourceManager().setCriticalHeapPercentage(float heapPercentage)的API。当启用此功能并由于运行查询或创建索引而导致堆内存使用超过阈值时，资源管理器将抛出异常并取消正在运行的查询或索引创建。 可以通过设置系统属性gemfire.cache.DISABLE_QUERY_MONITOR_FOR_LOW_MEMORY为true来显式禁用此功能。 当系统内存不足时，由cache.xml 文件中定义的临界堆百分比阈值决定。或者在getResourceManager API中，查询将抛出一个QueryExecutionLowMemoryException。正在创建的任何索引都将抛出一个InvalidIndexException，其中的消息指示原因。 分区区域查询和内存不足 分区区域查询可能是内存不足异常的原因。如果启用了查询监视，那么如果正在执行的服务器内存不足，分区区域查询将删除或忽略其他服务器正在收集的结果。 查询监视不处理在分区区域查询收集结果时展开低级收集的场景。例如，如果添加了一行，然后导致Java级别的集合或数组展开，那么可能会遇到内存不足异常。这种情况很少见，只有当集合大小本身在满足低内存条件之前扩展，然后扩展到剩余可用内存之外时，才有可能出现这种情况。作为一种变通方法，在遇到这种情况时，您可以通过降低critical-heap-percentage来优化系统。 长时间运行查询的超时 Geode可以在查询运行时间超过配置的时间时监视并抛出异常。通过设置critical-heap-percentage属性来启用该特性，该属性检测JVM的堆内存太少。 默认查询超时为5个小时。通过指定系统变量gemfire.cache.MAX_QUERY_EXECUTION_TIME来设置不同的时间量(以毫秒为单位)。值-1显式禁用超时。 当启用时，运行时间超过配置超时的查询将被取消，因此它不会完成，Geode将抛出一个QueryExecutionTimeoutException。 使用查询绑定参数 在Geode查询中使用查询绑定参数类似于在SQL中使用预置语句，在SQL中可以在查询执行期间设置参数。这允许用户一次构建查询，并在运行时通过传递查询条件多次执行查询。 查询对象是线程安全的。 在客户机到服务器的查询中，现在支持使用查询绑定参数。 查询参数由一个美元符号$标识，后面是一个数字，表示传递给execute方法的参数数组中的参数位置。计数从1开始，因此$1引用第一个绑定属性，$2引用第二个属性，依此类推。 查询接口提供了一个重载的执行方法，该方法接受对象数组中的参数。有关详细信息，请参见Query.execute JavaDocs。 对象数组的第0个元素用于第一个查询参数，等等。如果参数计数或参数类型与查询规范不匹配，则execute方法将抛出异常。具体地说，如果传入错误数量的参数，方法调用将抛出一个QueryParameterCountInvalidException。如果参数对象类型与预期的不兼容，方法调用将抛出一个TypeMismatchException。 在下面的示例中，第一个参数integer 2绑定到对象数组中的第一个元素。第二个参数active绑定到第二个元素。 示例代码 // specify the query string String queryString = \"SELECT DISTINCT * FROM /exampleRegion p WHERE p.id = $1 and p.status = $2\"; QueryService queryService = cache.getQueryService(); Query query = queryService.newQuery(queryString); // set query bind parameters Object[] params = new Object[2]; params[0] = 2; params[1] = \"active\"; // Execute the query locally. It returns the results set. SelectResults results = (SelectResults) query.execute(params); // use the results of the query; this example only looks at the size int size = results.size(); 在路径表达式中使用查询绑定参数 此外，查询引擎支持使用查询绑定参数代替区域路径。在查询的FROM子句中指定绑定参数时，参数的引用值必须绑定到集合。 例如，通过将集合作为查询参数值传入，可以对任何集合使用以下查询。在这个查询中，您可以以$1传入一个Region对象，但不能传入区域的字符串名称。 SELECT DISTINCT * FROM $1 p WHERE p.status = $2 查询分区的区域 Geode允许您使用分区区域跨分布式节点管理和存储大量数据。分区区域的基本存储单元是bucket，它驻留在Geode节点上，包含映射到单个hashcode的所有条目。在典型的分区区域查询中，系统将查询分布到所有节点上的所有bucket中，然后合并结果集并发回查询结果。 下面的列表总结了Geode支持的分区查询功能: 能够针对查询中的特定节点. 如果您知道特定的bucket包含您想要查询的数据，那么您可以使用一个函数来确保您的查询只运行保存数据的特定节点。这可以大大提高查询效率。只有在使用函数和在单个区域上执行函数时，才能查询特定节点上的数据。为此，您需要使用Query.execute(RegionFunctionContext context)。参见Java API和查询单个节点上的分区区域 以获得更多详细信息。 使用关键索引优化分区区域查询性能的能力. 通过创建键索引，然后使用Query.execute(RegionFunctionContext context)执行查询，可以提高按键或字段值分区的数据的查询性能,使用键或字段值作为筛选器.参见Java API和优化按键或字段值分区的数据查询以获得更多详细信息。 能够在分区区域之间以及分区区域和复制区域之间执行等连接查询. 通过函数服务支持分区区域之间以及分区区域和复制区域之间的连接查询。为了对分区区域或分区区域和复制区域执行等连接操作，必须对分区区域进行colocated，并且需要使用Query.execute(RegionFunctionContext context)。参见Java API和在分区区域上执行等价连接查询以获得更多详细信息。 对分区区域使用ORDER BY 在单个节点上查询分区区域 优化按键或字段值分区的数据查询 对分区区域执行等连接查询 分区区域查询限制 对分区区域使用ORDER BY 要在分区区域上使用ORDER BY子句执行查询，ORDER BY子句中指定的字段必须是投影列表的一部分。 当将ORDER BY子句与分区区域查询一起使用时，将在每个区域主机、本地查询协调器和所有远程成员上分别执行查询。查询协调器收集所有结果。累积结果集是通过对收集到的结果应用ORDER BY来构建的。如果查询中也使用了LIMIT子句，那么在将每个节点的结果返回给协调器之前，ORDER BY和LIMIT将应用于每个节点。然后将子句应用于累积结果集以获得最终结果集，并将结果集返回给调用应用程序。 例子: // This query works because p.status is part of projection list select distinct p.ID, p.status from /region p where p.ID > 5 order by p.status // This query works providing status is part of the value indicated by * select distinct * from /region where ID > 5 order by status 在单个节点上查询分区区域 要将查询指向特定的分区区域节点，可以在函数中执行查询。使用以下步骤: 实现一个使用RegionFunctionContext执行查询的函数. /** * This function executes a query using its RegionFunctionContext * which provides a filter on data which should be queried. * */ public class MyFunction extends FunctionAdapter { private final String id; @Override public void execute(FunctionContext context) { Cache cache = CacheFactory.getAnyInstance(); QueryService queryService = cache.getQueryService(); String qstr = (String) context.getArguments(); try { Query query = queryService.newQuery(qstr); //If function is executed on region, context is RegionFunctionContext RegionFunctionContext rContext = (RegionFunctionContext)context; SelectResults results = (SelectResults) query.execute(rContext) //Send the results to function caller node. context.getResultSender().sendResult((ArrayList) (results).asList()); context.getResultSender().lastResult(null); } catch (Exception e) { throw new FunctionException(e); } } @Override public boolean hasResult() { return true; } @Override public boolean isHA() { return false; } public MyFunction(String id) { super(); this.id = id; } @Override public String getId() { return this.id; } } 决定要查询的数据。基于此决策，您可以使用PartitionResolver配置要在分区区域中查询的bucket的组织。 例如，假设您已经定义了PortfolioKey类: public class PortfolioKey implements DataSerializable { private int id; private long startValidTime; private long endValidTime private long writtenTime public int getId() { return this.id; } ... } 您可以使用MyPartitionResolver将ID相同的所有键存储在同一个bucket中。这个PartitionResolver必须在分区区域创建时使用xml或api进行声明式配置。有关更多信息，请参见配置分区区域。 /** This resolver returns the value of the ID field in the key. With this resolver, * all Portfolios using the same ID are colocated in the same bucket. */ public class MyPartitionResolver implements PartitionResolver, Declarable { public Serializable getRoutingObject(EntryOperation operation) { return operation.getKey().getId(); } 通过在函数调用中设置筛选器，在客户端或任何其他节点上执行函数。 /** * Execute MyFunction for query on specified keys. * */ public class TestFunctionQuery { public static void main(String[] args) { ResultCollector rcollector = null; PortfolioKey portfolioKey1 = ...; //Filter data based on portfolioKey1 which is the key used in //region.put(portfolioKey1, portfolio1); Set filter = Collections.singleton(portfolioKey1); //Query to get all positions for portfolio ID = 1 String qStr = \"SELECT positions FROM /myPartitionRegion WHERE ID = 1\"; try { Function func = new MyFunction(\"testFunction\"); Region region = CacheFactory.getAnyInstance().getRegion(\"myPartitionRegion\"); //Function will be routed to one node containing the bucket //for ID=1 and query will execute on that bucket. rcollector = FunctionService .onRegion(region) .setArguments(qStr) .withFilter(filter) .execute(func); Object result = rcollector.getResult(); //Results from one or multiple nodes. ArrayList resultList = (ArrayList)result; List queryResults = new ArrayList(); if (resultList.size()!=0) { for (Object obj: resultList) { if (obj != null) { queryResults.addAll((ArrayList)obj); } } } printResults(queryResults); } catch (FunctionException ex) { getLogger().info(ex); } } } 优化按键或字段值分区的数据查询 您可以通过创建键索引，然后使用FunctionService和用作筛选器的键或字段值来执行查询，从而提高按键或字段值分区的数据的查询性能。 下面是一个如何优化将在按区域键值分区的数据上运行的查询的示例。在下面的示例中，数据由“orderId”字段分区。 在orderId字段上创建一个键索引。有关详细信息，请参见创建键索引。 使用orderId作为函数上下文的筛选器提供的函数服务执行查询。例如: /** * Execute MyFunction for query on data partitioned by orderId key * */ public class TestFunctionQuery { public static void main(String[] args) { Set filter = new HashSet(); ResultCollector rcollector = null; //Filter data based on orderId = '12345' filter.add(12345); //Query to get all orders that match ID 12345 and amount > 1000 String qStr = \"SELECT * FROM /Orders WHERE orderId = '12345' AND amount > 1000\"; try { Function func = new MyFunction(\"testFunction\"); Region region = CacheFactory.getAnyInstance().getRegion(\"myPartitionRegion\"); //Function will be routed to one node containing the bucket //for ID=1 and query will execute on that bucket. rcollector = FunctionService .onRegion(region) .setArguments(qStr) .withFilter(filter) .execute(func); Object result = rcollector.getResult(); //Results from one or multiple nodes. ArrayList resultList = (ArrayList)result; List queryResults = new ArrayList(); if (resultList.size()!=0) { for (Object obj: resultList) { if (obj != null) { queryResults.addAll((ArrayList)obj); } } } printResults(queryResults); } catch (FunctionException ex) { getLogger().info(ex); } } } 对分区区域执行等连接查询 为了在分区区域或分区区域和复制区域上执行等连接操作，您需要使用 query.execute方法，并为其提供一个函数执行上下文。您需要使用Geode的FunctionService executor，因为在不提供函数执行上下文的情况下，分区区域还不直接支持连接操作。 有关分区区域查询限制的更多信息，请参见分区区域查询限制。 例如，假设您的等连接查询如下: SELECT DISTINCT * FROM /QueryRegion1 r1, /QueryRegion2 r2 WHERE r1.ID = r2.ID 在这个示例中，QueryRegion2与QueryRegion1一起使用，并且两个区域具有相同类型的数据对象。 服务器端: Function prQueryFunction1 = new QueryFunction(); FunctionService.registerFunction(prQueryFunction1); public class QueryFunction extends FunctionAdapter { @Override public void execute(FunctionContext context) { Cache cache = CacheFactory.getAnyInstance(); QueryService queryService = cache.getQueryService(); ArrayList allQueryResults = new ArrayList(); ArrayList arguments = (ArrayList)(context.getArguments()); String qstr = (String)arguments.get(0); try { Query query = queryService.newQuery(qstr); SelectResults result = (SelectResults)query .execute((RegionFunctionContext)context); ArrayList arrayResult = (ArrayList)result.asList(); context.getResultSender().sendResult((ArrayList)result.asList()); context.getResultSender().lastResult(null); } catch (Exception e) { // handle exception } } } 在服务器端，Query.execute()对分区区域的本地数据进行操作。 客户端: Function function = new QueryFunction(); String queryString = \"SELECT DISTINCT * FROM /QueryRegion1 r1, /QueryRegion2 r2 WHERE r1.ID = r2.ID\"; ArrayList argList = new ArrayList(); argList.add(queryString); Object result = FunctionService.onRegion(CacheFactory.getAnyInstance() .getRegion(\"QueryRegion1\" )) .setArguments(argList).execute(function).getResult(); ArrayList resultList = (ArrayList)result; resultList.trimToSize(); List queryResults = null; if (resultList.size() != 0) { queryResults = new ArrayList(); for (Object obj : resultList) { if (obj != null ) { queryResults.addAll((ArrayList)obj); } } } 在客户端，注意您可以在调用FunctionService.onRegion()时指定桶过滤器。在这种情况下，查询引擎依赖FunctionService将查询定向到特定的节点。 关于使用Query.execute 和 RegionFunctionContext的附加说明 您还可以通过在客户端代码(FunctionService.onRegion(..). setarguments())中指定参数来向查询函数传递多个参数(除了查询本身)。然后您可以使用context.getArguments在服务器端处理函数内部的参数。请注意，指定参数的顺序并不重要，只要将服务器上的参数处理顺序与客户机中指定的顺序匹配即可。 分区区域查询限制 分区区域中的查询限制 分区区域查询的功能与非分区区域查询相同，但本节列出的限制除外。不遵循这些指导原则的分区区域查询将生成UnsupportedOperationException异常。 仅通过函数服务支持分区区域之间以及分区区域和复制区域之间的连接查询。客户端服务器API不支持分区的连接查询。 只有在分区区域和分区区域以及复制区域位于同一位置时，才能对它们运行连接查询。仅在共定位的分区区域以及查询的where子句中指示了共定位列的位置上支持等连接查询。对于多列分区，WHERE规范中还应该有AND子句。参见来自不同分区区域的Colocate数据了解关于分区区域共存位置的更多信息。 只要在所有分区区域节点上也存在本地复制区域，就允许在分区区域之间以及分区区域与本地复制区域之间进行等连接查询。要对一个分区区域和另一个分区(分区或不分区)执行连接查询，需要使用“查询”。方法，并为其提供一个函数执行上下文。参见在分区区域上执行等价连接查询作为示例。 查询必须只是一个SELECT表达式(与任意OQL表达式相反)，前面必须有零个或多个IMPORT语句。例如，这个查询是不允许的，因为它不仅仅是一个SELECT表达式: // NOT VALID for partitioned regions (SELECT DISTINCT *FROM /prRgn WHERE attribute > 10).size 允许以下查询： // VALID for partitioned regions SELECT DISTINCT *FROM /prRgn WHERE attribute > 10 只要只引用一个分区区域，SELECT表达式本身可以是任意复杂的，包括嵌套的SELECT表达式。 分区区域引用只能在第一个FROM子句迭代器中。如果子句迭代器不引用任何区域，则允许使用额外的FROM子句迭代器(例如深入到分区区域中的值)。 第一个FROM子句迭代器必须只包含对分区区域的一个引用(该引用可以是参数，例如$1)。 第一个FROM子句迭代器不能包含子查询，但是在附加的FROM子句迭代器中允许子查询。 您可以在分区区域查询上使用ORDER BY，但是ORDER BY子句中指定的字段必须是投影列表的一部分。 如果查询的分区区域(或桶)已被销毁，则在销毁桶的新主服务器上重新尝试查询(如果存在的话)。在多次尝试之后，如果无法查询所有bucket(在查询启动时计算)，则抛出QueryException。 查询调试 通过在要调试的查询字符串之前添加关键字，可以在查询级别调试特定的查询。 下面是一个例子: select * from /exampleRegion 你也可以这样写: select * from /exampleRegion 在执行查询时，Geode将在$GEMFIRE_DIR/system中记录一条消息。使用以下信息进行日志记录: [info 2011/08/29 11:24:35.472 PDT CqServer tid=0x1] Query Executed in 9.619656 ms; rowCount = 99; indexesUsed(0) \"select * from /exampleRegion\" 如果希望对所有查询启用调试，可以在启动时通过在命令行上设置系统属性来启用查询执行日志: gfsh>start server --name=server_name -–J=-Dgemfire.Query.VERBOSE=true 或者你可以通过编程来设置属性: System.setProperty(\"gemfire.Query.VERBOSE\",\"true\"); 例如，假设您有一个EmployeeRegion，它将Employee对象作为值包含，并且对象中具有ID和status等公共字段。 Employee.java Class Employee { public int ID; public String status; - - - - - - - - - - - - } 此外，您还为该区域创建了以下索引: 设置好gemfire.Query.VERBOSE为\"true\"之后。在EmployeeRegion或其索引上运行查询后，可以在日志中看到以下调试消息: 如果查询执行中没有使用索引，您将看到这样的调试消息: [info 2011/08/29 11:24:35.472 PDT CqServer tid=0x1] Query Executed in 9.619656 ms; rowCount = 99; indexesUsed(0) \"select * from /test k where ID > 0 and status='active'\" 在查询执行中使用单一索引时，您可能会看到这样的调试消息: [info 2011/08/29 11:24:35.472 PDT CqServer tid=0x1] Query Executed in 101.43499 ms; rowCount = 199; indexesUsed(1):sampleIndex-1(Results: 199) \"select count * from /test k where ID > 0\" 当查询使用多个索引时，您可能会看到这样的调试消息: [info 2011/08/29 11:24:35.472 PDT CqServer tid=0x1] Query Executed in 79.43847 ms; rowCount = 199; indexesUsed(2):sampleIndex-2(Results: 100),sampleIndex-1(Results: 199) \"select * from /test k where ID > 0 OR status='active'\" 在上述日志消息中，提供了以下信息: “rowCount” 表示查询的结果集大小。 “indexesUsed(\\n) ” 显示使用了n个索引来查找查询的结果。 分别报告每个索引名及其相应的结果。 可以使用最后附加的原始查询字符串标识日志。 使用索引 Geode查询引擎支持索引。索引可以为查询执行提供显著的性能收益。 查询在不借助索引的情况下运行，遍历集合中的每个对象。如果一个索引与部分或全部查询规范匹配，则查询仅在索引集上迭代，并且可以减少查询处理时间。 使用索引的提示和指南 使用索引优化查询需要一个仔细规划、测试和调优的周期。定义不良的索引会降低而不是改进查询的性能。本节给出查询服务中索引使用的指导原则。 创建、列出和删除索引 Geode ' QueryService ' API提供了创建、列出和删除索引的方法。您还可以使用gfsh命令行界面创建、列出和删除索引，并使用cache.xml创建索引。 创建键索引 在使用键或字段值对数据进行分区时，创建键索引是提高查询性能的好方法。您可以使用QueryService的createKeyIndex方法创建键索引，也可以在cache.xml中定义索引。创建键索引使查询服务知道区域中的值与区域中的键之间的关系。 创建哈希索引 不赞成使用哈希索引 Geode支持为执行基于平等的查询而创建哈希索引。 在映射字段上创建索引(“映射索引”) 为了帮助快速查找Map(或HashMap)类型字段中的多个值，可以在该字段中的特定(或所有)键上创建索引(有时称为“Map索引”)。 一次创建多个索引 为了在创建索引时提高速度和效率，可以定义多个索引，然后一次创建所有索引。 维护索引(同步或异步)和索引存储 索引与它们引用的区域数据自动保持同步。区域属性IndexMaintenanceSynchronous指定在修改区域时同步更新区域索引，还是在后台线程中异步更新区域索引。 使用查询索引提示 您可以使用hint关键字来允许Geode的查询引擎选择特定的索引。 在单个区域查询上使用索引 具有一个比较操作的查询可以使用键或范围索引进行改进，这取决于所比较的属性是否也是主键。 使用带有等连接查询的索引 相等连接查询是通过WHERE子句中的相等条件连接两个区域的查询。 使用带有溢出区域的索引 在查询溢出区域时可以使用索引;然而，也有一些警告。 在使用多个区域的等连接查询上使用索引 要跨多个区域查询，请标识所有等连接条件。然后，为相等连接条件创建尽可能少的索引，同时仍然连接所有区域。 索引样本 本主题提供用于创建查询索引的代码示例。 使用索引的提示和指南 使用索引优化查询需要一个仔细规划、测试和调优的周期。定义不良的索引会降低而不是改进查询的性能。本节给出查询服务中索引使用的指导原则。 在创建索引时，请记住以下几点: 索引会产生维护成本，因为当索引数据发生变化时，必须更新索引。与完全不使用索引相比，需要多次更新且不经常使用的索引可能需要更多的系统资源。 索引消耗内存。 索引对溢出区域的支持有限。有关详细信息，请参见使用带有溢出区域的索引。 如果要在同一区域上创建多个索引，请首先定义索引，然后一次创建所有索引，以避免在该区域上进行多次迭代。有关详细信息，请参见一次创建多个索引。 编写使用索引的查询的技巧 与在关系数据库上运行的查询处理器一样，查询的编写方式会极大地影响执行性能。此外，是否使用索引取决于如何声明每个查询。以下是优化Geode查询时需要考虑的一些问题: 通常，如果查询和索引的FROM子句完全匹配，那么索引将提高查询性能。 查询评估引擎没有复杂的基于成本的优化器。它有一个简单的优化器，可以根据索引大小和正在计算的操作符选择最佳索引(一个)或多个索引。 对于AND运算符，如果使用索引的条件和选择性更强的条件出现在查询中的其他条件之前，您可能会得到更好的结果。 索引不用于包含NOT的表达式中，因此在查询的WHERE子句中，qty >= 10可以在qty上应用索引以提高效率。然而，NOT(qty 不能应用相同的索引。 只要可能，提供提示，允许查询引擎选择特定的索引。参见使用查询索引提示 创建、列出和删除索引 Geode的QueryService API提供了创建、列出和删除索引的方法。您还可以使用gfsh命令行界面创建、列出和删除索引，并使用cache.xml创建索引。 创建索引 可以使用gfsh命令行接口或cache.xml以编程方式创建索引。 要创建索引，请使用以下QueryService方法之一: createIndex. 创建索引的默认类型，范围索引。如果要编写执行除相等比较之外的任何比较操作的查询，请使用这种类型的索引。 createKeyIndex. 创建键索引。有关更多信息，请参见创建键索引。 弃用. createHashIndex. 创建哈希索引。有关更多信息，请参见创建哈希索引。 createDefinedIndexes. 创建先前使用defineIndex定义的多个索引。有关更多信息，请参见一次创建多个索引。 以下部分提供了创建索引的示例: 使用 gfsh: gfsh> create index --name=myIndex --expression=status --region=/exampleRegion gfsh> create index --name=myKeyIndex --type=key --expression=id --region=/exampleRegion 更多示例请参见[Index Commands]https://geode.apache.org/docs/guide/17/tools_modules/gfsh/quick_ref_commands_by_area.html#topic_688C66526B4649AFA51C0F72F34FA45E)。 使用 Java API: QueryService qs = cache.getQueryService(); qs.createIndex(\"myIndex\", \"status\", \"/exampleRegion\"); qs.createKeyIndex(\"myKeyIndex\", \"id\", \"/exampleRegion\"); 使用 cache.xml: ... 注意: 如果没有指定缓存中的索引类型。类型默认为“range”。 列出索引 要从缓存或区域检索索引列表，请使用QueryService.getIndexes方法或gfsh命令行接口。 使用 gfsh: gfsh> list indexes gfsh> list indexes --with-stats 使用 Java API: QueryService qs = cache.getQueryService(); qs.getIndexes(); //returns a collection of all indexes in the cache qs.getIndexes(exampleRegion); //returns a collection of all indexes in exampleRegion qs.getIndexes(exampleRegion, myKeyIndex); //returns the index named myKeyIndex from the exampleRegion 删除 Indexes 要从缓存或区域删除索引或所有索引，请使用QueryService.removeIndexes。方法或gfsh命令行接口。 使用 gfsh: gfsh> destroy index gfsh> destroy index --name=myIndex gfsh> destroy index --region=/exampleRegion 使用 Java API: QueryService qs = cache.getQueryService(); qs.removeIndexes(); //removes all indexes from the cache qs.removeIndexes(myKeyIndex); //removes the index named myKeyIndex qs.removeIndexes(exampleRegion); //removes all indexes from the exampleRegion 创建键索引 在使用键或字段值对数据进行分区时，创建键索引是提高查询性能的好方法。您可以使用QueryService的createKeyIndex方法创建键索引，也可以在cache.xml中定义索引。创建键索引使查询服务知道区域中的值与区域中的键之间的关系。 主键索引的FROM子句必须只是一个区域路径。索引表达式是一种表达式，当应用于条目值时，将生成键。例如，如果一个区域的值是portfolio，键是portfolio区域的id字段，那么索引表达式就是id。 然后可以使用FunctionService(使用分区键作为传递给函数的筛选器，并作为查询等式条件的一部分)对索引数据执行查询。参见根据键或字段值对数据分区进行优化查询以获得更多详细信息。 键索引有两个问题需要注意: 键索引没有排序。没有排序，您只能进行等式测试。其他比较是不可能的。要获得主键上的已排序索引，请在用作主键的属性上创建函数索引。 查询服务不能自动知道区域值和键之间的关系。为此，必须创建键索引。 注意: 在cache.xml中使用显式type=range的键索引将导致异常。键索引将不会在'range’查询中使用。 创建键索引的示例 使用 Java API: QueryService qs = cache.getQueryService(); qs.createKeyIndex(\"myKeyIndex\", \"id\", \"/exampleRegion\"); 使用 gfsh: gfsh> create index --name=myKeyIndex --expression=id --region=/exampleRegion 使用 cache.xml: ... 注意: 如果在使用缓存定义索引时没有指定索引的类型。类型默认为“range”。 创建哈希索引 不赞成使用哈希索引. Geode支持创建哈希索引，以执行基于平等的查询。 哈希索引的性能 使用哈希索引时，put操作的性能和恢复时间会比使用范围索引差。由于哈希索引的实现和根据请求重新计算密钥的成本，查询速度预计会变慢。哈希索引可以提高索引的内存使用。因此，必须权衡哈希索引空间节省的代价和它带来的性能损失。如果不考虑内存使用，建议使用范围索引。 考虑索引包含字符串字段时的内存使用情况。字符串的副本包含在索引中。使用哈希索引，索引表达式被规范化，并作为指向驻留在该区域中的对象的指针存储在索引中，从而使用更少的内存。测试可以减少高达30%的内存占用，但是节省的内存取决于所使用的键和数据。 性能考虑 限制 在创建哈希索引时，必须考虑以下限制: 只能对等于和不等于查询使用哈希索引。 由于同步的添加方法，哈希索引的维护将比其他索引慢。 不能异步维护哈希索引。如果您试图在一个将异步设置为维护模式的区域上创建散列索引，则会引发异常。 不能对具有多个迭代器或嵌套集合的查询使用哈希索引。 使用哈希索引会大大降低put操作性能和恢复时间。如果内存不是问题，那么使用范围索引而不是哈希索引。 创建哈希索引的示例 不赞成使用哈希索引。 使用 Java API: QueryService qs = cache.getQueryService(); qs.createHashIndex(\"myHashIndex\", \"mktValue\", \"/exampleRegion\"); 使用 gfsh: gfsh> create index --name=myHashIndex --expression=mktValue --region=/exampleRegion --type=hash 使用 cache.xml: ... 在映射字段上创建索引（映射索引） 为了帮助快速查找Map(或HashMap)类型字段中的多个值，可以在该字段中的特定(或所有)键上创建索引(有时称为“Map索引”)。 例如，您可以创建一个映射索引来支持以下查询: SELECT * FROM /users u WHERE u.name['first'] = 'John' OR u.name['last'] = 'Smith' map索引扩展了在单个键上创建的常规范围索引，方法是为其他指定键或使用*时为所有键维护索引。映射索引的底层结构可以看作是所有这些索引的包装器。 下面的Java代码示例提供了如何创建映射索引的示例: QueryService qs = cache.getQueryService(); //This will create indexes for for keys 'PVTL' and 'VMW' qs.createIndex(\"indexName\", \"p.positions['PVTL', 'VMW']\", \"/portfolio p\"); QueryService qs = cache.getQueryService(); //This will create indexes for all keys qs.createIndex(\"indexName\", \"p.positions[*]\", \"/portfolio p\"); 在gfsh中，对等物为: gfsh>create index --name=\"IndexName\" --expression=\"p.positions['PVTL', 'VMW']\" --region=\"/portfolio p\" gfsh>create index --name=\"IndexName\" --expression=\"p.positions[*]\" --region=\"/portfolio p\" 为了创建或查询映射索引，必须使用方括号符号列出希望索引或查询的映射字段键。例如:[*], ['keyX1','keyX2’]。注意，使用p.pos.get('keyX1')将不会创建或查询映射索引。 注意: 您仍然可以查询Map或HashMap字段，而无需查询映射索引。例如，您总是可以在任意Map或HashMap字段中的单个键上创建常规的范围查询。但是，请注意，后续查询查找将仅限于单个键。 一次创建多个索引 为了在创建索引时提高速度和效率，可以定义多个索引，然后一次创建所有索引。 在创建多个索引之前定义它们，通过只迭代一次区域条目来加速索引创建过程。 通过在定义时指定 --type 参数，您可以一次定义不同类型的多个索引。 要定义多个索引，可以使用gfsh或Java API: gfsh 例子: gfsh> define index --name=myIndex1 --expression=exp1 --region=/exampleRegion gfsh> define index --name=myIndex2 --expression=\"c.exp2\" --region=\"/exampleRegion e, e.collection1 c\" gfsh> create defined indexes 如果索引创建失败，您可能会在gfsh中收到类似如下的错误消息: gfsh>create defined indexes Exception : org.apache.geode.cache.query.RegionNotFoundException , Message : Region ' /r3' not found: from /r3Occurred on following members 1. india(s1:17866):27809 Java API 例子: Cache cache = new CacheFactory().create(); QueryService queryService = cache.getQueryService(); queryService.defineIndex(\"name1\", \"indexExpr1\", \"regionPath1\"); queryService.defineIndex(\"name2\", \"indexExpr2\", \"regionPath2\"); queryService.defineKeyIndex(\"name4\", \"indexExpr4\", \"regionPath2\"); List indexes = queryService.createDefinedIndexes(); 如果一个或多个索引填充失败，Geode将收集异常并继续填充其余的索引。收集到的Exceptions存储在索引名和异常的映射中，可以通过MultiIndexCreationException访问这些索引名和异常。 索引定义存储在本地的gfsh客户机上。如果您想创建一组新索引，或者如果一个或多个索引创建失败，您可能希望使用 clear defined indexes命令清除存储的定义。定义的索引可以使用Java API清除: queryService.clearDefinedIndexes(); 或者 gfsh: gfsh> clear defined indexes 维护索引（同步或异步）和索引存储 索引与它们引用的区域数据自动保持同步。区域属性indexmaintenancesyn指定在修改区域时同步更新区域索引，还是在后台线程中异步更新区域索引。 索引维护行为 异步索引维护将多个更新批处理到同一个区域键。默认模式是同步的，因为这提供了与区域数据的最大一致性。 参见 RegionFactory.setIndexMaintenanceSynchronous. 这个声明性索引创建将维护模式设置为异步: 内部索引结构和存储 索引存储为基于索引表达式的紧凑或非紧凑数据结构(即使索引键类型相同)。例如，考虑以下乘客对象: Passenger { String name, Date travelDate, int age, Flight flt, } Flight { int flightId, String origin, String dest, } 乘客姓名字段上的索引在缓存中的内存空间要求与航班起源字段不同，尽管它们都是字符串字段类型。Geode为索引存储选择的内部数据结构将取决于对象中的字段级别。在本例中，name是顶级字段，name上的索引可以存储为紧凑索引。由于origin是一个二级字段，任何使用origin作为索引表达式的索引都将作为非紧凑索引存储。 紧凑索引 紧凑索引具有简单的数据结构，以最小化其占用空间，代价是在索引维护方面做额外的工作。此索引不支持存储投影属性。 目前只选择紧凑索引，只支持在区域路径上创建索引。此外，还必须满足以下条件: 索引维护是同步的。 索引表达式是一个路径表达式。 FROM子句只有一个迭代器。这意味着每个区域条目的索引中只有一个值，并且它直接位于区域值上(键、条目不支持)。 非紧凑索引 每当无法使用紧凑型索引时使用。 使用查询索引提示 您可以使用hint关键字来允许Geode的查询引擎选择特定的索引。 在查询中暗示索引的情况下，查询引擎过滤掉暗示索引(如果可能的话)，然后从结果值中迭代和过滤。 例子: SELECT * FROM /Portfolios p WHERE p.ID > 10 AND p.owner = 'XYZ' 如果将多个索引作为提示添加，那么查询引擎将尝试使用尽可能多的索引，同时为提示索引提供一个首选项。 例子: SELECT * FROM /Portfolios p WHERE p.ID > 10 AND p.owner = 'XYZ' AND p.value 在单个区域查询上使用索引 具有一个比较操作的查询可以使用键或范围索引进行改进，这取决于所比较的属性是否也是主键。 如果pkid是/exampleRegion区域的键，那么在pkid上创建键索引是最好的选择，因为键索引没有维护开销。如果pkid不是关键字，那么关于pkid的范围索引应该可以提高性能。 SELECT DISTINCT * FROM /exampleRegion portfolio WHERE portfolio.pkid = '123' 通过多个比较操作，可以在一个或多个属性上创建范围索引。试试以下: 在希望结果集大小最小的条件下创建单个索引。使用此索引检查性能。 保留第一个索引，在第二个条件下添加索引。添加第二个索引可能会降低性能。如果有，删除它，只保留第一个索引。查询中两个比较的顺序也会影响性能。一般来说，在OQL查询中，就像在SQL查询中一样，您应该对比较进行排序，以便前面的比较能够提供最少的结果来运行后续比较。 对于这个查询，您可以尝试对名称、年龄或两者都使用范围索引: SELECT DISTINCT * FROM /exampleRegion portfolio WHERE portfolio.status = 'active' and portfolio.ID > 45 对于嵌套级别的查询，可以通过深入索引和查询中的较低级别来获得更好的性能。 这个查询深入到一个层次: SELECT DISTINCT * FROM /exampleRegion portfolio, portfolio.positions.values positions where positions.secId = 'AOL' and positions.MktValue > 1 使用带有等连接查询的索引 相等连接查询是通过WHERE子句中的相等条件连接两个区域的查询。 使用索引与一个等连接查询: 为等连接条件的每一侧创建索引。查询引擎可以通过遍历左右两边索引的键来快速评估查询的等连接条件，以获得相等的匹配。 注意: 等连接查询需要常规索引。键索引不应用于等连接查询。 对于这个查询: SELECT DISTINCT inv.name, ord.orderID, ord.status FROM /investors inv, /orders ord WHERE inv.investorID = ord.investorID 创建两个索引: | FROM clause | Indexed expression | | -------------- | ------------------ | | /investors inv | inv.investorID | | /orders ord | ord.investorID | 如果在具有等连接条件的查询中有额外的单区域查询，则仅当您能够为查询中的每个区域创建至少一个这样的索引时，才为单区域条件创建额外的索引。查询中区域子集上的任何索引都会降低性能。 对于该示例查询: SELECT DISTINCT * FROM /investors inv, /securities sc, inv.heldSecurities inv_hs WHERE sc.status = \"active\" AND inv.name = \"xyz\" AND inv.age > 75 AND inv_hs.secName = sc.secName 为等连接条件创建索引: | FROM clause | Indexed expression | | ----------------------------------------- | ------------------ | | /investors inv, inv.heldSecurities inv_hs | inv_hs.secName | | /securities sc | sc.secName | 然后，如果您创建更多索引，请在 sc.status和 inv.age 或者 inv.name上创建一个，或两者兼而有之。 使用带有溢出区域的索引 在查询溢出区域时可以使用索引;然而，也有一些警告。 以下是查询溢出区域的注意事项: 您必须对区域使用同步索引维护。这是默认的维护设置。 index FROM子句必须只指定一个迭代器，并且它必须引用键或条目值。索引不能引用区域的entrySet。 索引数据本身没有存储在(溢出到)磁盘上。 例子: 下面的示例索引创建调用不适用于溢出区域。 // This index will not work on an overflow region because there are two iterators in the FROM clause. createIndex(\"secIdIndex\", \"b.secId\",\"/portfolios pf, pf.positions.values b\"); // This index will not work on an overflow region because the FROM clause specifies the entrySet createIndex(\"indx1\", \"entries.value.getID\", \"/exampleRegion.entrySet() entries\"); 下面的示例索引适用于溢出区域。 createIndex(\"pkidIndex\", \"p.pkid\", \"/Portfolios p\"); createIndex(\"indx1\", \"ks.toString\", \"/portfolio.keySet() ks\"); gfsh中的相同示例: gfsh> create index -name=\"pkidIndex\" --expression=\"p.pkid\" --region=\"/Portfolios p\" gfsh> create index -name=\"indx1\" --expression=\"ks.toString\" --region=\"/portfolio.keySet() ks\" 在使用多个区域的等连接查询上使用索引 要跨多个区域查询，请标识所有等连接条件。然后，为相等连接条件创建尽可能少的索引，同时仍然连接所有区域。 如果存在冗余连接两个区域的等连接条件(例如，为了更好地过滤数据)，那么为这些连接创建冗余索引将对性能产生负面影响。为每个区域对仅在一个等连接条件下创建索引。 在这个示例查询中: SELECT DISTINCT * FROM /investors inv, /securities sc, /orders or, inv.ordersPlaced inv_op, or.securities or_sec WHERE inv_op.orderID = or.orderID AND or_sec.secID = sc.secID 连接这些区域需要所有条件，因此需要创建四个索引，每个等连接条件创建两个索引: FROM clause Indexed expression /investors inv, inv.ordersPlaced inv_op inv_op.orderID /orders or, or.securities or_sec or.orderID FROM clause Indexed expression /orders or, or.securities or_sec or_sec.secID /securities sc sc.secID 在示例中添加另一个条件: SELECT DISTINCT * FROM /investors inv, /securities sc, /orders or, inv.ordersPlaced inv_op, or.securities or_sec, sc.investors sc_invs WHERE inv_op.orderID = or.orderID AND or_sec.secID = sc.secID AND inv.investorID = sc_invs.investorID 您仍然希望总共使用四个索引，因为这是连接所有区域所需的全部。你需要从以下三个索引对中选择性能最好的两个: FROM clause Indexed expression /investors inv, inv.ordersPlaced inv_op inv_op.orderID /orders or, or.securities or_sec or.orderID FROM clause Indexed expression /orders or, or.securities or_sec or_sec.secID /securities sc, sc.investors sc_invs sc.secID FROM clause Indexed expression /investors inv, inv.ordersPlaced inv_op inv.investorID /securities sc, sc.investors sc_invs sc_invs.investorID 最有效的性能集是将数据压缩到尽可能小的结果集。检查您的数据并使用这三个索引对进行试验，看看哪一个提供了最好的性能。 索引例子 本主题提供用于创建查询索引的代码示例。 // Key index samples. The field doesn't have to be present. createKeyIndex(\"pkidIndex\",\"p.pkid1\",\"/root/exampleRegion p\"); createKeyIndex(\"Index4\",\"ID\",\"/portfolios\"); // Simple index createIndex(\"pkidIndex\",\"p.pkid\",\"/root/exampleRegion p\"); createIndex(\"i\", \"p.status\", \"/exampleRegion p\") createIndex(\"i\", \"p.ID\", \"/exampleRegion p\") createIndex(\"i\", \"p.position1.secId\", \"/exampleRegion p\" // On Set type createIndex(\"setIndex\",\"s\",\"/root/exampleRegion p, p.sp s\"); // Positions is a map createIndex(\"secIdIndex\",\"b.secId\",\"/portfolios pf, pf.positions.values b\"); //... createIndex(\"i\", \"pf.collectionHolderMap[(pf.Id).toString()].arr[pf.ID]\", \"/exampleRegion pf\") createIndex(\"i\", \"pf.ID\", \"/exampleRegion pf\", \"pf.positions.values pos\") createIndex(\"i\", \"pos.secId\", \"/exampleRegion pf\", \"pf.positions.values pos\") createIndex(\"i\", \"e.value.getID()\", \"/exampleRegion.entrySet e\") createIndex(\"i\", \"e.value.ID\", \"/exampleRegion.entrySet e\") //... createIndex(\"i\", \"entries.value.getID\", \"/exampleRegion.entrySet() entries\") createIndex(\"i\", \"ks.toString\", \"/exampleRegion.getKeys() ks\") createIndex(\"i\", \"key.status\", \"/exampleRegion.keys key\") createIndex(\"i\", \"secIds.length\", \"/exampleRegion p, p.secIds secIds\") createIndex(\"i\", \"secId\", \"/portfolios.asList[1].positions.values\") createIndex(\"i\", \"secId\", \"/portfolios['1'].positions.valules\") //Index on Map types createIndex(\"i\", \"p.positions['key1']\", \"/exampleRegion p\") createIndex(\"i\", \"p.positions['key1','key2',key3',key7']\", \"/exampleRegion p\") createIndex(\"i\", \"p.positions[*]\", \"/exampleRegion p\") 下面是一些关于索引的示例查询。 SELECT * FROM (SELECT * FROM /R2 m) r2, (SELECT * FROM /exampleRegion e WHERE e.pkid IN r2.sp) p SELECT * FROM (SELECT * FROM /R2 m WHERE m.ID IN SET (1, 5, 10)) r2, (SELECT * FROM /exampleRegion e WHERE e.pkid IN r2.sp) p //examples using position index in the collection SELECT * FROM /exampleRegion p WHERE p.names[0] = 'aaa' SELECT * FROM /exampleRegion p WHERE p.position3[1].portfolioId = 2 SELECT DISTINCT positions.values.toArray[0], positions.values.toArray[0], status FROM /exampleRegion 连续查询 连续查询持续返回与您设置的查询匹配的事件。 连续查询是如何工作的 客户端通过使用sql类型的查询过滤订阅服务器端事件。服务器发送修改查询结果的所有事件。CQ事件交付使用客户机/服务器订阅框架。 实现连续查询 在客户机中使用连续查询来接收对服务器上运行的查询的连续更新。 管理连续查询 本主题讨论CQ管理选项、CQ状态和检索初始结果集。 连续查询是如何工作的 客户端通过使用sql类型的查询过滤订阅服务器端事件。服务器发送修改查询结果的所有事件。CQ事件交付使用客户机/服务器订阅框架。 使用CQ，客户机向服务器端发送一个查询以供执行，并接收满足条件的事件。例如，在存储股票市场交易订单的区域中，您可以通过运行一个CQ查询来检索某个价格上的所有订单，查询如下: SELECT * FROM /tradeOrder t WHERE t.price > 100.00 当CQ运行时，服务器向客户机发送影响查询结果的所有新事件。在客户端，由您编写的侦听器接收和处理传入的事件。对于这个关于/tradeOrder的查询示例，您可以编写一个侦听器来将事件推送到显示高价订单的GUI。CQ事件交付使用客户机/服务器订阅框架。 连续查询的逻辑架构 客户端可以执行任意数量的CQ，每个CQ分配任意数量的侦听器。 数据流与CQs CQs不更新客户端区域。这与其他服务器到客户机的消息传递(如为满足兴趣注册而发送的更新和从客户机的“池”获取请求的响应)形成了对比。CQs作为CQ侦听器的通知工具，可以按照应用程序所需的任何方式对其进行编程。 当对服务器区域运行CQ时，更新服务器缓存的线程根据CQ查询计算每个条目事件。如果旧的或新的条目值满足查询，线程将在客户机的队列中放置一个CqEvent。CqEvent包含来自原始缓存事件的信息以及特定于CQ执行的信息。一旦客户端接收到CqEvent，它就被传递给为CQ定义的所有CqListener的onEvent方法。 下面是服务器缓存中更新条目的典型CQ数据流: 条目事件从服务器或其对等方到达服务器的缓存，从远程站点分发，或从客户端更新。 对于每个事件，服务器的CQ执行器框架将检查其与正在运行的CQ是否匹配。 如果旧条目值或新条目值满足CQ查询，则将CQ事件发送到客户端CQ的侦听器。CQ的每个侦听器都获得事件。 如下图所示: 条目X的新价格和旧价格都满足CQ查询，因此事件被发送，指示对查询结果的更新。 条目Y的旧价格满足查询，因此它是查询结果的一部分。条目Y的无效使得它不满足查询。因此，事件被发送，表明它在查询结果中被销毁。 新创建的条目Z的价格不满足查询，因此没有发送事件。 CQ 事件 CQ事件不会更改您的客户机缓存。它们仅作为事件服务提供。这允许您拥有任意cq集合，而无需在区域中存储大量数据。如果您需要从CQ事件中持久化信息，请编写侦听器来存储对应用程序最有意义的信息。 CqEvent对象包含以下信息: 输入键和新值。 在服务器中触发缓存事件的基本操作。这是GemFire中用于缓存事件的标准Operation类实例。 CqQuery 对象与此CQ事件关联。 Throwable对象，只有在为缓存事件运行CqQuery时发生错误时才返回。这是非空的只有CqListener onError调用。 与此CQ事件关联的查询操作。此操作描述缓存事件对查询结果的影响。可能的值是: CREATE, 对应于标准的数据库INSERT操作 UPDATE DESTROY, 对应于标准的数据库DELETE删除操作 区域操作不转换为特定的查询操作，而查询操作也不特定地描述区域事件。相反，查询操作描述区域事件如何影响查询结果。 基于新旧条目值的查询操作 新值不满足查询 新值满足查询 旧值不满足查询 没有事件 CREATE 查询操作 旧值确实满足查询 DESTROY 查询操作 UPDATE 查询操作 您可以使用查询操作来决定如何处理侦听器中的CqEvent。例如，在屏幕上显示查询结果的CqListener可能会停止显示条目，开始显示条目，或者根据查询操作更新条目显示。 CQs的区域类型限制 您只能在复制或分区区域上创建CQs。如果您试图在未复制或未分区的区域上创建CQ，您将收到以下错误消息: The region specified in CQ creation is neither replicated nor partitioned; only replicated or partitioned regions are allowed in CQ creation. 此外，您不能在具有local-destroy驱逐设置的复制区域上创建CQ，因为该驱逐设置更改了该区域的数据策略。如果您试图在这类区域上创建CQ，您将收到以下错误消息: CQ is not supported for replicated region: with eviction action: LOCAL_DESTROY 还请参见配置分布式、复制和预加载区域，了解在复制区域上设置本地销毁回收的潜在问题。 实现连续查询 在客户机中使用连续查询来接收对服务器上运行的查询的连续更新。 CQs仅由客户端在其服务器上运行。 在开始之前，您应该熟悉查询并配置客户机/服务器系统。 将用于CQs的客户端池配置为 subscription-enabled ，设置为true。 要使CQ和兴趣订阅事件尽可能紧密地结合在一起，请为所有事件使用单个池。不同的池可能使用不同的服务器，这可能导致事件交付时间的更大差异。 编写OQL查询来从服务器检索所需的数据。 查询必须满足这些CQ要求，除了标准GemFire查询规范: FROM子句必须只包含一个区域规范，其中包含可选的iterator变量。 查询必须是一个SELECT表达式，前面必须有零个或多个IMPORT语句。这意味着查询不能是/tradeOrder.name或\"(SELECT * from /tradeOrder).size\".之类的语句。 CQ查询不能使用: 跨区域连接 向下钻取嵌套集合 DISTINCT 预测 绑定参数 必须在分区或复制区域上创建CQ查询。参见CQs的区域类型限制。 CQ查询的基本语法是: SELECT * FROM /fullRegionPath [iterator] [WHERE clause] 此示例查询可用于获取价格超过$100的所有交易订单: SELECT * FROM /tradeOrder t WHERE t.price > 100.00 编写您的CQ侦听器来处理来自服务器的CQ事件。实现org.apache.geode.cache.query.CqListener在您需要的每个事件处理程序中。除了您的主要CQ侦听器之外，您可能还有用于所有CQ的侦听器来跟踪统计信息或其他一般信息。 注意: 如果选择从CqListener更新缓存，请特别小心。如果侦听器更新在其自己的CQ中查询的区域，并且该区域有一个名为Pool的名称，则更新将被转发到服务器。如果服务器上的更新满足相同的CQ，那么它可能返回到执行更新的侦听器，这可能会将应用程序放入无限循环中。如果侦听器被编程来更新彼此的区域，那么可以使用多个区域和多个cq来执行相同的场景。 这个示例概述了一个CqListener，它可能用于使用来自服务器的当前数据更新显示屏幕。侦听器从CqEvent获取queryOperation和输入键和值，然后根据queryOperation的类型更新屏幕。 // CqListener class public class TradeEventListener implements CqListener { public void onEvent(CqEvent cqEvent) { // org.apache.geode.cache Operation associated with the query op Operation queryOperation = cqEvent.getQueryOperation(); // key and new value from the event Object key = cqEvent.getKey(); TradeOrder tradeOrder = (TradeOrder)cqEvent.getNewValue(); if (queryOperation.isUpdate()) { // update data on the screen for the trade order . . . } else if (queryOperation.isCreate()) { // add the trade order to the screen . . . } else if (queryOperation.isDestroy()) { // remove the trade order from the screen . . . } } public void onError(CqEvent cqEvent) { // handle the error } // From CacheCallback public void close() { // close the output screen for the trades . . . } } 安装侦听器并运行查询时，侦听器将处理所有CQ结果。 如果您需要CQs来检测它们是否连接到托管其订阅队列的任何服务器，请实现CqStatusListener而不是CqListener。CqStatusListener扩展了当前的CqListener，允许客户端检测CQ何时连接和/或从服务器断开。onCqConnected()方法将在连接CQ时调用，在断开连接后重新连接CQ时调用。当CQ不再连接到任何服务器时，将调用oncqdisconnect()方法。 以步骤3中的例子为例，我们可以实现一个CqStatusListener: public class TradeEventListener implements CqStatusListener { public void onEvent(CqEvent cqEvent) { // org.apache.geode.cache Operation associated with the query op Operation queryOperation = cqEvent.getQueryOperation(); // key and new value from the event Object key = cqEvent.getKey(); TradeOrder tradeOrder = (TradeOrder)cqEvent.getNewValue(); if (queryOperation.isUpdate()) { // update data on the screen for the trade order . . . } else if (queryOperation.isCreate()) { // add the trade order to the screen . . . } else if (queryOperation.isDestroy()) { // remove the trade order from the screen . . . } } public void onError(CqEvent cqEvent) { // handle the error } // From CacheCallback public void close() { // close the output screen for the trades . . . } public void onCqConnected() { //Display connected symbol } public void onCqDisconnected() { //Display disconnected symbol } } 当您安装CqStatusListener时，您的侦听器将能够检测到它与所查询的服务器的连接状态。 编程你的客户端运行CQ: 创建一个CqAttributesFactory并使用它来设置您的CqListener和CqStatusListener。 将属性工厂、CQ查询及其惟一名称传递给QueryService，以创建一个新的CqQuery。 通过调用CqQuery对象上的一个执行方法来启动正在运行的查询。可以使用或不使用初始结果集执行。 当你完成了CQ，关闭它。 连续查询实现 // Get cache and queryService - refs to local cache and QueryService // Create client /tradeOrder region configured to talk to the server // Create CqAttribute using CqAttributeFactory CqAttributesFactory cqf = new CqAttributesFactory(); // Create a listener and add it to the CQ attributes callback defined below CqListener tradeEventListener = new TradeEventListener(); cqf.addCqListener(tradeEventListener); CqAttributes cqa = cqf.create(); // Name of the CQ and its query String cqName = \"priceTracker\"; String queryStr = \"SELECT * FROM /tradeOrder t where t.price > 100.00\"; // Create the CqQuery CqQuery priceTracker = queryService.newCq(cqName, queryStr, cqa); try { // Execute CQ, getting the optional initial result set // Without the initial result set, the call is priceTracker.execute(); SelectResults sResults = priceTracker.executeWithInitialResults(); for (Object o : sResults) { Struct s = (Struct) o; TradeOrder to = (TradeOrder) s.get(\"value\"); System.out.println(\"Intial result includes: \" + to); } } catch (Exception ex) { ex.printStackTrace(); } // Now the CQ is running on the server, sending CqEvents to the listener . . . // End of life for the CQ - clear up resources by closing priceTracker.close(); 使用连续查询，您可以选择性地实现: 通过为高可用性配置服务器来实现高可用性CQs。 通过为持久消息配置客户端，并指示哪些CQs在创建时是持久的，从而实现持久CQs。 管理连续查询 本主题讨论CQ管理选项、CQ状态和检索初始结果集。 使用RegionService实例中的CQs 如果您正在从RegionService实例中运行持久的客户端队列，那么应该停止并启动整个客户端的脱机事件存储。服务器为整个客户机进程管理一个队列，因此您需要通过ClientCache实例请求整个缓存的持久CQ事件消息传递的停止和开始。如果关闭RegionService实例，事件处理将停止，但服务器将继续发送事件，这些事件将丢失。 停止: clientCache.close(true); 按以下顺序重新启动: 创建 ClientCache 实例。 创建所有 RegionService实例。初始化CQ监听器。 调用 ClientCache实例的readyForEvents 方法。 一个CQ的状态 CQ有三种可能的状态，它们在服务器上进行维护。您可以通过CqQuery.getState从客户端检查它们。 查询状态 这是什么意思? 什么时候CQ达到这个状态? 注释 STOPPED CQ已经就绪，可以运行了，但是没有运行。 当CQ第一次被创建和停止运行状态后。 停止的CQ使用系统资源。停止CQ只会停止从服务器到客户机的CQ事件消息传递。所有服务器端CQ处理都将继续，但是新的CQ事件不会被放置到服务器的客户机队列中。停止CQ不会改变客户端上的任何东西(当然，客户端会停止接收停止的CQ的事件)。 RUNNING CQ针对服务器区域事件运行，客户端侦听器等待CQ事件。 当CQ从停止状态执行时。 这是事件发送到客户机的唯一状态。 CLOSED CQ不能用于任何其他活动。您无法重新运行已关闭的CQ。 当客户端关闭CQ时，当缓存或连接条件使其无法维护或运行时。 关闭的CQ不使用系统资源。 CQ管理选项 从客户端管理CQs。所有调用都只针对调用客户机的CQs执行。 任务 对于单个CQ使用 … 用于CQs组的使用 … 创建一个 CQ QueryService.newCq N/A 执行一个 CQ CqQuery.execute and CqQuery.executeWithInitialResults QueryService.executeCqs 停止一个 CQ CqQuery.stop QueryService.stopCqs 关闭一个 CQ CqQuery.close QueryService.closeCqs 存取一个 CQ CqEvent.getCq and QueryService.getCq QueryService.getCq 修改 CQ Listeners CqQuery.getCqAttributesMutator N/A 访问CQ运行时统计数据 CqQuery.getStatistics QueryService.getCqStatistics 在服务器上注册所有持久CQs N/A QueryService.getAllDurableCqsFromServer 使用gfsh管理CQs和持久客户端 使用gfsh命令行实用工具，您可以执行以下操作: 关闭持久客户端和持久客户端CQs。参见关闭。 列出给定持久客户端ID的所有持久CQs。参见List。 显示给定持久客户端ID的订阅事件队列大小。 参见 show subscription-queue-size. 检索CQ的初始结果集 在执行CQ时，可以选择检索初始结果集。为此，使用executeWithInitialResults方法执行CQ。返回的初始SelectResults与您在特别运行查询时通过在服务器缓存上执行调用QueryService.newQuery.execute得到的相同，但包含key。这个示例从初始结果集中检索键和值: SelectResults cqResults = cq.executeWithInitialResults(); for (Object o : cqResults.asList()) { Struct s = (Struct) o; // Struct with Key, value pair Portfolio p = (Portfolio) s.get(\"value\"); // get value from the Struct String id = (String) s.get(\"key\"); // get key from the Struct } 如果您正在管理来自CQ结果的数据集，您可以通过遍历结果集并在事件到达时从侦听器更新结果集来初始化该数据集。例如，您可以使用初始结果填充新屏幕，然后从CQ侦听器更新屏幕。 如果使用ExecuteWithInitialResults方法执行CQ，返回的结果可能已经包含了与事件相关的更改。当CQ注册过程中该区域发生更新时，就会出现这种情况。CQ不会阻塞任何区域操作，因为它会影响区域操作的性能。将应用程序设计为在区域操作和CQ注册之间同步，以避免交付重复的事件。 事务 本节描述Geode事务。Geode为执行事务性工作的客户机应用程序提供了一个API。Geode使用熟悉的begin、commit和rollback方法实现乐观事务，这些方法实现与关系数据库事务方法相同的操作。 遵守ACID语义 本节解释Geode的乐观事务实现提供ACID语义的方式。 代码示例 基于应用程序的事务和嵌入在函数中的事务为建模提供了示例。 设计注意事项 超越基础的设计引入了其他考虑因素。本节标识并讨论事务如何与系统的其他方面交互。 遵守ACID语义 本节介绍Geode事务。Geode为执行事务性工作的客户机应用程序提供了一个API。Geode实现了乐观的事务，选择了它们提供的更高的事务性能，而不是传统关系数据库中缓慢的锁定方法。 乐观事务语义与传统关系数据库的原子-一致性-隔离-持久性(ACID)语义并不相同。 原子性 原子性是“全有或全无”的行为:只有当事务包含的所有操作都成功完成时，事务才会成功完成。如果在事务期间出现问题(可能是由于具有重叠更改的其他事务造成的)，在问题解决之前，事务无法成功完成。 乐观事务通过使用预约系统提供原子性并实现速度，而不是使用传统的两阶段锁行关系数据库技术。这种保留阻止了其他交叉事务的完成，允许提交检查冲突，并在对数据进行更改之前以全有或全无的方式保留资源。在本地和远程完成所有更改之后，将释放预订。在预订系统中，交叉事务将被简单地丢弃。避免了获取锁的序列化。 一致性 一致性要求在事务中编写的数据必须遵守为受影响区域建立的键和值约束。请注意，事务的有效性是应用程序的责任。 隔离 隔离是事务状态对系统组件可见的级别。Geode事务具有可重复的读隔离。一旦为给定的键读取提交的值，它总是返回相同的值。如果事务中的写操作删除了已读取的键的值，则后续的读操作将返回事务引用。 默认配置在流程线程级别隔离事务。当一个事务正在进行时，它的更改只在运行该事务的线程中可见。同一进程中的其他线程和其他进程中的线程在提交操作开始之前不能看到更改。在开始提交之后，更改在缓存中是可见的，但是访问更改数据的其他线程可能会看到事务的部分结果，从而导致脏读。有关如何更改默认行为，请参见更改脏读的处理。 持久性 关系数据库通过使用磁盘存储进行恢复和事务日志记录来提供持久性。Geode针对性能进行了优化，不支持事务的磁盘持久性。 参见允许事务在持久区域上工作了解如何允许以非持久方式在持久区域上操作的事务。 代码示例 应用程序可以直接运行事务或调用包含事务的函数。本节用代码片段演示了这两个用例，这些代码片段演示了正确的事务编程方法。 预期的用例操作事务中的两个区域。出于性能目的，Geode事务实现要求对分区区域的区域项进行colocated。参见自定义分区和配置数据了解如何配置区域条目的详细信息。 应用程序中的事务 应用程序/客户机使用CacheTransactionManagerAPI。这段最基本的代码片段显示了事务的结构，以它的begin开始事务，commit结束事务，以及处理这些方法可能抛出的异常。 CacheTransactionManager txManager = cache.getCacheTransactionManager(); try { txManager.begin(); // ... do transactional, region operations txManager.commit(); } catch (CommitConflictException conflict) { // ... do necessary work for a transaction that failed on commit } finally { // All other exceptions will be handled by the caller. // Examples of some exceptions: the data is not colocated, a rebalance // interfered with the transaction, or the server is gone. // Any exception thrown by a method other than commit() needs // to do a rollback to avoid leaking the transaction state. if(mgr.exists()) { mgr.rollback(); } } 下一个应用程序/客户端代码片段示例中将显示事务的更多细节。在这个典型的事务中，put操作必须是原子的，涉及两个区域。 在此交易中，记录客户的购买行为。现金区域包含每个客户可用来进行交易的现金余额。交易区域记录每个客户用于交易的余额。 如果事务提交时发生冲突，则抛出异常，本示例将再次尝试。 // inputs needed for this transaction; shown as variables for simplicity final String customer = \"Customer1\"; final Integer purchase = 1000; // region set up shown to promote understanding Cache cache = new CacheFactory().create(); Pool pool = PoolManager.createFactory() .addLocator(\"localhost\", LOCATOR_PORT) .create(\"pool-name\"); Region cash = cache.createClientRegionFactory(ClientRegionShortcut.PROXY) .setPoolName(pool.getName()) .create(\"cash\"); Region trades = cache.createClientRegionFactory(ClientRegionShortcut.PROXY) .setPoolName(pool.getName()) .create(\"trades\"); // transaction code CacheTransactionManager txmgr = cache.getCacheTransactionManager(); boolean retryTransaction = false; do { try { txmgr.begin(); // Subtract out the cost of the trade for this customer's balance Integer cashBalance = cash.get(customer); Integer newBalance = (cashBalance != null ? cashBalance : 0) - purchase; cash.put(customer, newBalance); // Add in the cost of the trade for this customer Integer tradeBalance = trades.get(customer); newBalance = (tradeBalance != null ? tradeBalance : 0) + purchase; trades.put(customer, newBalance); txmgr.commit(); retryTransaction = false; } catch (CommitConflictException conflict) { // entry value changed causing a conflict for this customer, so try again retryTransaction = true; } finally { // All other exceptions will be handled by the caller. // Any exception thrown by a method other than commit() needs // to do a rollback to avoid leaking the transaction state. if(mgr.exists()) { mgr.rollback(); } } } while (retryTransaction); 设计事务，使任何get操作都在事务中。这将导致这些条目成为事务状态的一部分，这样就可以检测到交叉的事务并发出提交conficts的信号。 函数内的事务 事务可以嵌入到函数中。应用程序调用该函数，该函数包含执行begin、区域操作和commit或rollback的事务。 这种函数的使用可以带来性能上的好处。性能优势来自于驻留在服务器上的函数和区域数据。当该函数调用区域操作时，那些对区域条目的操作将保留在服务器上，因此不存在对区域数据执行get或put操作的网络往返时间。 这个函数示例在表示库存中可用产品数量的单个区域上完成原子更新。在事务中这样做可以防止为同时下单的两个订单重复分配库存。 /** * Atomically reduce inventory quantity */ public class TransactionalFunction extends Function { /** * Returns true if the function had the requested quantity of * inventory and successfully completed the transaction to * record the reduced inventory that fulfills the order. */ @Override public void execute(FunctionContext context) { RegionFunctionContext rfc = (RegionFunctionContext) context; Region inventoryRegion = rfc.getDataSet(); CacheTransactionManager mgr = CacheFactory.getAnyInstance().getCacheTransactionManager(); // single argument will be a ProductId and a quantity ProductRequest request = (ProductRequest) rfc.getArguments(); ProductId productRequested = request.getProductId(); Integer qtyRequested = request.getQuantity(); Boolean success = false; do { Boolean commitConflict = false; try { mgr.begin(); Integer qtyAvailable = inventoryRegion.get(productRequested); Integer qtyRequested = request.getQuantity(); if (qtyAvail >= qtyRequested) { // enough inventory is available, so process request Integer remaining = qtyAvailable - qtyRequested; inventoryRegion.put(productRequested, remaining); success = true; } mgr.commit(); } catch (CommitConflictException conflict) { // retry transaction, as another request on this same key succeeded, // so this transaction attempt failed commitConflict = true; } finally { // All other exceptions will be handled by the caller; however, // any exception thrown by a method other than commit() needs // to do a rollback to avoid leaking the transaction state. if(mgr.exists()) { mgr.rollback(); } } } while (commitConflict); context.getResultSender().lastResult(success); } @Override public String getId() { return \"TxFunction\"; } /** * Returning true causes this function to execute on the server * that holds the primary bucket for the given key. It can save a * network hop from the secondary to the primary. */ @Override public Boolean optimizeForWrite() { return true; } } 本例中不讨论关于函数实现的应用程序端细节。应用程序设置函数上下文和参数。有关函数的详细信息，请参见[函数执行]一节(https://geode.apache.org/docs/guide/17/developing/function_exec/chapter_overview.html)。 函数实现需要捕获提交冲突异常，以便能够重试整个事务。只有当对同一产品的另一个请求与此产品相交，且该请求的事务首先提交时，才会出现异常。 定义optimizeForWrite方法是为了使系统在保存给定键的主桶的服务器上执行函数。它可以保存从辅助服务器到主服务器的网络跳转。 注意变量qtyAvailable是一个引用，因为Region.get操作返回服务器端代码中的引用。参见Region Operations Return References了解详细信息，以及在使用服务器代码时如何处理引用作为返回值的含义。 设计注意事项 包含更复杂特性的设计会引入更多的考虑。本节讨论事务如何与其他Geode特性交互。 按区域划分 区域操作返回引用 首先使用混合区域类型进行操作 允许事务在持久区域上工作 将事务与查询和索引混合在一起 将事务与驱逐混合在一起 将事务与过期混合 更改脏读的处理 按区域划分 为了提高性能，对多个分区区域进行操作的事务需要这些分区区域对其条目进行共定位。来自不同分区区域的Colocate数据描述了如何对条目进行Colocate。 区域操作返回引用 为了提高性能，服务器调用的区域操作返回对区域条目的引用。对该引用的任何赋值都会更改区域内的条目。这破坏了系统为处理程序(如缓存写入器和缓存加载器)维护一致性和回调链的能力。 使用在服务器上执行的事务中的引用更改条目具有相同的一致性问题，但更糟糕的是，更改不会被视为事务状态的一部分。 使用引用有两种方法:创建一个副本，或者配置系统返回副本而不是引用。让系统返回副本会带来性能损失。 这两种方法在安全条目修改中都有详细说明。 首先使用混合区域类型进行操作 当一个事务中有多个区域参与，且至少有一个分区和至少一个复制区域时，代码必须对分区区域执行第一次操作，以避免TransactionDataNotColocatedException。编写事务以在分区区域上执行其第一个操作，即使该操作是假的。 允许事务在持久区域上工作 Geode的原子事务实现禁止具有持久性的区域参与事务。在事务中对持久区域操作的调用会抛出一个UnsupportedOperationException异常和一条相关的消息 Operations on persist-backup regions are not allowed because this thread has an active transaction 希望在事务期间允许对持久区域进行操作的应用程序可以设置此系统属性: -Dgemfire.ALLOW_PERSISTENT_TRANSACTIONS=true 设置此系统属性可以消除异常。它不会改变事务提交时发生的磁盘写不强制原子性这一事实。提交期间的服务器崩溃可能在某些情况下成功，但不是所有的磁盘写操作都成功。 将事务与查询和索引混合在一起 查询和查询结果反映区域状态，而不是事务中发生的任何状态或更改。同样，索引的内容和更新不会与事务中的任何更改相交。因此，不要将事务与查询或索引区域混合。 将事务与驱逐混合在一起 LRU驱逐和事务可以很好地协作。从事务中操作的区域条目上的任何回收操作都将延迟到提交事务时才执行。此外，由于事务所接触的任何条目都已经重置了其LRU时钟，所以收回不太可能在提交之后立即选择这些条目作为受害者。 将事务与过期混合 事务禁用受事务影响的任何区域条目的过期。 更改脏读的处理 应用程序需要严格但较慢的隔离模型(比如不允许对过渡状态进行脏读)，应该设置一个属性并将读操作封装在事务中。使用属性配置这个严格的隔离模型: -Dgemfire.detectReadConflicts=true 此属性仅当读取一致的事务前或事务后状态时，才会导致读取操作成功。如果不一致，Geode抛出一个CommitConflictException异常。 函数执行 函数是驻留在服务器上的代码体，应用程序可以从客户机或另一台服务器调用它，而不需要发送函数代码本身。调用方可以指示依赖于数据的函数对特定数据集进行操作，也可以指示独立于数据的函数对特定服务器、成员或成员组进行操作。 函数执行服务为各种用例提供解决方案，包括: 应用程序需要对与key关联的数据执行操作。注册的服务器端函数可以检索数据、对其进行操作并将其返回，所有处理都在服务器本地执行。 应用程序需要在每个服务器上初始化一些组件，稍后执行的函数可能会使用这些组件。 第三方服务(如消息传递服务)需要初始化和启动。 任何任意聚合操作都需要对本地数据集进行迭代，可以通过对缓存服务器的一次调用更有效地进行迭代。 外部资源需要通过在服务器上执行函数来提供。 函数执行如何工作 在Apache Geode中执行一个函数 函数执行如何工作 函数在哪里执行 在Geode中，您可以在以下位置执行独立于数据的函数或依赖于数据的函数: Data-independent函数 在一个或多个特定的成员上—在对等集群中执行函数，通过使用FunctionService的方法onMember()和onMembers()指定希望在其中运行函数的成员。 在特定的服务器或服务器集上—如果作为客户机连接到集群，则可以在为特定连接池配置的服务器或服务器上执行该函数，或者在使用默认连接池连接到给定缓存的服务器或服务器上执行该函数。对于客户机/服务器架构上的独立于数据的函数，客户机调用FunctionService的方法onServer()或onServers()。(有关池连接的详细信息，请参见客户机/服务器连接如何工作。) 在成员组上或在每个成员组中的单个成员上—您可以将成员组织为逻辑成员组。(有关使用成员组的更多信息，请参见配置和运行集群。您可以对指定成员组或成员组中的所有成员调用独立于数据的函数，或者仅对每个指定成员组中的一个成员执行该函数。 对于依赖数据的函数 在一个区域上—如果您正在执行一个依赖于数据的函数，请指定一个区域和一组键(可选)，在这些键上运行函数。方法FunctionService.onRegion()指导依赖于数据的函数在特定区域上执行。 更多详细信息，请参阅FunctionService的Java API文档的org.apache.geode.cache.execute。 如何执行函数 在执行一个函数时，会发生以下情况: 对于启用安全的集群，在执行函数之前，要检查调用者是否被授权执行函数。授权所需的权限由函数的function .getrequiredpermissions()方法提供。有关此方法的讨论，请参见函数执行的授权。 如果授权成功，Geode将在需要运行该函数的所有成员上调用该函数。位置由FunctionService的on*方法调用、区域配置和任何筛选器确定。 如果函数有结果，则将结果返回给ResultCollector对象中的addResult方法调用。 发起成员使用`ResultCollector.getResult收集结果。 高度可用的函数 通常，函数执行错误返回给调用应用程序。您可以为返回结果的onRegion函数编写高可用性代码，因此如果一个函数没有成功执行，Geode将自动重试该函数。您必须对函数进行编码和配置，使其具有高可用性，调用该函数的应用程序必须使用结果收集器getResult方法调用该函数。 当发生故障(如执行错误或执行时成员崩溃)时，系统的响应方式为: 等待所有调用返回 设置指示重新执行的布尔值 调用结果收集器的clearResults方法 执行函数 对于客户端区域，系统根据org.apache.geode.cache.client.Pool retryAttempts重试执行。如果函数每次都不能运行，那么最后的异常将返回给getResult方法。 对于成员调用，系统将重试，直到成功或系统中没有数据保留以供函数操作为止。 函数执行场景 此图显示了从所有可用服务器上的客户机调用的独立于数据的函数的事件序列。 客户端联系定位器以获取集群中每个服务器的主机和端口标识符，并发出对每个服务器的调用。作为调用的发起者，客户机还接收调用结果。 此图显示了对对等集群中的成员执行的独立于数据的函数的事件序列。 您可以将onMembers()视为对onServers()的客户机-服务器调用的对等对等点。因为它是从集群中其他成员的对等点调用的，所以onMembers()函数调用可以访问详细的元数据，不需要定位器的服务。调用者调用函数本身(如果合适的话)以及集群中的其他成员，并收集所有函数执行的结果。 区域上的数据依赖函数 显示了在区域上运行的数据依赖函数。 图:一个区域的数据相关函数 onRegion()调用需要比定位器在其主机:端口标识符中提供的更详细的元数据。此图显示了当客户机缺少关于目标位置的详细元数据(如第一次调用时)或以前获得的元数据不再是最新数据时所遵循的路径。 当客户机第一次调用要在集群的特定区域上执行的函数时，客户机对目标位置的了解仅限于定位器提供的主机和端口信息。由于只有这些有限的信息，客户机将其执行请求发送到下一个根据池分配算法将要调用的服务器。因为它是集群中的参与者，所以该服务器可以访问详细的元数据，并可以将函数调用分派到适当的目标位置。当服务器将结果返回给客户机时，它设置一个标志，指示对不同服务器的请求是否提供了到目标的更直接的路径。为了提高效率，客户机请求元数据的副本。关于区域bucket布局的其他详细信息，客户机可以在后续调用中充当自己的分派器，并为自己标识多个目标，从而消除至少一个跃点。 在获得当前元数据之后，客户机可以在后续调用中充当自己的分派器，为自己标识多个目标并消除一个跳转，如[获得当前元数据后依赖于数据的函数]所示(https://geode.apache.org/docs/guide/17/developing/function_exec/how_function_execution_works.html#how_function_execution_works__fig_data_dependent_function_obtaining_current_metadata)。 图:获取当前元数据后的数据相关函数 (https://geode.apache.org/docs/guide/17/developing/function_exec/how_function_execution_works.html#how_function_execution_works__fig_data_dependent_function_region_keys)显示了相同的依赖于数据的函数，其中添加了一组要在其上运行的键的规范。 图:数据相关的函数，该函数依赖于带有键的区域 不保存任何key的服务器被排除在函数执行之外。 对等数据相关函数显示了一个对等数据相关调用。 图:点对点数据相关函数 调用者是集群的成员，而不是外部客户端，因此函数在调用者的集群中运行。请注意此图与前面的图(依赖于具有键的区域的数据函数之间的相似性)，其中显示了一个客户机-服务器模型，其中客户机具有关于集群中目标位置的最新元数据。 具有最新目标元数据的客户机-服务器系统演示了在客户机-服务器系统中调用高可用函数的一系列步骤，其中客户机具有关于目标位置的最新元数据。 图:具有最新目标元数据的客户机-服务器系统 在本例中，三个主键(X, Y, Z)及其辅助副本(X '， Y '， Z ')分布在三个服务器之间。因为optimizeForWrite是true，系统首先尝试调用主键所在的函数:Server 1和Server 2。但是，假设服务器2由于某种原因离线，因此针对键Y的调用失败。因为isHA被设置为true，所以调用在服务器1(第一次成功，很可能会再次成功)和服务器3(键Y '所在)上重试。这一次，函数调用成功返回。对高可用函数的调用重试，直到获得成功的结果或达到重试限制。 在Apache Geode中执行一个函数 在这个过程中，假设您已经定义了想要运行函数的成员和区域。 主要任务: 编写函数代码。 在希望执行该函数的所有服务器上注册该函数。注册函数最简单的方法是使用gfsh的deploy命令来部署包含函数代码的JAR文件。部署JAR会自动为您注册函数。有关详细信息，请参见通过部署JAR自动注册函数。或者，您可以编写XML或应用程序代码来注册函数。有关详细信息，请参见以编程方式注册函数。 编写应用程序代码以运行函数，如果函数返回结果，则处理结果。 如果函数返回结果，并且需要特殊的结果处理，那么编写一个定制的ResultsCollector实现并在函数执行中使用它。 编写函数代码 要编写函数代码，您需要在org.apache.geode.cache中实现function接口。执行的方案。 编写函数所需的方法。这些步骤不必按此顺序执行。 实现getId返回函数的唯一名称。您可以使用这个名称通过FunctionServiceAPI访问函数。 高可用性: 代码isHa返回true，向Geode表明在一个或多个成员失败后，它可以重新执行您的函数 编写函数代码以返回结果 代码hasResult返回true 如果你的函数返回要处理的结果，则返回true;如果你的函数不返回任何数据，则返回false。 如果函数将在一个区域上执行，则实现optimizeForWrite返回false(如果函数只从缓存中读取数据)，如果函数更新缓存则返回true。该方法只有在运行函数时，通过FunctionService onRegion调用获得Execution对象时才有效。optimizeForWrite'默认返回false。 如果函数运行时的授权级别不是默认的DATA:WRITE，则实现function.getrequiredpermissions()方法的覆盖。有关此方法的详细信息，请参见函数执行授权。 编写execute方法来执行函数的工作。 使execute线程安全以适应同步调用。 对于高可用性，代码execute可容纳对该函数的多个相同调用。使用RegionFunctionContext isPossibleDuplicate来确定调用是否是高可用性的重新执行。这个布尔值在执行失败时设置为true，否则为false。 注意: 可以在另一个成员执行函数失败后设置isPossibleDuplicate布尔值，因此它只表明执行可能是当前成员中的重复运行。 使用函数上下文获取关于执行和数据的信息: 上下文保存函数ID、用于将结果传递回发起者的ResultSender对象，以及函数起源的成员提供的函数参数。 提供给该函数的上下文是FunctionContext，如果通过FunctionService onRegion调用获得Execution对象，该上下文将自动扩展到RegionFunctionContext。 对于依赖于数据的函数，RegionFunctionContext保存Region对象、键筛选器的Set和指示对该函数的多个相同调用的布尔值，以实现高可用性。 对于分区区域，PartitionRegionHelper提供对该区域的其他信息和数据的访问。对于单个区域，使用getLocalDataForContext。对于被着色的区域，使用getLocalColocatedRegions。 注意: 当您使用PartitionRegionHelper.getLocalDataForContext时。如果您处理的是本地数据集而不是区域，则putIfAbsent可能不返回预期的结果。 要将错误条件或异常传播回函数的调用方，请从execute方法中抛出FunctionException。Geode将异常传递回调用方，就像它被抛出到调用方一样。有关[FunctionException]的更多信息，请参见[FunctionException]的Java API文档(https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/execute/FunctionException.html)。 示例函数代码: import java.io.Serializable; import java.util.HashSet; import java.util.Iterator; import java.util.Set; import org.apache.geode.cache.execute.Function; import org.apache.geode.cache.execute.FunctionContext; import org.apache.geode.cache.execute.FunctionException; import org.apache.geode.cache.execute.RegionFunctionContext; import org.apache.geode.cache.partition.PartitionRegionHelper; public class MultiGetFunction implements Function { public void execute(FunctionContext fc) { if(! (fc instanceof RegionFunctionContext)){ throw new FunctionException(\"This is a data aware function, and has to be called using FunctionService.onRegion.\"); } RegionFunctionContext context = (RegionFunctionContext)fc; Set keys = context.getFilter(); Set keysTillSecondLast = new HashSet(); int setSize = keys.size(); Iterator keysIterator = keys.iterator(); for(int i = 0; i 通过部署JAR自动注册函数 当您部署包含函数(换句话说，包含实现函数接口的类)的JAR文件时，该函数将通过FunctionService.registerFunction方法自动注册。 使用gfsh注册函数: 将类文件打包到JAR文件中。 启动gfsh提示符。如果需要，启动定位器并连接到要运行该函数的集群。 在gfsh提示符下，键入以下命令: gfsh>deploy --jar=group1_functions.jar 其中group1_functions.jar对应于步骤1中创建的JAR文件。 如果使用相同的函数部署了另一个JAR文件(使用相同的JAR文件名或另一个文件名)，则将注册该函数的新实现，覆盖旧的实现。如果一个JAR文件被取消部署，那么在部署时自动注册的任何函数都将被取消注册。由于多次部署具有相同名称的JAR文件会导致JAR被取消部署和重新部署，因此每次发生这种情况时，JAR中的函数都将被取消注册和重新注册。如果从多个不同名称的JAR文件中注册了具有相同ID的函数，那么如果其中一个JAR文件被重新部署或取消部署，那么该函数将被取消注册。 有关部署JAR文件的详细信息，请参见将应用程序JAR部署到Apache Geode成员。 以编程方式注册函数 本节适用于使用Execution.execute(String functionId)签名调用的函数。当调用此方法时，调用应用程序将函数ID发送到将要运行Function.execute的所有成员。接收成员使用ID在本地FunctionService中查找函数。为了进行查找，所有接收成员必须事先在函数服务中注册了函数。 另一种方法是“执行”签名。当调用此方法时，调用应用程序序列化Execution.execute(Function function)的实例并将其发送到运行Function.execute的所有成员。接收成员反序列化Function实例，创建它的新本地实例，并从中运行execute。此选项不适用于服务器上的非java客户端函数调用。 Java服务器必须注册由非Java客户机调用的函数。您可能希望在其他情况下使用注册，以避免成员之间发送Function实例的开销。 注册您的函数使用以下方法之一: XML: ... com.bigFatCompany.tradeService.cache.func.TradeCalc Java: myFunction myFun = new myFunction(); FunctionService.registerFunction(myFun); 注意: 注册后修改函数实例对注册的函数没有影响。如果要执行新函数，必须使用不同的标识符注册它。 运行函数 这假设您已经遵循了编写和注册函数的步骤。 在需要显式执行函数并处理结果的每个成员中，可以使用gfsh命令行运行函数，也可以编写应用程序来运行函数。 使用gfsh运行函数 启动gfsh提示符。 如果需要，启动定位器并连接到要运行该函数的集群。 在gfsh提示符下，键入以下命令: gfsh> execute function --id=function_id 其中function_id等于分配给函数的唯一ID。您可以使用Function.getId方法获得此ID。 有关函数的更多gfsh命令，请参见函数执行命令。 通过API调用运行函数 使用一个FunctionService on*方法创建一个Execute对象。on*方法、onRegion、onMembers等定义函数运行的最高级别。对于经过colocated分区的区域，使用onRegion并指定任何一个经过colocated分区。使用onRegion运行的函数称为数据依赖函数，其他函数称为数据独立函数。 根据需要使用Execution对象进行额外的函数配置。您可以: 提供一个键Set to withFilters来缩小onRegion execution对象的执行范围。您可以通过RegionFunctionContext.getFilter检索Function execute方法中的键集。 为setArguments提供函数参数。您可以通过FunctionContext.getArguments在Function execute方法中检索这些内容。 定义一个自定义的ResultCollector 调用execute对象以execute方法运行函数。 如果函数返回结果，则从execute返回的结果收集器调用getResult，并编写应用程序代码来处理结果。注意: 实现高可用性,您必须调用getResult方法。 运行函数的例子-执行成员: MultiGetFunction function = new MultiGetFunction(); FunctionService.registerFunction(function); writeToStdout(\"Press Enter to continue.\"); stdinReader.readLine(); Set keysForGet = new HashSet(); keysForGet.add(\"KEY_4\"); keysForGet.add(\"KEY_9\"); keysForGet.add(\"KEY_7\"); Execution execution = FunctionService.onRegion(exampleRegion) .withFilter(keysForGet) .setArguments(Boolean.TRUE) .withCollector(new MyArrayListResultCollector()); ResultCollector rc = execution.execute(function); // Retrieve results, if the function returns results List result = (List)rc.getResult(); 编写自定义结果收集器 本主题适用于返回结果的函数。 当您执行一个返回结果的函数时，该函数将结果存储到ResultCollector中，并返回ResultCollector对象。然后调用应用程序可以通过ResultCollector getResult方法检索结果。例子: ResultCollector rc = execution.execute(function); List result = (List)rc.getResult(); Geode的默认ResultCollector将所有结果收集到一个ArrayList中。它的getResult方法阻塞，直到收到所有结果。然后返回完整的结果集。 定制结果收集: 编写一个扩展ResultCollector的类，并根据需要编写存储和检索结果的方法。注意，这些方法有两种类型: 当Function实例SendResults方法的结果到达时，Geode调用addResult和endResults getResult可用于正在执行的应用程序(调用Execute .execute的应用程序)检索结果 使用高可用性的onRegion功能，已为其编码: 编写ResultCollector clearResults方法的代码，以删除任何部分结果数据。这为重新执行干净的函数做好了准备。 当您调用该函数时，调用结果收集器getResult方法。这支持高可用性功能。 在调用函数执行的成员中，使用withCollector方法创建Execution对象，并将其传递给自定义收集器。例子: Execution execution = FunctionService.onRegion(exampleRegion) .withFilter(keysForGet) .setArguments(Boolean.TRUE) .withCollector(new MyArrayListResultCollector()); 针对成员组中的单个成员或整个成员组 要在一组成员或一组成员中的一个成员上执行独立于数据的函数，可以编写自己的嵌套函数。如果从客户机到服务器执行一个函数，则需要编写一个嵌套函数;如果从服务器到所有成员执行一个函数，则需要编写另一个嵌套函数。 [id]: Copyright © WS 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-12-10 14:20:33 "},"Geode_7_Tools_and_Modules.html":{"url":"Geode_7_Tools_and_Modules.html","title":" gfsh","keywords":"","body":"工具和模块 gfsh 你可以用gfsh做什么 启动gfsh 配置gfsh环境 有用的gfsh Shell变量 基本Shell功能和命令行用法 在命令行选项中指定JSON 教程 - 使用gfsh执行常见任务 按功能区快速参考gfsh命令 gfsh命令帮助 工具和模块 工具和模块描述了与Apache Geode相关的工具和模块。 gfsh gfsh（发音为\"jee-fish\"）提供了一个强大的命令行界面，您可以从中启动，管理和监控Geode进程，数据和应用程序。 Gemcached Gemcached是一个Geode适配器，允许Memcached客户端与Geode服务器集群通信，就像服务器是memcached服务器一样。 Memcached是一个开源缓存解决方案，它使用分布式内存中的哈希映射来存储字符串或对象数据的键值对。 HTTP Session Management Modules Apache Geode HTTP会话管理模块为HTTP服务器提供快速，可扩展且可靠的会话复制，而无需更改应用程序。 Geode Pulse Geode Pulse是一个Web应用程序，它提供了一个图形仪表板，用于监视Geode集群，成员和区域的重要实时运行状况和性能。 Geode Redis Adapter Geode Redis适配器允许Geode作为Redis数据存储的直接替代品，让Redis应用程序可以利用Geode的扩展功能而无需更改其客户端代码。 Redis客户端使用IP地址和端口号以与连接Redis服务器相同的方式连接到Geode服务器。 Apache Lucene® Integration ApacheLucene®集成使用户能够创建Lucene索引并对存储在Geode中的数据执行Lucene搜索。 gfsh gfsh（发音为“jee-fish”）提供了一个强大的命令行界面，您可以从中启动，管理和监控Geode进程，数据和应用程序。 What You Can Do with gfsh](#What You Can Do with gfsh {#What_You_Can_Do_with_gfsh}) gfsh支持Apache Geode进程和应用程序的管理，调试和部署。 Startinggfsh 在开始gfsh之前，请确认您已设置JAVA_HOME，并且您的PATH变量包含gfsh可执行文件。 Configuring the gfsh Environment gfsh.bat和gfsh bash脚本自动将所需的Apache Geode和JDK的.jar库附加到现有的CLASSPATH。 您可以为安全性，环境变量，日志记录和故障排除设置用户可配置的属性。 Useful gfsh Shell Variables 您可以在脚本中使用内置的gfsh shell变量。 Basic Shell Features and Command-Line Usage gfsh实用程序为shell环境提供了有用的功能，包括命令自动完成，保留的命令历史记录和多行命令的分隔。 上下文相关的帮助可通过命令和主题获得。 Specifying JSON within Command-Line Options 一些gfsh命令允许在命令行选项中使用JSON规范。 Tutorial—Performing Common Tasks with gfsh 本主题将指导您在启动gfsh后执行的典型任务序列。 Quick Reference of gfsh Commands by Functional Area 此快速参考将所有命令分类到功能区域。 gfsh Command Help 本节提供按字母顺序列出的所有gfsh命令的帮助和用法信息。 Creating and Running gfsh Command Scripts gfsh提供了几种在脚本环境中运行命令的方法。 Running gfsh Commands on the OS Command Line Mapping of cache.xml Elements to gfsh Configuration Commands. 您可以使用cache.xml文件配置Geode集群，也可以使用gfsh和集群配置服务来配置集群。 本节将cache.xml元素映射到配置和管理集群的gfsh命令。 你可以用gfsh做什么 gfsh支持Apache Geode进程和应用程序的管理，调试和部署。 使用gfsh，您可以: 启动和停止Apache Geode进程，例如定位器和缓存服务器 启动和停止网关发送方和网关接收方进程 部署应用程序 创建和销毁区域 执行函数 管理磁盘存储 导入和导出数据 监控Apache Geode进程 启动Apache Geode监控工具 gfsh命令行界面使开发人员可以花更少的时间配置缓存实例XML，属性，日志和统计信息。 gfsh命令生成报告; 捕获集群范围的统计数据; 并支持导出统计信息，日志和配置。 与Spring Roo一样，gfsh具有命令完成功能（因此您无需了解语法），上下文相关帮助，脚本以及使用简单API从应用程序内调用任何命令的功能。 gfsh接口使用JMX/RMI与Apache Geode进程通信。 您可以使用HTTP协议将gfsh连接到远程群集。 请参阅使用gfsh通过HTTP或HTTPS管理远程群集。 默认情况下，群集配置服务会在您使用gfsh创建Apache Geode对象时保存Apache Geode群集的配置。 您可以导出此配置并将其导入另一个Apache Geode集群。 请参见群集配置服务概述。 启动gfsh 在启动gfsh之前，请确认您已设置JAVA_HOME并且您的PATH变量包含gfsh可执行文件。 注意:在Windows上，必须正确设置JAVA_HOME环境变量，才能对定位器和服务器使用start，stop和status命令。 要启动gfsh命令行界面，请在当前随Apache Geode一起安装的任何计算机上的提示符处执行以下命令: Start gfsh on Windows: \\bin\\gfsh.bat 其中product_directory>对应于安装Apache Geode的位置。 Start gfsh on Unix: /bin/gfsh 其中product_directory>对应于安装Apache Geode的位置。 执行时，gfsh脚本将所需的Apache Geode和JDK的Jar库附加到现有的CLASSPATH。 如果您已成功启动gfsh，则会出现gfsh启动画面和提示。 c:\\Geode\\Latest>gfsh.bat _________________________ __ / _____/ ______/ ______/ /____/ / / / __/ /___ /_____ / _____ / / /__/ / ____/ _____/ / / / / /______/_/ /______/_/ /_/ Monitor and Manage Geode gfsh> 您也可以直接在终端中运行一些gfsh命令，而无需输入gfsh提示。 例如，在Unix/Linux上你可以输入: $ gfsh start server --name=server1 或在Windows上: prompt> gfsh start server --name=server1 有关详细信息，请参阅创建和运行gfsh命令脚本。 配置gfsh环境 gfsh.bat和gfsh bash脚本自动将所需的Apache Geode和JDK jar库附加到现有的CLASSPATH。 您可以为安全性，环境变量，日志记录和故障排除设置用户可配置的属性。 CLASSPATH中的JAR库 当你启动gfsh时，它会自动加载已经打包在gfsh-dependencies.jar文件中的所需JAR文件。 您无需修改CLASSPATH即可运行gfsh。 JAR文件打包在lib目录的安装目录中。 机器主机名 在某些操作系统上，您可能需要确保在系统主机文件中配置了计算机的主机名。 例如，在macOS上，您可能需要将机器的主机名映射到/etc/hosts文件中的IP地址，以便gfsh和Pulse正常运行。 配置gfsh安全性 由于gfsh必须连接到JMX Manager成员才能运行某些命令（即管理和监视其他成员的那些命令），因此JMX Manager配置属性可能会影响gfsh安全性。 在gemfire.properties中，以下Geode属性可以影响JMX Manager的gfshconnection设置: jmx-manager-ssl jmx-manager-port jmx-manager-password-file jmx-manager-access-file 您可能还需要验证端口是否可用并对客户端连接开放。 有关这些安全属性的详细信息，请参阅配置JMX Manager。 配置gfsh环境变量 此外，您可以使用set variable命令设置特定于gfsh的预设SHELL变量。 例如，您可以将gfsh设置为以安静模式运行。 并非所有gfsh变量都是可修改的。 用户可配置的变量包括: APP_FETCH_SIZE APP_QUIET_EXECUTION 有关详细信息，请参阅有用的gfsh Shell变量。 配置gfsh会话日志记录 默认情况下，禁用gfsh会话日志记录。 要启用gfsh日志记录，必须设置Java系统属性-Dgfsh.log-level=desired_log_level，其中desired_log _level是以下值之一:severe，warning，info，config，fine，fine，finest。 例如，在Linux中: export JAVA_ARGS=-Dgfsh.log-level=info 然后，启动gfsh。 gfsh生成一个名为gfsh-%u_%g.log的日志文件。 此日志文件记录单个gfsh会话的事件。 它包括环境信息，例如Java和系统信息，以及详细的命令执行。 变量替换如下: %u - 解决冲突的唯一编号 %g - 用于区分旋转日志的世代号 gfsh使用JDK Logger生成gfsh会话日志文件。 有关如何在命名日志文件时使用变量的说明，请参见http://docs.oracle.com/javase/7/docs/api/java/util/logging/FileHandler.html。 无法更改生成的gfsh日志文件的默认名称。 默认情况下，日志文件将写入您执行gfsh或gfsh.bat脚本的当前工作目录。 要修改写入日志文件的目录位置，请使用gfsh.log-dir Java系统属性。 例如: export JAVA_ARGS=\"-Dgfsh.log-level=info -Dgfsh.log-dir=/machinename/logs\" 然后，启动gfsh。 另外，gfsh在${SYS_USER_HOME}/.geode/.gfsh.history文件中记录了命令的历史记录，您可以使用它来创建脚本或查看过去的命令。 成员日志文件 gfsh为通过gfsh启动的任何成员写入几个日志文件。 有用的成员日志文件包括: .log. 详细说明定位器的配置（包括所有gemfire.properties）以及启动后定位器上发生的所有活动。 此日志文件将写入以定位符命名的目录。 例如，如果启动名为locator1的定位器，则该文件将在/locator1目录中写为locator1.log。 vf.gf.locator.pid. 包含定位器的进程ID。 您可以使用PID来停止或查看此定位器的状态。 此文件将写入与定位器日志文件相同的目录位置。 .log. 详细说明服务器的配置（包括所有gemfire.properties）以及启动后服务器上发生的所有活动。 此日志文件将写入以服务器命名的目录。 例如，如果启动名为server1的服务器，则该文件将在/server1目录中写为server1.log。 如果停止并以相同的名称启动服务器，则较旧的日志文件将保留在同一目录中，但会重命名以进行版本控制。 vf.gf.server.pid. 包含服务器的进程ID。 您可以使用PID来停止或查看此服务器的状态。 此文件将写入与服务器日志文件相同的位置。 查看标准输出和标准错误 默认情况下，Geode不会将应用程序写入的消息显示为标准输出和标准错误。 要允许将这些消息分别写入定位器和服务器日志文件，请使用gfshstart locator或start server命令指定--redirect-output选项。 例如，以下命令会将stdout和stderr消息写入locator1.log文件: gfsh> start locator --name=locator1 --redirect-output Tab自动补全 本节仅适用于UNIX安装. 从UNIX bash shell运行gfsh命令时，可以通过运行以下命令在shell中启用自动tab-completion: source /bin/gfsh-completion.bash 运行此命令后，您可以在从bash shell运行gfsh命令时使用自动完成。 请参阅使用TAB自动补全。 命令历史和gfsh.history 已成功执行的命令历史记录在运行gfsh的用户的主目录下的.gemfire目录中的.gfsh.history文件中。 您还可以使用history --file=your_file_name命令导出历史文件。 JMX Manager更新率和系统监控 当您执行数据操作（例如put）然后监视系统状态（例如使用gfshshow metrics命令或Geode Pulse）时，受监视的系统可能不会立即反映最近的操作。 例如，如果执行put操作然后立即执行show metrics gfsh命令，则可能看不到该区域中正确的条目数。 管理层每2秒更新一次。 执行操作活动后等待几秒钟以查看最准确的结果。 您可以修改gemfire.properties中的jmx-manager-update-rate属性，以增加或减少将更新推送到JMX Manager的速率（以毫秒为单位）。 此属性设置应大于或等于statistic-sample-rate。 如果遇到性能问题，您可能希望提高此间隔; 但是，将此值设置得太高会导致在gfsh和Geode Pulse中看到陈旧值。 格式化结果 本节仅适用于UNIX安装. 诸如query之类的gfsh命令产生具有宽列的输出，这些列可能会变得不对齐并需要手动重新格式化以查看输出。 如果输出无法适应终端的可用宽度，gfsh会自动修剪列宽以适应。 您可以通过将gfsh环境变量GFSH.TRIMSCRWIDTH设置为false来禁用此行为。 您可以将APP_RESULT_VIEWER变量设置为external，以便使用UNIXless命令查看输出。 请参阅配置gfsh环境变量。 有用的gfsh Shell变量 您可以在脚本中使用内置的gfsh shell变量。 您还可以使用set variable命令修改shell行为或定义自己的变量。 要查看所有gfsh shell变量及其当前值的列表，请使用以下命令: gfsh>echo --string=$* 要获取现有变量的当前值，请使用以下命令语法（该变量必须括在大括号中）: gfsh>echo --string=${VARIABLE} 例如: gfsh>echo --string=${SYS_CLASSPATH} 系统变量 SYS_CLASSPATH gfsh JVM的CLASSPATH（只读）. SYS_GEMFIRE_DIR 已安装Geode的产品目录（只读）. SYS_HOST_NAME 启动gfsh的主机（只读）. SYS_JAVA_VERSION 使用的Java版本 （只读）. SYS_OS 操作系统名称 （只读）. SYS_OS_LINE_SEPARATOR 在编写gfsh脚本时可以使用的行分隔符（\\或^）变量。 （只读）. SYS_USER 用户名（只读）. SYS_USER_HOME 用户的主目录（只读）. GFSH环境变量 APP_FETCH_SIZE 查询时要使用的提取大小。 值:0 - 2147483647.默认值为100. APP_LAST_EXIT_STATUS 上次命令退出状态。 与$相似？ （Unix）和％errorlevel％（Windows）。 值:0（成功），1（错误），2（崩溃）（只读）. APP_LOGGING_ENABLED Whether gfsh logging is enabled. Default: false (read only). You can enable gfsh logging by setting the gfsh.log-level Java system property to a supported Java log level. APP_LOG_FILE 当前gfsh日志文件的路径和名称（只读）. APP_NAME 应用程序的名称 - “gfsh”（只读）. APP_PWD 启动gfsh的当前工作目录（只读）. APP_QUERY_RESULTS_DISPLAY_MODE 切换显示模式以返回查询结果。 值:table or catalog(表或编目)。 默认值为table. APP_QUIET_EXECUTION 执行是否应该处于安静模式。 值（不区分大小写）:true，false。 默认值为false. APP_RESULT_VIEWER 仅限Unix。 将此变量设置为external以使用UNIXless命令查看输出。 默认值为basic（gfsh）. 基本Shell功能和命令行用法 gfsh实用程序为shell环境提供了有用的功能，包括命令自动完成，保留的命令历史记录和多行命令的分隔。 上下文相关的帮助可通过命令和主题获得。 要查看可用的gfsh命令列表，请在空提示符下按Tab键. 您看到的命令列表取决于您是否连接到Geode群集。 如果未连接，则会看到可用的本地命令列表。 使用hint命令获取有关特定主题的信息. hint命令显示指定主题的单行描述和关联命令。 例如，hint data返回数据主题的描述以及可用于数据的所有可能操作: gfsh>hint Data User data as stored in regions of the Geode distributed system. create index : Create an index that can be used when executing queries. destroy index : Destroy/Remove the specified index. export data : Export user data from a region to a file. get : Display an entry in a region. If using a region whose key and value classes have been set, then specifying --key-class and --value-class is unnecessary. import data : Import user data from a file to a region. list indexes : Display the list of indexes created for all members. locate entry : Identifies the location, including host, member and region, of entries that have the specified key. put : Add/Update an entry in a region. If using a region whose key and value classes have been set, then specifying --key-class and --value-class is unnecessary. query : Run the specified OQL query as a single quoted string and display the results in one or more pages. Limit will default to the value stored in the \"APP_FETCH_SIZE\" variable. Page size will default to the value stored in the \"APP_COLLECTION_LIMIT\" variable. rebalance : Rebalance partitioned regions. The default is for all partitioned regions to be rebalanced. remove : Remove an entry from a region. If using a region whose key class has been set, then specifying --key-class is unnecessary. 要查看提示主题列表，请键入hint。 使用help命令获取有关特定命令的信息. 根据命令，键入help 将显示该特定命令的使用信息或与该命令相关的命令列表。 例如，键入help start以显示带有简短描述的启动命令列表。 说明指示命令是否可用，并取决于gfsh的连接状态。 以下示例假定gfsh当前未连接（通过连接到JMX Manager节点），因此某些启动命令不可用。 gfsh>help start start gateway-receiver (Not Available) Start the Gateway Receiver on a member or members. start gateway-sender (Not Available) Start the Gateway Sender on a member or members. start jconsole (Available) Start the JDK's JConsole tool in a separate process. JConsole will be launched, but connecting to GemFire must be done manually. start jvisualvm (Available) Start the JDK's Java VisualVM (jvisualvm) tool in a separate process. Java VisualVM will be launched, but connecting to GemFire must be done manually. start locator (Available) Start a Locator. start pulse (Available) Open a new window in the default Web browser with the URL for the Pulse application. start server (Available) Start a GemFire Cache Server. 使用Tab键自动完成命令或触发可能的完成. 输入部分命令以触发命令的自动完成或可能的命令完成列表后，使用Tab键。 例如，在键入hint后按Tab键会显示所有可用主题: gfsh>hint Configuration Data Debug-Utility Disk Store Function Execution GFSH GemFire Help JMX Lifecycle Locator Management-Monitoring Manager Region Server Statistics 键入hint d后按Tab键会显示以d开头的可用主题: gfsh>hint d data debug-Utility disk Store 自动完成还为命令提供可用参数和参数; 例如，在键入start后点击TAB键将列出可以启动的所有服务。 gfsh>start start data-browser start jconsole start jvisualvm start locator start pulse start server 在start locator之后点击TAB键将在命令后填充--name参数。 （如果您没有指定成员名称，gfsh将自动选择一个随机名称。这对自动化非常有用。） 使用向上箭头访问命令历史记录. 通过使用向上箭头滚动以前的命令来访问shell历史记录中的命令。 使用反斜杠分隔多行命令. 输入长命令时，可以使用反斜杠字符（'\\'）作为分隔符来中断命令行。 例如: gfsh>create region --name=region1 \\ --type=REPLICATE_PERSISTENT \\ --cache-writer=org.apache.geode.examples.MyCacheWriter \\ --group=Group1 --disk-store=DiskStore1 用单引号或双引号括起包含空格或逗号的字符串 在gfsh命令shell中执行gfsh命令时，请在单引号中包含任何包含空格或逗号的字符串。 例如: gfsh>start locator --name='locator 1' start locator --name=locator1 --port=9009 --mcast-port=0\\ --J='-Dgemfire.remote-locators=192.0.2.0[9009],192.0.2.1[9009]' 当您从操作系统shell在一行中执行多个gfsh命令时，请将gfsh命令用双引号括起来。 在双引号内，包含任何包含带单引号的空格或逗号的字符串。 例如: $ gfsh -e \"start locator --name='locator 1'\" -e \"start server --name=server1\" 在命令行选项中指定JSON 一些gfsh命令允许在某些选项中使用JSON规范。 这些JSON字符串以键/值对的形式指定初始化属性。 对于那些实现Declarable接口的类，JSON字符串被附加到完全限定的类名。 接口的init方法的参数是一个包含初始化属性的对象。 解析JSON字符串并将其分解为一组定义对象的属性名称和值。 gfsh create region命令中的缓存加载器类的规范可能具有JSON规范。 例如， gfsh>create region --name=region1 --type=PARTITION \\ --cache-loader=com.example.Setup{'k1':'v1','k2':'v2','k3':'v3'} 此示例中的JSON字符串是 {'k1':'v1','k2':'v2','k3':'v3'} JSON字符串由大括号括起，并且用逗号分隔。 每对由冒号分隔。 定义一对的两个字符串中的每一个都用单引号或双引号字符括起来。 在使用单引号或双引号字符时，在整个JSON字符串中保持一致。 空格字符分隔gfsh命令行选项，并且在解析JSON字符串之前进行选项的标记化。 如果命令行选项中的值包含空格，请使用双引号将其分隔。 例如，假设有一对，并且该对的值是value with space。 --cache-loader示例选项的右侧变为 gfsh>create region --name=region2 --type=PARTITION \\ --cache-loader=\"com.example.Setup{'k1': 'value with space'}\" 要在值中包含单引号字符，请使用两个反斜杠字符对其进行转义。 例如， gfsh>create region --name=region3 --type=PARTITION \\ --cache-loader=\"com.example.Setup{'k1': 'property\\\\'s value'}\" value的值是 property's value。 教程 - 使用gfsh执行常见任务 本主题将指导您在启动gfsh后执行的典型任务序列。 步骤1:创建临时工作目录并切换到该目录。 例如: $ mkdir gfsh_tutorial $ cd gfsh_tutorial Step 1: 启动gfsh提示符. $ gfsh _________________________ __ / _____/ ______/ ______/ /____/ / / / __/ /___ /_____ / _____ / / /__/ / ____/ _____/ / / / / /______/_/ /______/_/ /_/ Monitor and Manage Geode gfsh> 有关详细信息，请参阅启动gfsh。 Step 2: 启动定位器. 输入以下命令: gfsh>start locator --name=locator1 出现以下输出: gfsh>start locator --name=locator1 ..... Locator in /home/username/gfsh_tutorial/locator1 on 192.0.2.0[10334] as locator1 is currently online. Process ID: 67666 Uptime: 6 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /home/username/gfsh_tutorial/locator1.log JVM Arguments: -Dgemfire.enable-cluster-configuration=true -Dgemfire.load-cluster-configuration-from-dir=false -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /home/username/geode/geode-assembly/build/install/apache-geode/lib /geode-core-1.2.0.jar:/home/username/geode/geode-assembly/build/install/apache-geode /lib/geode-dependencies.jar Successfully connected to: JMX Manager [host=192.0.2.0, port=1099] Cluster configuration service is up and running. 如果你从gfsh运行start locator而没有指定成员名，gfsh会自动选择一个随机成员名。 这对自动化很有用。 在文件系统中，检查执行gfsh的文件夹位置。 请注意，start locator命令已自动创建了一个工作目录（使用定位器的名称），并在该工作目录中创建了一个日志文件，一个状态文件和一个.pid（包含定位器的进程ID）对于这个定位器。 此外，由于还没有其他JMX Manager存在，请注意gfsh已在定位器内的端口1099上自动启动嵌入式JMX Manager，并已将您连接到该JMX Manager。 Step 3: 检查现有的gfsh连接. 在当前shell中，键入以下命令: gfsh>describe connection 如果已连接到在步骤2中启动的定位器中启动的JMX Manager，则会显示以下输出: gfsh>describe connection Connection Endpoints -------------------- ubuntu.local[1099] 请注意，JMX Manager位于1099，而定位器的默认端口为10334。 Step 4: 从不同的终端连接到相同的locator/JMX Manager. 此步骤说明如何连接到locator/JMX Manager。 打开第二个终端窗口，然后启动第二个gfsh提示符。 在第二个提示中键入与步骤3中相同的命令: gfsh>describe connection 这一次，请注意您未连接到JMX Manager，并显示以下输出: gfsh>describe connection Connection Endpoints -------------------- Not connected 在第二个gfsh终端中键入以下命令: gfsh>connect 该命令将连接到您在步骤2中启动的当前运行的本地定位器。 gfsh>connect Connecting to Locator at [host=localhost, port=10334] .. Connecting to Manager at [host=ubuntu.local, port=1099] .. Successfully connected to: [host=ubuntu.local, port=1099] 请注意，如果您在启动定位器时使用了自定义--port，或者您从另一个成员的gfsh提示符连接时，您还需要在连接时指定--locator=hostname[port] 到群集。 例如（如果你想尝试下一个命令，首先键入disconnect）: gfsh>connect --locator=localhost[10334] Connecting to Locator at [host=localhost, port=10334] .. Connecting to Manager at [host=ubuntu.local, port=1099] .. Successfully connected to: [host=ubuntu.local, port=1099] 将gfsh连接到集群的另一种方法是直接连接到定位器内运行的JMX Manager。 例如（如果你想尝试下一个命令，首先键入disconnect）: gfsh>connect --jmx-manager=localhost[1099] Connecting to Manager at [host=localhost, port=1099] .. Successfully connected to: [host=localhost, port=1099] 此外，您还可以通过HTTP连接到远程群集。 请参阅使用gfsh通过HTTP或HTTPS管理远程群集。 Step 5: 断开并关闭第二个终端窗口. 键入以下命令以断开连接并退出第二个gfsh提示符: gfsh>disconnect Disconnecting from: localhost[1099] Disconnected from : localhost[1099] gfsh>exit 关闭第二个终端窗口。 Step 6: 启动服务器. 返回到第一个终端窗口，然后启动使用您在步骤2中启动的定位器的缓存服务器。键入以下命令: gfsh>start server --name=server1 --locators=localhost[10334] 如果服务器成功启动，则会显示以下输出: gfsh>start server --name=server1 --locators=localhost[10334] Starting a Geode Server in /home/username/gfsh_tutorial/server1/server1.log... ... Server in /home/username/gfsh_tutorial/server1 on 192.0.2.0[40404] as server1 is currently online. Process ID: 68375 Uptime: 4 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /home/username//gfsh_tutorial/server1/server1.log JVM Arguments: -Dgemfire.locators=localhost[10334] -Dgemfire.use-cluster-configuration=true -Dgemfire.start-dev-rest-api=false -XX:OnOutOfMemoryError=kill -KILL %p -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /home/username/geode/geode-assembly/build/install/apache-geode/lib /geode-core-1.2.0.jar:/home/username/geode/geode-assembly/build/install /apache-geode/lib/geode-dependencies.jar 如果从gfsh运行start server而不指定成员名称，gfsh将自动选择一个随机成员名称。 这对自动化很有用。 在文件系统中，检查执行gfsh的文件夹位置。 请注意，就像start locator命令一样，start server命令已经自动创建了一个工作目录（以服务器命名），并且在该工作目录中，它创建了一个日志文件和一个.pid（包含服务器的 进程ID）此缓存服务器。 此外，它还编写了日志文件。 Step 7: 列出成员. 使用list members命令查看刚刚创建的集群的当前成员。 gfsh>list members Name | Id ------------ | --------------------------------------- Coordinator: | ubuntu(locator1:5610:locator):34168 locator1 | ubuntu(locator1:5610:locator):34168 server1 | ubuntu(server1:5931):35285 Step 8: 通过执行describe member命令查看成员详细信息. gfsh>describe member --name=server1 Name : server1 Id : ubuntu(server1:5931):35285 Host : ubuntu.local Regions : PID : 5931 Groups : Used Heap : 12M Max Heap : 239M Working Dir : /home/username/gfsh_tutorial/server1 Log file : /home/username/gfsh_tutorial/server1/server1.log Locators : localhost[10334] Cache Server Information Server Bind : Server Port : 40404 Running : true Client Connections : 0 请注意，尚未为此成员分配任何区域。 Step 9: 创建您的第一个区域. 键入以下命令，然后键入Tab键: gfsh>create region --name=region1 --type= 将显示可能的区域类型列表，后跟您输入的部分命令: gfsh>create region --name=region1 --type= PARTITION PARTITION_REDUNDANT PARTITION_PERSISTENT PARTITION_REDUNDANT_PERSISTENT PARTITION_OVERFLOW PARTITION_REDUNDANT_OVERFLOW PARTITION_PERSISTENT_OVERFLOW PARTITION_REDUNDANT_PERSISTENT_OVERFLOW PARTITION_HEAP_LRU PARTITION_REDUNDANT_HEAP_LRU REPLICATE REPLICATE_PERSISTENT REPLICATE_OVERFLOW REPLICATE_PERSISTENT_OVERFLOW REPLICATE_HEAP_LRU LOCAL LOCAL_PERSISTENT LOCAL_HEAP_LRU LOCAL_OVERFLOW LOCAL_PERSISTENT_OVERFLOW PARTITION_PROXY PARTITION_PROXY_REDUNDANT REPLICATE_PROXY gfsh>create region --name=region1 --type= 使用您要创建的区域类型完成命令。 例如，创建一个本地区域: gfsh>create region --name=region1 --type=LOCAL Member | Status ------- | -------------------------------------- server1 | Region \"/region1\" created on \"server1\" 由于此时集群中只有一台服务器，因此该命令会在server1上创建本地区域。 Step 10: 启动其他服务器. 这次使用不同的服务器端口指定--server-port参数，因为您在同一主机上启动了缓存服务器进程。 gfsh>start server --name=server2 --server-port=40405 Starting a Geode Server in /home/username/gfsh_tutorial/server2... ... Server in /home/username/gfsh_tutorial/server2 on 192.0.2.0[40405] as server2 is currently online. Process ID: 68423 Uptime: 4 seconds Geode Version: 1.7 Java Version: 1.8.0_121 Log File: /home/username/gfsh_tutorial/server2/server2.log JVM Arguments: -Dgemfire.default.locators=192.0.2.0[10334] -Dgemfire.use-cluster-configuration=true -Dgemfire.start-dev-rest-api=false -XX:OnOutOfMemoryError=kill -KILL %p -Dgemfire.launcher.registerSignalHandlers=true -Djava.awt.headless=true -Dsun.rmi.dgc.server.gcInterval=9223372036854775806 Class-Path: /home/username/geode/geode-assembly/build/install/apache-geode /lib/geode-core-1.2.0.jar:/home/username/geode/geode-assembly/build/install /apache-geode/lib/geode-dependencies.jar Step 11: 创建复制区域. gfsh>create region --name=region2 --type=REPLICATE Member | Status ------- | -------------------------------------- server1 | Region \"/region2\" created on \"server1\" server2 | Region \"/region2\" created on \"server2\" Step 12: 创建分区区域. gfsh>create region --name=region3 --type=PARTITION Member | Status ------- | -------------------------------------- server1 | Region \"/region3\" created on \"server1\" server2 | Region \"/region3\" created on \"server2\" Step 13: 创建一个复制的持久区域. gfsh>create region --name=region4 --type=REPLICATE_PERSISTENT Member | Status ------- | -------------------------------------- server1 | Region \"/region4\" created on \"server1\" server2 | Region \"/region4\" created on \"server2\" Step 14: 列出区域. 将显示您刚刚创建的所有区域的列表. gfsh>list regions List of regions --------------- region1 region2 region3 region4 Step 15: 通过执行describe member命令再次查看成员详细信息. gfsh>describe member --name=server1 Name : server1 Id : ubuntu(server1:5931):35285 Host : ubuntu.local Regions : region4 region3 region2 region1 PID : 5931 Groups : Used Heap : 14M Max Heap : 239M Working Dir : /home/username/gfsh_tutorial/server1 Log file : /home/username/gfsh_tutorial/server1/server1.log Locators : localhost[10334] Cache Server Information Server Bind : Server Port : 40404 Running : true Client Connections : 0 请注意，您现在创建的所有区域都显示在成员说明的“Regions”部分中。 gfsh>describe member --name=server2 Name : server2 Id : ubuntu(server2:6092):17443 Host : ubuntu.local Regions : region4 region3 region2 region1 PID : 6092 Groups : Used Heap : 14M Max Heap : 239M Working Dir : /home/username/gfsh_tutorial/server2 Log file : /home/username/gfsh_tutorial/server2/server2.log Locators : 192.0.2.0[10334] Cache Server Information Server Bind : Server Port : 40405 Running : true Client Connections : 0 请注意，即使您在创建第一个区域（region1）后启动了第二个服务器，第二个服务器仍会列出region1，因为它从群集配置服务中选择了其配置。 Step 16: 将数据放进本地区域. 输入以下put命令: gfsh>put --key=('123') --value=('ABC') --region=region1 Result : true Key Class : java.lang.String Key : ('123') Value Class : java.lang.String Old Value : Step 17: 将数据放在复制区域中. 输入以下put命令: gfsh>put --key=('123abc') --value=('Hello World!!') --region=region2 Result : true Key Class : java.lang.String Key : ('123abc') Value Class : java.lang.String Old Value : Step 18: 检索数据. 您可以使用locate entry,query或get来返回刚刚放入该区域的数据。 例如，使用get命令: gfsh>get --key=('123') --region=region1 Result : true Key Class : java.lang.String Key : ('123') Value Class : java.lang.String Value : ('ABC') 例如，使用locate entry命令: gfsh>locate entry --key=('123abc') --region=region2 Result : true Key Class : java.lang.String Key : ('123abc') Locations Found : 2 MemberName | MemberId ---------- | ------------------------------- server2 | ubuntu(server2:6092):17443 server1 | ubuntu(server1:5931):35285 请注意，由于条目已放入复制区域，因此该条目位于两个集群成员上。 例如，使用query命令: gfsh>query --query='SELECT * FROM /region2' Result : true startCount : 0 endCount : 20 Rows : 1 Result ----------------- ('Hello World!!') NEXT_STEP_NAME : END Step 19: 导出您的数据. 要保存区域数据，可以使用export data命令。 例如: gfsh>export data --region=region1 --file=region1.gfd --member=server1 您可以稍后使用import data命令将该数据导入另一个成员的同一区域。 Step 20: 关闭群集. gfsh>shutdown --include-locators=true 按功能区快速参考gfsh命令 此快速参考将所有命令分类到功能区域。 单击命令可查看其他信息，包括语法，选项列表和示例。 Basic Geode gfsh Commands Configuration Commands Data Commands Deployment Commands Disk Store Commands Durable CQ and Client Commands Function Execution Commands Gateway (WAN) Commands Geode Monitoring Commands Index Commands JMX Connection Commands Locator Commands Lucene Commands PDX Commands Region Commands Server Commands 基本Geode gfsh命令 命令 描述 可用性 debug 在gfsh中启用或禁用调试输出. online, offline echo 回显给定文本，其中可能包括系统和用户变量. online, offline exit 退出gfsh shell。 您也可以使用quit退出shell. online, offline help 如果参数是gfsh命令，则显示该命令的语法和用法信息。 如果没有参数，则显示所有可用命令的列表. online, offline hint 显示有关主题的信息以及与主题关联的命令列表. online, offline history 显示或保存命令历史记录. online, offline run 执行一组GFSH命令. online, offline set variable 在GFSH环境中设置变量. online, offline sh 执行操作系统（OS）命令. offline, online sleep 延迟gfsh命令执行. online, offline version 显示产品版本信息. online, offline 配置命令 命令 描述 可用性 alter runtime 在一个或多个成员运行时更改特定成员的配置属性. online change loglevel 更改指定服务器上的日志记录级别. online configure pdx 此命令可更改所有高速缓存的群集范围的PDX配置设置. online 注意: 必须在启动数据成员之前运行此命令才能强制执行配置设置. describe config 显示成员的配置. online export config 导出配置，数据，日志和堆栈跟踪. online export cluster-configuration 导出共享配置ZIP文件，其中包含配置和操作集群所需的cache.xml文件，gemfire.properties文件和JAR文件. online import cluster-configuration 导入导出的配置. online status cluster-config-service 报告群集配置服务器的状态. online 数据命令 命令 描述 可用性 export data 将用户数据从区域导出到文件. online get 显示区域中的条目. online import data 将用户数据从文件导入区域. online locate entry 在成员上找到区域条目. online put 添加或更新区域条目. online query 对Geode区域运行查询. online remove 从区域中删除条目. online 部署命令 命令 描述 可用性 deploy 将JAR打包的应用程序部署到一个或多个成员. online list deployed 显示使用deploy命令部署到成员的JAR列表. online undeploy 取消部署部署使用deploy命令部署在成员或群体的JAR文件. online 磁盘存储命令 命令 描述 可用性 alter disk-store 修改现有的Geode资源. online backup disk-store 将所有成员的持久数据备份到指定目录. online compact disk-store 压缩在线磁盘存储. online compact offline-disk-store 压缩脱机磁盘存储. online, offline create disk-store 定义一个或多个磁盘存储的池，可供区域和客户端订阅队列使用. online describe disk-store 显示有关成员磁盘存储的信息. online describe offline-disk-store 显示有关脱机成员磁盘存储的信息 online, offline destroy disk-store 删除磁盘存储以及磁盘存储使用的磁盘上的所有文件。 先前使用此磁盘存储的封闭区域的数据将丢失. online list disk-stores 列出Geode集群中的所有可用磁盘存储. online revoke missing-disk-store 指示集群成员停止等待磁盘存储可用. online show missing-disk-stores 显示群集中当前缺少的磁盘存储的摘要. online validate offline-disk-store 验证脱机磁盘存储. online, offline 持久的CQ和客户端命令 命令 描述 可用性 list durable-cqs 列出与指定的持久客户端ID关联的持久客户端CQ. online close durable-cq 关闭持久客户端注册的持久CQ，并从订阅队列中为持久CQ保留排除事件. online close durable-client 试图关闭持久客户端。 客户端必须断开连接. online show subscription-queue-size 显示订阅队列中的事件数。 如果提供CQ名称，则它计算指定CQ的订阅队列中的事件数. online 函数执行命令 命令 描述 可用性 destroy function Destroy or unregister a function. The default is for the function to be unregistered from all members. online execute function Execute the function with the specified ID. By default, executes on all members. online list functions Display a list of registered functions. The default is to display functions for all members. online 网关(WAN)命令 命令 描述 可用性 create async-event-queue 创建异步事件队列. online create gateway-receiver 在一个或多个成员上创建网关接收器. online create gateway-sender 在一个或多个成员上创建网关发件人. online destroy gateway-sender 销毁一个或多个成员上的网关发件人. online list async-event-queues 显示所有成员的异步事件队列列表. online list gateways 显示一个或多个成员的网关发件人和收件人. online load-balance gateway-sender 使指定的网关发送方关闭其当前连接并以更平衡的方式重新连接到远程网关接收方. online pause gateway-sender 暂停网关发件人. online resume gateway-sender 恢复已暂停的所有网关发件人. online start gateway-receiver 在给定成员或成员组上启动网关接收器. online start gateway-sender 在一个或多个成员上启动网关发件人. online status gateway-receiver 显示指定网关接收器的状态. online status gateway-sender 显示指定网关发件人的状态. online stop gateway-receiver 停止一个或多个成员的网关接收器. online stop gateway-sender 在指定成员或指定成员组成员上具有给定ID的网关发件人. online Geode 异步事件队列命令 命令 描述 可用性 create async-event-queue 创建异步事件队列. online list async-event-queues 显示所有成员的异步事件队列列表. online Geode监控命令 命令 描述 可用性 describe client 显示指定客户端的详细信息. online describe member 显示具有给定名称/ID的成员的详细信息. online export logs 将日志导出/转储到给定目录. online export stack-traces 导出一个或多个成员的堆栈跟踪. online gc 强制成员或成员的垃圾回收. online list clients 显示已连接客户端的列表. online list members 显示全部或部分成员. online netstat 通过“netstat”操作系统命令报告网络信息和统计信息. online show dead-locks 显示死锁，日志，指标和丢失的磁盘存储. online show log 显示成员的日志. online show metrics 显示或导出整个群集，成员或区域的度量标准. online shutdown 关闭所有具有缓存的成员. online start jconsole 在单独的进程中启动JDK JConsole监视应用程序。 JConsole会自动连接到正在运行的JMX Manager节点（如果有） online, offline start jvisualvm 在单独的进程中启动JDK的Java VisualVM监视应用程序. online, offline start pulse 在用户的默认系统浏览器中启动Geode Pulse监控仪表板工具. online, offline 索引命令 命令 描述 可用性 clear defined indexes 清除所有已定义的索引. online, offline create defined indexes 创建所有已定义的索引. online create index 创建可在执行查询时使用的索引. online define index 定义可在执行查询时使用的索引。 然后，您可以一次创建多个索引. online, offline destroy index 销毁或删除指定的索引. online list indexes 显示为所有成员创建的索引列表. online JMX连接命令 命令 描述 可用性 connect 直接或通过定位器连接到jmx-manager. offline describe connection 显示连接信息详细信息. online, offline disconnect 关闭所有活动连接. online 定位器命令 命令 描述 可用性 start locator 启动定位器。 该命令创建一个以定位符命名的子目录和日志文件。 如果定位器检测到不存在其他JMX Manager，则定位器将自动启动嵌入式JMX Manager并将当前的gfsh会话连接到JMX Manager. online, offline status locator 显示指定定位器的状态。 online, offline stop locator 停止定位器. online, offline Lucene 命令 命令 描述 可用性 create lucene index 创建Lucene索引. online describe lucene index 描述一个Lucene索引. online destroy lucene index 销毁Lucene索引. online list lucene indexes 列出为所有成员创建的Lucene索引。 可选的--with-stats限定符显示索引上的活动. online search lucene 搜索Lucene索引. online PDX 命令 命令 描述 可用性 configure pdx 为群集中的所有缓存配置Portable Data eXchange. online, offline pdx rename 在脱机磁盘存储中重命名PDX类型. online, offline 区域 命令 命令 描述 可用性 alter region 改变区域的配置。 online create region 创建和配置区域. online describe region 显示区域的属性和关键信息. online destroy region 销毁或删除某个地区. online list regions 显示成员或成员的区域。 如果未指定参数，则列出群集中的所有区域. online rebalance 重新平衡分区区域. online 服务器命令 命令 描述 可用性 start server 启动Geode缓存服务器进程. online, offline status server 显示指定的Geode缓存服务器的状态. online, offline stop server 停止Geode缓存服务器. online, offline gfsh命令帮助 本节提供按字母顺序列出的所有gfsh命令的帮助和用法信息。 alter 修改现有的Geode资源。 backup disk-store 将所有成员的持久数据备份到指定目录。 change loglevel 更改指定成员的日志记录级别。 clear defined indexes 清除所有已定义的索引。 close 关闭持久客户CQ和持久客户。 compact 压缩在线和离线磁盘存储。 configure 为群集中的所有缓存配置Portable Data eXchange。 connect 直接或通过定位器连接到jmx-manager。 create 创建异步事件队列，磁盘存储，网关接收器，网关发件人，索引和区域。 debug 在gfsh中启用或禁用调试输出。 define index 定义可在执行查询时使用的索引。 然后，您可以使用create defined indexes执行单个命令以一次创建多个索引。 deploy 将JAR打包的应用程序部署到一个或多个成员。 describe 显示成员配置，shell连接，磁盘存储，成员或区域的详细信息。 destroy 删除或取消注册功能，删除索引，磁盘存储和区域。 disconnect 关闭所有活动连接。 echo 回显给定文本，其中可能包括系统和用户变量。 execute function 在成员或区域上执行功能。 exit 退出gfsh shell。 您也可以使用quit退出shell。 export 导出配置，数据，日志和堆栈跟踪。 gc 对一个或多个成员强制GC（垃圾收集）。 get 显示区域中的条目。 help 显示所有可用命令的语法和用法信息。 hint 显示有关主题的信息以及与主题关联的命令列表。 history 显示或保存命令历史记录。 import 您可以将数据导入区域或将现有群集配置导入群集。 list 列出现有的Geode资源，例如已部署的应用程序，磁盘存储，功能，成员，服务器和区域。 load-balance gateway-sender 使指定的网关发送方关闭其当前连接并以更平衡的方式重新连接到远程网关接收方。 locate entry 在成员上找到区域条目。 netstat 通过“netstat”操作系统命令报告网络信息和统计信息。 pause gateway-sender 暂停网关发件人。 pdx rename 在脱机磁盘存储中重命名PDX类型。 put 添加或更新区域条目。 query 对Geode区域运行查询。 rebalance 重新平衡分区区域。 remove 从区域中删除条目。 resume gateway-sender 恢复已暂停的所有网关发件人。 revoke missing-disk-store 指示群集的成员停止等待磁盘存储可用。 run 执行一组GFSH命令。 set variable 在GFSH环境中设置变量。 sh 执行操作系统命令。 show 显示死锁，日志，指标和丢失的磁盘存储。 shutdown 停止所有成员。 sleep 延迟gfsh命令执行。 start 启动服务器，定位器，网关发送器和网关接收器以及监视工具。 status 检查群集配置服务和Geode成员进程的状态，包括定位器，网关接收器，网关发件人和服务器。 stop 停止网关接收器，网关发送器，定位器和服务器。 undeploy 取消使用deploy命令部署在成员或组上部署的JAR文件。 validate offline-disk-store 验证脱机磁盘存储。 version 显示产品版本信息。 alter Modify an existing Geode resource. alter async-event-queue 修改异步事件队列的属性 alter disk-store 修改或删除脱机磁盘存储中的区域。 alter region 改变区域的配置。 alter runtime 在成员或成员运行时更改所有成员或成员子集的配置属性。 alter async-event-queue 更改指定的异步事件队列的属性。 必须重新启动托管指定异步事件队列的每个服务器，新属性设置才能在该服务器上生效。 可用性: Online. 必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: alter async-event-queue --id=value [--batch-size=value] [--batch-time-interval=value] [--max-queue-memory=value] [--if-exists(=value)] 必需的选项--id标识要更改的异步事件队列。 Parameters, alter async-event-queue 名称 描述 ‑‑id Required. 要更改的异步事件队列的ID ‑‑batch‑size 批处理可以包含的最大事件数 ‑‑batch‑time‑interval 在批次交付之前可以经过的最长时间（以毫秒为单位） ‑‑max‑queue‑memory 在溢出到磁盘之前队列可以消耗的最大内存量（以兆字节为单位） ‑‑if‑exists 如果指定的异步事件队列不存在，gfsh将响应该消息。 如果此参数为true，则响应的前缀为\"Skipping:\"标签。 对脚本测试很有用。 默认值（如果未指定参数）:false。 默认值（如果指定的参数没有值）:true。 示例命令: alter async-event-queue --id=myAsyncEventQueue --batch-size=50 --if-exists alter disk-store 修改或删除脱机磁盘存储中的区域。 修改区域的配置时，通常会使该区域脱机并使用新配置重新启动。 您可以使用alter disk-store命令更改磁盘存储中存储的区域的配置，以匹配您在重新启动时使用的配置。 可用性: Offline. 句法: alter disk-store --name=value --region=value --disk-dirs=value(,value)* [--compressor(=value)] [--concurrency-level=value] [--enable-statistics=value] [--initial-capacity=value] [--load-factor=value] [--lru-algorithm=value] [--lru-action=value] [--lru-limit=value] [--off-heap(=value)] [--remove(=value)] 三个必需的选项--name，--region和--disk-dirs标识要更改的磁盘存储区和区域。 如果未指定其他选项，gfsh将显示当前配置而不进行任何更改。 Parameters, alter disk-store 名称 描述 --name Required. 将更改其内容的磁盘存储的名称。 --region Required. 使用磁盘存储区域的名称（包括路径）。 --disk-dirs Required. 先前已写入磁盘存储数据的目录。 --compressor 压缩区域条目值时要使用的压缩程序的完全限定类名。 值为none会删除压缩器。 --concurrency-level 估计将同时访问区域条目的最大应用程序线程数。 与--initial-capacity和--load-factor一起，在用于存储区域条目的底层java.util.ConcurrentHashMap上设置参数。 此属性不适用于分区区域。 --enable-statistics 启用--region选项指定的区域的统计信息。 有效值为true或false。 如果指定的参数没有值，则使用true值。 --initial-capacity 与--concurrency-level和--load-factor一起，在用于存储区域条目的底层java.util.ConcurrentHashMap上设置参数。 --load-factor 与--concurrency-level和--initial-capacity一起，在用于存储区域条目的底层java.util.ConcurrentHashMap上设置参数。 这必须是0到1之间的浮点数，包括0和1。 --lru-action 驱逐该地区的条目时要采取的行动。 有效值为:none,overflow-to-disk,local-destroy --lru-algorithm 最近最少使用逐出算法。 有效类型是:none,lru-entry-count,lru-heap-percentage,lru-memory-size --lru-limit 驱逐前该地区允许的条目数量。 --off-heap 指定区域值是在堆内存还是堆外内存中。 如果为true，则区域值位于堆外内存中。 如果指定的参数没有值，则使用true值。 --remove 指定是否从磁盘存储中删除该区域。 如果指定的参数没有值，则使用true值。 注意: --remove删除该区域的所有持久数据。 如果您可能希望在以后检索数据，请考虑在使用此选项之前将磁盘存储文件复制到备份。 示例命令: alter disk-store --name=DiskStore1 --region=region1 --disk-dirs=/Disks/DiskStore1 --off-heap alter disk-store --name=DiskStore1 --region=region1 --disk-dirs=/Disks/DiskStore1 --remove alter region 改变区域的配置。 有关语法详细信息，请参阅在命令行选项中指定JSON。 可用性: Online. 必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: alter region --name=value [--groups=value(,value)*] [--entry-idle-time-expiration=value] [--entry-idle-time-expiration-action(=value)?] [--entry-time-to-live-expiration=value] [--entry-time-to-live-expiration-action(=value)?] [--entry-idle-time-custom-expiry=value] [--entry-time-to-live-custom-expiry=value] [--region-idle-time-expiration=value] [--region-idle-time-expiration-action(=value)?] [--region-time-to-live-expiration=value] [--region-time-to-live-expiration-action(=value)?] [--cache-listener=value(,value)*] [--cache-loader=value] [--cache-writer=value] [--async-event-queue-id=value(,value)*] [--gateway-sender-id=value(,value)*] [--enable-cloning(=value)?] [--eviction-max(=value)?] Parameters, alter region 名称 描述 默认值 --async-event-queue-id 将用于后写操作的异步事件队列的ID。 --cache-listener 要实例化的插件的完全限定类名，用于接收对区域及其条目的更改的事件后通知。 可以配置任意数量的缓存侦听器。 完全限定的类名可以附加一个JSON规范，该规范将被解析成为实现Declarable接口的类的init()方法的参数字段。 --cache-loader 要实例化的插件的完全限定类名，用于接收区域中缓存未命中的通知。 最多可以在该区域的每个成员中定义一个缓存加载器。 对于分布式区域，可以从具有定义区域的其他成员远程调用缓存加载器。 完全限定的类名可以附加一个JSON规范，该规范将被解析成为实现Declarable接口的类的initialize()方法的参数字段。 --cache-writer 要实例化的插件的完全限定类名，用于接收区域及其条目更改的事件前通知。 插件可能会取消该事件。 最多可以在该区域的每个成员中定义一个缓存写入器。 完全限定的类名可以附加一个JSON规范，该规范将被解析为实现Declarable接口的类的init()方法的参数字段。 --enable-cloning 确定fromDelta如何将增量应用于本地缓存以进行增量传播。 如果为true，则将更新应用于值的克隆，然后将克隆保存到缓存中。 如果为false，则在缓存中就地修改该值。 false --entry-idle-time-expiration 区域或条目到期之前的秒数。 指定-1表示此类型没有到期 -1 --entry-idle-time-expiration-action 应在区域或条目到期时发生的操作。选择以下过期操作之一:local-destroy，从本地缓存中删除区域或条目，但不将删除操作分发给远程成员。 您不能对分区区域条目使用此操作。 destroy，从缓存中完全删除区域或条目。 根据区域的分布设置分发销毁操作。 当群集中的任何应用程序不再需要区域或条目时，请使用此选项。使默认到期操作无效。 将区域中的条目或所有条目标记为无效。 根据区域范围分配失效。 当区域或条目不再对群集中的任何应用程序有效时，这是正确的选择。 local-invalidate将区域中的条目或所有条目标记为无效，但不分发操作。 您不能对分区区域条目使用此操作。 仅对未配置为复制区域的区域支持本地区域失效。 invalidate --entry-time-to-live-expiration 在区域或项过期前的秒数。指定-1表示该类型没有过期。 -1 --entry-time-to-live-expiration-action 应在区域或条目到期时执行的操作。选择以下过期操作之一: local-destroy从本地缓存中删除区域或条目，但不将删除操作分发给远程成员。您不能对分区区域条目使用此操作。 destroy从缓存中完全删除区域或条目。根据区域的分布设置分发销毁操作。当群集中的任何应用程序不再需要区域或条目时，请使用此选项。 invalidate默认到期操作。将区域中的条目或所有条目标记为无效。根据区域范围分配失效。当区域或条目不再对群集中的任何应用程序有效时，这是正确的选择。 local-invalidate将区域中的条目或所有条目标记为无效，但不分发操作。您不能对分区区域条目使用此操作。仅对未配置为复制区域的区域支持本地区域失效。 invalidate --entry-idle-time-custom-expiry 为入口空闲时间实现CustomExpiry的类的名称。 为初始化属性附加JSON字符串。 --entry-time-to-live-custom-expiry 实现CustomExpiry以进入生存时间的类的名称。 为初始化属性附加JSON字符串。 --eviction-max 驱逐算法用于确定何时执行其驱逐操作的驱逐属性的最大值。 最大值的单位由驱逐算法确定。 0 –gateway-sender-id 数据路由的网关发件人的ID。 –groups 该地区将被改变的成员组。 –name Required. 该地区的名称（包括路径）。 –region-idle-time-expiration 区域或条目到期之前的秒数。 如果未指定超时，则默认为零（这意味着没有到期）。 -1 –region-idle-time-expiration-action 应在区域或条目到期时执行的操作。选择以下过期操作之一:local-destroy从本地缓存中删除区域或条目，但不将删除操作分发给远程成员。您不能对分区区域条目使用此操作。 destroy从缓存中完全删除区域或条目。根据区域的分布设置分发销毁操作。当群集中的任何应用程序不再需要区域或条目时，请使用此选项。 invalidate默认到期操作。将区域中的条目或所有条目标记为无效。根据区域范围分配失效。当区域或条目不再对群集中的任何应用程序有效时，这是正确的选择。 local-invalidate将区域中的条目或所有条目标记为无效，但不分发操作。您不能对分区区域条目使用此操作。仅对未配置为复制区域的区域支持本地区域失效。 invalidate –region-time-to-live-expiration 区域或条目到期之前的秒数。 如果未指定超时，则默认为零（这意味着没有到期）。 -1 –region-time-to-live-expiration-action 应在区域或条目到期时执行的操作。选择以下过期操作之一:local-destroy从本地缓存中删除区域或条目，但不将删除操作分发给远程成员。您不能对分区区域条目使用此操作。 destroy从缓存中完全删除区域或条目。根据区域的分布设置分发销毁操作。当群集中的任何应用程序不再需要区域或条目时，请使用此选项。 invalidate默认到期操作。将区域中的条目或所有条目标记为无效。根据区域范围分配失效。当区域或条目不再对群集中的任何应用程序有效时，这是正确的选择。 local-invalidate将区域中的条目或所有条目标记为无效，但不分发操作。您不能对分区区域条目使用此操作。仅对未配置为复制区域的区域支持本地区域失效。 invalidate 示例命令: alter region --name=region1 --eviction-max=5000 [-group=all] 样本输出: gfsh>alter region --name=customer --eviction-max=5000 Member | Status ------- | ---------------------------------- server1 | Region \"/customer\" altered on \"server1\" alter runtime 在成员或成员运行时更改所有成员或成员子集的配置属性。 有关这些配置属性的更多信息，请参阅cache.xml 和配置参数参考。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: alter runtime [--members=value(,value)*] [--groups=value(,value)*] [--archive-disk-space-limit=value] [--archive-file-size-limit=value] [--log-disk-space-limit=value] [--log-file-size-limit=value] [--log-level=value] [--statistic-archive-file=value] [--statistic-sample-rate=value] [--enable-statistics=value] [--copy-on-read(=value)?] [--lock-lease=value] [--lock-timeout=value] [--message-sync-interval=value] [--search-timeout=value] Parameters, alter runtime 名称 描述 默认值 –members 要在运行时更改其配置的成员的名称或ID。 如果未指定此参数，则会使用群集配置服务为所有群集成员修改配置属性。 如果未指定，则使用群集配置服务的所有成员 –groups 要更改其成员的运行时配置的组的名称。 如果未指定此参数，则会使用群集配置服务为所有群集成员修改配置属性。 如果未指定，则使用群集配置服务的所有成员 –archive-disk-space-limit 归档磁盘空间限制。 组合的所有非活动统计归档文件的最大大小（以兆字节为单位）。 如果超出此限制，则会删除非活动归档文件，最先删除，直到总大小在限制范围内。 如果设置为零，则磁盘空间使用不受限制。 有效值为（以兆字节为单位）:0 - 1000000。 0 –archive-file-size-limit 存档文件大小限制。 单个统计存档文件的最大大小（以兆字节为单位）。 超过此限制后，将创建新的统计存档文件，并且当前存档文件将变为非活动状态。 如果设置为零，则文件大小不受限制。 有效值为（以兆字节为单位）:0 - 1000000。 0 –log-disk-space-limit 记录磁盘空间限制。 所有非活动日志文件的最大大小（以兆字节为单位）。 如果超出此限制，则会删除非活动日志文件，这是最早的，直到总大小在限制范围内。 如果设置为零，则磁盘空间使用不受限制。 有效值为（以兆字节为单位）:0 - 1000000。 0 –log-file-size-limit 日志文件大小限制。 日志文件关闭之前的最大大小（兆字节），并且日志记录将滚动到新的（子）日志文件。 如果设置为零，则禁用日志滚动。 有效值为（以兆字节为单位）:0 - 1000000。 0 –loglevel 新的日志级别。 此选项是必需的，您必须指定一个值。 有效值包括:ALL， TRACE， DEBUG，INFO，WARN，ERROR，FATAL，OFF。 INFO –statistic-archive-file 正在运行的系统成员写入统计样本的文件。 例如:“StatisticsArchiveFile.gfs”。 必须定义为将归档存储到文件。 将.gz后缀添加到文件名会导致它被压缩。 请参阅统计。 not set –statistic-sample-rate 统计抽样率。 有效值为（以毫秒为单位）:100 - 60000.请参阅统计。 1000 –enable-statistics 是否应启用统计抽样。 指定--statistic-archive-file将统计信息存储到文件中。 有效值为:true和false。 请参阅统计。 false –copy-on-read 对或错。 设置高速缓存读取操作的“读取时复制”功能。 请参阅安全条目修改。 false –lock-lease 设置此缓存获取的分布式锁定租约的长度（以秒为单位）。 请参阅设置缓存超时。 120 –lock-timeout 设置高速缓存操作在超时之前可等待以获取分布式锁定租约的秒数。 请参阅设置缓存超时。 60 –message-sync-interval 设置主缓存服务器节点将消息发送到所有辅助缓存服务器节点的频率（以秒为单位），以删除已从队列调度的事件。 请参阅更改服务器队列同步频率。 1 –search-timeout 设置缓存获取操作可用于搜索值的秒数。 请参阅设置缓存超时。 300 示例命令: alter runtime --members=server1 --loglevel=WARN --enable-statistics=true 样本输出: gfsh>alter runtime --members=server1 --loglevel=WARN --enable-statistics=true Runtime configuration altered successfully for the following member(s) 192.0.2.0(server1:240):64871 backup disk-store 将所有成员的持久数据备份到指定目录。 指定的目录必须存在于所有成员上，但它可以是每台计算机上的本地目录。 此命令可确保备份文件不会被并发操作损坏。 建议不要使用操作系统复制命令备份正在运行的系统。 您还可以使用此命令执行增量备份。 有关增量备份的详细信息，请参阅为系统恢复和操作管理创建备份。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: backup disk-store --dir=value [--baseline-dir=value] 名称 描述 --dir Required. 写入备份文件的目录。 --baseline-dir 包含用于在增量备份期间进行比较的基准备份的目录。增量备份操作会备份--baseline-dir中指定的目录中不存在的任何数据。 如果该成员找不到以前备份的数据，或者先前备份的数据已损坏，则该命令会对该成员执行完全备份。 Table 1. 备份磁盘存储参数 示例命令: backup disk-store --dir=data/backups backup disk-store --dir=data/backup/disk-store --baselineDir=data/backups/2012-09-24-17-08-50 样本输出: gfsh>backup disk-store --dir=data/backups The following disk stores were backed up successfully Member | UUID | Directory | Host ------- | ------------------------------------ | ------------------------------------ | --------------- server2 | a6bb11f0-0baa-45c9-b23e-64876d02a586 | c:\\PivotalGemFire70\\Latest\\server2\\. | 192.0.2.0 server1 | 8dc365bd-c086-4af4-99d0-86b0b521aa04 | c:\\PivotalGemFire70\\Latest\\server1\\. | 192.0.2.0 change loglevel 更改指定成员的日志记录级别。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: change loglevel --loglevel=value [--members=value(,value)*] [--groups=value(,value)*] Name Description Default Value --members Name or ID of one or more member(s) whose logging level you want to change. --groups One or more group names. The logging level changes for all members of these groups. --loglevel Required. Log level to change. Valid options are: ALL, TRACE, DEBUG, INFO, WARN, ERROR, FATAL, OFF. Table 1. 更改Loglevel参数 示例命令: gfsh>change loglevel --loglevel=DEBUG --members=server1 样本输出: gfsh>change loglevel --loglevel=DEBUG --members=server1 Summary Member | Changed log-level --------------------------------- | ----------------- 192.0.2.0(server1:3060):24653 | true clear defined indexes 清除所有已定义的索引。 索引定义本地存储在gfsh客户端上。 如果要创建一组新索引，或者如果一个或多个索引创建失败，则可能需要清除定义 另请参见define index。 可用性: Online or offline. 句法: clear defined indexes 示例命令: gfsh> clear defined indexes 样本输出: gfsh>clear defined indexes Index definitions successfully cleared close 关闭持久客户CQ和持久客户。 close durable-client 试图关闭一个持久的客户端。 必须断开客户端才能使此命令起作用。 close durable-cq 关闭持久客户端注册的持久连续查询（CQ），并从订阅队列中排除为持久CQ保留的事件。 close durable-client 试图关闭一个持久的客户端。 必须断开客户端才能使此命令起作用。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: close durable-client --durable-client-id=value [--members=value(,value)*] [--groups=value(,value)*] 名称 描述 --durable-client-id Required. 持久客户端的ID. --members 要关闭持久客户端的成员的名称或ID. --groups 持久客户将被关闭的成员组. Table 1. 关闭持久客户端参数 示例命令: close durable-client --durable-client-id=client1 样本输出: gfsh>close durable-client --durable-client-id=client1 Closed the durable client : \"client1\". on following members. 1.server4 2.server3 错误消息: gfsh>close durable-cq --durable-cq-name=cq1 --durable-client-id=client1 Could not close the durable-cq : \"cq1\" for the durable-client-id : \"client1\" due to following reasons. CacheClientProxy: Could not drain cq cq1 because client proxy id client1 is connected. Occurred on members 1.server4 2.server3 No client found with client-id : client1 Occurred on members 1.server1 close durable-cq 关闭持久客户端注册的持久连续查询（CQ），并从订阅队列中排除为持久CQ保留的事件。 可用性: Online. You must be connected in gfsh to a JMX Manager member to use this command. 句法: close durable-cq --durable-client-id=value --durable-cq-name=value [--members=value(,value)*] [--groups=value(,value)*] 名称 描述 --durable-client-id Required. 持久客户端的ID. --durable-cq-name Required. 要关闭的CQ的名称. --members 注册持久客户端的成员的名称或ID以及要关闭的持久CQ. --groups 持久客户注册的成员组和关闭的持久CQ. Table 2. 关闭Durable-CQ参数 示例命令: close durable-cq --durable-client-id=client1 --durable-cq-name=cq1 示例输出: gfsh>close durable-cq --durable-cq-name=cq1 --durable-client-id=client1 Closed the durable cq : \"cq1\" for the durable client : \"client1\". on following members. 1.server4 2.server3 错误消息: gfsh>close durable-client --durable-client-id=client1 Unable to close the durable client : \"client1\" due to following reasons. Cannot close a running durable client : client1 Occurred on members 1.server4 2.server3 No client found with client-id : client1 Occurred on members 1.server1 compact 压缩在线和离线磁盘存储。 compact disk-store 使用该磁盘存储在所有成员上压缩磁盘存储。 compact offline-disk-store 压缩脱机磁盘存储。 compact disk-store 使用该磁盘存储在所有成员上压缩磁盘存储。 此命令使用每个成员为其磁盘存储配置的压缩阈值。 磁盘存储必须将allow-force-compaction属性设置为true。 有关详细信息，请参阅在磁盘存储日志文件上运行压缩。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: compact disk-store --name=value [--groups=value(,value)*] 名称 描述 --name Required. 要压缩的磁盘存储的名称。 --groups 执行磁盘压缩的成员组。 如果未指定组，则磁盘存储将由所有成员压缩。 Table 1. 压缩磁盘存储参数 示例命令: compact disk-store --name=Disk1 compact disk-store --name=Disk1 --group=MemberGroup1,MemberGroup2 错误消息: \"Disk store \\\"{0}\\\" does not exist.\"; \" for group(s) \\\"{0}\\\"\"; \"No members found in the specified group(s) \\\"{0}\\\".\"; \"Compaction was attempted but nothing to compact.\"; \"Error occurred while doing compaction. Reason: \\\"{0}\\\"\"; compact offline-disk-store 压缩脱机磁盘存储。 如果磁盘存储很大，则可能需要使用-J=-XmxNNNm参数为进程分配额外的内存。 有关详细信息，请参阅在磁盘存储日志文件上运行压缩。 注意: 不要在增量备份的基线目录上执行脱机压缩。 可用性: Online or offline. 句法: compact offline-disk-store --name=value --disk-dirs=value(,value)* [--max-oplog-size=value] [--J=value(,value)*] 名称 描述 默认值 --name Required. 要压缩的脱机磁盘存储的名称。 --disk-dirs Required. 一个或多个目录，其中先前已写入磁盘存储的数据。 用逗号分隔目录。 --max-oplog-size 压缩创建的oplog的最大大小（以兆字节为单位）。 -1 --J 传递给Java虚拟机的参数在磁盘存储上执行压缩操作。 例如：-J=-Xmx1024m。 Table 2. 压缩离线磁盘存储参数 示例命令: compact offline-disk-store --name=Disk2 --disk-dirs=/Disks/Disk2 compact offline-disk-store --name=Disk2 --disk-dirs=/Disks/Disk2 --max-oplog-size=512 -J=-Xmx1024m configure 为集群中的所有缓存配置Portable Data eXchange。 configure pdx 为集群中的所有缓存配置Geode的Portable Data eXchange。 此命令不会影响系统中正在运行的成员。 此命令将使用群集配置服务在定位器中保留pdx配置。 注意: 应在启动任何数据成员之前发出此命令。 可用性: Online. 句法: configure pdx [--read-serialized=value] [--ignore-unread-fields=value] [--disk-store=value] [--auto-serializable-classes=value(,value)*] [--portable-auto-serializable-classes=value(,value)* 名称 描述 默认值 --read-serialized 设置为true以使PDX反序列化生成PdxInstance而不是域类的实例。 false --ignore-unread-fields 控制PDX是否忽略反序列化期间未读取的字段。 默认设置是在序列化期间保留未读字段包括其数据。 但是，如果将缓存配置为忽略未读字段，则在序列化期间它们的数据将丢失。如果您知道此成员将只读取缓存数据，则应仅将此属性设置为true。 在此用例中，您不需要支付保留未读字段的成本，因为您永远不会重新序列化PDX数据。 false --disk-store 命名磁盘存储，其中将存储PDX类型数据。 none --auto-serializable-classes 将ReflectionBasedAutoSerializer配置为成员类的PDX序列化程序。 与域类名称匹配的模式，以确定它们是否应自动序列化。 不检查类是否可以移植到非java语言（相当于check-portability=false）。 none --portable-auto-serializable-classes 将ReflectionBasedAutoSerializer配置为成员类的PDX序列化程序。 与域类名匹配的模式，以确定是否应序列化它们。 如果这些类的对象不能移植到非Java语言（相当于check-portability=true），PDX autoserializer完成的序列化将引发异常。 none Table 1. Configure PDX Parameters 示例命令: gfsh>configure pdx --read-serialized=true 示例输出: gfsh>configure pdx --read-serialized=true persistent = false read-serialized = true ignore-unread-fields = false gfsh>configure pdx --disk-store=/home/username/server4/DEFAULT.drf persistent = true disk-store = /home/username/server4/DEFAULT.drf read-serialized = false ignore-unread-fields = false 错误消息: \"Failed to persist the configuration changes due to this command, Revert the command to maintain consistency. Please use \"status cluster-config-service\" to determing whether Cluster configuration service is RUNNING.\" connect 直接或通过定位器连接到JMX管理器。 如果您通过定位器进行连接，并且JMX管理器尚不存在，则定位器将启动一个。 gfsh作为发现客户端连接到定位器服务并询问JMX Manager的位置。 定位器知道何时没有当前配置为JMX管理器的成员，只需在其自身内启动JMX管理器服务。 gfsh作为JMX客户端连接到定位器的JMX RMI端口。 您还可以使用HTTP协议连接到远程定位器，如下面的第二个示例所示。 可用性: Offline. 如果您已连接，您将收到“已连接到：主机[端口]”的通知。 句法: connect [--locator=value] [--jmx-manager=value] [--use-http(=value)?] [--url=value] [--user=value][--password=value] [--key-store=value] [--key-store-password=value] [--trust-store=value] [--trust-store-password=value] [--ciphers=value] [--protocols=value] [--security-properties-file=value] [--use-ssl(=value)?] [--skip-ssl-validation(=value)?] 名称 描述 默认值 --locator 定位器的网络地址格式为：host [port]。 localhost[10334] --jmx-manager JMX管理器的网络地址格式为：host [port]。 --use-http 使用HTTP协议连接到JMX管理器HTTP服务。 如果未指定参数：false如果指定的参数没有值：true --url 用于连接到JMX管理器的HTTP服务的URL http://localhost:8080/gemfire/v1 --user 连接到JMX管理器时用于身份验证的凭据的用户名。 如果指定，如果未指定--password选项，gfsh将提示输入密码。 --password 连接到JMX管理器时用于身份验证的凭据的密码部分。 --key-store 包含此应用程序的证书和私钥的Java密钥库文件。 如果未指定--key-store-password参数，gfsh会提示操作员输入密码。 --key-store-password 用于从--key-store指定的密钥库文件访问私钥的密码。 --trust-store 包含此应用程序信任的CA证书集合的Java密钥库文件。 如果未指定--trust-store-password参数，gfsh会提示操作员输入密码。 --trust-store-password 用于解锁--trust-store指定的密钥库文件的密码。 --ciphers 加密连接时使用的SSL/TLS密码。 默认值为“any”。 --protocols 加密连接时启用的SSL/TLS协议版本。 默认值为“any”。 --security-properties-file gfsecurity.properties文件，用于配置gfsh以连接到Locator/Manager。 文件路径可以是当前gfsh目录的绝对路径或相对路径。 --use-ssl 是否使用SSL与Locator和/或JMX Manager进行通信。 如果设置为true，则connect命令也会读取gfsecurity.properties。 SSL选项优先于属性文件中设置的值。 如果未指定，则使用默认值。 如果未指定参数：false如果指定的参数没有值：true --skip-ssl-validation 启用SSL通信并指定此选项或赋值为true时，此gfsh客户端接受任何SSL证书，允许此gfsh客户端验证它所连接的任何定位器或服务器。 此选项的存在是为了便于测试，而不适用于生产系统。 false Table 1. 连接参数 示例命令: 如果未指定定位器或JMX管理器，则gfsh将连接到默认端口上localhost上的定位器。 gfsh>connect 示例输出: gfsh>connect Connecting to Locator at [host=localhost, port=10334] .. Connecting to Manager at [host=GemFireStymon, port=1099] .. Successfully connected to: [host=GemFireStymon, port=1099] 通过HTTP连接到远程定位器的示例: gfsh>connect --use-http=true --url=\"http://myLocatorHost.example.com:8080/gemfire/v1\" Successfully connected to: GemFire Manager's HTTP service @ http://myLocatorHost.example.com:8080/gemfire/v1 错误消息: \"Locator could not find a JMX Manager\"; \"jmx password must be specified.\"; \"Could not connect to : {0}. {1}\"; \"Could not find a GemFire jmx-manager service running at {0}.\"; \"Could not connect to GemFire Locator service at {0}.\" create 创建异步事件队列，磁盘存储，网关接收器，网关发件人，索引和区域。 create async-event-queue 在网关发件人传递事件之前，为批处理事件创建异步事件队列。 create defined indexes 创建所有已定义的索引。 create disk-store 定义一个或多个磁盘存储池，可供区域和客户机订阅队列使用，以及网关发送方队列用于WAN分发。 create gateway-receiver 创建网关接收器。 每个成员只能有一个网关接收器，与网关发送器不同，您不需要为网关接收器指定标识符。 create gateway-sender 在群集的一个或多个成员上创建网关发件人。 create index 创建可在执行查询时使用的索引。 create jndi-binding 创建一个JNDI绑定，指定描述JDBC连接的资源属性。 create lucene index 创建具有给定路径和配置的区域。 create region 创建具有给定路径和配置的区域。 create async-event-queue 在网关发件人传递事件之前，为批处理事件创建异步事件队列。 请参阅配置多站点（WAN）事件队列。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: create async-event-queue --id=value --listener=value [--groups=value(,value)*] [--parallel(=value)?] [--enable-batch-conflation(=value)?] [--batch-size=value] [--batch-time-interval=value] [--persistent(=value)?] [--disk-store=value] [--disk-synchronous(=value)?] [--max-queue-memory=value] [--dispatcher-threads=value] [--order-policy=value] [--gateway-event-filter=value(,value)*] [--gateway-event-substitution-filter=value] [--listener-param=value(,value)*] Parameters, create async-event-queue: 名称 描述 默认值 –id Required. 异步事件队列的ID –groups 队列是在组的所有成员上创建的。 如果未指定组，则会在所有成员上创建队列。 –parallel 指定队列是否并行。 false –enable-batch-conflation 启用批处理混合。 false –batch-size 批处理可以包含的最大消息数。 100 –batch-time-interval 在批处理之前可以经过的最长时间（以毫秒为单位）。 5 –persistent 确定Geode是否持久保留此队列的布尔值。 false如果指定了一个值，则默认为true。 –disk-store 命名磁盘存储，用于存储队列溢出或持久化队列。 如果指定值，则必须存在指定的磁盘存储。 如果指定空值，Geode将使用默认磁盘存储来进行溢出和队列持久性。 –disk-synchronous 指定磁盘写入是否同步。 true –max-queue-memory 在溢出到磁盘之前队列可以消耗的最大内存量（兆字节）。 100 –dispatcher-threads 用于发送事件的线程数。 5 –order-policy 当–dispatcher-threads is > 1时调度事件的策略。可能的值是THREAD，KEY，PARTITION。 KEY –gateway-event-filter 此队列的GatewayEventFilters的完全限定类名列表。 这些类在分派到远程服务器之前过滤事件。 –gateway-event-substitution-filter 此队列的GatewayEventSubstitutionFilter的完全限定类名。 –listener Required. 此队列的Async Event Listener的完全限定类名 –listener-param 要传递给Async Event Listener类的参数名称和值。 （可选）您可以通过使用＃字符和值跟随参数名称来指定值。 例如：--listener-param=myParam#24 –forward-expiration-destroy 允许将到期销毁操作转发到AsyncEventListener实例。 如果指定没有值，则此参数设置为“false”。 false 示例命令: create async-event-queue --id=myAEQ --listener=myApp.myListener create defined indexes 创建所有已定义的索引。 另请参阅define index和clear defined indexes。 可用性: Online. 必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: create defined indexes [--members=value(,value)*] [--groups=value(,value)*] 参数，创建定义的索引: 名称 描述 默认值 --members 将在其上创建索引的成员的名称/ID。 --groups 将在成员组中的所有成员上创建索引。 示例命令: create defined indexes 示例输出: gfsh>create defined indexes Indexes successfully created. Use list indexes to get details. 1. ubuntu(server1:17682):27574 如果索引创建失败，您可能会在gfsh中收到类似于以下内容的错误消息: gfsh>create defined indexes Exception : org.apache.geode.cache.query.RegionNotFoundException , Message : Region ' /r3' not found: from /r3Occurred on following members 1. india(s1:17866):27809 create disk-store 定义一个或多个磁盘存储池，可供区域和客户机订阅队列使用，以及网关发送方队列用于WAN分发。 请参阅磁盘存储 可用性: Online. 必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: create disk-store --name=value --dir=value(,value)* [--allow-force-compaction(=value)?] [--auto-compact(=value)?] [--compaction-threshold=value] [--max-oplog-size=value] [--queue-size=value] [--time-interval=value] [--write-buffer-size=value] [--groups=value(,value)*] [--disk-usage-warning-percentage=value] [--disk-usage-critical-percentage=value] 参数，创建磁盘存储: 名称 描述 默认值 --name Required. 此磁盘存储的名称。 --dir Required. 写入磁盘存储文件的一个或多个目录名。 可选地，目录名后面可以跟#和磁盘存储可以在目录中使用的最大兆字节数。 例如：--dir=/data/ds1 --dir=/data/ds2#5000。如果指定的目录不存在，该命令将为您创建目录。 --allow-force-compaction 设置为true以允许在此磁盘存储上强制执行磁盘压缩。 false --auto-compact 设置为true以自动压缩磁盘文件。 true --compaction-threshold 磁盘存储符合压缩条件之前允许的垃圾百分比。 50 --max-oplog-size oplog文件的最大大小（以兆字节为单位）。 当oplog文件达到此大小时，该文件将转到新文件。 1024 --queue-size 可以异步排队以写入磁盘的最大操作数。 0 --time-interval 将未写入的数据写入磁盘之前可以经过的毫秒数。 1000 –groups 磁盘存储在组的所有成员上创建。 如果未指定组，则会在所有成员上创建磁盘存储。 --write-buffer-size 此磁盘存储在将数据写入磁盘时使用的写入缓冲区的大小。 较大的值可能会提高性能但会占用更多内存。 磁盘存储分配一个此大小的直接内存缓冲区。 32768 --disk-usage-warning-percentage 磁盘使用率高于此阈值会生成警告消息。 例如，如果阈值设置为90%，则在100 GB可用磁盘空间下的1 TB驱动器上会生成警告。设置为“0”（零）以禁用。 90 --disk-usage-critical-percentage 磁盘使用率高于此阈值会生成错误消息并关闭成员的缓存。 例如，如果阈值设置为99%，则1 TB驱动器上的10 GB可用磁盘空间不足会生成错误并关闭缓存。设置为“0”（零）以禁用。 99 示例命令: create disk-store --name-store1 --dir=/data/ds1 示例输出: gfsh>create disk-store --name-store1 --dir=/data/ds1 Member | Result ------- | ------- server1 | Success create gateway-receiver 创建网关接收器。 每个成员只能有一个网关接收器，与网关发送器不同，您不需要为网关接收器指定标识符。 除非指定了--groups或--members选项，否则创建将在所有服务器上进行。 如果网关接收器创建成功至少一个成员，则此gfsh命令退出，退出代码表示成功。 输出每个成员的网关接收器的表格格式状态，与创建的成功或失败无关。 请参阅网关接收器。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: create gateway-receiver [--groups=value(,value)*] [--members=value(,value)*] [--manual-start=value] [--start-port=value] [--end-port=value] [--bind-address=value] [--maximum-time-between-pings=value] [--socket-buffer-size=value] [--gateway-transport-filter=value(,value)*] [--hostname-for-senders=value] [--if-not-exists=(value)?] 参数，创建网关接收器: 名称 描述 默认值 --groups 网关接收器是在组的成员上创建的。 --members 要在其上创建网关接收器的成员的名称。 为了向后兼容，如果指定了此选项并且启用了集群配置，则不会保留网关接收器配置。 --manual-start 布尔值，指定是否需要手动启动网关接收器。 如果提供空值，则网关接收器自动启动默认值为“false”。 true --start-port 在指定可能的端口号范围时使用的起始端口号，此网关接收器将用于连接到其他站点中的网关发送器。 Geode在指定的端口号范围内选择一个未使用的端口号来启动接收器。 如果该范围内没有可用的端口号，则抛出异常。STARTPORT值包含在内，而ENDPORT值是独占的。 例如，如果指定STARTPORT =\"50510\"和ENDPOINT =\"50520\"，Geode会选择50510到50519之间的端口值。 5000 --end-port 定义在指定此网关接收器将用于来自其他站点中的网关发件人的连接的可能端口号范围时要使用的上限端口号。 Geode在指定的端口号范围内选择一个未使用的端口号来启动接收器。 如果该范围内没有可用的端口号，则抛出异常.ENDPORT值是独占的，而STARTPORT值是包含的。 例如，如果指定STARTPORT=\"50510\"和ENDPOINT=\"50520\"，Geode会选择50510到50519之间的端口值。 5500 --bind-address 来自其他站点中的网关发件人的连接的网络地址。 将地址指定为文字字符串值。 --socket-buffer-size 一个整数值，用于设置此网关接收器的套接字连接的缓冲区大小（以字节为单位）。 此值应与连接到此接收器的网关发件人的socket-buffer-size设置相匹配。 32768 --gateway-transport-filter 要添加到网关接收器的GatewayTransportFilter的完全限定类名。 --maximum-time-between-pings 整数值，指定ping到连接的WAN站点之间使用的时间间隔（以毫秒为单位）。 此值确定在将远程WAN站点视为脱机之前可以经过的最长时间。 60000 --hostname-for-senders 主机名或IP地址告知网关发件人作为他们连接的地址。 定位器通知网关发件人此值。 --if-not-exists 如果指定时未提供布尔值或指定并设置为true，则网关接收器（如果已存在）将不会创建。 命令输出报告每次创建尝试的状态。 false 示例命令: gfsh>create gateway-receiver --members=server1 示例输出: gfsh>create gateway-receiver --members=server1 Member | Status ------- | --------------------------------------------------------------------------- server1 | GatewayReceiver created on member \"server1\" and will listen on the port \"0\" create gateway-sender 在群集的一个或多个成员上创建网关发件人。 请参阅网关发件人。 注意: 在承载网关发件人的每个Geode成员上，特定发件人id的网关发件人配置必须相同。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: create gateway-sender --id=value --remote-distributed-system-id=value [--groups=value(,value)*] [--members=value(,value)*] [--parallel=value] [--manual-start=value] [--socket-buffer-size=value] [--socket-read-timeout=value] [--enable-batch-conflation=value] [--batch-size=value] [--batch-time-interval=value] [--enable-persistence=value] [--disk-store-name=value] [--disk-synchronous=value] [--maximum-queue-memory=value] [--alert-threshold=value] [--dispatcher-threads=value] [--order-policy=value][--gateway-event-filter=value(,value)*] [--gateway-transport-filter=value(,value)*] 参数，创建网关发件人: 名称 描述 默认值 --id Required. 网关发件人的唯一标识符，通常是与物理位置关联的标识符。 --remote-distributed-system-id Required. 此网关发件人发送事件的远程群集的ID。 --groups 网关发件人是在组成员上创建的。 --members 要在其上创建网关发件人的成员的名称。 --parallel 设置为true时，指定并行网关发件人。 false --enable-batch-conflation 确定Geode是否应该混淆消息的布尔值。 false --manual-start 不推荐使用 布尔值，指定是否需要手动启动网关发件人。 如果提供空值，则使用默认值false，网关发件人自动启动。 手动启动可能会导致数据丢失，因此不应在生产系统中使用手动启动。 false --socket-buffer-size 将消息发送到远程站点的套接字缓冲区的大小。 此大小应与处理区域事件的远程网关接收器的socket-buffer-size属性的大小相匹配。 32768 --socket-read-timeout 网关发件人等待从远程站点接收确认的时间量（以毫秒为单位）。 默认情况下，此值设置为0，表示没有超时。 如果设置此超时，则必须将其设置为最小值30000（毫秒）。 将其设置为较小的数字将生成错误消息并将值重置为默认值0。 0 --batch-size 批处理可以包含的最大消息数。 100 --batch-time-interval 发送批次之间可以经过的最大毫秒数。 1000 --enable-persistence 确定Geode是否持久保存网关队列的布尔值。 false --disk-store-name 命名磁盘存储，用于存储队列溢出或持久化队列。 如果指定值，则必须存在指定的磁盘存储。 如果指定空值，Geode将使用默认磁盘存储来进行溢出和队列持久性。 --disk-synchronous 对于写入磁盘的区域，boolean指定是否为该区域同步完成磁盘写入。 true --maximum-queue-memory 在溢出到磁盘之前队列可以消耗的最大内存量（兆字节）。 100 MB --alert-threshold 在Geode记录警报之前，区域事件可以保留在网关发件人队列中的最大毫秒数。 0 --dispatcher-threads 用于处理来自网关发件人队列或异步事件队列的区域事件的调度程序线程数。 5 --order-policy 当dispatcher-threads属性大于1时，order-policy配置多个调度程序线程处理来自串行网关队列或串行异步事件队列的区域事件的方式。此属性可以具有以下值之一：key从本地队列分发区域事件时，多个调度程序线程保留密钥更新的顺序。thread从本地队列分发区域事件时，多个调度程序线程保留给定线程将区域事件添加到队列的顺序。partition从本地队列分发区域事件时，多个调度程序线程保留区域事件添加到本地队列的顺序。对于分区区域，这意味着传递到特定分区的所有区域事件都以相同的顺序传递到远程Geode站点。对于分布式区域，这意味着传递到本地网关发送方队列的所有密钥更新都以相同的顺序分发到远程站点。您无法为并行事件队列配置order-policy，因为并行队列无法保留事件订购地区。只能保留给定分区（或分布式区域的给定队列）中事件的顺序。 key --gateway-event-filter 要与GatewaySender关联的GatewayEventFilters（由逗号分隔）的完全限定类名列表。 这用作用户在调度到远程集群之前过滤掉事件的回调。 例如：gateway-event-filter=com.user.filters.MyFilter1,com.user.filters.MyFilters2 --gateway-transport-filter 要添加到GatewaySender的GatewayTransportFilter的完全限定类名。 示例命令: gfsh>create gateway-sender --remote-distributed-system-id=\"2\" --id=\"sender2\" 示例输出: gfsh>create gateway-sender --remote-distributed-system-id=\"2\" --id=\"sender2\" Member | Status ------- | -------------------------------------------- server1 | GatewaySender \"sender2\" created on \"server1\" create index 创建可在执行查询时使用的索引。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 请参阅使用索引。 句法: create index --name=value --expression=value --region=value [--members=value(,value)*] [--type=value] [--groups=value(,value)*] 参数，创建索引: 名称 描述 默认值 --name Required. 要创建的索引的名称。 ‑‑expression Required. 索引引用的区域值的字段。 --region Required. 与查询中的“from”子句对应的区域的名称/路径。 --members 将在其上创建索引的成员的名称/ID。 --type 索引的类型。 有效值为：range和key。 （第三种类型，hash，仍然被识别，但不推荐使用哈希索引。） range --groups 将在组中的所有成员上创建索引。 示例命令: create index --name=myKeyIndex --expression=region1.Id --region=region1 --type=key 示例输出: gfsh>create index --name=myKeyIdex --expression=region1.Id --region=region1 --type=key Index successfully created with following details Name : myKeyIdex Expression : region1.Id RegionPath : /region1 Members which contain the index 1. ubuntu(server1:17682):27574 gfsh>create index --name=myIndex2 --expression=exp2 --region=/exampleRegion Failed to create index \"myIndex2\" due to following reasons Index \"myIndex2\" already exists. Create failed due to duplicate name. Occurred on following members 1. ubuntu(server1:17682):27574 create jndi-binding 创建一个JNDI绑定，指定描述JDBC连接的资源属性。 可用性: Online. 必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: create jndi-binding --name=value --type=value --jdbc-driver-class=value --connection-url=value [--blocking-timeout-seconds=value] [--conn-pooled-datasource-class=value] [--idle-timeout-seconds=value] [--init-pool-size=value] [--login-timeout-seconds=value] [--managed-conn-factory-class=value] [--max-pool-size=value] [--password=value] [--transaction-type=value] [--username=value] [--xa-datasource-class=value] [--if-not-exists(=value)?] [--datasource-config-properties=value(,value)*] 参数，创建jndi绑定: 名称 描述 默认值 --name Required. 要创建的绑定的名称。 --type Required. XA数据源的类型。 其中之一：MANAGED，SIMPLE，POOLED或XAPOOLED。 --jdbc-driver-class Required. JDBC驱动程序类的标准名称。 --connection-url Required. JDBC驱动程序连接URL字符串。 例如，jdbc:hsqldb:hsql://localhost:1701。 --blocking-timeout-seconds 指定在抛出异常之前等待连接时阻塞的最长时间（以秒为单位）。 --conn-pooled-datasource-class 包含XA数据源连接的连接池实现的标准名称。 --idle-timeout-seconds 指定连接在关闭之前可能处于空闲状态的时间（以秒为单位）。 --init-pool-size 指定池应保留的初始连接数。 --login-timeout-seconds 客户端线程因不活动而断开连接的秒数。 --managed-conn-factory-class 连接工厂实现的完全限定名称。 --max-pool-size 池中可以创建的最大连接数。 --password 创建新连接时使用的默认密码。 --transaction-type 交易类型。 一个是XATransaction，NoTransaction或LocalTransaction。 --username 指定创建新连接时要使用的默认用户名。 --xa-datasource-class javax.sql.XADataSource实现类的完全限定名。 --if-not-exists 如果为true，则如果已存在具有相同名称的jndi绑定，则不会创建重复的jndi绑定。 如果为false，则尝试创建重复的jndi绑定会导致错误。 如果指定的选项没有值，则该选项设置为true。 false --datasource-config-properties 自定义XADataSource驱动程序的属性。 附加包含（名称，类型，值）元组的JSON字符串以设置任何属性。 例如：--datasource-config-properties={'name':'name1','type':'type1','value':'value1'},{'name':'name2','type':'type2','value':'value2'} 示例命令: gfsh>create jndi-binding --name=jndi1 --type=SIMPLE \\ --jdbc-driver-class=org.apache.derby.jdbc.EmbeddedDriver \\ --connection-url=\"jdbc:derby:newDB;create=true\" create lucene index 创建Lucene索引。 有关Lucene索引创建的详细信息，请参阅Apache Lucene Integration。 有关Lucene相关的其他gfsh命令，请参阅describe lucene index, destroy lucene index, list lucene indexes 和 search lucene。 可用性: Online. 必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: create lucene index --name=value --region=value --field=value(,value)* [--analyzer=value(,value)*] [--serializer=value] [--group=value(,value)*] 参数，创建lucene索引: 名称 描述 默认值 --name Required. 要创建的索引的名称. --region Required. 要定义索引的区域的名称/路径. --field Required. 索引引用的区域值的字段，指定为以逗号分隔的列表。 要将整个值视为单个字段，请指定__REGION_VALUE_FIELD. ‑‑analyzer 分析器从文本中提取术语，指定为以逗号分隔的列表。 如果未指定，则默认分析器将用于所有字段。 如果指定，分析器的数量必须与指定的字段数完全匹配。 列出分析器时，对于将使用默认分析器的任何字段使用关键字DEFAULT。 Lucene StandardAnalyzer ‑‑serializer 与此索引一起使用的序列化程序的完全限定类名。 序列化器必须实现LuceneSerializer接口。 您可以使用内置的org.apache.geode.cache.lucene.FlatFormatSerializer来索引和搜索集合和嵌套字段。 如果未指定，则使用简单的默认序列化程序，该序列化程序仅索引和搜索区域对象的顶级字段. simple serializer --group 将在指定成员组中的所有成员上创建索引. 示例命令: gfsh>create lucene index --name=customerIndex --region=/Customer --field=__REGION_VALUE_FIELD gfsh>create lucene index --name=analyzerIndex --region=/Person --field=name,email,address,revenue --analyzer=DEFAULT,org.apache.lucene.analysis.core.KeywordAnalyzer, examples.MyCharacterAnalyzer,DEFAULT 示例输出: gfsh>create lucene index --name=testIndex --region=testRegion --field=__REGION_VALUE_FIELD Member | Status -------------------------------------- | --------------------------------- 192.168.1.23(server505:17200):1025 | Successfully created lucene index create region 创建具有给定路径和配置的区域。 在创建区域时，必须为初始配置指定--type或--template-region。 指定--key-constraint和--value-constraint会在查询和索引期间使对象类型信息可用。 请参阅区域数据存储和分发。 有关语法详细信息，请参阅在命令行选项中指定JSON。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: create region --name=value [--type=value] [--template-region=value] [--groups=value(,value)*] [--if-not-exists(=value)?] [--key-constraint=value] [--value-constraint=value] [--enable-statistics=value] [--entry-idle-time-expiration=value] [--entry-idle-time-expiration-action=value] [--entry-time-to-live-expiration=value] [--entry-time-to-live-expiration-action=value] [--entry-idle-time-custom-expiry=value] [--entry-time-to-live-custom-expiry=value] [--region-idle-time-expiration=value] [--region-idle-time-expiration-action=value] [--region-time-to-live-expiration=value] [--region-time-to-live-expiration-action=value] [--disk-store=value] [--enable-synchronous-disk=value] [--enable-async-conflation=value] [--enable-subscription-conflation=value] [--cache-listener=value(,value)*] [--cache-loader=value] [--cache-writer=value] [--async-event-queue-id=value(,value)*] [--gateway-sender-id=value(,value)*] [--enable-concurrency-checks=value] [--enable-cloning=value] [--concurrency-level=value] [--colocated-with=value] [--local-max-memory=value] [--recovery-delay=value] [--redundant-copies=value] [--startup-recovery-delay=value] [--total-max-memory=value] [--total-num-buckets=value] [--compressor=value] [--off-heap(=value)] [--partition-resolver=value] [--eviction-entry-count=value] [--eviction-max-memory=value] [--eviction-action=value] [--eviction-object-sizer=value] 参数，创建区域: 名称 描述 默认值 --name Required. 要创建的区域的名称/路径. --type Required （如果未指定template-region。）要创建的区域类型。 选项包括：PARTITION，PARTITION_REDUNDANT，REPLICATE，LOCAL等。要获取所有区域类型选项的列表，请添加--type参数，然后选择TAB键以显示完整列表. --template-region Required （如果未指定type。）创建此区域时应重复其属性的区域的名称/路径. --groups 将在其上创建区域的成员组. --if-not-exists 如果已存在具有相同名称的区域，则不会创建新区域。 默认情况下，尝试创建重复区域会报告为错误。 如果指定此选项没有值或指定值为true，则gfsh会显示“跳过...”确认，但不会引发错误. false --key-constraint 作为区域键允许的对象的完全限定类名。 确保区域条目的键都属于同一类. --value-constraint 允许作为区域值的对象的完全限定类名。 如果未指定，则区域值可以是任何类. --enable-statistics 是否收集该地区的统计数据。 必须为true才能在该地区使用expiration. --entry-idle-time-expiration 区域的条目可以在未被访问的情况下保留在缓存中多长时间. no expiration --entry-idle-time-expiration-action 对超过空闲到期的条目采取的操作。 有效的到期操作包括destroy，local-destroy，invalidate（默认），local-invalidate。 --entry-time-to-live-expiration 区域的条目可以在未被访问或更新的情况下保留在缓存中多长时间。 默认值为此类型没有到期。 no expiration --entry-time-to-live-expiration-action 对超过TTL到期的条目采取的措施。 有效的到期操作包括destroy，local-destroy，invalidate（默认），local-invalidate。 --entry-idle-time-custom-expiry 为条目空闲时间实现CustomExpiry的类的名称。 为初始化属性附加JSON字符串。 --entry-time-to-live-custom-expiry 实现CustomExpiry以进入生存时间的类的名称。 为初始化属性附加JSON字符串。 --region-idle-time-expiration 该区域可以在未被访问的情况下保留在缓存中多长时间。 默认值为此类型没有到期。 --region-idle-time-expiration-action 对超过空闲到期的区域采取的措施。 有效的到期操作包括destroy，local-destroy，invalidate（默认），local-invalidate。 --region-time-to-live-expiration 该区域可以在未被访问或更新的情况下保留在缓存中多长时间。 默认值为此类型没有到期。 no expiration --region-time-to-live-expiration-action 对超过TTL到期的区域采取的措施。 有效的到期操作包括destroy，local-destroy，invalidate（默认），local-invalidate。 --disk-store 此区域使用的磁盘存储。 list disk-stores命令可用于显示现有磁盘存储。 --enable-synchronous-disk 对于将数据持久保存到磁盘的区域，是否同步完成写入。 --enable-async-conflation 是否允许聚合由该区域的生产者成员发送的异步TCP/IP消息。 false值会导致所有异步消息单独发送。 --enable-subscription-conflation 服务器是否应将其消息与客户端混淆。 false值会导致所有服务器 - 客户端消息单独发送。 --cache-listener 要实例化的插件的完全限定类名，用于接收对区域及其条目的更改的事件后通知。 可以配置任意数量的缓存侦听器。 完全限定的类名可以附加一个JSON规范，该规范将被解析成为实现Declarable接口的类的init()方法的参数字段。 --cache-loader 要实例化的插件的完全限定类名，用于接收区域中缓存未命中的通知。 最多可以在该区域的每个成员中定义一个缓存加载器。 对于分布式区域，可以从具有定义区域的其他成员远程调用缓存加载器。 完全限定的类名可以附加一个JSON规范，该规范将被解析成为实现Declarable接口的类的initialize()方法的参数字段。 --cache-writer 要实例化的插件的完全限定类名，用于接收区域及其条目更改的事件前通知。 插件可能会取消该事件。 最多可以在该区域的每个成员中定义一个缓存写入器。 完全限定的类名可以附加一个JSON规范，该规范将被解析成为实现Declarable接口的类的init()方法的参数字段。 --async-event-queue-id 将用于后写操作的异步事件队列的ID。 --gateway-sender-id 要将数据路由到的网关发件人的ID。 --enable-concurrency-checks 是否实现了区域版本向量。 区域版本向量是版本控制方案的扩展，有助于复制区域的同步。 --enable-cloning 确定fromDelta如何将增量应用于本地缓存以进行增量传播。 如果为true，则将更新应用于值的克隆，然后将克隆保存到缓存中。 如果为false，则在缓存中就地修改该值。 --concurrency-level 估计将同时访问区域条目的最大应用程序线程数。 此属性不适用于分区区域。 --colocated-with 与该地区相关的中部地区。 --local-max-memory 此进程中区域使用的最大内存量（以兆字节为单位）。 (默认值为可用堆的90%。) --recovery-delay 现有成员在成员崩溃之后等待的延迟（以毫秒为单位），然后在其余成员上恢复此区域的冗余。 默认值（-1）表示在发生故障后不会恢复冗余。 --redundant-copies 所需桶的额外副本数量。 额外的副本允许面对VM离开（有意或无意）的高可用性和负载平衡读取操作。 （允许值：0,1,2和3） --startup-recovery-delay 新成员在假定其共享级别冗余之前将等待的延迟（以毫秒为单位）。 这允许在将冗余工作负载分配给新成员之前启动多个区域的时间。 值-1表示添加新成员不会触发冗余恢复。 默认设置是在添加新成员时立即恢复冗余。 --total-max-memory 所有进程中该区域使用的最大内存量（以兆字节为单位）。 --total-num-buckets 所有进程中该区域使用的哈希桶总数。 113 --compressor 实现区域压缩的Java类名称。 您可以编写一个实现org.apache.geode.compression.Compressor的自定义压缩器，或者您可以指定与Geode捆绑在一起的Snappy压缩器(org.apache.geode.compression.SnappyCompressor)。 请参阅区域压缩。 no compression --off-heap 指定区域值是存储在堆内存还是堆外内存中。 如果为true，则区域值位于堆外内存中。 如果指定的参数没有值，则使用true值。 false --partition-resolver 指定自定义分区解析程序的完整路径。 指定org.apache.geode.cache.util.StringPrefixPartitionResolver以使用包含的字符串前缀分区解析程序。 --eviction-entry-count 启用逐出，其中逐出策略基于区域中的条目数。 --eviction-max-memory 启用驱逐，其中驱逐策略基于区域消耗的内存量（以兆字节为单位）。 --eviction-action 达到驱逐阈值时采取的行动。 local-destroy: 条目在本地被销毁。 谨慎使用-可能导致不一致。 overflow-to-diskEntry: 条目溢出到磁盘。 对于分区区域，这提供了整个区域中最可靠的读取行为。 –eviction-object-sizer 指定ObjectSizer接口的实现，以测量区域中对象的大小。 sizer仅适用于基于堆和内存的驱逐。 示例命令: create region --name=region1 --type=REPLICATE_PERSISTENT \\ --cache-writer=org.apache.geode.examples.MyCacheWriter \\ --group=Group1 --disk-store=DiskStore1 create region --name=region12 --template-region=/region1 create region --name=region2 --type=REPLICATE \\ --cache-listener=org.apache.geode.examples.MyCacheListener1,\\ org.apache.geode.examples.MyCacheListener2 \\ --group=Group1,Group2 create region --name=region3 --type=PARTITION_PERSISTENT --redundant-copies=2 \\ --total-max-memory=1000 --startup-recovery-delay=5 --total-num-buckets=100 \\ --disk-store=DiskStore2 --cache-listener=org.apache.geode.examples.MyCacheListener3 \\ --group=Group2 create region --name=region4 --type=REPLICATE_PROXY \\ --cache-listener=org.apache.geode.examples.MyCacheListener1 --group=Group1,Group2 create region --name=myRegion --type=REPLICATE --eviction-max-memory=100 \\ --eviction-action=overflow-to-disk --eviction-object-sizer=my.company.geode.MySizer create region --name=r1 --type=PARTITION \\ --cache-loader=org.example.myLoader{'URL':'jdbc:cloudscape:rmi:MyData'} 示例输出: gfsh>create region --name=myRegion --type=LOCAL Member | Status ------- | --------------------------------------- server1 | Region \"/myRegion\" created on \"server1\" debug 在gfsh中启用或禁用调试输出。 可用性: Online or offline. 句法: debug --state=value 名称 描述 默认值 ‑‑state 是否打开或关闭调试。 有效选项包括：ON，OFF（不区分大小写） OFF Table 1. 调试参数 示例命令: debug --state=off debug --state=on 示例输出: gfsh>debug --state=on Debug is on define index 定义可在执行查询时使用的索引。 然后，您可以使用create defined indexes执行单个命令以一次创建多个索引。 可用性: Online or offline. 句法: define index --name=value --expression=value --region=value [--type=value] 名称 描述 默认值 --name Required. 要定义的索引的名称。 ‑‑expression Required. 索引引用的区域值的字段。 --region Required. Name/Path of the region which corresponds to the “from” clause in a query. --type Type of the index. Valid values are: range, key and hash. range Table 1. 定义索引参数 示例命令: gfsh> define index --name=myIndex1 --expression=exp1 --region=/exampleRegion gfsh> define index --name=myIndex2 --expression=”c.exp2” --region=\"/exampleRegion e, e.collection1 c\" gfsh> define index --name=myIndex3 --expression=exp3 --region=/exampleRegion --type=hash //then to create the indexes, execute: gfsh> create defined indexes 示例输出: gfsh>define index --name=myIndex1 --expression=exp1 --region=/exampleRegion Index successfully defined with following details Name : myIndex1 Expression : exp1 RegionPath : /exampleRegion deploy 将JAR打包的应用程序部署到一个或多个成员。 只能指定--jars或--dir中的一个。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: deploy [--groups=value(,value)*] [--jars=value(,value)*] [--dir=value] 名称 描述 ‑‑groups 将部署指定JAR的组。 如果未指定此选项，则将在所有成员上进行部署。 --jars 要部署的JAR的路径。 --dir 从中部署JAR的目录。 Table 1. 部署参数 示例命令: deploy --jars=group1_functions.jar --groups=Group1 deploy --dir=libs/group1-libs --groups=Group2 示例输出: gfsh> deploy --jars=group1_functions.jar --groups=Group1 Member | Deployed JAR | Deployed JAR Location --------- | -------------------- | --------------------------------------------------- datanode1 | group1_functions.jar | /usr/local/gemfire/deploy/GF#group1_functions.jar#1 datanode2 | group1_functions.jar | /usr/local/gemfire/deploy/GF#group1_functions.jar#1 gfsh> deploy --dir=libs/group1-libs --groups=Group2 Deploying files: group2_functions.jar, group2_dependencies.jar Total file size is: 0.64MB Continue? (Y/n): Y Member | Deployed JAR | Deployed JAR Location --------- | ----------------------- | --------------------------------------------- datanode3 | group2_functions.jar | /usr/local/gemfire/deploy/GF#group2_functions.jar#1 datanode3 | group2_dependencies.jar | /usr/local/gemfire/deploy/GF#group2_dependencies.jar#1 datanode4 | group2_functions.jar | /usr/local/gemfire/deploy/GF#group2_functions.jar#1 datanode4 | group2_dependencies.jar | /usr/local/gemfire/deploy/GF#group2_dependencies.jar#1 describe 显示成员配置，shell连接，磁盘存储，成员或区域的详细信息。 describe client 显示指定客户端的详细信息。 describe config 显示成员的配置。 describe connection 显示连接信息详细信息 describe disk-store 显示有关成员磁盘存储的信息。 describe jndi-binding 显示有关JNDI绑定配置的信息。 describe lucene index 显示有关Lucene索引的信息。 describe member 显示具有给定名称/ID的成员的详细信息。 describe offline-disk-store 显示有关脱机成员磁盘存储的信息。 describe region 显示区域的属性和关键信息。 describe client 显示指定客户端的详细信息。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: describe client --clientID=value 参数，描述客户端: 名称 描述 ‑‑clientID Required. 客户的ID。 要查找客户端ID，可以使用list clients命令显示已连接客户端及其ID的列表。 示例命令: describe client --clientID=192.0.2.0(4987:loner):58922:7b3398cf 示例输出: gfsh>describe client --clientID=192.0.2.0(4987:loner):58922:7b3398cf ------------------------------------------------------------------- Primary Servers : 192.0.2.0(server1:5764):15189 Secondary Servers : 192.0.2.0(server2:5891):39082 CPU : 0 Number of Cache Listner Calls : 0 Number of Gets : 0 Number of Misses : 0 Number of Puts : 0 Number of Threads : 0 Process CPU Time (nanoseconds) : 0 Queue size : 1 UP Time (seconds) : 67 Is Durable : No describe config 显示成员的配置。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: describe config --member=value [--hide-defaults(=value)?] 参数，描述配置: 名称 描述 默认值 --member 要显示其配置的成员的名称或ID。 --hide-defaults 是否使用默认值隐藏属性的配置信息。 true 示例命令: describe config --member=Member1; 示例输出: gfsh>describe config --member=server1 Configuration of member : \"server1\" JVM command line arguments ----------------------------------- -Dgemfire.mcast-port=0 -Dgemfire.locators=localhost[10334] GemFire properties defined using the API ................................................ log-file : vf.gf.server.log name : server1 GemFire properties defined at the runtime ................................................ log-level : finest statistic-sampling-enabled : true Cache attributes ................................................ is-server : true Cache-server attributes . bind-address : localhost describe connection 显示连接信息详细信息 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: describe connection 示例命令: describe connection 示例输出: gfsh>describe connection Connection Endpoints -------------------- GemFireUser[1099] describe disk-store 显示有关成员磁盘存储的信息。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: describe disk-store --member=value --name=value 参数，描述磁盘存储: 名称 描述 --member Required. 具有要描述的磁盘存储的成员的名称/ID。 --name Required. 要描述的磁盘存储的名称。 示例命令: describe disk-store --member=server1 --name=DiskStore1 示例输出: gfsh>describe disk-store --name=disk1 --member=server1 Disk Store ID : a531bc7b-5188-4510-85d7-de7de30c6671 Disk Store Name : disk1 Member ID : ubuntu(server1:7467):35249 Member Name : server1 Allow Force Compaction : No Auto Compaction : Yes Compaction Threshold : 50 Max Oplog Size : 1024 Queue Size : 0 Time Interval : 1000 Write Buffer Size : 32768 Disk Usage Warning Percentage : 90 Disk Usage Critical Percentage : 99 PDX Serialization Meta-Data Stored : No Disk Directory | Size ------------------------------- | ---------- /home/user/server1/DiskStore1 | 2147483647 describe jndi-binding 打印描述JDBC连接的配置信息。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: describe jndi-binding --name=value 参数，描述jndi绑定: 名称 描述 --name Required. 要描述的JNDI绑定的名称。 示例命令: describe jndi-binding --name=jndi1 示例输出: gfsh>describe jndi-binding --name=jndi1 Property | Value ----------------- | ------------------------------------ type | SimpleDataSource jndi-name | jndi1 jdbc-driver-class | org.apache.derby.jdbc.EmbeddedDriver user-name | connection-url | jdbc:derby:newDB describe lucene index 描述一个Lucene索引。 另请参阅create lucene index, destroy lucene index, list lucene indexes 和 search lucene. 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: describe lucene index --name=value --region=value 参数，描述lucene索引: 名称 描述 --name Required. 要描述的Lucene索引的名称 --region Required. Lucene索引所在区域的名称和路径 示例命令: gfsh>describe lucene index --name=personIndex --region=/Person 示例输出: gfsh>describe lucene index --name=personIndex --region=/Person Index Name | Region Path | Indexed Fields | Field Analyzer | Status | Query Executions | Updates | Commits | Documents ----------- | ----------- | ---------------------------------------------- | -------------- | ----------- | ---------------- | ------- | ------- | --------- personIndex | /Person | [name, email, address, streetAddress, revenue] | {} | Initialized | 339 | 1008 | 962 | 1004 gfsh>describe lucene index --name=analyzerIndex --region=/Person Index Name | Region Path | Indexed Fields | Field Analyzer | Status | Query Executions | Updates | Commits | Documents ------------- | ----------- | ---------------------- | ------------------------------------- | ----------- | ---------------- | ------- | ------- | --------- analyzerIndex | /Person | [address, name, email] | {address=MyCharacterAnalyzer, email.. | Initialized | 1695 | 1008 | 962 | 1004 describe member 显示具有给定名称/ID的成员的详细信息。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: describe member --name=value 参数，描述成员: 名称 描述 ‑‑name Required. 显示有关成员的信息，包括姓名，ID，组，区域等。 示例命令: describe member --name=server1 示例输出: gfsh>describe member --name=server1 Name : server1 Id : GemFireUser(server1:240):64871 Host : 192.0.2.0 Regions : region4 region5 region3 region2 region1 PID : 240 Groups : Used Heap : 5M Max Heap : 123M Working Dir : c:\\PivotalGemFire70\\Latest\\server1 Log file : C:\\PivotalGemFire70\\Latest\\server1\\vf.gf.server.log Locators : localhost[10334] Server Bind : localhost Server Port : 40404 Running : true Client Connections : 0 describe offline-disk-store 显示有关脱机成员磁盘存储的信息。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: describe offline-disk-store --name=value --disk-dirs=value(,value)* [--pdx=value] [--region=value] 参数，描述offline-disk-store: 名称 描述 --name Required. 要描述的磁盘存储的名称。 --disk-dirs Required. 包含磁盘存储文件的目录。 --pdx 如果设置（或设置为true），则显示存储在磁盘存储中的所有pdx类型。 --region 要描述的磁盘存储区中的区域的名称和路径。 示例命令: describe offline-disk-store --name=DiskStore1\\ --disk-dirs=/home/username/gemfire/mydiskStore1Dir describe offline-disk-store --name=DiskStore1 --disk-dirs=/DiskDir1 --pdx=true 示例输出: gfsh>describe offline-disk-store --name=DiskStore1 --disk-dirs=/DiskDir1 --pdx=true Regions in the disk store: /PdxTypes: -lru=none -concurrencyLevel=16 -initialCapacity=16 -loadFactor=0.75 -compressor=none -statisticsEnabled=false /Region1: -lru=none -concurrencyLevel=16 -initialCapacity=16 -loadFactor=0.75 -compressor=none -statisticsEnabled=false PDX Types: com.app.data.PositionPdx: id=1 long avg20DaysVol; String bondRating; double convRatio; String country; double delta; long industry; long issuer; double mktValue; double qty; String secId; // identity String secIdIndexed; String secLinks; double sharesOutstanding; String underlyer; long volatility; int pid; int portfolioId; com.app.data.StockPdx: id=2 int ID; // identity String pkid; Object position1; Object position2; Object positions; Object collectionHolderMap; String type; String status; String[] names; String description; long createTime; Object[] position3; Object aDay; Date date; PDX Enums: com.app.data.StockPdx$Day.Monday describe region 显示区域的属性和关键信息。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: describe region --name=value 参数，描述区域: 名称 描述 --name Required. 要描述的区域的名称/路径。 示例命令: describe region --name=region1 示例输出: gfsh>describe region --name=Region1 .......................................................... Name : Region1 Data Policy : persistent replicate Hosting Members : server-5 server-4 server-3 server-2 Non-Default Attributes Shared By Hosting Members Type | Name | Value ------ | --------------- | -------------------- Region | data-policy | PERSISTENT_REPLICATE | disk-store-name | DiskStore1 | size | 0 | scope | distributed-ack ........................................................... Name : Region1 Data Policy : empty Accessor Members : server-1 Non-Default Attributes Shared By Accessor Members Type | Name | Value ------ | ----------- | --------------- Region | data-policy | EMPTY | size | 0 | scope | distributed-ack destroy 删除或取消注册功能，删除索引，磁盘存储和区域。 destroy async-event-queue 销毁异步事件队列。 destroy disk-store 删除磁盘存储以及磁盘存储使用的磁盘上的所有文件。 destroy function 销毁或取消注册功能。 destroy gateway-sender 销毁网关发件人。 destroy index 销毁或删除指定的索引。 destroy jndi-binding 销毁指定的JNDI绑定。 destroy lucene index 销毁或删除指定的Lucene索引。 destroy region 销毁或删除某个地区。 destroy async-event-queue 销毁异步事件队列。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: destroy async-event-queue --id=value [--groups=value(,value)*] [--if-exists=value] 参数，销毁async-event-queue: 名称 描述 --id Required. 要删除的异步事件队列的ID. ‑‑groups 将销毁异步事件队列的成员组。 如果未指定组，则会在所有成员上销毁队列. ‑‑if‑exists 如果指定的异步事件队列不存在，gfsh将响应该消息。 如果此参数为true，则响应的前缀为“跳过：”标签。 对脚本测试很有用。 默认（如果未指定参数）：false。 默认值（如果指定的参数没有值）：true。 示例命令: destroy async-event-queue --id=myAsyncEventQueue destroy disk-store 删除磁盘存储以及磁盘存储使用的磁盘上的所有文件。 先前使用此磁盘存储的封闭区域的数据将丢失。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: destroy disk-store --name=value [--groups=value(,value)*] [--if-exists=value] 参数，销毁磁盘存储: 名称 描述 --name Required. 要删除的磁盘存储的名称。 ‑‑groups 将销毁磁盘存储的成员组。 如果未指定任何组，则会在所有成员上销毁磁盘存储。 ‑‑if‑exists 如果指定的磁盘存储不存在，gfsh将响应该消息。 如果此参数为true，则响应的前缀为“跳过：”标签。 对脚本测试很有用。 默认（如果未指定参数）：false。 默认值（如果指定的参数没有值）：true。 示例命令: destroy disk-store --name=store1 示例输出: gfsh>destroy disk-store --name=store1 Member | Result ------- | ------- server1 | Success destroy function 销毁或取消注册一个函数。 默认设置是从所有成员取消注册该函数。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: destroy function --id=value [--groups=value(,value)*] [--member=value] 参数，销毁函数: 名称 描述 --id Required. 唯一函数标识符。 使用list functions命令获取ID。 --groups 一个或多个成员组，从中取消注册此函数。 ‑‑member 将从中取消注册此函数的成员的名称或ID。 示例命令: (1) destroy function --id=InterestCalculations (2) destroy function --id=InterestCalculations --member=server1 (3) destroy function --id=InterestCalculations --group=Group1 destroy gateway-sender 销毁区域不再使用的网关发件人。 默认设置是在所有成员上销毁网关发件人。 没有区域可以附加到要销毁的网关发送方。 如果仍然附加了某个区域，系统会发出类似于以下内容的错误消息： ERROR: The GatewaySender ParallelGatewaySender{id=ln,remoteDsId=2,isRunning =false} could not be destroyed as it is still used by region(s). 使用类似于以下命令的命令从区域中删除网关发件人： gfsh>alter region --name=regionA --gateway-sender-id=\"\" 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: destroy gateway-sender --id=value [--groups=value(,value)*] [--members=value(,value)*] [--if-exists=value] 参数，销毁网关发送者: 名称 描述 --id Required. 唯一网关发件人标识 使用list gateways命令获取ID。 --groups 将从中销毁此网关发件人的一个或多个成员组。 ‑‑members 将从中销毁此网关发件人的成员的名称或ID。 ‑‑if‑exists 如果指定的网关发送方不存在，gfsh将响应该消息。 如果此参数为true，则响应的前缀为“跳过：”标签。 对脚本测试很有用。 默认（如果未指定参数）：false。 默认值（如果指定的参数没有值）：true。 示例命令: destroy gateway-sender --id=SiteASender destroy index 销毁或删除指定的索引。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: destroy index [--name=value] [--region=value] [--members=value(,value)*] [--groups=value(,value)*] [--if-exists=value] 注意: 您必须至少指定一个参数选项。 如果输入destroy index而没有任何参数，该命令将要求您指定至少一个选项。 参数，销毁索引: 名称 描述 --name 要删除的索引的名称。 ‑‑members 要删除索引的成员的ID。 --region 要从中销毁索引或所有索引的区域的名称。 --groups 将删除该组中所有成员的索引。 ‑‑if‑exists 如果指定的索引不存在，gfsh将响应该消息。 如果此参数为true，则响应的前缀为“跳过：”标签。 对脚本测试很有用。 默认（如果未指定参数）：false。 默认值（如果指定的参数没有值）：true。 示例命令: destroy index --members=server2 destroy index --name=MyKeyIndex destroy jndi-binding 销毁包含XA数据源配置的指定JNDI绑定。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: destroy jndi-binding --name=value [--if-exists=value] 参数，破坏jndi绑定: 名称 描述 --name Required. 要销毁的JNDI绑定的名称。 ‑‑if‑exists 当指定的JNDI绑定不存在时，跳过destroy操作。 如果没有此选项，则会因不存在的JNDI绑定的规范而导致错误。 默认（如果未指定参数）：false。 默认值（如果指定的参数没有值）：true。 示例命令: destroy jndi-binding --name=jndi1 destroy lucene index 销毁或删除指定的Lucene索引。 参见 create lucene index, describe lucene index, list lucene indexes 和 search lucene. 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: destroy lucene index --region=value [--name=value] 参数，销毁lucene索引: 名称 描述 ‑‑region Required. 要从中删除索引的区域的名称。 如果未指定--name选项，则销毁与该区域关联的所有索引。 ‑‑name 要删除的索引的名称。 示例命令: destroy lucene index --region=region1 destroy lucene index --region=region1 --name=MyKeyIndex destroy region 销毁或删除某个地区。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: destroy region --name=value [--if-exists=value] 参数，销毁区域: 名称 描述 --name Required. 要删除的区域的名称和路径。 ‑‑if‑exists 如果指定的区域不存在，gfsh将响应该消息。 如果此参数为true，则响应的前缀为“跳过：”标签。 对脚本测试很有用。 默认（如果未指定参数）：false。 默认值（如果指定的参数没有值）：true。 示例命令: destroy region --name=region4 destroy region --name=/region1/subregion1 示例输出: gfsh>destroy region --name=region1 \"region1\" destroyed successfully. disconnect 关闭所有活动连接。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: disconnect 示例命令: disconnect 示例输出: gfsh>disconnect Disconnecting from: Locator1[1099] Disconnected from : Locator1[1099] 错误消息: Error occurred while disconnecting: {0} Not connected! echo 回显给定文本，其中可能包括系统和用户变量。 该命令还可以回显gfsh环境属性（使用 ’set variable’命令）如果变量名称 预先加上$ - 就像UNIX一样。 有关gfsh环境变量的列表，请参阅有用的gfsh Shell变量。 可用性: Online or offline. 句法: echo [--string=value] 名称 描述 --string 要回显的字符串。 例如，SYS_USER变量设置为${SYS_USER}。 Table 1. 回显参数 示例命令: echo --string=\"Hello World!\" echo --string=\"Hello World! This is ${SYS_USER}\" echo --string=${APP_FETCH_SIZE} 要查看shell中设置的所有变量： echo --string=$* 示例输出: gfsh>echo --string=${SYS_JAVA_VERSION} Post substitution: echo --string=1.8.0_60 1.8.0_60 execute function 在成员或区域上执行函数。 执行函数 执行具有指定ID的函数。 默认情况下，该函数在所有成员上执行。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: execute function --id=value [--groups=value(,value)*] [--members=value(,value)*] [--region=value] [--arguments=value(,value)*] [--result-collector=value] [--filter=value] --id Required. ID of the function to execute. --groups One or more groups of members on which this function should be executed. --members Name/ID of the member(s) on which the function will be executed. --region Region on which the data dependent function will be executed. --arguments Arguments to the function in comma separated string format. --result-collector Fully qualified class name of the ResultCollector to instantiate for gathering results. --filter Key list which causes the function to only be executed on members which have entries with these keys. Table 1. 执行函数参数 示例命令: execute function --id=InterestCalculations --region=/InterestRegion execute function --id=InterestCalculations --members=server1 execute function --id=InterestCalculations --groups=Group1 exit 退出gfsh shell。 您也可以使用quit退出shell。 退出gfsh shell并返回OS shell。 可用性: Online or offline. 句法: exit 示例命令: exit export 导出配置，数据，日志和堆栈跟踪。 export cluster-configuration 导出包含配置和操作集群所需的cache.xml文件，gemfire.properties文件和应用程序JAR文件的集群配置ZIP文件。 export config 导出成员或成员的配置属性。 export data 将用户数据从区域导出到文件。 export logs 将日志导出到给定目录。 export offline-disk-store 将区域数据从脱机磁盘存储导出到gemfire快照文件。 export stack-traces 导出一个或多个成员的堆栈跟踪。 export cluster-configuration 使用群集配置导出单个XML文件或ZIP文件，其中包含配置和操作群集所需的cache.xml文件，gemfire.properties文件和应用程序JAR文件。 如果既未指定文件名也未指定ZIP文件名，则群集配置将写入标准输出。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 参见 Overview of the Cluster Configuration Service. 句法: export cluster-configuration [--group(=value)?] [--xml-file=value] [--zip-file-name=value] 导出群集配置参数: 名称 描述 默认值 ‑‑group 导出指定服务器组的配置。 如果未指定组，请使用默认的cluster组。 ‑‑xml-file 用于包含导出的群集配置的文件名。 也可能包括绝对或相对路径。 只指定--xml-file或--zip-file-name中的一个。 ‑‑zip-file-name 包含导出的群集配置的ZIP文件的文件名。 也可能包括绝对或相对路径。 只指定--xml-file或--zip-file-name中的一个。 示例命令: gfsh>export cluster-configuration --zip-file-name=/group/shared-configs/devClusterConfig.zip gfsh>export cluster-configuration --zip-file-name=my-configs/myClusterConfig.zip gfsh>export cluster-configuration --zip-file-name=myClusterConfig.zip gfsh>export cluster-configuration --xml-file=Cluster3Config.xml 示例输出: gfsh>export cluster-configuration --zip-file-name=mySharedConfig.zip Downloading cluster configuration : /home/username/gemfire/mySharedConfig.zip export config 导出成员或成员的配置属性。 如果未指定任何参数，则将导出所有成员配置。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: export config [--members=value(,value)*] [--groups=value(,value)*] [--dir=value] 导出配置参数: 名称 描述 --members 将导出其配置的成员的名称/ID。 --groups 将导出其配置的成员组。 --dir 将写入导出的配置文件的目录。 示例命令: export config export config --members=member1 示例输出: gfsh>export config --members=member1 Downloading Cache XML file: c:\\PivotalGemFire\\Latest\\.\\member1-cache.xml Downloading properties file: c:\\PivotalGemFire\\Latest\\.\\member1-gf.properties export data 将用户数据从一个区域导出到一个或多个文件。 可用性: 线上。 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: 要将数据从任何区域（已复制或已分区）按顺序导出到单个文件，请使用--file选项: export data --region=value --member=value --file=value 在此方案中，来自复制和分区区域的数据将按顺序导出到指定成员上的单个文件中。 对于分区区域，可以使用--parallel选项加快导出过程: export data --parallel --region=value --member=value --dir=value 在这种情况下，分区区域数据在所有托管节点上同时导出到这些相应节点的本地目录。 并行导出仅适用于分区区域。 --file和--dir选项是互斥的; --file只能用于串行导出，--dir可用于串行和并行导出。 导出数据参数: 名称 描述 --region Required. 要从中导出数据的区域. ‑‑member Required. 托管该区域的成员的Name/ID。 在串行导出中，所有数据都将导出到运行该成员的主机上的指定文件中。 在并行导出中，来自部分托管在此成员上的分区区域的数据将为每个分区导出到承载这些分区的节点上的文件. --file 要写入导出数据的文件。 该文件必须具有.gfd的扩展名。 不能与--dir同时指定，不能与--parallel一起使用. --dir 要写入导出数据的目录。 如果--parallel为true，则为必需。 不能同时指定--file. --parallel 将每个节点上的本地数据导出到该计算机上的目录。 仅适用于分区区域. 示例命令: export data --region=region2 --file=region2_20121001.gfd --member=server2 样本输出: gfsh>export data --region=region2 --file=region2_20121001.gfd --member=server1 Data succesfully exported from region : region2 to file : C:\\PivotalGemFire\\ Latest\\server1\\region2_20121001.gfd on host : 192.0.2.0 export logs 将日志导出到给定目录。 将导出具有指定时间范围内日志的所有文件。 如果未指定时间范围，则将导出所有日志。 --dir参数指定将写入日志文件的本地目录。 仅在使用http连接导出日志时使用。 如果通过http执行，则zip存档将保存在用户客户端计算机上的指定目录中。 如果未指定，则将日志写入user.dir系统属性指定的位置。 当命令在JMX上执行时，日志将在连接的定位器的工作目录中保存为exportedlogs_xxx.zip。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: export logs [--dir=value] [--groups=value(,value)*] [--members=value(,value)*] [--log-level=value] [--only-log-level=value] [--merge-log=value] [--start-time=value] [--end-time=value] [logs-only(=value)?] [--stats-only(=value)?] [--file-size-limit(=value)?] 导出日志参数: 名称 描述 默认值 --dir 使用http连接导出日志时将写入日志文件的本地目录。 在JMX上执行命令时忽略。 --groups 将导出其日志文件的成员组。 ‑‑members 将导出其日志文件的成员的名称/ID。 --log-level 要导出的最低日志条目级别。 有效值包括：OFF，FATAL，ERROR，WARN，INFO，DEBUG，TRACE 和 ALL。 INFO --only-log-level 是否仅包含与指定的--log-level完全匹配的条目。 false ‑‑merge‑log 导出到目标目录后是否合并日志（不建议使用）。 false --start-time 将导出此时间之后发生的日志条目。 格式：yyyy/MM/dd/HH/mm/ss/SSS/z 或者 yyyy/MM/dd no limit --end-time 将导出在此时间之前发生的日志条目。 格式：yyyy/MM/dd/HH/mm/ss/SSS/z 或者 yyyy/MM/dd no limit --logs-only 是否仅导出日志（不是统计信息） 如果未指定参数：false。 如果指定的参数没有值：true --stats-only 是否仅导出统计信息（不是日志） 如果未指定参数：false。 如果指定的参数没有值：true --file-size-limit 限制导出文件的总解压缩大小。 指定0（零）无限制。 默认值为兆字节，或者可以指定[k，m，g，t]。 如果未指定参数：100m。 如果指定的参数没有值：0 示例命令，显示输出: gfsh>export logs --dir=data/logs Logs exported to the connected member's file system: /my-locator/data/logs/exportedLogs_1489513007261.zip gfsh>export logs --dir=data/logs --file-size-limit=1k Estimated exported logs expanded file size = 95599, file-size-limit = 1024. To disable exported logs file size check use option \"--file-size-limit=0\". gfsh>export logs --dir=data/logs --file-size-limit=99k Logs exported to the connected member's file system: /my-locator/data/logs/exportedLogs_1489513007261.zip export offline-disk-store 将区域数据从脱机磁盘存储导出到gemfire快照文件。 可用性: Online or offline. 句法: export offline-disk-store --name=value --disk-dirs=value(,value)* --dir=value 导出脱机磁盘存储参数: 名称 描述 --name Required. 要导出的磁盘存储的名称。 --disk-dirs 包含磁盘存储文件的目录。 --dir 将快照文件导出到的目录。 示例命令: export offline-disk-store --name= DiskStore1 \\ --disk-dirs=/home/username/gemfire/mydiskStore1Dir --dir=/home/username/gemfire/export export stack-traces 导出一个或多个成员的堆栈跟踪。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: export stack-traces --file=value [--members=value(,value)*] [--groups=value(,value)*] 导出堆栈跟踪参数: 名称 描述 --file Required. 要写入堆栈跟踪的文件名。 --members 将导出其日志文件的成员的名称或ID。 --groups 将导出其日志文件的成员组。 示例命令: export stack-traces --file=stack.txt 示例输出: gfsh>export stack-traces --file=stack.txt stack-trace(s) exported to file: C:\\PivotalGemFire\\Latest\\locator1\\stack.txt On host : GemFireStymon gc 对一个或多个成员强制GC（垃圾收集）。 默认设置是在所有缓存成员上进行垃圾收集。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: gc [--groups=value(,value)*] [--member=value] 名称 描述 --groups 将强制进行垃圾收集的一个或多个成员组。 --member 将强制进行垃圾收集的成员的名称/ID。 Table 1. GC 参数 示例命令: gc --member=server1 gc --groups=Group1 gc 示例输出: gfsh>gc Sucessfully executed GC get 显示区域中的条目。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: get --key=value --region=value [--key-class=value] [--value-class=value] 名称 描述 默认值 --key Required. 从中创建键的字符串或JSON文本。 例如：“James”, “100L” and “('id': 'l34s')”。 ‑‑region Required. 从中获取条目的区域。 --key-class 键类型的完全限定类名。 默认值是当前区域或String的键约束。 --value-class 值类型的完全限定类名。 默认值是当前区域或String的值约束。 --load-on-cache-miss 在为高速缓存未命中时检索指定Key的值时，显式启用或禁用在指定Region上使用任何已注册的CacheLoader。 true (enabled) Table 1. Get 参数 示例命令: get --key=('id':'133abg124') --region=region1 // Retrieving when key type is a wrapper(primitive)/String get --key=('133abg124') --region=/region1/region12 --value-class=data.ProfileDetails get --key=('100L') --region=/region1/region12 --value-class=data.ProfileDetails --key-class=java.lang.Long 示例输出: gfsh>get --key=('123') --region=region1 Result : true Key Class : java.lang.String Key : ('123') Value Class : java.lang.String Value : ABC help 显示所有可用命令的语法和用法信息。 在没有命令作为参数的情况下键入帮助会列出所有可用命令。 可用性: Online or offline. 句法: help [command] Examples Commands: help help rebalance 示例输出: gfsh>help rebalance NAME rebalance IS AVAILABLE true SYNOPSIS Rebalance partitioned regions. The default is for all partitioned region s to be rebalanced. SYNTAX rebalance [--include-region=value(,value)*] [--exclude-region=value(,val ue)*] [--time-out=value] [--simulate(=value)?] PARAMETERS include-region Partitioned regions to be included when rebalancing. Includes ta ke precedence over excludes. Required:false exclude-region Partitioned regions to be excluded when rebalancing. Required:false time-out Time to wait (in seconds) before GFSH returns to a prompt while rebalancing continues in the background. The default is to wait for rebalancing to complete. Required:false Default if the parameter is not specified:-1 simulate Whether to only simulate rebalancing. The --time-out parameter i s not available when simulating. Required:false Default if no value for the parameter is given:true Default if the parameter is not specified:false hint 显示有关主题的信息以及与主题关联的命令列表。 提供主题提示或列出所有可用主题（如果未指定主题）。 可用性: Online or offline. 句法: hint [topic] 示例命令: hint hint Server 示例输出: gfsh>hint Hints are available for the following topics. Use \"hint \" for a specific hint. Configuration Data Debug-Utility Disk Store Function Execution GFSH Help JMX Lifecycle Locator Management-Monitoring Manager Region Server Statistics gfsh>hint server A server is GemFire cluster member which holds a GemFire cache. Depending on the topology used it can refer to either a system that responds to client requests or a system that is only a peer to other members. describe member : Display information about a member, including name, id, groups , regions, etc. export logs : Export the log files for a member or members. list members : Display all or a subset of members. start server : Start a GemFire Cache Server. status server : Display the status of a GemFire Cache Server. stop server : Stop a GemFire Cache Server.. history 显示或保存命令历史记录。 此历史记录可以保存到文件中，以后也可以用作脚本。 已成功执行的命令历史记录也记录在运行gfsh的用户的主目录中的.geode/.gfsh.history文件中。 可用性: Online or offline. 句法: history [--file=] 名称 描述 默认值 --file 要保存历史记录的文件。 --clear 设置为true时，清除gfsh命令的历史记录。 false Table 1. History 参数 示例命令: history history --file=./mycommands.gfsh; 示例输出: gfsh>history --file=./mycommands.gfsh Wrote successfully to file ./mycommands.gfsh import 您可以导入导出的群集配置以创建新群集或将数据导入区域。 import cluster-configuration 导入群集配置。 import data 将用户数据从文件导入区域。 import cluster-configuration 从ZIP文件或XML文件导入以前导出的群集配置。 在启动新群集时，此命令很有用。 在给定群集中，只有一个定位器需要执行导入。 该定位器与集群中所有其他连接的定位器共享导入的配置。 当服务器启动时，定位器与数据成员（服务器）共享导入的配置，或者最近启动了服务器，没有在其中定义区域，并且自启动以来没有给出任何其他配置更改。 要导入集群配置，请启动一个或多个定位器，然后运行gfsh``import cluster-configuration命令。 可用性: Online. 您必须在gfsh中连接到定位器才能使用此命令。 句法: import cluster-configuration [--action=value] [--group(=value)?] [--xml-file=value] [--zip-file-name=value] Import Cluster-Configuration 参数: 名称 描述 ‑‑action 当值为APPLY（默认值）时，配置将应用于没有配置的正在运行的服务器。 如果任何服务器已配置，则命令失败。 当值为STAGE时，配置将被覆盖，并将在将来的服务器创建期间使用; 当前运行的服务器的配置不会更改。 ‑‑group 执行指定服务器组的导入。 如果没有指定组，则隐含cluster。 ‑‑xml-file 用于导入群集配置的文件名。 也可能包括绝对或相对路径。 只指定--xml-file或--zip-file-name中的一个。 --zip-file-name 包含要导入的集群配置工件的ZIP文件的名称。 只指定--xml-file或--zip-file-name中的一个。 示例命令: gfsh>import cluster-configuration --zip-file-name=/home/username/myClusterConfig.zip gfsh>import cluster-configuration --xml-file=configs/Cluster3Config.xml 示例输出: gfsh>import cluster-configuration --zip-file-name=/home/username/myClusterConfig.zip Cluster configuration successfully imported import data 将用户数据从一个或多个文件导入区域。 可用性: 线上。 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: 如果数据按顺序导出到单个文件，请使用import命令的序列形式导入数据: import data --region=value --file=value --member=value [--invoke-callbacks=value] 在此方案中，从指定成员上的单个文件顺序导入来自复制和分区区域的数据。 有关串行和并行数据导出之间差异的说明，请参阅导出数据。 如果数据是以并行格式从分区区域导出的，请使用--parallel选项导入数据: import data --parallel --region=value --member=value --dir=value [--invoke-callbacks=value] 在这种情况下，分区区域数据在所有托管节点上从这些相应节点的本地目录同时导入。 并行导入仅适用于以并行模式导出的分区区域。 --file和--dir选项是互斥的; --file只能用于串行导入，--dir可用于串行和并行导入。 导入数据参数: 名称 描述 缺省值 --region Required. 将导入数据的区域. ‑‑member Required. 托管该区域的成员的Name/ID。 在串行导入中，所有数据都是从运行该成员的主机上的指定文件导入的。 在并行导入中，从托管这些分区的节点上的文件为每个分区导入部分托管在此成员上的分区区域的数据。 --file 将从中读取导入数据的文件。 该文件必须具有.gfd的扩展名，并且必须位于该成员的文件系统上（或通过NFS可访问该成员），该目标是导入。 不能与--dir同时指定，不能与--parallel一起使用. --dir 从中导入数据的目录。 如果--parallel为true，则为必需。 不能同时指定--file。 如果给定节点在指定目录中没有数据文件，则会以静默方式跳过该节点的导入操作. ‑‑invoke‑callbacks 布尔值，当为true时，在数据导入期间调用回调. false 示例命令: import data --region=region2 --file=/mnt5/region2_20121001.gfd --member=server1 list 列出现有的Geode资源，例如已部署的应用程序，磁盘存储，功能，成员，服务器和区域。 list async-event-queues 显示所有成员的异步事件队列列表。 list clients 显示已连接客户端的列表。 list deployed 显示使用deploy命令部署到成员的JAR列表。 list disk-stores 列出Geode集群中的所有可用磁盘存储 list durable-cqs 列出与指定的持久客户端ID关联的持久客户端CQ。 list functions 显示已注册的函数列表。 默认设置是显示所有成员的功能。 list gateways 显示一个或多个成员的网关发件人和收件人。 list indexes Display the list of indexes created for all members. list jndi-binding List all JNDI bindings, active and configured. list lucene indexes 列出为所有成员创建的Lucene索引。 list members 显示全部或部分成员。 list regions 显示成员或成员的区域。 如果未指定参数，则列出群集中的所有区域。 list async-event-queues 显示所有成员的异步事件队列列表。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: list async-event-queues 示例命令: list async-event-queues list clients 显示已连接客户端的列表。 显示已连接客户端及其连接的服务器的列表。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: list clients 示例命令: list clients 示例输出: gfsh>list clients ClientList Client Name / ID | Server Name / ID ----------------------------------------- | ----------------------------------------------------- 192.0.2.0(4987:loner):58922:7b3398cf | member=server2,port=53508; member=server1,port=56806 192.0.2.0(5065:loner):39906:a6f598cf | member=server2,port=53508; member=server1,port=56806 list deployed 显示使用deploy命令部署到成员的JAR列表。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: list deployed [--groups=value(,value)*] 参数，已部署列表: 名称 描述 ‑‑groups 将显示已部署JAR的成员组。 如果未指定，则显示所有成员的JAR。 示例命令: list deployed list deployed --groups=Group2 示例输出: gfsh> list deployed --groups=Group2 Member | Deployed JAR | JAR Location --------- | -------------------- | --------------------------------------------------- datanode1 | group1_functions.jar | /usr/local/gemfire/deploy/vf.gf#group1_functions.jar#1 datanode2 | group1_functions.jar | /usr/local/gemfire/deploy/vf.gf#group1_functions.jar#1 错误消息: No JAR Files Found list disk-stores 列出Geode集群中的所有可用磁盘存储 该命令还使用磁盘存储列出已配置的磁盘目录以及任何区域，高速缓存服务器，网关，PDX序列化和异步事件队列，以便将信息溢出和/或保留到磁盘。 使用describe disk-store命令查看特定磁盘存储的详细信息。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: list disk-stores 示例命令: list disk-stores 示例输出: gfsh> list disk-stores Member Name | Member Id | Disk Store Name | Disk Store ID -------------- | --------------------------------------------- | --------------- | ------------------------------------ consumerServer | 192.0.2.0(consumerServer:13825):3545 | consumerData | 4029af26-fd82-4997-bd6c-33382cdbb5e9 consumerServer | 192.0.2.0(consumerServer:13825):3545 | observerData | 7e0316ad-963c-49b0-9b01-8f59b8d9e29e producerServer | 192.0.2.0(producerServer:13826):53764 | producerData | 4670e4eb-1c50-4465-b418-08ede3d5dbed 错误消息: gfsh> list disk-stores No Disk Stores Found list durable-cqs 列出与指定的持久客户端ID关联的持久客户端CQ。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: list durable-cqs --durable-client-id=value [--members=value(,value)*] [--groups=value(,value)*] 参数, 列出 durable-cqs: 名称 描述 --durable-client-id Required. 用于标识持久客户端的ID。 --members 注册持久客户端的成员的名称或ID以及将显示持久CQ。 --groups 将显示持久客户注册的成员组和持久CQ。 示例命令: list durable-cqs --durable-client-id=client1 样本输出: gfsh>list durable-cqs --durable-client-id=client1 member | durable-cq-name ------- | --------------- server3 | cq3 | cq1 | cq2 server4 | cq3 | cq1 错误消息: gfsh>list durable-cqs --durable-client-id=client1 Unable to list durable-cqs for durable-client-id : \"client1\" due to following reasons. No client found with client-id : client1 Occurred on members 1.server4 2.server1 3.server3 list functions 显示已注册的函数列表。 默认设置是显示所有成员的函数。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: list functions [--matches=value] [--groups=value(,value)*] [--members=value(,value)*] 参数，列表函数: 名称 描述 --matches 函数ID必须匹配才能包含的模式。 使用Java模式匹配规则，而不是UNIX。 例如，要多次匹配任何字符，请使用“.”而不是“”。 --groups 将显示函数的成员组。 对多个组使用逗号分隔列表。 ‑‑members 将显示函数的成员的名称或ID。 对多个成员使用逗号分隔列表。 示例命令: gfsh> list functions gfsh> list functions --matches=reconcile.* 示例输出: list functions Member | Function --------- | -------------------------- camelot | loadDataFromExternalSource camelot | reconcileWeeklyExpenses excalibur | loadDataFromExternalSource excalibur | reconcileDailyExpenses Example of 'list function' with a \"matches\" filter: gfsh> list functions --matches=reconcile.* Member | Function --------- | ----------------------- camelot | reconcileWeeklyExpenses excalibur | reconcileDailyExpenses Example of 'list functions' when no functions are found in Geode : gfsh> list functions No Functions Found. list gateways 显示一个或多个成员的网关发件人和收件人。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: list gateways [--members=value(,value)*] [--groups=value(,value)*] 参数，列出网关: 名称 描述 ‑‑members 网关发送者和接收者显示的成员。 --groups 将显示网关发件人和接收者的成员组。 对多个组使用逗号分隔列表。 示例命令: list gateways list indexes 显示为所有成员创建的索引列表。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: list indexes [--with-stats(=value)?] 参数，列表索引: 名称 描述 默认值 --with-stats 指定是否还应显示统计信息。 false 示例命令: list indexes list indexes --with-stats 示例输出: gfsh>list indexes Member Name | Member ID | Region Path | Name | Type | Indexed Expression | From Clause -------------- | --------------------------------------------- | ----------- | -------- | ----- | ------------------ | ----------- consumerServer | 192.0.2.0(consumerServer:13873):6317 | /consumers | cidIdx | KEY | id | /consumers consumerServer | 192.0.2.0(consumerServer:13873):6317 | /consumers | cnameIdx | RANGE | name | /consumers producerServer | 192.0.2.0(producerServer:13874):19198 | /producers | pidIdx | RANGE | id | /producers Example of 'list indexes' with stats printed: gfsh>list indexes --with-stats Member Name | Member ID | Region Path | Name | Type | Indexed Expression | From Clause | Uses | Updates | Update Time | Keys | Values ------------ | --------- | ----------- | -------- | ----- | ------------------ | ----------- | ---- | ------- | ----------- | ---- | ------ cs... | 192... | /consumers | cidIdx | KEY | id | /consumers | 2512 | 0 | 0 | 5020 | 5020 cs... | 192... | /consumers | cnameIdx | RANGE | name | /consumers | 0 | 5020 | 421224000 | 0 | 5020 ps... | 192... | /producers | pidIdx | RANGE | id | /producers | 0 | 5031 | 497872000 | 5031 | 5031 错误消息: 在Geode中找不到索引时的输出示例： gfsh> list indexes No Indexes Found list jndi-binding 列出所有JNDI绑定，活动和配置。 活动绑定是绑定到服务器的JNDI上下文的绑定，也在群集配置中列出。 已配置的绑定是群集配置中列出的绑定，但可能在服务器上不活动。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: list jndi-binding 示例输出: gfsh>list jndi-binding Configured JNDI bindings: Group Name | JNDI Name | JDBC Driver Class ---------- | --------- | ------------------------------------ cluster | jndi1 | org.apache.derby.jdbc.EmbeddedDriver Active JNDI bindings found on each member: Member | JNDI Name | JDBC Driver Class --------------- | ----------------------- | ---------------------------------------------------- land-gifted-gun | java:UserTransaction | org.apache.geode.internal.jta.UserTransactionImpl land-gifted-gun | java:TransactionManager | org.apache.geode.internal.jta.TransactionManagerImpl list lucene indexes 显示为所有成员创建的Lucene索引列表。 可选的--with-stats限定符显示索引上的活动。 参见 create lucene index, describe lucene index, destroy lucene index and search lucene. 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: list lucene indexes [--with-stats(=value)] 参数，列出lucene索引: Name Description Default Value --with-stats Specifies whether statistics should also be displayed. false if not specified, true if specified 示例命令: list lucene indexes 示例输出: gfsh>list lucene indexes --with-stats Index Name | Region Path | Indexed Fields | Field Analy.. | Status | Query Executions | Updates | Commits | Documents ---------- | ----------- | ---------------------- | ------------- | ------- | ---------------- | ------- | ------- | --------- testIndex | /testRegion | [__REGION_VALUE_FIELD] | {__REGION_V.. | Defined | NA | NA | NA | NA gfsh>list lucene indexes Index Name | Region Path | Indexed Fields | Field Analy.. | Status ------------- | ----------- | ------------------------------------------------------------------ | ------------- | ----------- analyzerIndex | /Person | [revenue, address, name, email] | {revenue=St.. | Initialized customerIndex | /Customer | [symbol, revenue, SSN, name, email, address, __REGION_VALUE_FIELD] | {} | Initialized pageIndex | /Page | [id, title, content] | {} | Initialized personIndex | /Person | [name, email, address, revenue] | {} | Initialized list members 显示全部或部分成员。 在输出中，列出了成员协调员。 标识成员当前拥有的视图; N将为零或正整数。 表示哪些成员有资格成为会员协调员。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: list members [--group=value] 参数,列出成员: 名称 描述 --group 将显示成员的组名称。 示例命令: list members list members --group=Group1 示例输出: gfsh>list members Name | Id ------------ | ------------------------------------- Coordinator: | 192.0.2.0(locator1:216:locator):33368 locator1 | 192.0.2.0(locator1:216:locator):33368 server1 | 192.0.2.0(server1:888):10839 server2 | 192.0.2.0(server2:3260):16721 list regions 显示成员或成员的区域。 如果未指定参数，则列出群集中的所有区域。 句法: list regions [--groups=value(,value)*] [--members=value(,value)*] 参数，列出区域: 名称 描述 --groups 将显示区域的成员组。 --members 将显示区域的成员的名称或ID。 示例命令: list regions list regions --groups=G1 list regions --members=member1 示例输出: gfsh>list regions List of regions --------------- region1 region2 load-balance gateway-sender 使指定的网关发送方关闭其当前连接并以更平衡的方式重新连接到远程网关接收方。 使用此命令可以平衡网关发件人与接收者之间的连接。 例如，在远程站点添加新的网关接收器节点时，请执行此命令，以便新网关接收器可以从指定的网关发送器获取连接。 调用此命令可在所有网关接收器之间更均匀地重新分配发送方的连接。 注意: 此命令对ping连接没有影响。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: load-balance gateway-sender --id=value 名称 描述 --id Required. 网关发件人的ID。 Table 1. 负载平衡网关 - 发件人参数 示例命令: load-balance gateway-sender --id=sender1-LN 示例输出: load-balance gateway-sender --id=ny Member | Result | Message --------------------------------- | ------ |-------------------------------------------------------------------------- boglesbymac(ln-1:88651):48277 | OK | GatewaySender ny is rebalanced on member boglesbymac(ln-1:88651):48277 boglesbymac(ln-4:88681):42784 | OK | GatewaySender ny is rebalanced on member boglesbymac(ln-4:88681):42784 boglesbymac(ln-3:88672):43675 | OK | GatewaySender ny is rebalanced on member boglesbymac(ln-3:88672):43675 boglesbymac(ln-2:88662):12796 | OK | GatewaySender ny is rebalanced on member boglesbymac(ln-2:88662):12796 locate entry 在成员上找到区域条目。 找到条目 使用指定的键在成员上找到给定的条目。 使用分区区域时，此命令很有用。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: locate entry --key=value --region=value [--key-class=value] [--value-class=value] [--recursive=value] Name Description Default Value --key Required. String or JSON text from which to create a key. Examples include: “James”, “100L” and “('id': 'l34s')”. --region Required. Region in which to locate values. --key-class Fully qualified class name of the key’s type. java.lang.String --value-class Fully qualified class name of the value’s type. java.lang.String ‑‑recursive Whether to traverse regions and subregions recursively. false Table 1. 找到条目参数 示例命令: locate entry --key=('id':'133abg124') --region=/region1 --key-class=data.ProfileKey --recursive=true; 示例输出: gfsh>locate entry --key=('123abc') --region=region2 Result : true Key Class : java.lang.String Key : ('123abc') Locations Found : 2 MemberName | MemberId ---------- | ------------------------------------- server1 | GemFireStymon(server1:3692):13487 server2 | GemFireStymon(server2:2340):11613 netstat 通过“netstat”操作系统命令报告网络信息和统计信息。 报告给定成员的重要网络使用信息/统计信息。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: netstat [--members=value(,value)*] [--group=value] [--file=value] [--with-lsof(=value)?] Name Description Default Value --members Name or ID of the member(s) on which to run the netstat command. --group Group of members on which to run the netstat command. --file Text file to which output from the netstat command will be written. A “.txt” extension will be added if it is not already part of the specified name. ‑‑with‑lsof Specifies whether lsof (list open files) command output should also be displayed. Not applicable for Microsoft Windows hosts. false Table 1. Netstat 参数 示例命令: netstat netstat --members=server1 netstat --members=server1 --file=server1_netstat.txt 示例输出: gfsh>netstat #################################### Host: GemFireTest OS: Windows XP 5.1 x86 Member(s): server2, locator1, server1 #################################### Active Connections Proto Local Address Foreign Address State TCP GemFireTest:epmap GemFireTest:0 LISTENING TCP GemFireTest:microsoft-ds GemFireTest:0 LISTENING TCP GemFireTest:1034 GemFireTest:0 LISTENING TCP GemFireTest:1069 GemFireTest:0 LISTENING TCP GemFireTest:1099 GemFireTest:0 LISTENING TCP GemFireTest:1134 GemFireTest:0 LISTENING TCP GemFireTest:3389 GemFireTest:0 LISTENING TCP GemFireTest:8080 GemFireTest:0 LISTENING TCP GemFireTest:8081 GemFireTest:0 LISTENING TCP GemFireTest:10334 GemFireTest:0 LISTENING TCP GemFireTest:40404 GemFireTest:0 LISTENING TCP GemFireTest:40405 GemFireTest:0 LISTENING TCP GemFireTest:1025 GemFireTest:0 LISTENING TCP GemFireTest:5152 GemFireTest:0 LISTENING TCP GemFireTest:netbios-ssn GemFireTest:0 LISTENING TCP GemFireTest:1035 GemFireTest:0 LISTENING TCP GemFireTest:1035 GemFireTest:1081 ESTABLISHED TCP GemFireTest:1035 GemFireTest:1086 ESTABLISHED TCP GemFireTest:1035 GemFireTest:1147 ESTABLISHED TCP GemFireTest:1035 GemFireTest:1156 ESTABLISHED TCP GemFireTest:1046 GemFireTest:1099 ESTABLISHED TCP GemFireTest:1049 osdc-proxy-vip.vmware.com:http CLOSE_WA TCP GemFireTest:1050 osdc-proxy-vip.vmware.com:3128 CLOSE_WA TCP GemFireTest:1071 GemFireTest:0 LISTENING TCP GemFireTest:1071 GemFireTest:1077 ESTABLISHED TCP GemFireTest:1071 GemFireTest:1150 ESTABLISHED TCP GemFireTest:1071 GemFireTest:1157 ESTABLISHED TCP GemFireTest:1077 GemFireTest:1071 ESTABLISHED TCP GemFireTest:1078 GemFireTest:24400 ESTABLISHED TCP GemFireTest:1081 GemFireTest:1035 ESTABLISHED TCP GemFireTest:1086 GemFireTest:1035 ESTABLISHED TCP GemFireTest:1099 GemFireTest:1046 ESTABLISHED TCP GemFireTest:1136 GemFireTest:0 LISTENING TCP GemFireTest:1136 GemFireTest:1143 ESTABLISHED TCP GemFireTest:1136 GemFireTest:1151 ESTABLISHED TCP GemFireTest:1136 GemFireTest:1201 ESTABLISHED TCP GemFireTest:1141 GemFireTest:4247 ESTABLISHED TCP GemFireTest:1142 GemFireTest:48640 ESTABLISHED TCP GemFireTest:1143 GemFireTest:1136 ESTABLISHED TCP GemFireTest:1147 GemFireTest:1035 ESTABLISHED TCP GemFireTest:1150 GemFireTest:1071 ESTABLISHED TCP GemFireTest:1151 GemFireTest:1136 ESTABLISHED TCP GemFireTest:1156 GemFireTest:1035 ESTABLISHED TCP GemFireTest:1157 GemFireTest:1071 ESTABLISHED TCP GemFireTest:1201 GemFireTest:1136 ESTABLISHED TCP GemFireTest:1349 GemFireTest:10334 TIME_WAIT TCP GemFireTest:1350 GemFireTest:10334 TIME_WAIT TCP GemFireTest:1351 GemFireTest:10334 TIME_WAIT TCP GemFireTest:1352 GemFireTest:10334 TIME_WAIT TCP GemFireTest:1353 GemFireTest:10334 TIME_WAIT TCP GemFireTest:1354 GemFireTest:10334 TIME_WAIT TCP GemFireTest:4247 GemFireTest:0 LISTENING TCP GemFireTest:4247 GemFireTest:1141 ESTABLISHED TCP GemFireTest:24400 GemFireTest:0 LISTENING TCP GemFireTest:24400 GemFireTest:1078 ESTABLISHED TCP GemFireTest:48640 GemFireTest:0 LISTENING TCP GemFireTest:48640 GemFireTest:1142 ESTABLISHED UDP GemFireTest:microsoft-ds *:* UDP GemFireTest:isakmp *:* UDP GemFireTest:4500 *:* UDP GemFireTest:ntp *:* UDP GemFireTest:1900 *:* UDP GemFireTest:ntp *:* UDP GemFireTest:netbios-ns *:* UDP GemFireTest:netbios-dgm *:* UDP GemFireTest:1900 *:* UDP GemFireTest:32270 *:* UDP GemFireTest:42838 *:* UDP GemFireTest:47727 *:* pause gateway-sender 暂停网关发件人。 暂停成员或成员上的网关发件人。 有关暂停网关发件人的详细信息，请参阅暂停网关发件人。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: pause gateway-sender --id=value [--groups=value(,value)*] [--members=value(,value)*] Name Description --id Required. ID of the gateway sender. --groups Group(s) of members on which to pause the gateway sender. --members Name or ID of the member(s) on which to pause the gateway sender. Table 1. 暂停 网关-发件人 参数 示例命令: pause gateway-sender --id=sender1 pdx rename 在脱机磁盘存储中重命名PDX类型。 重命名的任何PDX类型都将在输出中列出。 如果未完成重命名或磁盘存储在线，则此命令将失败。 可用性: Offline. 句法: pdx rename --old=value --new=value --disk-store=value --disk-dirs=value(,value)* Name Description --old Required. If a PDX type’s fully qualified class name has a word that matches this text then it will be renamed. Words are delimited by ’.’ and ’$’. --new Required. The text to replace the word that matched old. ‑‑disk‑store Required. Name of the disk store to operate on. --disk-dirs Required. Directories which contain the disk store files. 示例命令: 将以“com.gemstone”开头的所有包更改为“com.pivotal”： gfsh>pdx rename --old=com.gemstone --new=com.pivotal --disk-store=ds1 --disk-dirs=/diskDir1 将名为“MyClassName”的类更改为“YourClassName”： gfsh>pdx rename --old=MyClassName --new=YourClassName --disk-store=ds1 --disk-dirs=/diskDir1 将FQCN“com.target.app1.OldClass”更改为“com.target.app2.NewClass”： gfsh>pdx rename --old=com.target.app1.OldClass --new=com.target.app2.NewClass --disk-store=ds1 --disk-dirs=/diskDir1 示例输出: gfsh>pdx rename --old=PortfolioPdx --new=StockPdx --disk-store=DiskStore1 --disk-dirs=/DiskDir1 Successfully renamed pdx types: com.app.data.StockPdx: id=2 com.app.data.StockPdx$Day.Monday 错误消息: 如果没有类型匹配，您可能会收到以下错误消息： gfsh>pdx rename --old=gemstone --new=pivotal --disk-store=DiskStore1 --disk-dirs=/DiskDir1 Could not process command due to GemFire error. No Pdx types found to rename. 如果存储PDX类型的磁盘存储在线，您将收到以下错误消息： gfsh>pdx rename --old=StockPdx --new=PortfolioPdx --disk-store=DiskStore1 --disk-dirs=/DiskDir1 Could not process command due to GemFire error. Error renaming pdx types : GemFireCache[id = 484629896; isClosing = false; isShutDownAll = false; closingGatewayHubsByShutdownAll = false; created = Wed Jan 07 10:29:45 PST 2015; server = false; copyOnRead = false; lockLease = 120; lockTimeout = 60]: An open cache already exists. put 添加或更新区域中的条目。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: put --key=value --value=value --region=value [--key-class=value] [--value-class=value] [--if-not-exists(=value)] 名称 描述 默认值 --key Required. 从中创建键的字符串或JSON文本。 例如：“James”, “100L” 和“('id': 'l34s')”。 --value Required. 从中创建值的字符串或JSON文本。 例如：“James”, “100L” 和“('id': 'l34s')”。 --region Required. 条目将放入的区域。 --key-class 键类型的完全限定类名。 java.lang.String --value-class 值类型的完全限定类名。 java.lang.String --if-not-exists 当具有相同键的条目已存在时，跳过放置操作。 false 示例命令: put --key=('id':'133abg125') --value=('firstname':'James','lastname':'Gosling') --region=/region1 --key-class=data.ProfileKey --value-class=data.ProfileDetails put --key=('133abg124') --value=('Hello World!!') --region=/region2 put --key=('100F') --value=('2146547689879658564') --region=/region1/region12 --key-class=java.lang.Float --value-class=java.lang.Long 示例输出: gfsh>put --key=('123abc') --value=('Hello World!!') --region=region2 Result : true Key Class : java.lang.String Key : ('123abc') Value Class : java.lang.String Old Value : 错误消息: \"Region name is either empty or Null\"; \"Key is either empty or Null\"; \"Value is either empty or Null\"; \"Region not found in any of the members\"; \"Region Not Found\"; \"Key is not present in the region\"; query 对Geode区域运行查询。 如果在查询中未设置限制结果大小的限制，则为有用的gfsh Shell变量中定义的gfsh环境变量APP_FETCH_SIZE的默认限制。 使用单引号围绕OQL查询。 注意: 如果被查询的对象包含循环引用，则不应从gfsh执行此命令。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: query --query=value [--step-name=value] [--file=path/to/results/file] 名称 描述 --query Required. OQL 字符串. --file 指定后，所有查询结果都将写入指定的文件。 如果文件已存在，则会发出错误。 Table 1. 查询参数 示例输出: gfsh>query --query='SELECT * FROM /region2' Result : true startCount : 0 endCount : 20 Rows : 1 Result ----------------- ('Hello World!!') NEXT_STEP_NAME : END rebalance 重新平衡分区区域。 默认情况下，所有分区区域都要重新平衡。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: rebalance [--include-region=value(,value)*] [--exclude-region=value(,value)*] [--time-out=value] [--simulate(=value)?] 名称 描述 默认值 --include-region 为重新平衡操作包含的分区区域路径。 包括优先于排除。 --exclude-region 要为重新平衡操作排除的分区区域路径。 --time-out GFSH返回到提示之前等待的时间（以秒为单位），同时在后台继续重新平衡。 -1 (等待重新平衡完成) --simulate 是否只模拟重新平衡。 模拟时-time-out参数不可用. false Table 1. 重新平衡的参数 示例命令: rebalance --include-region=/region3 --simulate=true 示例输出: rebalance 1. server1 host1(3467):12435:12423 Row Rebalanced Stats | Value --- ---------------- | ----- 1 TotalBucketCreateBytes | 0 2 TotalBucketCreateTime | 0 3 TotalBucketCreatesCompleted | 0 4 TotalBucketTransferBytes | 0 5 TotalBucketTransferTime | 0 6 TotalBucketTransfersCompleted | 0 7 TotalPrimaryTransferTime | 0 8 TotalPrimaryTransfersCompleted | 0 9 TotalTime | 56 Rebalance complete on host1(3467):12435:12423. remove 从区域中删除条目。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: remove --region=value [--key=value] [--all(=value)?] [--key-class=value] 名称 描述 默认值 --key 将用于创建检索值的键的字符串或JSON文本。 ‑‑key‑class 键类型的完全限定类名。 当前区域或String的键约束 --region Required. 要从中删除条目的区域。 --all 一个布尔值，当为true时，通过删除所有条目来清除该区域。 此选项不适用于分区区域。 false 示例命令: gfsh>remove --region=/region1 --key=('id': '133abg134') gfsh>remove --region=/region1 --key=('id': '133abg134') --key-class=data.ProfileKey gfsh>remove --region=/region1 --all=true 错误消息: \"Region name is either empty or Null\" \"Key is either empty or Null\" \"Value is either empty or Null\" \"Region not found in any of the members\" \"Region Not Found\" \"Key is not present in the region\" \"Option --all is not supported on partitioned region\" resume gateway-sender 恢复已暂停的所有网关发件人。 恢复成员或成员上的网关发件人。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: resume gateway-sender --id=value [--groups=value(,value)*] [--members=value(,value)*] 名称 描述 --id Required. 网关发件人的ID。 --groups 要恢复网关发件人的成员组。 --members 要恢复网关发件人的成员的名称/ID。 Table 1. 恢复网关发件人参数 示例命令: resume gateway-sender --id=sender1-LN --groups=LN-Group1 revoke missing-disk-store 指示群集的成员停止等待磁盘存储可用。 仅在文件丢失时撤消磁盘存储，因为在启动撤销后它将不再可恢复。 使用show missing-disk-store命令获取缺少磁盘存储的描述。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: revoke missing-disk-store --id=value 名称 描述 --id Required. 要撤消的丢失磁盘存储的ID。 Table 1. 撤消丢失磁盘存储参数 示例命令: revoke missing-disk-store --id=60399215-532b-406f-b81f-9b5bd8d1b55a 示例输出: gfsh>revoke missing-disk-store --id=60399215-532b-406f-b81f-9b5bd8d1b55a Missing disk store successfully revoked 错误消息: 无法找到磁盘存储时revoke missing-disk-store的示例： gfsh> revoke missing-disk-store --id=60399215-532b-406f-b81f Unable to find missing disk store to revoke run 执行一组GFSH命令。 Commands that normally prompt for additional input will instead use default values. 可用性: Online or offline. 注意: 文件中指定的某些命令需要在线状态。 句法: run --file=value [--quiet(=value)?] [--continue-on-error(=value)?] 名称 描述 默认值 --file Required. 使用gfsh识别的命令编写脚本的文件路径。 路径应该是相对的或绝对的。 --quiet 指定是否显示命令输出。注意: 当使用run命令时，脚本中的所有命令都以非交互方式运行。 此选项不会更改该功能。 false --continue-on-error 指定在执行其中一个命令失败时是否存在错误，是否应继续执行脚本。 false Table 1. Run 参数 示例命令: run --file=create-regions.gfsh --quiet=true (2) From command line: prompt> /home/user1/gemfire70/bin/gfsh run ./create-regions.gfsh --quiet=true prompt> /home/user1/gemfire70/bin/gfsh run ./create-regions.gfsh --continue-on-error=true 示例输出: gfsh>run --file=create-regions.gfsh 1. Executing - create region --name=region4 --type=REPLICATE Member | Status ------- | -------------------------------------- server2 | Region \"/region4\" created on \"server2\" server1 | Region \"/region4\" created on \"server1\" 2. Executing - create region --name=region1/subregion1 --type=LOCAL Parent region for \"region1/subregion1\" doesn't exist. search lucene 搜索Lucene索引 参见 create lucene index, describe lucene index, destroy lucene index 和 list lucene indexes. 可用性: Online. 句法: search lucene --name=value --region=value --queryString=value --defaultField=value [--limit=value] [--keys-only=value] 参数, 搜索lucene: 名称 描述 默认值 --name Required. 要搜索的Lucene索引的名称。 --region Required. Lucene索引所在区域的名称/路径。 ‑‐queryString Required. 查询字符串以搜索Lucene索引。 当字段为原始值时，使用__REGION_VALUE_FIELD作为查询字符串中的字段名称。 用双引号括起一个字符串，以完成字符串的匹配。 ‑‐defaultField Required. 要搜索的默认字段.__REGION_VALUE_FIELD将字段标识为原始值。 --limit Number of search results needed. 如果未指定参数: -1 --keys-only 仅返回搜索结果的键。 如果未指定参数: false 示例命令: gfsh> search lucene --name=testIndex --region=/testRegion --queryString=value1 --defaultField=__REGION_VALUE_FIELD gfsh> search lucene --name=indexOfStrings --region=/stringTestRegion --queryString='__REGION_VALUE_FIELD:\"my exact string\"' --defaultField=__REGION_VALUE_FIELD 示例输出: gfsh>search lucene --name=testIndex --region=/testRegion --queryString=value* --defaultField=__REGION_VALUE_FIELD key | value | score --- | ------ | ----- 3 | value3 | 1 2 | value2 | 1 1 | value1 | 1 gfsh>search lucene --region=/Person --name=analyzerIndex --defaultField=addr --queryString=\"97763\" key | value | score ------ | ------------------------------------------------------------------ | -------- key763 | Person{name='Kris Cat', addr='7 Ash St, Portland_OR_97763', emai.. | 1.669657 set variable 在GFSH环境中设置变量。 设置命令可以使用的GFSH变量。 您可以使用echo命令查看变量的值。 例如，要查看所有环境变量及其当前值的列表，请使用以下命令： gfsh>echo --string=$* 有关预设环境变量的说明，请参阅有用的gfsh Shell变量。 可用性: Online or offline. 句法: set variable --name=value --value=value 名称 描述 ‑‑name Required. 变量的名称。 名称必须仅由字母，数字和“_”字符组成，并且不能以数字开头。 ‑‑value Required. 变量将设置为的值。 Table 1. 设置变量的参数 示例命令: set variable --name=APP_COLLECTION_LIMIT --value=10 set variable --name=FOO --value=\"foo\" set variable --name=BAR --value=\"bar\" 示例输出: gfsh>set variable --name=APP_COLLECTION_LIMIT --value=10 Value for variable APP_COLLECTION_LIMIT is now: 10. gfsh>set variable --name=BAR --value=\"bar\" Value for variable BAR is now: \"bar\". sh 执行操作系统命令。 执行操作系统（OS）命令。 使用＆立即返回gfsh提示符。 注意: 不支持将输出传递给另一个shell命令的命令。 句法: sh command [--use-console(=value)?] 名称 描述 默认值 --use-console 在UNIX系统上为需要控制台句柄的应用程序设置此参数。 将“/dev/tty”添加到指定的命令。 false Table 1. Sh 参数 示例命令: gfsh>sh ls -al total 80 drwxrwxr-x. 10 username username 4096 Sep 3 15:10 . drwxrwxr-x. 4 username username 4096 Sep 3 14:58 .. drwx------. 2 username username 4096 Sep 3 15:09 bin drwx------. 2 username username 4096 Sep 3 15:09 defaultConfigs drwx------. 3 username username 4096 Sep 3 15:09 docs drwx------. 2 username username 4096 Sep 3 15:09 dtd -rwx------. 1 username username 31830 Sep 3 15:09 EULA.txt drwx------. 2 username username 4096 Sep 3 15:09 lib drwx------. 6 username username 4096 Sep 3 15:09 SampleCode drwx------. 4 username username 4096 Sep 3 15:09 templates drwx------. 5 username username 4096 Sep 3 15:09 tools show 显示死锁，日志，指标和丢失的磁盘存储。 show dead-locks 显示群集中的所有死锁。 show log 显示成员的日志。 show metrics 显示或导出整个群集，成员或区域的度量标准。 show missing-disk-stores 显示群集中当前缺少的磁盘存储的摘要。 show subscription-queue-size 显示订阅队列中的事件数。 show dead-locks 显示群集中的所有死锁。 可用性: Online. 必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: show dead-locks --file=value 名称 描述 --file Required. 将写入成员之间依赖关系的文件的名称。 Table 1. 显示死锁参数 示例命令: show dead-locks --file=deadlocks.txt 示例输出: gfsh>show dead-locks --file=deadlocks.txt No dead lock detected. Please view the dependencies between the members in file : deadlocks.txt show log 显示成员的日志。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: show log --member=value [--lines=value] 名称 描述 默认值 --member Required. 将显示其日志文件的成员的名称/ID。 --lines 要显示的日志文件中的行数。 最大值为100。 0 示例命令: show log --member=locator1 --lines=5 示例输出: gfsh>show log --member=locator1 --lines=5 SystemLog: [info 2012/09/25 14:04:51.340 PDT locator1 tid=0x57] (tid=12 msgId=4) Parent region for \"region1/subregion1\" doesnt exi st. [info 2012/09/25 14:04:51.372 PDT locator1 tid=0x57] (tid=12 msgId=5) Error occurred while executing \"create region --n ame=region1/subregion1 --type=LOCAL\". [info 2012/09/25 15:14:34.314 PDT locator1 tid=0x68] (tid=13 msgId=6) Error occurred while executing \"show log --membe r=server1 --lines=5\". show metrics 显示或导出整个群集，成员或区域的度量标准。 如果未给出命令行参数，则会显示集群，缓存，磁盘库和查询类别下的度量标准。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: show metrics [--member=value] [--region=value] [--file=value] [--port=value] [--categories=value(,value)*] 名称 描述 --member 将显示/导出其指标的成员的名称/ID。 --region 将显示/导出其指标的区域的名称/路径。 --file 要写入度量标准的文件的名称。 --port 要显示/导出其度量标准的高速缓存服务器的端口号。 这只能与--member参数一起使用。 --categories 基于指定的参数（上面列出的）可用的类别是：region specified: cluster, region, partition, diskstore, callback, evictionmember specified: member, jvm, region, serialization, communication, function, transaction, diskstore, lock, eviction, distribution, offheapmember and region specified: region, partition, diskstore, callback, eviction Table 3. 显示度量标准参数 示例命令: // Metrics for the entire system show metrics // Metrics for a region: show metrics --region=region1 // Metrics for a given member show metrics --member=server1 // Metrics for a region on a member show metrics --region=region1 --member=server1 // Metrics for a member and the cacheserver it hosts // NOTE: port option only work when used with --member option show metrics --member=server1 --port=10334 // Export metrics for the entire system show metrics --file=data/stats/system-stats.csv 示例输出: gfsh>show metrics Cluster-wide Metrics Type | Metric | Value --------- | --------------------- | ----- cluster | totalHeapSize | 123 cache | totalRegionEntryCount | 0 | totalRegionCount | 0 | totalMissCount | 0 | totalHitCount | 0 diskstore | totalBytesOnDisk | 0 | diskReadsRate | 0 | diskWritesRate | 0 | flushTimeAvgLatency | 0 | totalBackupInProgress | 0 query | queryRequestRate | 0 show missing-disk-stores 显示群集中当前缺少的磁盘存储的摘要。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: show missing-disk-stores 示例命令: show missing-disk-stores 示例输出: gfsh> show missing-disk-stores Disk Store ID | Host | Directory ------------------------------------ | --------- | ------------------------------------- 60399215-532b-406f-b81f-9b5bd8d1b55a | excalibur | /usr/local/gemfire/deploy/disk_store1 show subscription-queue-size 显示订阅队列中的事件数。 如果提供CQ名称，则它计算指定CQ的订阅队列中的事件数。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: show subscription-queue-size --durable-client-Id=value [--members=value(,value)*] [--groups=value(,value)*] 名称 描述 --durable-client-id Required. 用于标识持久客户端的ID。 --durable-cq-name 标识CQ的名称。 --members 要对订阅队列事件进行计数的成员的名称/ID。 --groups 要对订阅队列事件进行计数的成员组。 Table 4. 显示订阅 - 队列大小参数 示例命令: show subscription-queue-size --durable-client-id=client1 示例输出: gfsh>show subscription-queue-size --durable-client-Id=client1 member | subcription-queue-size for durable-client : \"client1\". ------- | ------------------------------------------------------ server3 | 1 server4 | 0 错误消息: gfsh>show subscription-queue-size --durable-client-Id=client1 No client found with client-id : client1 Occurred on members 1.server4 2.server1 3.server3 shutdown 停止所有成员。 要求所有具有缓存的成员关闭缓存并断开与系统的连接。 如果指定了--include-locators参数，则该命令将逐个关闭所有正在运行的定位符。 timeout参数允许您指定在超过时间后强制关闭系统。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: shutdown [--time-out=value] [--include-locators=value] 名称 描述 默认值 --time-out 等待（以秒为单位）正常关闭的时间。 应该至少10秒。 如果未指定，则默认值为10。 10 --include-locators 要关闭定位器，请将此选项指定为true。 false Table 1. 停止参数 示例命令: shutdown shutdown --time-out=15 shutdown --include-locators=true 示例输出: gfsh>shutdown \"As a lot of data in memory will be lost, including possibly events in queues, do you really want to shutdown the entire distributed system? (Y/n):\" Y Shutdown is triggered sleep 延迟gfsh命令执行。 以秒为单位延迟指定的时间 - 允许浮点值。 可用性: Online of offline. 句法: sleep [--time=value] 名称 描述 默认值 --time 延迟的秒数。 3 Table 1. 延迟参数 示例命令: sleep sleep --time=60 示例输出: gfsh>sleep --time=60 gfsh> start 启动服务器，定位器，网关发送器和网关接收器以及监视工具。 start gateway-receiver 在给定成员或成员组上启动网关接收器。 start gateway-sender 在一个或多个成员上启动网关发件人。 start jconsole 在单独的进程中启动JDK JConsole监视应用程序。 start jvisualvm 在单独的进程中启动JDK的Java VisualVM监视应用程序。 start locator 启动定位器。 start pulse 在用户的默认系统浏览器中启动Geode Pulse监控仪表板工具，并将用户导航到登录页面（登录页面）。 start server 启动Geode缓存服务器进程。 start gateway-receiver 在给定成员或成员组上启动网关接收器。 请注意，每个成员只能有一个网关接收器，与网关发送器不同，您不需要为网关接收器指定标识符。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: start gateway-receiver [--groups=value(,value)*] [--members=value(,value)*] 参数，启动网关-接收器 名称 描述 --members 启动网关接收器的成员的名称或ID。 --groups 要在其上启动网关接收器的成员组。 示例命令: start gateway-receiver start gateway-receiver --members=member1 示例输出: gfsh>start gateway-receiver Member | Result | Message --------------------------- | -------| ----------------------------------------------------------------------- pc13(2266):56852 | OK | GatewayReceiver is started on member pc13(2266):56852 pc13(Manager:2242):57631| Error | GatewayReceiver is not available on member pc13(Manager:2242):57631 pc13(2275):47480 | OK | GatewayReceiver is started on member pc13(2275):47480 pc13(2293):55472 | OK | GatewayReceiver is started on member pc13(2293):55472 gfsh>start gateway-receiver --members=pc13(2266):36579 GatewayReceiver is started on member pc13(2266):36579 gfsh>start gateway-receiver --group=RG1 Member | Result | Message -------------------- | -------| ---------------------------------------------------------- pc13(2275):27484| OK | GatewayReceiver is started on member pc13(2275):27484 pc13(2293):55810| OK | GatewayReceiver is started on member pc13(2293):55810 pc13(2266):4522 | OK | GatewayReceiver is started on member pc13(2266):4522 start gateway-sender 在一个或多个成员上启动网关发件人。 有关如何配置网关发件人的信息，请参阅配置网关发件人。 注意: 默认情况下，网关发件人配置为自动启动。 手动重启会带来数据丢失的风险; 它不适用于生产系统。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: start gateway-sender --id=value [--groups=value(,value)*] [--members=value(,value)*] 参数，启动网关发件人 名称 描述 --id Required. GatewaySender的ID。 --groups 启动Gateway Sender的成员组。 --members 启动Gateway Sender的成员 示例命令: start gateway-sender --id=sender1-NY start gateway-sender --id=sender1-NY --members=server1 start gateway-sender --id=sender1-NY --groups=MemberGroup1,MemberGroup2 示例输出: gfsh>start gateway-sender --id=ln Member | Result | Message ------------------------------| ------- | ------------------------------------------------------------------------- pc13(30614):63670 | OK | GatewaySender ln is started on member pc13(30614):63670 pc13(30621):36015 | OK | GatewaySender ln is started on member pc13(30621):36015 pc13(30633):13633 | OK | GatewaySender ln is started on member pc13(30633):13633 pc13(Manager:30588):42792 | Error | GatewaySender ln is not available on member pc13(Manager:30588):42792 gfsh>start gateway-sender --id=ln --members=pc13(30614):44519 GatewaySender ln is started on member pc13(30614):44519 gfsh>start gateway-sender --id=ln --groups=SenderGroup1 Member | Result| Message ---------------------- | ------| ------------------------------------------------------------ pc13(30614):15201 | OK | GatewaySender ln is started on member pc13(30614):15201 pc13(30621):61437 | OK | GatewaySender ln is started on member pc13(30621):61437 pc13(30633):22567 | OK | GatewaySender ln is started on member pc13(30633):22567 start jconsole 在单独的进程中启动JDK JConsole监视应用程序。 JConsole会自动连接到正在运行的JMX Manager节点（如果有）。 请注意，您必须安装JDK（而不仅仅是JRE）并设置正确的PATH和JAVA_HOME环境变量。 有关将JConsole与Geode管理和监视系统一起使用的示例，请参阅通过JConsole浏览Geode MBean。 可用性: Online or offline. 句法: start jconsole [--interval=] [--notile] [--version] [--J] 参数，启动jconsole 名称 描述 默认值 --interval 将更新间隔设置为n秒（默认为4秒）。 （相当于JConsole的-interval = n） 4 --notile 是否最初为两个或更多连接平铺窗口。 此参数作为-notile传递给JConsole。 false ‑‑pluginpath 搜索JConsole插件的目录或JAR文件。 该路径应包含一个名为META-INF/services/com.sun.tools.jconsole.JConsolePlugin的提供者配置文件，每个插件包含一行，用于指定实现com.sun.tools.jconsole.JConsolePlugin的类的完全限定类名。 --version 显示JConsole版本信息。 此参数作为-version传递给JConsole。 false --J 传递给JConsole运行的JVM的参数 示例命令: gfsh>start jconsole --interval=8 --notile; Running JDK JConsole gfsh>start jconsole --version; JConsole version \"1.8.0_31-b01-1\" Java(TM) SE Runtime Environment (build 1.8.0_31-b01-1-11) Java HotSpot(TM) 64-Bit Server VM (build 20.6-b01-11, mixed mode) 示例输出: gfsh>start jconsole Running JDK JConsole JConsole应用程序出现并自动连接到JMX Manager节点（如果有）： 错误消息: An error occurred while launching JConsole = %1$s Connecting by the Geode member's name or ID is not currently supported. Please specify the member as '[PORT]. An IO error occurred while launching JConsole. Please ensure that JAVA_HOME is set to the JDK installation or the JDK bin directory is in the system PATH. JConsole could not be found.\\nPlease ensure that JAVA_HOME is set to the JDK installation or the JDK bin directory is in the system PATH. start jvisualvm 在单独的进程中启动JDK的Java VisualVM监视应用程序。 可用性: Online or offline. 句法: start jvisualvm [--J=value(,value)*] 参数，启动jvisualvm 名称 描述 --J VM-option传递给生成的CacheServer VM。 例如：--J=-Dfoo.bar=true将foo.bar设置为`true'。 示例命令: start jvisualvm 示例输出: start locator 启动定位器。 该命令创建一个以定位符命名的子目录和日志文件。 如果定位器检测到不存在其他JMX Manager，则定位器将自动启动嵌入式JMX Manager并将当前的gfsh会话连接到JMX Manager。 注意: 在启动gfsh之前必须设置JAVA_HOME才能使用此命令。 此外，如果gfsh尚未连接到JMX Manager，则gfsh控制台将自动连接到由新定位器启动的新嵌入式JMX Manager。 注意: 当在定位器启动期间指定--max-heap和--initial-heap时，Geode的资源管理器在内部指定其他GC参数。 如果您不希望资源管理器设置其他默认GC属性，请使用-Xms和-Xmx JVM选项。 有关详细信息，请参阅使用资源管理器控制堆使用。 可用性: Online or offline. 句法: start locator --name=value [--bind-address=value] [--force(=value)] [--groups=value(,value)*] [--hostname-for-clients=value] [--locators=value] [--log-level=value] [--mcast-address=value] [--mcast-port=value] [--port=value] [--dir=value] [--properties-file=value] [--security-properties-file=value] [--initial-heap=value] [--max-heap=value] [--connect(=value)] [--enable-cluster-configuration(=value)] [--load-cluster-configuration-from-dir(=value)] [--cluster-config-dir=value] [--redirect-output(=value)] [--http-service-port=value] [--http-service-bind-address=value] [--J=value(,value)*] 参数，启动定位器 名称 描述 默认值 --name 用于此Geode定位器服务的名称。 如果未指定，gfsh将生成随机名称。 --bind-address 定位器绑定的IP地址。 绑定到所有地址 --force 是否允许覆盖先前定位器运行的PID文件。 false --groups 组定位器将成为其中的一部分。 --hostname-for-clients 将发送到客户端的主机名或IP地址，以便它们可以连接到此定位器。 使用 bind-address --locators 此定位器用于加入适当的Geode集群的定位器列表。 --log-level 记录到定位器日志文件的输出级别。 日志级别的可能值包括：ALL，TRACE，DEBUG，INFO，WARN，ERROR，FATAL，OFF。 --mcast-address 用于绑定UPD套接字以进行多播联网的IP地址或主机名，以便定位器可以定位Geode集群中的其他成员。 如果mcast-port为零，则忽略mcast-address。 --mcast-port 用于多播网络的端口，因此定位器可以定位Geode集群的其他成员。 零值禁用mcast。 --port 定位器的监听端口。 10334 --dir 将启动并运行定位器的目录。 ./ --properties-file 指定gemfire.properties文件以配置定位器的集群。 文件的路径应该是绝对的或相对于gfsh的工作目录。 --security-properties-file gfsecurity.properties文件，用于在集群中配置Locator的安全配置。 文件的路径可以是gfsh的工作目录的绝对路径或相对路径。 --initial-heap Size的格式与-Xmx/-Xms JVM选项相同。注意: 如果使用-J-Xms和-J-Xmx JVM属性而不是-initial-heap和-max-heap，则Geode不使用默认的JVM资源管理属性。 如果使用JVM属性，则必须手动为驱逐，垃圾收集，堆百分比等指定所有属性。 --max-heap Size的格式与-Xmx/-Xms JVM选项相同。注意: 如果使用-J-Xms和-J-Xmx JVM属性而不是-initial-heap和-max-heap，则Geode不使用默认的JVM资源管理属性。 如果使用JVM属性，则必须手动为驱逐，垃圾收集，堆百分比等指定所有属性。 --connect 当connect设置为false时，gfsh不会自动连接到使用此命令启动的定位器。 true --enable-cluster-configuration 启用集群配置行为，其中定位器维护集群的所有成员的配置。 请参见群集配置服务概述。 true --load-cluster-configuration-from-dir 已过时。 使用gfsh import cluster-configuration实现此功能。从shared-config目录加载集群配置。 （当设置为false时，配置将从定位器用于持久保存配置的内部持久区域的磁盘存储区加载。） false --cluster-config-dir 群集配置服务用于将群集配置存储在文件系统上的目录 cluster-config --redirect-output 如果为true，则将标准输出和标准错误重定向到定位器日志文件。 如果指定没有值，则该值设置为true。 false --http-service-port 指定HTTP服务端口。 7070 --http-service-bind-address 指定HTTP服务绑定到的IP地址。 本地主机的地址 --J 参数传递给定位器将运行的JVM。 例如，指定--J=-Dfoo.bar=true将属性“foo.bar”设置为“true”。注意:如果要传递的参数包含空格或逗号，请将选项括在单引号中。 例如：start locator --name=locator1 --port=9009 --mcast-port=0\\ --J='-Dgemfire.remote-locators=192.0.2.0[9009],192.0.2.1[9009]' none 示例命令: start locator --name=locator1 start pulse 在用户的默认系统浏览器中启动Geode Pulse监控仪表板工具，并将用户导航到登录页面（登录页面）。 有关Geode Pulse的更多信息，请参阅Geode Pulse。 可用性: Online or offline. 句法: start pulse [--url=value] 参数，启动pulse 名称 描述 默认值 --url Pulse Web应用程序的URL http://localhost:7070/pulse 示例命令: start pulse start pulse --url=http://gemfire.example.com:7070/pulse 示例输出: 有关Pulse的示例，请参阅Geode Pulse。 start server 启动Geode缓存服务器进程。 注意: 如果在服务器启动期间指定了--max-heap和--initial-heap，则会代表您指定其他GC参数。 如果您不希望设置其他默认GC属性，则使用-Xms和-Xmx JVM选项来设置这些参数。 有关详细信息，请参阅使用资源管理器控制堆使用。 可用性: Online or offline. 句法: start server --name=value [--assign-buckets(=value)] [--bind-address=value] [--cache-xml-file=value] [--classpath=value] [--disable-default-server(=value)] [--disable-exit-when-out-of-memory(=value)] [--enable-time-statistics(=value)] [--force(=value)] [--include-system-classpath(=value)] [--properties-file=value] [--security-properties-file=value] [--groups=value(,value)*] [--locators=value] [--locator-wait-time=value] [--log-level=value] [--mcast-address=value] [--mcast-port=value] [--memcached-port=value] [--memcached-protocol=value] [--rebalance(=value)] [--server-bind-address=value] [--server-port=value] [--spring-xml-location=value] [--statistic-archive-file=value] [--dir=value] [--initial-heap=value] [--max-heap=value] [--use-cluster-configuration(=value)] [--J=value(,value)*] [--critical-heap-percentage=value] [--critical-off-heap-percentage=value] [--eviction-heap-percentage=value] [--eviction-off-heap-percentage=value] [--hostname-for-clients=value] [--max-connections=value] [--message-time-to-live=value] [--max-message-count=value] [--max-threads=value] [--socket-buffer-size=value] [--lock-memory=value] [--off-heap-memory-size=value] [--start-rest-api=value] [--redirect-output(=value)] [--http-service-port=value] [--http-service-bind-address=value] [--user=value] [--password=value] 参数，启动服务器 名称 描述 默认值 --name 此服务器的成员名称。 如果未指定，gfsh将生成随机名称。 --assign-buckets 是否在服务器启动时将桶分配给缓存的分区区域。 false --bind-address 服务器绑定的IP地址。 绑定到所有本地地址 --cache-xml-file 指定用于在创建缓存时初始化缓存的XML文件或资源的名称。 --classpath 应用程序类在核心jar文件之后添加到服务器的CLASSPATH。 有关详细信息，请参阅设置CLASSPATH。 --include-system-classpath 如果为true，则在服务器的CLASSPATH上包含System CLASSPATH，因为默认情况下不包含System CLASSPATH。 如果指定没有值，则该值设置为true。 false --disable-default-server W除此之外，默认情况下将启动缓存服务器。 如果指定的参数没有值，则该值设置为true。 如果设置为true，则缓存服务器充当对等方。 false --disable-exit-when-out-of-memory 发生OutOfMemoryError时阻止JVM退出。 false --enable-time-statistics 是否打开Geode操作收集其他基于时间的统计信息。 true --properties-file gemfire.properties文件，用于配置服务器的集群。 文件的路径可以是gfsh工作目录的绝对路径或相对路径。 --security-properties-file gfsecurity.properties文件，用于在集群中配置服务器的安全配置。 文件的路径可以是gfsh目录的绝对路径或相对路径。 --groups 缓存服务器的组名称。 --force 是否允许覆盖先前高速缓存服务器运行的PID文件。 false --locators 设置高速缓存服务器用于加入适当的Geode集群的定位器列表。 --locator-wait-time 设置服务器在放弃之前等待定位器在启动期间可用的秒数。 0 --log-level 设置记录到Cache Server日志文件的输出级别。 日志级别的可能值包括：ALL，TRACE，DEBUG，INFO，WARN，ERROR，FATAL，OFF。 --mcast-address 用于绑定UDP套接字以进行多播联网的IP地址或主机名，以便缓存服务器可以找到Geode集群中的其他成员。 如果mcast-port为零，则忽略mcast-address。 --mcast-port 设置用于多播联网的端口，以便缓存服务器可以找到Geode群集的其他成员。 零值禁用mcast。 --memcached-port 如果指定且非零，则设置嵌入式Gemcached服务器的端口号并启动Gemcached服务器。 --memcached-protocol 设置嵌入式Gemcached服务器使用的协议。 有效值为BINARY和ASCII。如果省略此属性，则使用ASCII协议。 --server-bind-address 覆盖此服务器将侦听客户端连接的bind-address。 在多宿主服务器环境中设置此选项以区分与客户端的通信。 设置空字符串（“”）的值使用bind-address的值。 bind-address的值 --server-port 服务器端口将侦听客户端连接。 40404 --spring-xml-location 指定用于引导和配置Geode Server的Spring XML配置文件的位置。 此配置文件可以存在于CLASSPATH（默认）或Spring的Resource（Loader）位置说明符支持的任何位置（例如，classpath:，file：等）。 ResourceLoader在Spring文档中描述。 --rebalance 是否在Geode集群中启动重新平衡。 false --dir 指定运行服务器的目录。此目录将写入您启动gfsh的位置。 如果未指定，则以服务器命名该目录。 --statistic-archive-file 写入统计样本的文件。 例如：“StatisticsArchiveFile.gfs”。 必须定义为将归档存储到文件。 空字符串（默认）禁用统计信息存档。 not set --initial-heap 堆的初始大小，格式与JVM -Xms参数相同。注意: 如果使用--J=-Xms 和--J=-Xmx JVM属性而不是--initial-heap和--max-heap，那么Geode不使用默认的JVM资源管理属性。 如果使用JVM属性，则必须手动为驱逐，垃圾收集，堆百分比等指定所有属性。 --max-heap 堆的最大大小，格式与JVM -Xmx参数相同。注意: 如果使用--J=-Xms 和--J=-Xmx JVM属性而不是--initial-heap和--max-heap，那么Geode不使用默认的JVM资源管理属性。 如果使用JVM属性，则必须手动为驱逐，垃圾收集，堆百分比等指定所有属性。. --J 参数传递给运行缓存服务器的JVM。 例如，--J=-Dfoo.bar=true会将属性“foo.bar”设置为“true”。如果要传递的参数包含空格或逗号，请将选项括在单引号中。 --use-cluster-configuration 指定服务器是否从定位器请求群集配置。 请参见群集配置服务概述。 true --critical-heap-percentage 设置堆的百分比等于或高于该百分比，由于垃圾收集暂停或内存不足异常，缓存被认为有可能无法运行。 超过阈值，需要堆空间的操作将抛出一个LowMemoryException。 此功能需要额外的VM标志才能正常执行; 你必须设置--initial-heap和--max-heap或相应的JVM属性来使用这个阈值。 您还必须将--max-heap和--initial-heap设置为相同的值。 0 (没有强制执行关键堆阈值) --critical-off-heap-percentage 由于内存不足异常，高速缓存被认为有可能无法运行的危险时使用的堆外内存百分比。 超过阈值，需要堆空间的操作将抛出一个LowMemoryException。 0 (没有严格的堆外阈值强制执行) --eviction-heap-percentage 设置应在HeapLRU驱逐配置的区域上开始驱逐的堆的百分比。 更改此值可能会导致驱逐立即开始。 在任何给定时间只允许对此属性或关键堆百分比进行一次更改，并且在允许下一次更改之前将完全实现其效果。 此功能需要额外的VM标志才能正常执行; 你必须设置--initial-heap和--max-heap或相应的JVM属性来使用这个阈值。 您还必须将--max-heap和--initial-heap设置为相同的值。 0，如果没有使用堆eviction配置区域，则将critical-heap-percentage设置为非零值，比该值小5%。如果未配置critical-heap-percentage，则为80%。 --eviction-off-heap-percentage 在为堆外和HeapLRU驱逐配置的区域上应该开始驱逐的堆外存储器的百分比。 更改此值可能会导致驱逐立即开始。 在任何给定时间，只允许对此属性或关键堆外百分比进行一次更改，并且在允许下一次更改之前将完全实现其效果。 0，如果没有区域配置堆驱逐如果critical-off-heap-percentage设置为非零值，则比该值小5%。 80%，如果没有配置critical-off-heap-percentage。 --hostname-for-clients 设置定位器将为客户端提供的IP地址或主机名。 客户端使用该地址连接到服务器。 当客户端使用不同的地址与服务器连接而不是bind-address时，设置此值，因为这些客户端可能与私有云或多宿主环境中的服务器连接。 不指定此选项或将此选项设置为空字符串（“”）会导致将bind-address提供给客户端。 --max-connections 设置允许的最大客户端连接数。 达到最大值时，缓存服务器将停止接受连接 --message-time-to-live 设置客户端队列中的消息将过期的时间（以秒为单位）。 --max-message-count 设置可以在客户端队列中排队的最大消息数。 --max-threads 设置此缓存服务器中允许的最大线程数，以便为客户端请求提供服务。 默认值为0会导致缓存服务器为每个客户端连接专用一个线程。 --socket-buffer-size 设置此CacheServer的套接字连接的缓冲区大小（以字节为单位）。 默认值为32768字节。 --lock-memory （仅限Linux）如果为true，则成员的堆和堆外内存将锁定在RAM中，从而阻止它们被分页到磁盘。 您必须增加相关的ulimit操作系统资源，以允许操作系统锁定足够大小的内存块。 false --off-heap-memory-size 用于存储区域值的整数堆外堆内存。 以千兆字节为单位，后缀为g，或者后缀为m的兆字节。 例如，使用--off-heap-memory-size=2g分配2 GB的堆外空间。 默认值0不使用任何堆外内存。 0 --start-rest-api 如果为true，则启动REST API服务。 false --redirect-output 如果为true，则将标准输出和标准错误重定向到服务器日志文件。 如果指定没有值，则该值设置为true。 false --http-service-port 指定HTTP服务端口。 7070 --http-service-bind-address 指定HTTP服务绑定到的IP地址。 本地主机的地址 --user 用于对群集进行身份验证的凭据的用户名。 如果指定，如果未指定--password选项，则gfsh将提示输入密码。 --password 用于对群集进行身份验证的凭据的密码部分。 例子 gfsh>start server --name=server1 gfsh>start server --name=server2 --server-port=40405 status 检查群集配置服务和Geode成员进程的状态，包括定位器，网关接收器，网关发件人和服务器。 status cluster-config-service 显示集群配置服务的状态。 status gateway-receiver 显示指定网关接收器的状态。 status gateway-sender 显示指定网关发件人的状态。 status locator 显示指定定位器的状态。 status server 显示指定的Geode缓存服务器的状态。 status cluster-config-service 显示集群配置服务的状态。 显示enable-cluster-configuration设置为true的所有定位器上的集群配置服务的状态。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: status cluster-config-service 示例命令: status cluster-config-service 示例输出: gfsh>status cluster-config-service Status of shared configuration on locators Name | Status -------- | ------- locator8 | RUNNING status gateway-receiver 显示指定网关接收器的状态。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: status gateway-receiver [--groups=value(,value)*] [--members=value(,value)*] 名称 描述 --groups 用于显示状态的网关接收器组。 --members 要显示其状态的网关接收器的名称或ID。 Table 1. 状态网关 - 接收器参数 示例命令: status gateway-receiver --groups=LN-Group1 status gateway-receiver --members=server1 示例输出: gfsh>status gateway-receiver Member | Port | Status ---------------------| ------| ------- pc13(8151):26518 | 26837 | Running pc13(8175):53787 | 23753 | Running pc13(8164):24081 | 25457 | Running Member | Error -----------------------------| --------------------------------------------------- pc13(Manager:8124):52410 | GatewayReceiver is not available or already stopped pc13(8130):8180 | GatewayReceiver is not available or already stopped gfsh>status gateway-receiver --members=pc13(8151):50130 Member | Port | Status -------------------- | ----- | -------- pc13(8151):50130 | 28592 | Running gfsh>status gateway-receiver --group=RG1 Member | Port | Status -----------------------| ------| ------- pc13(8151):19450 | 27815 | Running pc13(8175):14139 | 27066 | Running pc13(8164):45150 | 29897 | Running status gateway-sender 显示指定网关发件人的状态。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: status gateway-sender --id=value [--groups=value(,value)*] [--members=value(,value)*] 名称 描述 --id Required. 网关发件人的ID。 --groups 要显示状态的网关发件人组。 多个成员组的逗号分隔列表。 ‑‑members 要显示其状态的网关发件人的名称/ID。 Table 2. 状态网关 - 发件人参数 示例命令: status gateway-receiver receiver1-LN --groups=LN-Group1; 示例输出: gfsh>status gateway-sender --id=ln_Serial Member | Type | Runtime Policy | Status -----------------------| -------| -------------- | ----------- pc13(8175):21449 | Serial | Secondary | Not Running pc13(8151):40761 | Serial | Secondary | Not Running pc13(8164):33476 | Serial | Secondary | Not Running Member | Error ------------------------------ | ------------------------------ pc13(8130):2365 | GatewaySender is not available pc13(Manager:8124):43821 | GatewaySender is not available gfsh>status gateway-sender --id=ln_Serial --members=pc13(8151):7411 Member | Type | Runtime Policy | Status ------------------- | ------ | -------------- | ----------- pc13(8151):7411 | Serial | Secondary | Not Running gfsh>status gateway-sender --id=ln_Serial --members=pc13(8151):7411 Member | Type | Runtime Policy | Status ------------------- -| ------ | -------------- | ------- pc13(8151):7411 | Serial | Primary | Running gfsh>status gateway-sender --id=ln_Serial --groups=Serial_Sender ==> Member | Type | Runtime Policy | Status ---------------------- | -------| -------------- | ----------- pc13(8151):44396 | Serial | Secondary | Not Running pc13(8164):29475 | Serial | Secondary | Not Running Member | Error ---------------------- | ------------------------------ pc13(8186):45840 | GatewaySender is not available status locator 显示指定定位器的状态。 状态将是以下之一： started online offline not responding 可用性: Online or offline. 如果要在脱机时获取定位器的状态，请使用--dir选项。 句法: status locator [--name=value] [--host=value] [--port=value] [--dir=value] 名称 描述 默认值 ‑‑name 要显示其状态的定位器的名称/ ID。 您必须连接到JMX Manager才能使用此选项。 可用于获取远程定位器的状态。 请参阅使用gfsh通过HTTP或HTTPS管理远程群集。 --host 运行定位器的主机名或IP地址。 --port 定位器正在侦听的端口。 10334 --dir 启动定位器的目录。 当前目录 Table 3. 状态定位器参数 示例命令: status locator status locator --name=locator1 status server 显示指定的Geode缓存服务器的状态。 可用性: Online or offline. 如果要在脱机时获取服务器的状态，请使用--dir选项。 句法: status server [--name=value] [--dir=value] 名称 描述 默认值 ‑‑name 要显示其状态的高速缓存服务器的名称或ID。 您必须连接到JMX Manager才能使用此选项。 可用于获取远程服务器的状态。 请参阅使用gfsh通过HTTP或HTTPS管理远程群集。 --dir 启动Geode缓存服务器的目录。 当前目录 Table 4. 状态服务器参数 示例命令: status server status server --name=server1 stop 停止网关接收器，网关发送器，定位器和服务器。 stop gateway-receiver 停止一个或多个成员的网关接收器。 stop gateway-sender 停止指定成员或指定成员组成员上具有给定ID的网关发件人。 stop locator 停止定位器。 stop server 停止Geode缓存服务器。 stop gateway-receiver 停止一个或多个成员的网关接收器。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: stop gateway-receiver [--groups=value(,value)*] [--members=value(,value)*] 名称 描述 --groups 停止Gateway接收器的成员组。 对多个成员组使用逗号分隔列表。 ‑‑members 要停止网关接收器的成员的名称/ID。 Table 1. 停止网关 - 接收器参数 示例命令: stop gateway-receiver --members=receiver1-LN stop gateway-receiver --groups=LN-Group1 示例输出: gfsh>stop gateway-receiver Member | Result | Message --------------------------- | -------| ----------------------------------------------------------------------- pc13(2266):56852 | OK | GatewayReceiver is stopped on member pc13(2266):56852 pc13(Manager:2242):57631| Error | GatewayReceiver is not available on member pc13(Manager:2242):57631 pc13(2275):47480 | OK | GatewayReceiver is stopped on member pc13(2275):47480 pc13(2293):55472 | OK | GatewayReceiver is stopped on member pc13(2293):55472 gfsh>stop gateway-receiver --members=pc13(2266):36579 GatewayReceiver is stopped on member pc13(2266):36579 gfsh>stop gateway-receiver --groups=RG1 Member | Result | Message -------------------- | -------| ---------------------------------------------------------- pc13(2275):27484| OK | GatewayReceiver is stopped on member pc13(2275):27484 pc13(2293):55810| OK | GatewayReceiver is stopped on member pc13(2293):55810 pc13(2266):4522 | OK | GatewayReceiver is stopped on member pc13(2266):4522 stop gateway-sender 停止指定成员或指定成员组成员上具有给定ID的网关发件人。 警告: 在并行网关发件人上使用stop gateway-sender命令（或等效的GatewaySender.stop()API）要小心。 我们建议关闭整个成员，以确保将分区区域事件正确地故障转移到其他网关发件人成员，而不是在成员上停止单个并行网关发件人。 在单个并行网关上使用此命令发送方可能在事件丢失时发生。 有关详细信息，请参阅停止网关发件人。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: stop gateway-sender --id=value [--groups=value(,value)*] [--members=value(,value)*] 名称 描述 --id Required. 网关发件人的ID。 --groups 需要停止的网关发件人的成员组。 --members 要停止Gateway Sender的成员的名称/ID。 Table 2. 停止网关 - 发件人参数 示例命令: stop gateway-sender --id=ln --members=server1 示例输出: gfsh>stop gateway-sender --id=ln Member | Result | Message ---------------------------- | ------ | ------------------------------------------------------------------------ pc13(5184):41914 | OK | GatewaySender ln is stopped on member pc13(5184):41914 pc13(5192):25704 | OK | GatewaySender ln is stopped on member pc13(5192):25704 pc13(5174):53996 | OK | GatewaySender ln is stopped on member pc13(5174):53996 pc13(Manager:5148):64040 | Error | GatewaySender ln is not available on member pc13(Manager:5148):64040 gfsh>stop gateway-sender --id=ln --members=pc13(5174):17819 GatewaySender ln is stopped on member pc13(5174):17819 gfsh>stop gateway-sender --id=ln --groups=SenderGroup1 Member | Result | Message --------------------- | ------ | ----------------------------------------------------------- pc13(5174):63332 | OK | GatewaySender ln is stopped on member pc13(5174):63332 pc13(5184):20055 | OK | GatewaySender ln is stopped on member pc13(5184):20055 pc13(5192):14622 | OK | GatewaySender ln is stopped on member pc13(5192):14622 stop locator 停止定位器。 注意: 必须指定命令行选项之一--name或--dir以标识要停止的定位符。 可用性: Online or offline. 如果要在脱机时停止定位器，请使用--dir选项。 句法: stop locator --name=value | --dir=value 名称 描述 默认值 ‑‑name 要停止的定位器的Geode成员名称。 您必须连接到JMX Manager才能使用此选项。 可用于停止远程定位器。 请参阅使用gfsh通过HTTP或HTTPS管理远程群集。 --dir 启动定位器的目录。 当前目录 Table 3. 停止定位器参数 示例命令: stop locator --name=locator3 示例输出: gfsh>stop locator --name=locator3 Stopping Locator running in /Users/test/locator3 on 192.0.2.0[10334] as locator3... Process ID: 71531 Log File: /Users/test/locator3/locator3.log ... No longer connected to 192.0.2.0[1099]. gfsh>stop locator --dir=loc2 Stopping Locator running in /Users/test/loc2 on 192.0.2.0[10334] as loc2... Process ID: 71714 Log File: /Users/test/loc2/loc2.log ... No longer connected to 192.0.2.0[1099]. stop server 停止Geode缓存服务器。 可用性: Online or offline. 如果要在脱机时停止缓存服务器，请使用--dir选项。 句法: stop server [--name=value] [--dir=value] 名称 描述 默认值 ‑‑name 要停止的Geode缓存服务器的名称/ ID。 您必须连接到JMX Manager才能使用此选项。 可用于停止远程服务器。 请参阅使用gfsh通过HTTP或HTTPS管理远程群集。 --dir 启动Geode缓存服务器的目录。 当前目录 Table 4. 停止服务器参数 示例命令: stop server --name=server1 stop server --dir=server1 undeploy 使用deploy命令取消部署在成员或组上部署的JAR文件。 如果未指定--jars，该命令将取消部署所有已部署的JAR。 如果未指定--groups，则该命令适用于整个集群。 请注意，此命令无法卸载在部署期间加载的类。 成员应该重新启动。 可用性: Online. 您必须在gfsh中连接到JMX Manager成员才能使用此命令。 句法: undeploy [--jars=value(,value)*] [--groups=value(,value)*] 名称 描述 默认值 --groups 将取消部署指定JAR的组。 取消部署将在所有成员上发生 --jars JAR或JAR将被取消部署。 所有JAR都将被取消部署 Table 1. 取消部署参数 示例命令: undeploy --jars=domain-objects.jar undeploy --groups=Group1 示例输出: gfsh>undeploy --jars=domain-objects.jar Member | Un-Deployed JAR | Un-Deployed From JAR Location ---------- | ------------------ | --------------------------------------------- datanode10 | domain-objects.jar | /usr/local/gemfire/deploy/GF#domain-objects#1 datanode11 | domain-objects.jar | /usr/local/gemfire/deploy/GF#domain-objects#1 gfsh> undeploy --groups=Group1 Member | Un-Deployed JAR | Un-Deployed From JAR Location --------- | ----------------------- | ------------------------------------------------------ datanode1 | group1_functions.jar | /usr/local/gemfire/deploy/GF#group1_functions.jar#1 datanode1 | group1_dependencies.jar | /usr/local/gemfire/deploy/GF#group1_dependencies.jar#1 datanode2 | group1_functions.jar | /usr/local/gemfire/deploy/GF#group1_functions.jar#1 datanode2 | group1_dependencies.jar | /usr/local/gemfire/deploy/GF#group1_dependencies.jar#1 错误消息: No JAR Files Found validate offline-disk-store 验证脱机磁盘存储。 可用性: Offline. 句法: validate offline-disk-store --name=value --disk-dirs=value(,value)* 名称 描述 --name Required. 要验证的磁盘存储的名称。 --disk-dirs Required. 先前已写入磁盘存储数据的目录。 Table 1. 验证脱机磁盘存储参数 示例命令: validate offline-disk-store --name=DiskStore2 --disk-dirs=data/dir3,data/dir4 version 显示产品版本信息。 可用性: Online or offline. 句法: version [--full] 名称 描述 默认值 --full 显示完整版本信息。 false Table 1. 版本参数 示例命令: version version --full 示例输出: gfsh>version v8.0.0 gfsh>version --full Java version: 8.0.0 build 48319 07/31/2014 17:26:09 PDT javac 1.8.0_1 Native version: native code unavailable Source revision: 48319 Source repository: gemfire/branches/cedar_dev_Oct12 Running on: /192.0.2.0, 1 cpu(s), amd64 Linux 2.6.32-38-generic Creating and Running gfsh Command Scripts gfsh提供了几种在脚本环境中运行命令的方法。 Running gfsh Scripts 您可以创建和运行包含要执行的gfsh命令的脚本。 要执行该脚本，请使用gfsh run命令。 例如： gfsh run --file=mycommands.gfsh 注意: 运行gfsh脚本时，将忽略交互式参数。 您还可以将脚本设置为以安静模式运行以防止输出并指示脚本跳过它遇到的任何错误。 编写gfsh脚本时，命令历史记录文件会很有用。 已成功执行的命令历史记录在运行gfsh的用户的主目录中的.gfsh.history文件中。 您还可以使用history --file=your_file_name命令导出历史文件。 当用户从gfsh运行start server或start locator而不指定成员名称时，gfsh将自动选择一个随机成员名称。 这对自动化很有用。 Running gfsh Commands on the OS Command Line 您可以通过在命令前加上gfsh直接从操作系统的提示符运行一些gfsh命令。 这对于Unix shell或Windows批处理脚本非常有用。 例如： $ gfsh start locator --name=locator2 --port=10335 要在提示符下直接查看哪些gfsh命令可用： $ gfsh help 在OS命令行上运行多个gfsh命令 要直接在命令行上运行多个命令，请在引号中使用-e选项，然后使用gfsh命令。 例如： prompt>gfsh -e \"start locator --name=locator1\" -e \"start server --name=server1\" prompt>gfsh -e \"start jconsole\" prompt>gfsh -e \"connect --locator=remotehost[10334]\" -e \"rebalance\" -e \"gc\" Mapping cache.xml Elements to gfsh Configuration Commands You can configure a Geode cluster using either cache.xml files, or you can use gfsh and the cluster configuration service to configure a cluster. This table maps cache.xml elements to the gfsh commands that configure and manage a cluster. cache.xml 元素 gfsh 命令 , start serverstatus serverstop serveralter runtime create async-event-queuelist async-event-queues configure pdx create regionalter regiondestroy regiondescribe regionlist regionsrebalance create indexdestroy indexlist indexes create disk-storealter disk-storebackup disk-storecompact disk-storecompact offline-disk-storedescribe disk-storedescribe offline-disk-storedestroy disk-storelist disk-storesrevoke missing-disk-storeshow missing-disk-storesvalidate offline-disk-store Table 1. 将cache.xml元素迁移到gfsh命令 Copyright © WS 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-12-10 10:28:41 "}}